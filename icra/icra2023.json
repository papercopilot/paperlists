[
    {
        "id": "10160459",
        "title": "3-D Reconstruction Using Monocular Camera and Lights: Multi-View Photometric Stereo for Non-Stationary Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel underwater Multi-View Photometric Stereo (MVPS) framework for reconstructing scenes in 3-D with a non-stationary low-cost robot equipped with a monocular camera and fixed lights. The underwater realm is the primary focus of study here, due to the challenges in utilizing underwater camera imagery and lack of low-cost reliable localization systems. Previous underwater PS approaches provided accurate scene reconstruction results, but assumed that the robot was stationary at the bottom. This assumption is limiting, as many artifacts, reefs, and man-made structures are large and meters above the bottom. Our proposed MVPS framework relaxes the stationarity assumption by utilizing a monocular SLAM system to estimate small robot motions and extract an initial sparse feature map. To compensate for the scale inconsistency in monocular SLAM output, our MVPS optimization scheme collectively estimates a high-quality, dense 3-D reconstruction and corrects the camera pose estimates. We also present an attenuation and camera-light extrinsic parameter calibration method for non-stationary robots. Finally, validation experiments with a BlueROV2 demonstrated the low-cost capability of producing high-quality scene reconstructions. Overall, this work is the foundation of an active perception pipeline for robots (i.e., underwater, ground, and aerial) to explore and map complex structures in high accuracy and resolution with an inexpensive sensor-light configuration.",
        "primary_area": "",
        "author": "Monika Roznere;Philippos Mordohai;Ioannis Rekleitis;Alberto Quattrini Li;Monika Roznere;Philippos Mordohai;Ioannis Rekleitis;Alberto Quattrini Li",
        "authorids": "/37087322448;/38480615300;/37281356300;/37085808885;/37087322448;/38480615300;/37281356300;/37085808885",
        "aff": "Dartmouth College, Hanover, NH, USA; Stevens Institute of Technology, Hoboken, NJ, USA; University of South Carolina, Columbia, SC, USA; Dartmouth College, Hanover, NH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160459/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10801659359361735906&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Dartmouth College;Stevens Institute of Technology;University of South Carolina",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.dartmouth.edu;https://www.stevens.edu;https://www.sc.edu",
        "aff_unique_abbr": "Dartmouth;SIT;USC",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Hanover;Hoboken;Columbia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161199",
        "title": "3-Dimensional Sonic Phase-invariant Echo Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Parallax and Time-of-Flight (ToF) are often regarded as complementary in robotic vision where various light and weather conditions remain challenges for advanced camera-based 3-Dimensional (3-D) reconstruction. To this end, this paper establishes Parallax among Corresponding Echoes (PaCE) to triangulate acoustic ToF pulses from arbitrary sensor positions in 3-D space for the first time. This is achieved through a novel round-trip reflection model that pinpoints targets at the intersection of ellipsoids, which are spanned by sensor locations and detected arrival times. Inter-channel echo association becomes a crucial prerequisite for target detection and is learned from feature similarity obtained by a stack of Siamese Multi-Layer Perceptrons (MLPs). The PaCE algorithm enables phase-invariant 3-D object localization from only 1 isotropic emitter and at least 3 ToF receivers with relaxed sensor position constraints. Experiments are conducted with airborne ultrasound sensor hardware and back this hypothesis with quantitative results.",
        "primary_area": "",
        "author": "Christopher Hahne;Christopher Hahne",
        "authorids": "/37085358844;/37085358844",
        "aff": "Artificial Intelligence on Medical Imaging group at the ARTORG Center, University of Bern, Bern, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161199/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1521871625237998548&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Bern",
        "aff_unique_dep": "ARTORG Center",
        "aff_unique_url": "https://www.unibe.ch",
        "aff_unique_abbr": "UniBE",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Bern",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161467",
        "title": "3D Reconstruction of Tibia and Fibula using One General Model and Two X-ray Images",
        "track": "main",
        "status": "Poster",
        "abstract": "The 3D reconstruction of patient specific bone models plays a crucial role in orthopaedic surgery for clinical evaluation, surgical planning and precise implant design or selection. This paper considers the problem of reconstructing a patient-specific 3D tibia and fibula model from only two 2D X-ray images and one 3D general model segmented from the lower leg CT scans of one randomly selected patient. Currently, the bone 3D reconstruction mainly relies on computed tomography (CT) and magnetic resonance imaging (MRI) scanning-based mode segmentation which result in high radiation exposure or expensive costs. While, the proposed algorithm can accurately and efficiently deform a 3D general model to achieve a patient-specific 3D model that matches the patient's tibia and fibula projections in two 2D X-rays. The algorithm undergoes a preliminary deformation, 2D contour registration, and opti-misation based on the deformation graph that represents the shape deformation of models. Evaluations using simulations, cadaver and in-vivo experiments demonstrate that the proposed algorithm can effectively reconstruct the patient's 3D tibia and fibula surface model with high accuracy.",
        "primary_area": "",
        "author": "Kai Pan;Shuai Zhang;Liang Zhao;Shoudong Huang;Yanhao Zhang;Hua Wang;Qi Luo;Kai Pan;Shuai Zhang;Liang Zhao;Shoudong Huang;Yanhao Zhang;Hua Wang;Qi Luo",
        "authorids": "/37089894384;/37086326556;/37857963600;/37421307400;/37088452302;/37089895332;/37089893662;/37089894384;/37086326556;/37857963600;/37421307400;/37088452302;/37089895332;/37089893662",
        "aff": "Faculty of Engineering and Information Technology, Robotics Institute, University of Technology Sydney; Faculty of Engineering and Information Technology, Robotics Institute, University of Technology Sydney; Faculty of Engineering and Information Technology, Robotics Institute, University of Technology Sydney; Faculty of Engineering and Information Technology, Robotics Institute, University of Technology Sydney; School of Computing, Australian National University; Osteoarthropathy Surgery Department, Shenzhen People's Hospital, Shenzhen, China; Osteoarthropathy Surgery Department, Shenzhen People's Hospital, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161467/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5878891055493206133&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;2",
        "aff_unique_norm": "University of Technology Sydney;Australian National University;Shenzhen People's Hospital",
        "aff_unique_dep": "Faculty of Engineering and Information Technology, Robotics Institute;School of Computing;Osteoarthropathy Surgery Department",
        "aff_unique_url": "https://www.uts.edu.au;https://www.anu.edu.au;",
        "aff_unique_abbr": "UTS;ANU;",
        "aff_campus_unique_index": "0;0;0;0;2;2",
        "aff_campus_unique": "Sydney;;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;1;1",
        "aff_country_unique": "Australia;China"
    },
    {
        "id": "10161400",
        "title": "3D Reconstruction-Based Seed Counting of Sorghum Panicles for Agricultural Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a method for creating high-quality 3D models of sorghum panicles for phenotyping in breeding experiments. This is achieved with a novel reconstruction approach that uses seeds as semantic landmarks in both 2D and 3D. To evaluate the performance, we develop a new metric for assessing the quality of reconstructed point clouds without ground-truth. Finally, a counting method is presented where the density of seed centers in the 3D model allows 2D counts from multiple views to be effectively combined into a whole-panicle count. We demonstrate that using this method to estimate seed count and weight for sorghum outperforms count extrapolation from 2D images, an approach used in most state of the art methods for seeds and grains of comparable size.",
        "primary_area": "",
        "author": "Harry Freeman;Eric Schneider;Chung Hee Kim;Moonyoung Lee;George Kantor;Harry Freeman;Eric Schneider;Chung Hee Kim;Moonyoung Lee;George Kantor",
        "authorids": "/37089195649;/37089895374;/37086595964;/37089896112;/37273878300;/37089195649;/37089895374;/37086595964;/37089896112;/37273878300",
        "aff": "Carnegie Mellon University Robotics Institute, PA, USA; Carnegie Mellon University Robotics Institute, PA, USA; Carnegie Mellon University Robotics Institute, PA, USA; Carnegie Mellon University Robotics Institute, PA, USA; Carnegie Mellon University Robotics Institute, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161400/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7303932956812115763&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160430",
        "title": "3D Spectral Domain Registration-Based Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a spectral domain registration-based visual servoing scheme that works on 3D point clouds. Specifically, we propose a 3D model/point cloud alignment method, which works by finding a global transformation between reference and target point clouds using spectral analysis. A 3D Fast Fourier Transform (FFT) in \\mathbb{R}^{3}R3\\mathbb{R}^{3} is used for the translation estimation, and the real spherical harmonics in \\boldsymbol{SO}(3)\\boldsymbol{SO}(3) are used for the rotations estimation. Such an approach allows us to derive a decoupled 6 degrees of freedom (DoF) controller, where we use gradient ascent optimisation to minimise translation and rotational costs. We then show how this methodology can be used to regulate a robot arm to perform a positioning task. In contrast to the existing state-of-the-art depth-based visual servoing methods that either require dense depth maps or dense point clouds, our method works well with partial point clouds and can effectively handle larger transformations between the reference and the target positions. Furthermore, the use of spectral data (instead of spatial data) for transformation estimation makes our method robust to sensor-induced noise and partial occlusions. We validate our approach by performing experiments using point clouds acquired by a robot-mounted depth camera. Obtained results demonstrate the effectiveness of our visual servoing approach.",
        "primary_area": "",
        "author": "Maxime Adjigble;Brahim Tamadazte;Cristiana de Farias;Rustam Stolkin;Naresh Marturi;Maxime Adjigble;Brahim Tamadazte;Cristiana de Farias;Rustam Stolkin;Naresh Marturi",
        "authorids": "/37085407107;/37681656800;/37088812520;/37424300500;/37085558507;/37085407107;/37681656800;/37088812520;/37424300500;/37085558507",
        "aff": "Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Edgbaston, UK; Sorbonne Universit\u00e9, Paris, France; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Edgbaston, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160430/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2334396510505089572&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Birmingham;Sorbonne Universit\u00e9",
        "aff_unique_dep": "School of Metallurgy and Materials;",
        "aff_unique_url": "https://www.birmingham.ac.uk;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "UoB;Sorbonne U",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Edgbaston;Paris",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United Kingdom;France"
    },
    {
        "id": "10161212",
        "title": "3D VSG: Long-term Semantic Scene Change Prediction through 3D Variable Scene Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Numerous applications require robots to operate in environments shared with other agents, such as humans or other robots. However, such shared scenes are typically subject to different kinds of long-term semantic scene changes. The ability to model and predict such changes is thus crucial for robot autonomy. In this work, we formalize the task of semantic scene variability estimation and identify three main varieties of semantic scene change: changes in the position of an object, its semantic state, or the composition of a scene as a whole. To represent this variability, we propose the Variable Scene Graph (VSG), which augments existing 3D Scene Graph (SG) representations with the variability attribute, representing the likelihood of discrete long-term change events. We present a novel method, DeltaVSG, to estimate the variability of VSGs in a supervised fashion. We evaluate our method on the 3RScan long-term dataset, showing notable improvements in this novel task over existing approaches. Our method DeltaVsgachieves an accuracy of 77.1% and a recall of 72.3%, often mimicking human intuition about how indoor scenes change over time. We further show the utility of VSG prediction in the task of active robotic change detection, speeding up task completion by 66.0% compared to a scene-change-unaware planner. We make our code available as open-source.",
        "primary_area": "",
        "author": "Samuel Looper;Javier Rodriguez-Puigvert;Roland Siegwart;Cesar Cadena;Lukas Schmid;Samuel Looper;Javier Rodriguez-Puigvert;Roland Siegwart;Cesar Cadena;Lukas Schmid",
        "authorids": "/37089509020;/37089274491;/37281398300;/37593590400;/37086444000;/37089509020;/37089274491;/37281398300;/37593590400;/37086444000",
        "aff": "ETH Z\u00fcrich, Autonomous Systems Lab, Z\u00fcrich, Switzerland; Universidad de Zaragoza, Zaragoza, Spain; ETH Z\u00fcrich, Autonomous Systems Lab, Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Autonomous Systems Lab, Z\u00fcrich, Switzerland; Massachusetts Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161212/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=179872218157962870&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "ETH Z\u00fcrich;Universidad de Zaragoza;Massachusetts Institute of Technology",
        "aff_unique_dep": "Autonomous Systems Lab;;",
        "aff_unique_url": "https://www.ethz.ch;https://www.unizar.es;https://web.mit.edu",
        "aff_unique_abbr": "ETH;;MIT",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Z\u00fcrich;Zaragoza;",
        "aff_country_unique_index": "0;1;0;0;2",
        "aff_country_unique": "Switzerland;Spain;United States"
    },
    {
        "id": "10160669",
        "title": "3D-DAT: 3D-Dataset Annotation Toolkit for Robotic Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots operating in the real world are expected to detect, classify, segment, and estimate the pose of objects to accomplish their task. Modern approaches using deep learning not only require large volumes of data but also pixel-accurate annotations in order to evaluate the performance and therefore safety of these algorithms. At present, publicly available tools for annotating data are scarce and those that are available rely on depth sensors, which excludes their use for transparent, metallic, and general non-Lambertian objects. To address this issue, we present a novel method for creating valuable datasets that can be used in these more difficult cases. Our key contribution is a purely RGB-based scene-level annotation approach that uses a neural radiance field-based method to automatically align objects. A set of user studies demonstrates the accuracy and speed of our approach over a purely manual or depth sensor assisted pipeline. We provide an open-source implementation of each component and a ROS-based recorder for capturing data with a eye-in-hand robot system. Code will be made available at https://github.com/markus-suchi/3D-DAT.",
        "primary_area": "",
        "author": "Markus Suchi;Bernhard Neuberger;Amanzhol Salykov;Jean-Baptiste Weibel;Timothy Patten;Markus Vincze;Markus Suchi;Bernhard Neuberger;Amanzhol Salykov;Jean-Baptiste Weibel;Timothy Patten;Markus Vincze",
        "authorids": "/37086800889;/37088416236;/37089895723;/37086341387;/37085763735;/37269163100;/37086800889;/37088416236;/37089895723;/37086341387;/37085763735;/37269163100",
        "aff": "Vision for Robotics Laboratory, Automation and Control Institute, TU Wien, Vienna, Austria; Vision for Robotics Laboratory, Automation and Control Institute, TU Wien, Vienna, Austria; Vision for Robotics Laboratory, Automation and Control Institute, TU Wien, Vienna, Austria; Vision for Robotics Laboratory, Automation and Control Institute, TU Wien, Vienna, Austria; Robotics Institute, University of Technology Sydney, Sydney, Australia; Vision for Robotics Laboratory, Automation and Control Institute, TU Wien, Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160669/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12051235406378277486&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "TU Wien;University of Technology Sydney",
        "aff_unique_dep": "Automation and Control Institute;Robotics Institute",
        "aff_unique_url": "https://www.tuwien.ac.at;https://www.uts.edu.au",
        "aff_unique_abbr": "TU Wien;UTS",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Vienna;Sydney",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Austria;Australia"
    },
    {
        "id": "10160829",
        "title": "3D-Printed Adaptive Microgripper Driven by Thin-Film NiTi Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Creating microscale actuated mechanisms in 3D space is extremely challenging due to limitations in microfabrication processes. In this work, we present a 3D-printed adaptive microgripper that is driven by thin-film NiTi microactuators with 3D-printed linkage mechanisms. The microgripper's fingers are passively adaptive so that the microgripper can provide conformal gripping on 3D objects. The microgripper can move its fingers by \\mathbf{225}\\ \\boldsymbol{\\mu} \\mathbf{m}\\mathbf{225}\\ \\boldsymbol{\\mu} \\mathbf{m} and apply a blocking force of \\mathbf{30}\\ \\boldsymbol{\\mu} \\mathbf{N}\\mathbf{30}\\ \\boldsymbol{\\mu} \\mathbf{N} per one finger when 20 mA was applied to the NiTi actuators. The microgripper was also integrated onto a printed circuit board with a current regulating circuit and a 9 V battery. Since the NiTi actuator requires a low voltage for actuation, the microgripper could be integrated with simple and affordable electronics. The fully integrated microgripper system was demonstrated playing with a shape sorting box at the microscale for the first time.",
        "primary_area": "",
        "author": "Sukjun Kim;Sarah Bergbreiter;Sukjun Kim;Sarah Bergbreiter",
        "authorids": "/37088359436;/37542605000;/37088359436;/37542605000",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160829/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9939666132149573638&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160305",
        "title": "3DMODT: Attention-Guided Affinities for Joint Detection & Tracking in 3D Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method for joint detection and tracking of multiple objects in 3D point clouds, a task conventionally treated as a two-step process comprising object detection followed by data association. Our method embeds both steps into a single end-to-end trainable network eliminating the dependency on external object detectors. Our model exploits temporal information employing multiple frames to detect objects and track them in a single network, thereby making it a utilitarian formulation for real-world scenarios. Computing affinity matrix by employing features similarity across consecutive point cloud scans forms an integral part of visual tracking. We propose an attention-based refinement module to refine the affinity matrix by suppressing erroneous correspondences. The module is designed to capture the global context in affinity matrix by employing self-attention within each affinity matrix and cross-attention across a pair of affinity matrices. Unlike competing approaches, our network does not require complex post-processing algorithms, and directly processes raw LiDAR frames to output tracking results. We demonstrate the effectiveness of our method on three tracking benchmarks: JRDB, Waymo, and KITTI. Experimental evaluations indicate the ability of our model to generalize well across datasets.",
        "primary_area": "",
        "author": "Jyoti Kini;Ajmal Mian;Mubarak Shah;Jyoti Kini;Ajmal Mian;Mubarak Shah",
        "authorids": "/37086798996;/37283914600;/37275509600;/37086798996;/37283914600;/37275509600",
        "aff": "Center for Research in Computer Vision, University of Central Florida, USA; University of Western, Australia; Center for Research in Computer Vision, University of Central Florida, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160305/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16500783332936893116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Central Florida;University of Western Australia",
        "aff_unique_dep": "Center for Research in Computer Vision;",
        "aff_unique_url": "https://www.ucf.edu;https://www.uwa.edu.au",
        "aff_unique_abbr": "UCF;UWA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "10160350",
        "title": "3DSGrasp: 3D Shape-Completion for Robotic Grasp",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-world robotic grasping can be done robustly if a complete 3D Point Cloud Data (PCD) of an object is available. However, in practice, PCDs are often incomplete when objects are viewed from few and sparse viewpoints before the grasping action, leading to the generation of wrong or inaccurate grasp poses. We propose a novel grasping strategy, named 3DSGrasp, that predicts the missing geometry from the partial PCD to produce reliable grasp poses. Our proposed PCD completion network is a Transformer-based encoder-decoder network with an Offset-Attention layer. Our network is inherently invariant to the object pose and point's permutation, which generates PCDs that are geometrically consistent and completed properly. Experiments on a wide range of partial PCD show that 3DSGrasp outperforms the best state-of-the-art method on PCD completion tasks and largely improves the grasping success rate in real-world scenarios. The code and dataset are available at: https://github.com/NunoDuarte/3DSGrasp.",
        "primary_area": "",
        "author": "Seyed S. Mohammadi;Nuno F. Duarte;Dimitrios Dimou;Yiming Wang;Matteo Taiana;Pietro Morerio;Atabak Dehban;Plinio Moreno;Alexandre Bernardino;Alessio Del Bue;Jos\u00e9 Santos-Victor;Seyed S. Mohammadi;Nuno F. Duarte;Dimitrios Dimou;Yiming Wang;Matteo Taiana;Pietro Morerio;Atabak Dehban;Plinio Moreno;Alexandre Bernardino;Alessio Del Bue;Jos\u00e9 Santos-Victor",
        "authorids": "/37089381294;/37086436863;/37086573410;/37088909595;/38274209800;/38466848500;/37085794792;/38274327100;/37442087500;/37563648400;/38274231800;/37089381294;/37086436863;/37086573410;/37088909595;/38274209800;/38466848500;/37085794792;/38274327100;/37442087500;/37563648400;/38274231800",
        "aff": "Pattern Analysis & Computer Vision (PAVIS), Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Vislab, ISR|Lisboa, Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal; Vislab, ISR|Lisboa, Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal; Deep Visual Learning (DVL), Fondazione Bruno Kessler, Trento, Italy; Pattern Analysis & Computer Vision (PAVIS), Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Pattern Analysis & Computer Vision (PAVIS), Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Vislab, ISR|Lisboa, Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal; Vislab, ISR|Lisboa, Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal; Vislab, ISR|Lisboa, Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal; Pattern Analysis & Computer Vision (PAVIS), Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Vislab, ISR|Lisboa, Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160350/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=208170388196347534&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;1;1;2;0;0;1;1;1;0;1",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Universidade de Lisboa;Fondazione Bruno Kessler",
        "aff_unique_dep": "Pattern Analysis & Computer Vision (PAVIS);Instituto Superior T\u00e9cnico;Deep Visual Learning (DVL)",
        "aff_unique_url": "https://www.iit.it;https://www IST.utl.pt;https://www.fbk.eu",
        "aff_unique_abbr": "IIT;IST;",
        "aff_campus_unique_index": "0;1;1;2;0;0;1;1;1;0;1",
        "aff_campus_unique": "Genoa;Lisboa;Trento",
        "aff_country_unique_index": "0;1;1;0;0;0;1;1;1;0;1",
        "aff_country_unique": "Italy;Portugal"
    },
    {
        "id": "10160670",
        "title": "4DRadarSLAM: A 4D Imaging Radar SLAM System for Large-scale Environments based on Pose Graph Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR-based SLAM may easily fail in adverse weathers (e.g., rain, snow, smoke, fog), while mmWave Radar remains unaffected. However, current researches are primarily focused on 2D (x,y)(x,y) or 3D (x, yx, y, doppler) Radar and 3D LiDAR, while limited work can be found for 4D Radar (x, y, zx, y, z, doppler). As a new entrant to the market with unique characteristics, 4D Radar outputs 3D point cloud with added elevation information, rather than 2D point cloud; compared with 3D LiDAR, 4D Radar has noisier and sparser point cloud, making it more challenging to extract geometric features (edge and plane). In this paper, we propose a full system for 4D Radar SLAM consisting of three modules: 1) Front-end module performs scan-to-scan matching to calculate the odometry based on GICP, considering the probability distribution of each point; 2) Loop detection utilizes multiple rule-based loop pre-filtering steps, followed by an intensity scan context step to identify loop candidates, and odometry check to reject false loop; 3) Back-end builds a pose graph using front-end odometry, loop closure, and optional GPS data. Optimal pose is achieved through \\mathrm{g}2\\mathrm{o}\\mathrm{g}2\\mathrm{o}. We conducted real experiments on two platforms and five datasets (ranging from 240m to 4.8km) and will make the code open-source to promote further research at: https://github.com/zhuge2333/4DRadarSLAM",
        "primary_area": "",
        "author": "Jun Zhang;Huayang Zhuge;Zhenyu Wu;Guohao Peng;Mingxing Wen;Yiyao Liu;Danwei Wang;Jun Zhang;Huayang Zhuge;Zhenyu Wu;Guohao Peng;Mingxing Wen;Yiyao Liu;Danwei Wang",
        "authorids": "/37086009222;/37089893931;/37088406849;/37087049757;/37086451677;/37089583662;/37279547600;/37086009222;/37089893931;/37088406849;/37087049757;/37086451677;/37089583662;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160670/",
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11000721814694253048&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160529",
        "title": "6D Pose Estimation for Textureless Objects on RGB Frames using Multi-View Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "6D pose estimation of textureless objects is a valuable but challenging task for many robotic applications. In this work, we propose a framework to address this challenge using only RGB images acquired from multiple viewpoints. The core idea of our approach is to decouple 6D pose estimation into a sequential two-step process, first estimating the 3D translation and then the 3D rotation of each object. This decoupled formulation first resolves the scale and depth ambiguities in single RGB images, and uses these estimates to accurately identify the object orientation in the second stage, which is greatly simplified with an accurate scale estimate. Moreover, to accommodate the multi-modal distribution present in rotation space, we develop an optimization scheme that explicitly handles object symmetries and counteracts measurement uncertainties. In comparison to the state-of-the-art multi-view approach, we demonstrate that the proposed approach achieves substantial improvements on a challenging 6D pose estimation dataset for textureless objects.",
        "primary_area": "",
        "author": "Jun Yang;Wenjie Xue;Sahar Ghavidel;Steven L. Waslander;Jun Yang;Wenjie Xue;Sahar Ghavidel;Steven L. Waslander",
        "authorids": "/37088838125;/37089337132;/37089893141;/37301169100;/37088838125;/37089337132;/37089893141;/37301169100",
        "aff": "University of Toronto Institute for Aerospace Studies and Robotics Institute; Epson Canada; Epson Canada; University of Toronto Institute for Aerospace Studies and Robotics Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160529/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11858239242332149010&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Toronto;Epson",
        "aff_unique_dep": "Institute for Aerospace Studies and Robotics Institute;",
        "aff_unique_url": "https://www.utoronto.ca;https://www.epson.ca",
        "aff_unique_abbr": "U of T;Epson",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161005",
        "title": "A Benchmark for Multi-Robot Planning in Realistic, Complex and Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Several successful approaches exist for solving the complex problem of multi-robot planning and coordination. Due to the lack of adequate benchmarking tools, comparing these approaches and judging their suitability for use in realistic scenarios is currently difficult. Therefore, we propose an open-source benchmark suite that aims to close this gap. Unlike existing benchmarks, our approach uses full-stack multi-robot navigation systems in realistic 3D simulated environments from the intralogistic and household domains. Using the open-source frameworks ROS 2, Gazebo and RMF allows the user to add other robot platforms easily. The framework provides easy-to-use abstractions, typical metrics and interfaces to several established planning libraries for multi-robot systems. With all these features, our framework successfully aids practitioners and researchers in comparing multi-robot planning and coordination systems to the state of the art. Our experiments show how the proposed benchmark simplifies gaining insights on relevant close to real-life robotics use cases.",
        "primary_area": "",
        "author": "Simon Schaefer;Luigi Palmieri;Lukas Heuer;Ruediger Dillmann;Sven Koenig;Alexander Kleiner;Simon Schaefer;Luigi Palmieri;Lukas Heuer;Ruediger Dillmann;Sven Koenig;Alexander Kleiner",
        "authorids": "/37088998632;/37085383074;/37089895342;/37280242100;/37284916000;/37326400800;/37088998632;/37085383074;/37089895342;/37280242100;/37284916000;/37326400800",
        "aff": "Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Robert Bosch GmbH, Corporate Research, Stuttgart, Germany; Robert Bosch GmbH, Corporate Research, Stuttgart, Germany; Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Computer Science Department, University of Southern, California; Robert Bosch GmbH, Corporate Research, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161005/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2508035111685307258&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;2;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Robert Bosch GmbH;University of Southern California",
        "aff_unique_dep": ";Corporate Research;Computer Science Department",
        "aff_unique_url": "https://www.kit.edu;https://www.bosch.com;https://www.usc.edu",
        "aff_unique_abbr": "KIT;Bosch;USC",
        "aff_campus_unique_index": "0;1;1;0;2;1",
        "aff_campus_unique": "Karlsruhe;Stuttgart;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "10161198",
        "title": "A Bioinspired Synthetic Nervous System Controller for Pick-and-Place Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The Synthetic Nervous System (SNS) is a biologically inspired neural network (NN). Due to its capability of capturing complex mechanisms underlying neural computation, an SNS model is a candidate for building compact and interpretable NN controllers for robots. Previous work on SNSs has focused on applying the model to the control of legged robots and the design of functional subnetworks (FSNs) to realize dynamical systems. However, the FSN approach has previously relied on the analytical solution of the governing equations, which is difficult for designing more complex NN controllers. Incorporating plasticity into SNSs and using learning algorithms to tune the parameters offers a promising solution for systematic design in this situation. In this paper, we theoretically analyze the computational advantages of SNSs compared with other classical artificial neural networks. We then use learning algorithms to develop compact subnetworks for implementing addition, subtraction, division, and multiplication. We also combine the learning-based methodology with a bioinspired architecture to design an interpretable SNS for the pick-and-place control of a simulated gantry system. Finally, we show that the SNS controller is successfully transferred to a real-world robotic platform without further tuning of the parameters, verifying the effectiveness of our approach.",
        "primary_area": "",
        "author": "Yanjun Li;Ravesh Sukhnandan;Jeffrey P. Gill;Hillel J. Chiel;Victoria Webster-Wood;Roger D. Quinn;Yanjun Li;Ravesh Sukhnandan;Jeffrey P. Gill;Hillel J. Chiel;Victoria Webster-Wood;Roger D. Quinn",
        "authorids": "/37088532271;/37089447826;/37089894308;/37329503300;/37088689130;/37281297100;/37088532271;/37089447826;/37089894308;/37329503300;/37088689130;/37281297100",
        "aff": "Department of Mechanical Engineering, Case Western Reserve University, Cleveland, OH, United States; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, United States; Department of Biology, Case Western Reserve University, Cleveland, OH, United States; Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, United States; Department of Mechanical Engineering, Case Western Reserve University, Cleveland, OH, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161198/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10264025887601333579&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "Case Western Reserve University;Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.case.edu;https://www.cmu.edu",
        "aff_unique_abbr": "CWRU;CMU",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "Cleveland;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160264",
        "title": "A Coarse-to-Fine Framework for Dual-Arm Manipulation of Deformable Linear Objects with Whole-Body Obstacle Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulating deformable linear objects (DLOs) to achieve desired shapes in constrained environments with obstacles is a meaningful but challenging task. Global planning is necessary for such a highly-constrained task; however, accurate models of DLOs required by planners are difficult to obtain owing to their deformable nature, and the inevitable modeling errors significantly affect the planning results, probably resulting in task failure if the robot simply executes the planned path in an open-loop manner. In this paper, we propose a coarse-to-fine framework to combine global planning and local control for dual-arm manipulation of DLOs, capable of precisely achieving desired configurations and avoiding potential collisions between the DLO, robot, and obstacles. Specifically, the global planner refers to a simple yet effective DLO energy model and computes a coarse path to find a feasible solution efficiently; then the local controller follows that path as guidance and further shapes it with closed-loop feedback to compensate for the planning errors and improve the task accuracy. Both simulations and real-world experiments demonstrate that our framework can robustly achieve desired DLO configurations in constrained environments with imprecise DLO models, which may not be reliably achieved by only planning or control.",
        "primary_area": "",
        "author": "Mingrui Yu;Kangchen Lv;Changhao Wang;Masayoshi Tomizuka;Xiang Li;Mingrui Yu;Kangchen Lv;Changhao Wang;Masayoshi Tomizuka;Xiang Li",
        "authorids": "/37089448870;/37089717220;/37086426211;/37281933000;/37280877200;/37089448870;/37089717220;/37086426211;/37281933000;/37280877200",
        "aff": "Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Automation, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160264/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12235331186003970373&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Tsinghua University;University of California, Berkeley",
        "aff_unique_dep": "Department of Automation;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.berkeley.edu",
        "aff_unique_abbr": "THU;UC Berkeley",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Beijing;Berkeley",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10161174",
        "title": "A Compact, Two-Part Torsion Spring Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "Springs are essential mechanical elements that are used across a wide variety of industries and mechanisms. Common across many spring types and applications is the importance of compactness, low mass and customizability. In this paper, we present a novel rotary spring design that is lightweight, compact and customizable. In addition, we empirically validate the design by experimentally quantifying the performance of two test springs on a custom dynamometry testbed. Our two-part spring geometry is comprised of a central rotating gear-like cam shaft, and a disk that includes a circular array of radially-spaced tapered cantilevered beams. The two springs that we designed and tested matched desired performance specifications within 3\u20136%, confirming the efficacy of this unique design approach.",
        "primary_area": "",
        "author": "Zachary Bons;Gray C. Thomas;Luke M. Mooney;Elliott J. Rouse;Zachary Bons;Gray C. Thomas;Luke M. Mooney;Elliott J. Rouse",
        "authorids": "/37089892976;/37085525465;/38362612600;/37991140400;/37089892976;/37085525465;/38362612600;/37991140400",
        "aff": "Department of Mechanical Engineering, University of Michigan, Ann Arbor, USA; Department of Robotics, University of Michigan, Ann Arbor, USA; Dephy Inc., Maynard, MA, USA; Department of Robotics, University of Michigan, Ann Arbor, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161174/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=671499441894559048&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Michigan;Dephy Inc.",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.umich.edu;",
        "aff_unique_abbr": "UM;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160312",
        "title": "A Complete Set of Connectivity-aware Local Topology Manipulation Operations for Robot Swarms",
        "track": "main",
        "status": "Poster",
        "abstract": "The topology of a robotic swarm affects the convergence speed of consensus and the mobility of the robots. In this paper, we prove the existence of a complete set of local topology manipulation operations that allow the transformation of a swarm topology. The set is complete in the sense that any other possible set of manipulation operations can be performed by a sequence of operations from our set. The operations are local as they depend only on the first and second hop neighbors' information to transform any initial spanning tree of the network's graph to any other connected tree with the same number of nodes. The flexibility provided by our method is similar to global methods that require full knowledge of the swarm network. We prove the existence of a sequence of transformations for any tree-to-tree transformation, and derive sequences of operations to form a line or star from any initial spanning tree. Our work provides a theoretical and practical framework for topological control of a swarm, establishing global properties using only local information.",
        "primary_area": "",
        "author": "Karthik Soma;Koresh Khateri;Mahdi Pourgholi;Mohsen Montazeri;Lorenzo Sabattini;Giovanni Beltrame;Karthik Soma;Koresh Khateri;Mahdi Pourgholi;Mohsen Montazeri;Lorenzo Sabattini;Giovanni Beltrame",
        "authorids": "/37089894901;/37086487903;/37945616100;/37541467200;/37594737400;/37295768000;/37089894901;/37086487903;/37945616100;/37541467200;/37594737400;/37295768000",
        "aff": "\u00c9cole Polytechnique de Montr\u00e9al, Qu\u00e9bec, CA; Shahid Beheshti University, Tehran, Iran; Shahid Beheshti University, Tehran, Iran; University of Modena and Reggio Emilia, Reggio Emilia, Italy; University of Modena and Reggio Emilia, Reggio Emilia, Italy; \u00c9cole Polytechnique de Montr\u00e9al, Qu\u00e9bec, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160312/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14471073602647150592&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;2;0",
        "aff_unique_norm": "\u00c9cole Polytechnique de Montr\u00e9al;Shahid Beheshti University;University of Modena and Reggio Emilia",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.polymtl.ca;https://www.sbu.ac.ir;https://www.unimore.it",
        "aff_unique_abbr": "Polytechnique Montr\u00e9al;SBU;",
        "aff_campus_unique_index": "0;1;1;2;2;0",
        "aff_campus_unique": "Montr\u00e9al;Tehran;Reggio Emilia",
        "aff_country_unique_index": "0;1;1;2;2;0",
        "aff_country_unique": "Canada;Iran;Italy"
    },
    {
        "id": "10160954",
        "title": "A Consistency-Based Loss for Deep Odometry Through Uncertainty Propagation",
        "track": "main",
        "status": "Poster",
        "abstract": "Conventionally, deep odometry networks use objective functions that only penalize short-term deviations from the true path. Since such an objective does not impose any constraints on the long-term deviations from the path, a second consistency-based loss term may be added to lower long-term drift. However, maintaining a balance between the two loss terms is challenging and often treated as a design hyperparameter. To mitigate this balancing issue, we propose to use the uncertainty over both odometry and the long-term transformations in a maximum likelihood setting and allow the network to tune the weighting between the two loss terms. To this end, we derive the odometry uncertainty alongside the pose outputs using the network itself and to derive the covariance matrix over the integrated transformation, we propose to propagate the odometry uncertainty through each iteration. This formulation provides an adaptive and statistically consistent method to weigh the incremental and integrated loss terms against each other, noting the increase in uncertainty as more steps are integrated over. We show that our approach to consistency-based losses allows the network to surpass the accuracy of the state-of-the-art visual odometry approaches. Then, the efficacy of the derived uncertainty as weighting medium is visualized and the performance benefits of uncertainty quantification are shown in a pose-graph based localization scenario.",
        "primary_area": "",
        "author": "Hamed Damirchi;Roohollah Khorrambakht;Hamid D. Taghirad;Behzad Moshiri;Hamed Damirchi;Roohollah Khorrambakht;Hamid D. Taghirad;Behzad Moshiri",
        "authorids": "/37086927645;/37086457359;/38180146500;/37300833400;/37086927645;/37086457359;/38180146500;/37300833400",
        "aff": "Advanced Robotics and Automated Systems, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, New York University, New York, USA; Advanced Robotics and Automated Systems, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; School of ECE, University College of Engineering, University of Tehran, Tehran, Iran",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160954/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16263333782012907255&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "K. N. Toosi University of Technology;New York University;University of Tehran",
        "aff_unique_dep": "Faculty of Electrical Engineering;Department of Electrical and Computer Engineering;School of ECE",
        "aff_unique_url": ";https://www.nyu.edu;https://www.ut.ac.ir",
        "aff_unique_abbr": "KNTU;NYU;UT",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Tehran;New York",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Iran;United States"
    },
    {
        "id": "10160473",
        "title": "A Contextual Bandit Approach for Learning to Plan in Environments with Probabilistic Goal Configurations",
        "track": "main",
        "status": "Poster",
        "abstract": "Object-goal navigation (Object-nav) entails searching, recognizing and navigating to a target object. Object-nav has been extensively studied by the Embodied-AI community, but most solutions are often restricted to considering static objects (e.g., television, fridge, etc.), We propose a modular framework for object-nav that is able to efficiently search indoor environments for not just static objects but also movable objects (e.g. fruits, glasses, phones, etc.) that frequently change their positions due to human intervention. Our contextual-bandit agent efficiently explores the environment by showing optimism in the face of uncertainty and learns a model of the likelihood of spotting different objects from each navigable location. The likelihoods are used as rewards in a weighted minimum latency solver to deduce a trajectory for the robot. We evaluate our algorithms in two simulated environments and a real-world setting, to demonstrate high sample efficiency and reliability.",
        "primary_area": "",
        "author": "Sohan Rudra;Saksham Goel;Anirban Santara;Claudio Gentile;Laurent Perron;Fei Xia;Vikas Sindhwani;Carolina Parada;Gaurav Aggarwal;Sohan Rudra;Saksham Goel;Anirban Santara;Claudio Gentile;Laurent Perron;Fei Xia;Vikas Sindhwani;Carolina Parada;Gaurav Aggarwal",
        "authorids": "/37088729814;/37089894964;/37085616097;/37089894919;/37089894526;/37086564490;/37282057000;/37593707400;/37269749700;/37088729814;/37089894964;/37085616097;/37089894919;/37089894526;/37086564490;/37282057000;/37593707400;/37269749700",
        "aff": "Google; Google; Google; Google; Google; Google; Google; Google; Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160473/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16932115727718532869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161189",
        "title": "A Continuous Off-Policy Reinforcement Learning Scheme for Optimal Motion Planning in Simply-Connected Workspaces",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, an Integral Reinforcement Learning (RL) framework is employed to provide provably safe, convergent and almost globally optimal policies in a novel Off-Policy Iterative method for simply-connected workspaces. This restriction stems from the impossibility of strictly global navigation in multiply connected manifolds, and is necessary for formulating continuous solutions. The current method generalizes and improves upon previous results, where parametrized controllers hindered the method in scope and results. Through enhancing the traditional reactive paradigm with RL, the proposed scheme is demonstrated to outperform both previous reactive methods as well as an RRT* method in path length, cost function values and execution times, indicating almost global optimality.",
        "primary_area": "",
        "author": "Panagiotis Rousseas;Charalampos P. Bechlioulis;Kostas J. Kyriakopoulos;Panagiotis Rousseas;Charalampos P. Bechlioulis;Kostas J. Kyriakopoulos",
        "authorids": "/37088688420;/37396608300;/38181756700;/37088688420;/37396608300;/38181756700",
        "aff": "School of Mechanical Engineering, Control Systems Laboratory, National Technical University of Athens, Greece; Department of Electrical and Computer Engineering, University of Patras; Center of AI & Robotics (CAIR), New York University, Abu Dhabi",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161189/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12916744034577032778&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "National Technical University of Athens;University of Patras;New York University",
        "aff_unique_dep": "School of Mechanical Engineering, Control Systems Laboratory;Department of Electrical and Computer Engineering;Center of AI & Robotics (CAIR)",
        "aff_unique_url": "https://www.ntua.gr;https://www.upatras.gr;https://www.nyu.edu",
        "aff_unique_abbr": "NTUA;UPatras;NYU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Abu Dhabi",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Greece;United Arab Emirates"
    },
    {
        "id": "10161454",
        "title": "A Control Approach for Human-Robot Ergonomic Payload Lifting",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots can relief human operators from excessive efforts during payload lifting activities. Modelling the human partner allows the design of safe and efficient collaborative strategies. In this paper, we present a control approach for human-robot collaboration based on human monitoring through whole-body wearable sensors, and interaction modelling through coupled rigid-body dynamics. Moreover, a trajectory advancement strategy is proposed, allowing for online adaptation of the robot trajectory depending on the human motion. The resulting framework allows us to perform payload lifting tasks, taking into account the ergonomic requirements of the agents. Validation has been performed in an experimental scenario using the iCub3 humanoid robot and a human subject sensorized with the iFeel wearable system.",
        "primary_area": "",
        "author": "Lorenzo Rapetti;Carlotta Sartore;Mohamed Elobaid;Yeshasvi Tirupachuri;Francesco Draicchio;Tomohiro Kawakami;Takahide Yoshiike;Daniele Pucci;Lorenzo Rapetti;Carlotta Sartore;Mohamed Elobaid;Yeshasvi Tirupachuri;Francesco Draicchio;Tomohiro Kawakami;Takahide Yoshiike;Daniele Pucci",
        "authorids": "/37087238330;/37087043162;/37088752671;/37086076224;/37086481049;/37088504439;/37682554700;/37706167200;/37087238330;/37087043162;/37088752671;/37086076224;/37086481049;/37088504439;/37682554700;/37706167200",
        "aff": "Machine Learning and Optimisation, The University of Manchester, Manchester, United Kingdom; Machine Learning and Optimisation, The University of Manchester, Manchester, United Kingdom; Center for Robotics and Intelligent Systems, Artificial and Mechanical Intelligence at Italian Insititute of Technology, Genoa, Italy; Center for Robotics and Intelligent Systems, Artificial and Mechanical Intelligence at Italian Insititute of Technology, Genoa, Italy; Department of Occupational and Environmental Medicine, Epidemiology and Hygiene, INAIL, Roma, Italy; Honda R&D Co., Ltd., Saitama, Japan; Honda R&D Co., Ltd., Saitama, Japan; Machine Learning and Optimisation, The University of Manchester, Manchester, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161454/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15887494585556161763&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;1;2;3;3;0",
        "aff_unique_norm": "The University of Manchester;Italian Institute of Technology;INAIL;Honda R&D Co., Ltd.",
        "aff_unique_dep": "Machine Learning and Optimisation;Center for Robotics and Intelligent Systems;Department of Occupational and Environmental Medicine, Epidemiology and Hygiene;",
        "aff_unique_url": "https://www.manchester.ac.uk;https://www.iit.it;https://www.inail.it;https://www.honda.com",
        "aff_unique_abbr": "UoM;IIT;;Honda R&D",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Manchester;Genoa;",
        "aff_country_unique_index": "0;0;1;1;1;2;2;0",
        "aff_country_unique": "United Kingdom;Italy;Japan"
    },
    {
        "id": "10161513",
        "title": "A Curvature and Trajectory Optimization-based 3D Surface Reconstruction Pipeline for Ultrasound Trajectory Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultrasound scanning is an efficient imaging modality preferred for quick medical procedures. However, due to the lack of skilled sonographers, researchers have developed many Robotic Ultrasound System (RUS) prototypes for various procedures. Most of these systems have a human-in-the-loop and require an expert to point the robot to the region of the subject to be scanned. Only a few systems try to incorporate some knowledge from the exterior shape of the subject for ultrasound scanning. Accurate 3D surface reconstruction of a patient's exterior can enable an RUS to perceive subjects more like a clinician would. It can help localize the subject for the robot while eliminating input from an expert. Ultrasound scanning trajectories can be better planned if the RUS first detects critical regions on the surface of the subject and corresponding curvatures. We use an RGB-D sensor to acquire point clouds representing the 3D surface of the subject, which in the present work is for a lower-torso leg phantom. A consolidated pipeline for creating an optimized 3D surface reconstruction of a subject is presented and is used to autonomously identify a region of interest for scanning femoral vessels with an ultrasound probe. To make our system more robust to inter-subject variations in shape and size, we incorporate a trajectory optimization module of the RUS-mounted RGB-D sensor. To this end, we introduce a comprehensive evaluation score to quantify the quality of point cloud reconstructions. The resulting improvements in 3D surface scanning and reconstruction enable near-automation in generating ultrasound scanning trajectories for femoral vessels. Our pipeline produces ultrasound images with an average ZNCC score of 0.86 and our 3D point cloud reconstructions are accurate up to le-5 m from a ground-truth high-resolution CT scan.",
        "primary_area": "",
        "author": "Ananya Bal;Ashutosh Gupta;Fnu Abhimanyu;John Galeotti;Howie Choset;Ananya Bal;Ashutosh Gupta;Fnu Abhimanyu;John Galeotti;Howie Choset",
        "authorids": "/37088941525;/37089892488;/37089447292;/38558753600;/37281322200;/37088941525;/37089892488;/37089447292;/38558753600;/37281322200",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Birla Institute of Technology & Science, India; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161513/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7672113742245367297&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Birla Institute of Technology & Science",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.bits-pilani.ac.in",
        "aff_unique_abbr": "CMU;BITS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "10160540",
        "title": "A Decoupled and Linear Framework for Global Outlier Rejection over Planar Pose Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a robust framework for planar pose graph optimization contaminated by loop closure outliers. Our framework rejects outliers by first decoupling the robust PGO problem wrapped by a Truncated Least Squares kernel into two subproblems. Then, the framework introduces a linear angle representation to rewrite the first subproblem that is originally formulated in rotation matrices. The framework is configured with the Graduated Non-Convexity (GNC) algorithm to solve the two non-convex subproblems in succession without initial guesses. Thanks to the linearity property of the angle representation, our framework requires only a linear solver to optimally solve the optimization problems encountered in GNC. We extensively validate the proposed framework, named DEGNC- LAF (DEcoupled Graduated Non-Convexity with Linear Angle Formulation) in planar PGO benchmarks. It turns out that it runs significantly (sometimes up to over 30 times) faster than the standard and general-purpose GNC while resulting in high-quality estimates.",
        "primary_area": "",
        "author": "Tianyue Wu;Fei Gao;Tianyue Wu;Fei Gao",
        "authorids": "/37089892574;/37086045143;/37089892574;/37086045143",
        "aff": "State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160540/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14857926264796343425&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161404",
        "title": "A Deep Learning Human Activity Recognition Framework for Socially Assistive Robots to Support Reablement of Older Adults",
        "track": "main",
        "status": "Poster",
        "abstract": "Many older adults prefer to stay in their own homes and age-in-place. However, physical and cognitive limitations in independently completing activities of daily living (ADLs) requires older adults to receive assistive support, often necessitating transitioning to care centers. In this paper, we present the development of a novel deep learning human activity recognition and classification architecture capable of autonomously identifying ADLs in home environments to enable long-term deployment of socially assistive robots to aid older adults. Our deep learning architecture is the first to use multimodal inputs to create an embedding vector approach for classifying and monitoring multiple ADLs. It uses spatial mid-fusion to combine geometric, motion and semantic features of users, environments, and objects to classify and track ADLs. We leverage transfer learning to extract generic features using the early layers of deep networks trained on large datasets to apply our architecture to various ADLs. The embedding vector enables identification of unseen ADLs and determines intra-class variance for monitoring user ADL performance. Our proposed unique architecture can be used by socially assistive robots to promote reablement in the home via autonomously supporting the assistance of varying ADLs. Extensive experiments show improved classification accuracy compared to unimodal/dual-modal models and the ADL embedding space also incorporates the ability to distinctly identify and track seen and unseen ADLs.",
        "primary_area": "",
        "author": "Fraser Robinson;Goldie Nejat;Fraser Robinson;Goldie Nejat",
        "authorids": "/37089549266;/37296198900;/37089549266;/37296198900",
        "aff": "Autonomous Systems and Biomechatronics Laboratory, University of Toronto, Toronto, ON, CAN; Autonomous Systems and Biomechatronics Laboratory, University of Toronto, Toronto, ON, CAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161404/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9525268685690020870&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Autonomous Systems and Biomechatronics Laboratory",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161556",
        "title": "A Digital Twin for Teleoperation of Vehicles in Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperated driving (ToD) is increasingly considered as a fallback solution for autonomous driving. Up to now, ToD requires a highly reliable mobile network capable of transmitting multiple video streams with low latency. Recently, significant advancements have been made in vehicular sensors and perception algorithms, which have huge implications for the challenges faced in ToD. We envisage that a real-time digital twin that tracks the remote vehicle's environment will play a crucial role in reducing the required communication band-width and providing a more convenient teleoperator interface, ultimately enhancing safety of ToD in crowded environments. Furthermore, it would allow various degrees of cooperation between automated driving functionalities and human teleoperators. In this paper, the concept of digital twin for ToD is outlined and a proof of concept is implemented using a real-world vehicle simulator and a teleoperator hardware setup. A significant reduction in required bandwidth is reported by transmitting less video data and reconstructing the scene from the digital twin.",
        "primary_area": "",
        "author": "Philipp Kremer;Navid Nourani-Vatani;Sangyoung Park;Philipp Kremer;Navid Nourani-Vatani;Sangyoung Park",
        "authorids": "/37088596893;/38274535000;/37539543700;/37088596893;/38274535000;/37539543700",
        "aff": "Smart Mobility Systems, Technical University of Berlin; Imperium Drive Ltd., UK; Smart Mobility Systems, Technical University of Berlin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161556/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17511751974712477355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Technical University of Berlin;Imperium Drive Ltd.",
        "aff_unique_dep": "Smart Mobility Systems;",
        "aff_unique_url": "https://www.tu-berlin.de;",
        "aff_unique_abbr": "TU Berlin;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berlin;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "10160700",
        "title": "A Distributed Online Optimization Strategy for Cooperative Robotic Surveillance",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a distributed algorithm to control a team of cooperating robots aiming to protect a target from a set of intruders. Specifically, we model the strategy of the defending team by means of an online optimization problem inspired by the emerging distributed aggregative framework. In particular, each defending robot determines its own position depending on (i) the relative position between an associated intruder and the target, (ii) its contribution to the barycenter of the team, and (iii) collisions to avoid with its teammates. We highlight that each agent is only aware of local, noisy measurements about the location of the associated intruder and the target. Thus, in each robot, our algorithm needs to (i) locally reconstruct global unavailable quantities and (ii) predict its current objective functions starting from the local measurements. The effectiveness of the proposed methodology is corroborated by simulations and experiments on a team of cooperating quadrotors.",
        "primary_area": "",
        "author": "Lorenzo Pichierri;Guido Carnevale;Lorenzo Sforni;Andrea Testa;Giuseppe Notarstefano;Lorenzo Pichierri;Guido Carnevale;Lorenzo Sforni;Andrea Testa;Giuseppe Notarstefano",
        "authorids": "/37089890671;/37089452731;/37089278196;/37086200546;/37296816100;/37089890671;/37089452731;/37089278196;/37086200546;/37296816100",
        "aff": "Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160700/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3881570585279393426&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bologna",
        "aff_unique_dep": "Department of Electrical, Electronic and Information Engineering",
        "aff_unique_url": "https://www.unibo.it",
        "aff_unique_abbr": "UNIBO",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Bologna",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10160949",
        "title": "A Dual-Arm Participated Human-Robot Collaboration Method for Upper Limb Rehabilitation of Hemiplegic Patients",
        "track": "main",
        "status": "Poster",
        "abstract": "Upper limb rehabilitation robots are mainly used as a physical therapy method to passively or actively train the affected side. However, they are rarely implemented in accordance with the occupational therapy theory, which is dedicated to improving the sensorimotor coordination of hemiplegic patients by considering both healthy and affected limbs. To realize the occupational therapy concept in robot-assisted upper limb rehabilitation, we propose a new human-robot collaboration framework for hemiplegic patients that integrates healthy/affected limbs and robot. The strategy aims at achieving patient-specific movement capabilities and improving the participation of the affected limb during rehabilitation. To accomplish this task, we have addressed two essential issues: accurate motion estimation of the healthy limb and the rehabilitation trajectory learning technique. The posture estimation is achieved by introducing the calibration model to reduce static and time dependent errors during the measurement. We also introduce a force term to the conventional imitation learning method to improve the adaptability in integrating the affected side in cooperation with the robot. Various experiments have been conducted to validate the feasibility and effectiveness of our proposed dual-arm collaboration strategy.",
        "primary_area": "",
        "author": "Lufeng Chen;Jing Qiu;Xuan Zou;Hong Cheng;Lufeng Chen;Jing Qiu;Xuan Zou;Hong Cheng",
        "authorids": "/37085783910;/37086356733;/37089892649;/37280209600;/37085783910;/37086356733;/37089892649;/37280209600",
        "aff": "Department of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Buffalo Robot Technology (Chengdu) Co., Ltd.; Department of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160949/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16677482448566130564&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China;Buffalo Robot Technology",
        "aff_unique_dep": "Department of Automation Engineering;",
        "aff_unique_url": "http://www.uestc.edu.cn;",
        "aff_unique_abbr": "UESTC;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chengdu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160301",
        "title": "A Fast Geometric Framework for Dynamic Cosserat Rods with Discrete Actuated Joints",
        "track": "main",
        "status": "Poster",
        "abstract": "Current dynamical models of Cosserat rods often use the finite element method limited by computational efficiency or the finite difference method in a Cartesian framework with a compromise to accuracy. We employ the finite difference method in a geometric framework to develop solutions that are both computationally efficient and accurate. A numerical study is conducted on various backward-differentiation discretization and Runge-Kutta-Munthe-Kaas integration schemes, focusing on their accuracy and computational efficiency. Case studies are conducted on a single-degree-of-freedom joint actuated Cosserat rod to mitigate additional sources of undesired error from the numerical analysis, e.g. multi-body interactions, moving base dynamics, etc. The proposed geometric integrators are demonstrated to improve solution accuracy compared to the published finite difference models. The presented solution is parameterization-free and also computationally efficient with the potential for use in real-time applications, e.g., model-based control of soft manipulators.",
        "primary_area": "",
        "author": "Hossain Samei;Robin Chhabra;Hossain Samei;Robin Chhabra",
        "authorids": "/37089892855;/37580470100;/37089892855;/37580470100",
        "aff": "Department of Mechanical and Aerospace Engineering, Carleton University, Ottawa, ON, Canada; Department of Mechanical and Aerospace Engineering, Carleton University, Ottawa, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160301/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12232268947047586913&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carleton University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://carleton.ca",
        "aff_unique_abbr": "Carleton",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ottawa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160637",
        "title": "A Flexible 3D Force Sensor with In-Situ Tunable Sensitivity",
        "track": "main",
        "status": "Poster",
        "abstract": "Following biology's lead, soft robotics has emerged as a perfect candidate for actuation within complex environments. While soft actuation has been developed intensively over the last few decades, soft sensing has so far slowed to catch up. A largely unresearched area is the change of the soft material properties through prestress to achieve a degree of mechanical sensitivity tunability within soft sensors. Here, a new 3D force sensor which employs novel hydraulic filament artificial muscles capable of in-situ sensitivity tunability is introduced. Using a neural network (NN) model, the new soft 3D sensor can precisely detect external forces based on the change of the hydraulic pressures with error of \\sim 1.0, \\sim 1.3\\sim 1.0, \\sim 1.3, and \\sim 0.94\\sim 0.94 % in the \\text{x, y}\\text{x, y}, and z-axis directions, respectively. The sensor is also able to sense large force ranges, comparable to other similar sensors available in the literature. The sensor is then integrated into a soft robotic surgical arm for monitoring the tool-tissue interaction during an ablation process.",
        "primary_area": "",
        "author": "James Davies;Mai Thanh Thai;Trung Thien Hoang;Chi Cong Nguyen;Phuoc Thien Phan;Kefan Zhu;Dang Bao Nhi Tran;Van Anh Ho;Hung Manh La;Quang Phuc Ha;Nigel Hamilton Lovell;Thanh Nho Do;James Davies;Mai Thanh Thai;Trung Thien Hoang;Chi Cong Nguyen;Phuoc Thien Phan;Kefan Zhu;Dang Bao Nhi Tran;Van Anh Ho;Hung Manh La;Quang Phuc Ha;Nigel Hamilton Lovell;Thanh Nho Do",
        "authorids": "/37089446972;/37088497860;/37088498761;/37089447104;/37086208825;/37089894564;/37089892748;/37529964700;/37542872700;/37300884000;/37300634000;/37085436676;/37089446972;/37088497860;/37088498761;/37089447104;/37086208825;/37089894564;/37089892748;/37529964700;/37542872700;/37300884000;/37300634000;/37085436676",
        "aff": "Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; School of Science, Engineering & Technology, RMIT University, Ho Chi Minh City, Vietnam; School of Material Science, Japan Advanced Institute of Science, and Technology (JAIST), Ishikawa, Japan Science and Technology Agency, PRESTO, Kawaguchi Saitama, Japan; Department of Computer Science and Engineering, University of Nevada, Reno, Reno, NV, USA; Faculty of Engineering and IT, University of Technology, Sydney, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160637/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:-X9nSlUS8awJ:scholar.google.com/&scioq=A+Flexible+3D+Force+Sensor+with+In-Situ+Tunable+Sensitivity&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;0;0;0;1;2;3;4;0;0",
        "aff_unique_norm": "UNSW Sydney;RMIT University;Japan Advanced Institute of Science and Technology;University of Nevada, Reno;University of Technology, Sydney",
        "aff_unique_dep": "Graduate School of Biomedical Engineering;School of Science, Engineering & Technology;School of Material Science;Department of Computer Science and Engineering;Faculty of Engineering and IT",
        "aff_unique_url": "https://www.unsw.edu.au;https://www.rmit.edu.au;https://www.jaist.ac.jp;https://www.unr.edu;https://www.uts.edu.au",
        "aff_unique_abbr": "UNSW;RMIT;JAIST;UNR;UTS",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;2;3;4;0;0",
        "aff_campus_unique": "Kensington;Ho Chi Minh City;Ishikawa;Reno;Sydney",
        "aff_country_unique_index": "0;0;0;0;0;0;1;2;3;0;0;0",
        "aff_country_unique": "Australia;Vietnam;Japan;United States"
    },
    {
        "id": "10161175",
        "title": "A Force-Sensitive Exoskeleton for Teleoperation: An Application in Elderly Care Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "With the increasing demand for new healthcare solutions and technologies, such as those resulting from the COVID-19 crisis, and the growing elderly population, exoskeletons for teleoperation are a promising solution for many future medical applications. In this context, we propose two force- sensitive upper-limb exoskeletons for teleoperation, that are characterized by: i) torque-controlled robotic actuators, ii) rigid-body model compensations, and iii) a lightweight design achieved through the use of Bowden cable transmissions and remotely placed actuators. Specifically, we present a semi-active upper-limb exoskeleton for which we demonstrate human- device interaction control and bilateral teleoperation with force- feedback, evaluated via simulation, in the lab and over the Internet. We also introduce a design for a future fully-active upper-limb exoskeleton with two contact force/torque sensors, for a dual-arm device, which features a novel 3-degrees-of- freedom exoskeleton shoulder design and a contact wrench mitigation controller, as demonstrated through simulation. With this work, we propose the essential technical steps towards a novel teleoperation system for elderly care.",
        "primary_area": "",
        "author": "Alexander Toedtheide;Xiao Chen;Hamid Sadeghian;Abdeldjallil Naceri;Sami Haddadin;Alexander Toedtheide;Xiao Chen;Hamid Sadeghian;Abdeldjallil Naceri;Sami Haddadin",
        "authorids": "/37085751151;/37088992427;/38539589600;/37546043900;/37542865300;/37085751151;/37088992427;/38539589600;/37546043900;/37542865300",
        "aff": "Chair of Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair of Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Faculty of Engineering, University of Isfahan, Isfahan, Iran; Chair of Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair of Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161175/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=749683412553271079&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Technical University of Munich;University of Isfahan",
        "aff_unique_dep": "Chair of Robotics and Systems Intelligence;Faculty of Engineering",
        "aff_unique_url": "https://www.tum.de;http://www.ui.ac.ir",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Munich;Isfahan",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Germany;Iran"
    },
    {
        "id": "10160996",
        "title": "A Framework for Active Haptic Guidance Using Robotic Haptic Proxies",
        "track": "main",
        "status": "Poster",
        "abstract": "Haptic feedback is an important component of creating an immersive mixed reality experience. Traditionally, haptic forces are rendered in response to the user's interactions with the virtual environment. In this work, we explore the idea of rendering haptic forces in a proactive manner, with the explicit intention to influence the user's behavior through compelling haptic forces. To this end, we present a framework for active haptic guidance in mixed reality, using one or more robotic haptic proxies to influence user behavior and deliver a safer and more immersive virtual experience. We provide details on common challenges that need to be overcome when implementing active haptic guidance, and discuss example applications that show how active haptic guidance can be used to influence the user's behavior. Finally, we apply active haptic guidance to a virtual reality navigation problem, and conduct a user study that demonstrates how active haptic guidance creates a safer and more immersive experience for users.",
        "primary_area": "",
        "author": "Niall L. Williams;Nicholas Rewkowski;Jiasheng Li;Ming C. Lin;Niall L. Williams;Nicholas Rewkowski;Jiasheng Li;Ming C. Lin",
        "authorids": "/37086941217;/37086348683;/37089894739;/37278387400;/37086941217;/37086348683;/37089894739;/37278387400",
        "aff": "Department of Computer Science, University of Maryland, College Park; Department of Computer Science, University of Maryland, College Park; Department of Computer Science, University of Maryland, College Park; Department of Computer Science, University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160996/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14311433275423074580&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Maryland, College Park",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160586",
        "title": "A Framework for Fast Prototyping of Photo-realistic Environments with Multiple Pedestrians",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic applications involving people often require advanced perception systems to better understand complex real-world scenarios. To address this challenge, photo-realistic and physics simulators are gaining popularity as a means of generating accurate data labeling and designing scenarios for evaluating generalization capabilities, e.g., lighting changes, camera movements or different weather conditions. We develop a photo-realistic framework built on Unreal Engine and AirSim to generate easily scenarios with pedestrians and mobile robots. The framework is capable to generate random and customized trajectories for each person and provides up to 50 ready-to-use people models along with an API for their metadata retrieval. We demonstrate the usefulness of the proposed framework with a use case of multi-target tracking, a popular problem in real pedestrian scenarios. The notable feature variability in the obtained perception data is presented and evaluated.",
        "primary_area": "",
        "author": "Sara Casao;Andr\u00e9s Otero;\u00c1lvaro Serra-G\u00f3mez;Ana C. Murillo;Javier Alonso-Mora;Eduardo Montijano;Sara Casao;Andr\u00e9s Otero;\u00c1lvaro Serra-G\u00f3mez;Ana C. Murillo;Javier Alonso-Mora;Eduardo Montijano",
        "authorids": "/37088996416;/37089893813;/37088691504;/37393616700;/38271697300;/37681715400;/37088996416;/37089893813;/37088691504;/37393616700;/38271697300;/37681715400",
        "aff": "RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain; RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain; Cognitive Robotics, at TU Delft, The Netherlands; RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain; Cognitive Robotics, at TU Delft, The Netherlands; RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160586/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15435415553480448433&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;0",
        "aff_unique_norm": "Universidad de Zaragoza;Delft University of Technology",
        "aff_unique_dep": "DIIS - I3A;Cognitive Robotics",
        "aff_unique_url": "https://www.unizar.es;https://www.tudelft.nl",
        "aff_unique_abbr": ";TU Delft",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Delft",
        "aff_country_unique_index": "0;0;1;0;1;0",
        "aff_country_unique": "Spain;Netherlands"
    },
    {
        "id": "10160445",
        "title": "A Framework for Simultaneous Workpiece Registration in Robotic Machining Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "This article presents a novel framework called Simultaneous Registration and Machining (SRAM), a generalized method to improve workpiece registration using real-time acquired data in robotic contouring applications. The method allows for online corrections to the toolpath, while a live covariance estimate is simultaneously leveraged to adaptively tune the force controller aggressively when uncertainty is high, but conservatively otherwise to minimize chatter and instability. The SRAM framework is validated in simulation and shown to significantly reduce the path corrections required from the force controller, while correctly predicting optimal controller tuning adaptations. The SRAM method is proposed to improve force control stability, increase peripheral accuracy, smooth surface finish, and reduce cycle times in contouring applications.",
        "primary_area": "",
        "author": "Steffan Lloyd;Rishad Irani;Mojtaba Ahmadi;Steffan Lloyd;Rishad Irani;Mojtaba Ahmadi",
        "authorids": "/37088402030;/37086210263;/37348076400;/37088402030;/37086210263;/37348076400",
        "aff": "Department of Mechanical and Aerospace Engineering, Carleton University, Ottawa, ON, Canada; Department of Mechanical and Aerospace Engineering, Carleton University, Ottawa, ON, Canada; Department of Mechanical and Aerospace Engineering, Carleton University, Ottawa, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160445/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17704352209833977530&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carleton University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://carleton.ca",
        "aff_unique_abbr": "Carleton",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ottawa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161071",
        "title": "A Framework for the Unsupervised Inference of Relations Between Sensed Object Spatial Distributions and Robot Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "The spatial distribution of sensed objects strongly influences the behavior of mobile robots. Yet, as robots evolve in complexity to operate in increasingly rich environments, it becomes much more difficult to specify the underlying relations between sensed object spatial distributions and robot behaviors. We aim to address this challenge by leveraging system trace data to automatically infer relations that help to better characterize these spatial associations. In particular, we introduce SpRinG, a framework for the unsupervised inference of system specifications from traces that characterize the spatial relationships under which a robot operates. Our method builds on a parameterizable notion of reachability to encode relationships of spatial neighborship, which are used to instantiate a language of patterns. These patterns provide the structure to infer, from system traces, the connection between such relationships and robot behaviors. We show that SpRinG can automatically infer spatial relations over two distinct domains: autonomous vehicles in traffic and a surgical robot. Our results demonstrate the power and expressiveness of SpRinG, in its ability to learn existing specifications as machine-checkable first-order logic, uncover previously unstated specifications that are rich and insightful, and reveal contextual differences between executions.",
        "primary_area": "",
        "author": "Christopher Morse;Lu Feng;Matthew Dwyer;Sebastian Elbaum;Christopher Morse;Lu Feng;Matthew Dwyer;Sebastian Elbaum",
        "authorids": "/37086237482;/37085539356;/37283377500;/37272376100;/37086237482;/37085539356;/37283377500;/37272376100",
        "aff": "University of Virginia, USA; University of Virginia, USA; University of Virginia, USA; University of Virginia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161071/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4471056530700364169&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161010",
        "title": "A Gaze-Speech System in Mixed Reality for Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot interaction (HRI) demands efficient time performance along the tasks. However, some interaction approaches may extend the time to complete such tasks. Thus, the time performance in HRI must be enhanced. This work presents an effective way to enhance the time performance in HRI tasks with a mixed reality (MR) method based on a gaze-speech system. In this paper, we design an MR world for pick-and-place tasks. The hardware system includes an MR headset, the Baxter robot, a table, and six cubes. In addition, the holographic MR scenario offers two modes of interaction: gesture mode (GM) and gaze-speech mode (GSM). The input actions during the GM and GSM methods are based on the pinch gesture and gaze with speech commands, respectively. The proposed GSM approach can improve the time performance in pick-and-place scenarios. The GSM system is 21.33 % faster than the traditional system, GM. Also, we evaluated the target- to-target time performance against a reference based on Fitts' law. Our findings show a promising method for time reduction in HRI tasks through MR environments.",
        "primary_area": "",
        "author": "John David Prieto Prada;Myung Ho Lee;Cheol Song;John David Prieto Prada;Myung Ho Lee;Cheol Song",
        "authorids": "/37089894314;/37089896107;/37676950900;/37089894314;/37089896107;/37676950900",
        "aff": "Department of Robotics and Mechatronics Engineering, DGIST, Daegu, South Korea; Department of Robotics and Mechatronics Engineering, DGIST, Daegu, South Korea; Department of Robotics and Mechatronics Engineering, DGIST, Daegu, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161010/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10367876842776551656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": "Department of Robotics and Mechatronics Engineering",
        "aff_unique_url": "https://www.dgist.ac.kr",
        "aff_unique_abbr": "DGIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daegu",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160881",
        "title": "A General Locomotion Approach for a Novel Multi-legged Spherical Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "As a kind of ground mobile robot, deformable robots have many advantages, such as solid terrain adaptability, lightweight, and portability. Among these robots, the radial skeleton robot has better stability and controllability. However, because the friction of foot and ground is hard to be predicted, the accuracy of its gait generation algorithms that have been studied is very low. Furthermore, there is currently no closed-loop control scheme for this kind of robot. We designed a 12-legged radial skeleton robot with high extension ratio legs, proposed a high-precision gait generation algorithm for any multi-legged radial skeleton robot, and first proposed a closed-loop control scheme for this kind of robot. A dynamic model considering contact friction is established. And the robot has the advantages of omnidirectional motion, high-precision trajectory tracking, and motion robustness. By conducting prototype experiments, it is verified that our method achieves the highest accuracy when tracking trajectory and holds robustness in the unknown environment.",
        "primary_area": "",
        "author": "Dun Yang;Yunfei Liu;Yang Yu;Dun Yang;Yunfei Liu;Yang Yu",
        "authorids": "/37089831450;/37089833666;/37089830230;/37089831450;/37089833666;/37089830230",
        "aff": "Beihang University, Beijing, China; Beihang University, Beijing, China; Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160881/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15306182138742866579&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.buaa.edu.cn/",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160758",
        "title": "A Graph-Based Optimization Framework for Hand-Eye Calibration for Multi-Camera Setups",
        "track": "main",
        "status": "Poster",
        "abstract": "Hand-eye calibration is the problem of estimating the spatial transformation between a reference frame, usually the base of a robot arm or its gripper, and the reference frame of one or multiple cameras. Generally, this calibration is solved as a non-linear optimization problem, what instead is rarely done is to exploit the underlying graph structure of the problem itself. Actually, the problem of hand-eye calibration can be seen as an instance of the Simultaneous Localization and Mapping (SLAM) problem. Inspired by this fact, in this work we present a pose-graph approach to the hand-eye calibration problem that extends a recent state-of-the-art solution in two different ways: i) by formulating the solution to eye-on-base setups with one camera; ii) by covering multi-camera robotic setups. The proposed approach has been validated in simulation against standard hand-eye calibration methods. Moreover, a real application is shown. In both scenarios, the proposed approach overcomes all alternative methods. We release with this paper an open-source implementation of our graph-based optimization framework for multi-camera setups.",
        "primary_area": "",
        "author": "Daniele Evangelista;Emilio Olivastri;Davide Allegro;Emanuele Menegatti;Alberto Pretto;Daniele Evangelista;Emilio Olivastri;Davide Allegro;Emanuele Menegatti;Alberto Pretto",
        "authorids": "/37086945001;/37089375675;/37089576094;/37317887300;/37542911000;/37086945001;/37089375675;/37089576094;/37317887300;/37542911000",
        "aff": "Department of Information Engineering (DEI), University of Padova, Padova, Italy; Department of Information Engineering (DEI), University of Padova, Padova, Italy; Department of Information Engineering (DEI), University of Padova, Padova, Italy; Department of Information Engineering (DEI), University of Padova, Padova, Italy; Department of Information Engineering (DEI), University of Padova, Padova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160758/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11809252871273223002&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Padova",
        "aff_unique_dep": "Department of Information Engineering",
        "aff_unique_url": "https://www.unipd.it",
        "aff_unique_abbr": "UNIPD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Padova",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161480",
        "title": "A Gravity Compensation Strategy for On-ground Validation of Orbital Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "The on-ground validation of orbital manipulators is a challenging task because the robot is designed for a gravity-free operational environment, but it is validated under the effect of gravity. As a consequence, joint torque limits can be easily reached in certain configurations when gravity is actively compensated by the joints. Hence, the workspace for on-ground testing is restricted. In this paper, an optimal strategy is proposed for achieving gravity compensation of an orbital manipulator arm on ground. The strategy minimizes the joint torques acting on the manipulator by solving an optimization problem and it computes the necessary forces to be tracked by an external carrier. Hence, full gravity compensation is achieved for the orbital manipulator. Experimental results validate the effectiveness of the method on the DLR CAESAR space robot, which uses a cable suspended system as external carrier to track the desired gravity compensation force, resulting from the proposed method.",
        "primary_area": "",
        "author": "Marco De Stefano;Ria Vijayan;Andreas Stemmer;Ferdinand Elhardt;Christian Ott;Marco De Stefano;Ria Vijayan;Andreas Stemmer;Ferdinand Elhardt;Christian Ott",
        "authorids": "/37085376264;/37088471411;/37313206200;/37089892320;/37282440400;/37085376264;/37088471411;/37313206200;/37089892320;/37282440400",
        "aff": "German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; TU Wien and German Aerospace Center (DLR)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161480/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18420269352945405946&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "German Aerospace Center (DLR);TU Wien",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;",
        "aff_unique_url": "https://www.dlr.de;https://www.tuwien.ac.at",
        "aff_unique_abbr": "DLR;TU Wien",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Germany;Austria"
    },
    {
        "id": "10161196",
        "title": "A Handheld Hydraulic Cardiac Catheter with Omnidirectional Manipulator and Touch Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Atrial fibrillation (AF) is mostly treated via robotic catheter-based cardiac ablation procedures. Over the last few decades, cables or tendon mechanisms are at the core of available cardiac catheters. Despite advances, the use of cables often results in considerable force loss, nonlinear hysteresis, and control challenges. Most catheters are not equipped with force sensing, which increases the risk of the ablation process and decreases their efficacy in clinical settings. In addition, current catheters have a poor user interface and therefore the ablation process requires skilled or trained surgeons to steer the complex motion of the catheter tip within the heart chambers. To improve the cardiac ablation procedure, a new robotic catheter that has the ability to extend its working space without moving its flexible body and a real-time force sensor for safe operation is highly desired. In this work, a new handheld and soft robotic catheter for AF ablation is introduced. The new device consists of several improved components such as a soft manipulator for navigation and bending motion, an ergonomic handheld controller, and a soft force sensor for monitoring tool-tissue contact. The design, modeling, and fabrication of the device are presented and followed by experimental characterizations and ex-vivo validation.",
        "primary_area": "",
        "author": "Chi Cong Nguyen;James Davies;Mai Thanh Thai;Trung Thien Hoang;Phuoc Thien Phan;Kefan Zhu;Dang Bao Nhi Tran;Van Anh Ho;Hung Manh La;Hoang-Phuong Phan;Nigel H. Lovell;Thanh Nho Do;Chi Cong Nguyen;James Davies;Mai Thanh Thai;Trung Thien Hoang;Phuoc Thien Phan;Kefan Zhu;Dang Bao Nhi Tran;Van Anh Ho;Hung Manh La;Hoang-Phuong Phan;Nigel H. Lovell;Thanh Nho Do",
        "authorids": "/37089447104;/37089446972;/37088497860;/37088498761;/37086208825;/37089894564;/37089895555;/37529964700;/37542872700;/37085391254;/37300634000;/37085436676;/37089447104;/37089446972;/37088497860;/37088498761;/37086208825;/37089894564;/37089895555;/37529964700;/37542872700;/37085391254;/37300634000;/37085436676",
        "aff": "Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, NSW, Australia; School of Science Engineering & Technology, RMIT University, Ho Chi Minh City, Vietnam; Science and Technology Agency, PRESTO, Kawaguchi Saitama, Japan; Department of Computer Science and Engineering, University of Nevada, Reno, Reno, NV, USA; Faculty of Engineering, UNSW Sydney, School of Mechanical and Manufacturing Engineering, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161196/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=520420134241327190&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;0;0;0;1;2;3;0;0;0",
        "aff_unique_norm": "UNSW Sydney;RMIT University;Science and Technology Agency;University of Nevada, Reno",
        "aff_unique_dep": "Graduate School of Biomedical Engineering;School of Science Engineering & Technology;PRESTO;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.unsw.edu.au;https://www.rmit.edu.au;;https://www.unr.edu",
        "aff_unique_abbr": "UNSW;RMIT;;UNR",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;3;0;0;0",
        "aff_campus_unique": "Sydney;Ho Chi Minh City;;Reno",
        "aff_country_unique_index": "0;0;0;0;0;0;1;2;3;0;0;0",
        "aff_country_unique": "Australia;Vietnam;Japan;United States"
    },
    {
        "id": "10160744",
        "title": "A Hierarchical Decoupling Approach for Fast Temporal Logic Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast motion planning is of great significance, espe-cially when a timely mission is desired. However, the complexity of motion planning can grow drastically with the increase of environment details and mission complexity. This challenge can be further exacerbated if the tasks are coupled with the desired locations in the environment. To address these issues, this work aims at fast motion planning problems with temporal logical specifications. In particular, we develop a hierarchical decoupling framework that consists of three layers: the high-level task planner, the decoupling layer, and the low-level motion planner. The decoupling layer is designed to bridge the high and low layers by providing necessary information exchange. Such a framework enables the decoupling of the task planner and path planner, so that they can run independently, which significantly reduces the search space and enables fast planing in continuous or high-dimension discrete workspaces. In addition, the implicit constraint during task-level planning is taken into account, so that the low-level path planning is guaranteed to satisfy the mission requirements. Numerical simulations demonstrate at least one order of magnitude speed up in terms of computational time over existing methods.",
        "primary_area": "",
        "author": "Ziyang Chen;Zhangli Zhou;Shaochen Wang;Zhen Kan;Ziyang Chen;Zhangli Zhou;Shaochen Wang;Zhen Kan",
        "authorids": "/37089896027;/37086957975;/37088518790;/37545883400;/37089896027;/37086957975;/37088518790;/37545883400",
        "aff": "Department of Automation, University of Science and Technology of China, Hefei, Anhui, China; Department of Automation, University of Science and Technology of China, Hefei, Anhui, China; Department of Automation, University of Science and Technology of China, Hefei, Anhui, China; Department of Automation, University of Science and Technology of China, Hefei, Anhui, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160744/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11309534643269489124&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hefei",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161045",
        "title": "A Hybrid Cable-Driven Robot for Non-Destructive Leafy Plant Monitoring and Mass Estimation using Structure from Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel hybrid cable-based robot with manipulator and camera for high-accuracy, medium-throughput plant monitoring in a vertical hydroponic farm and, as an example application, demonstrate non-destructive plant mass estimation. Plant monitoring with high temporal and spatial resolution is important to both farmers and researchers to detect anomalies and develop predictive models for plant growth. The availability of high-quality, off-the-shelf structure-from-motion (SfM) and photogrammetry packages has enabled a vibrant community of roboticists to apply computer vision for non-destructive plant monitoring. While existing approaches tend to focus on either high-throughput (e.g. satellite, unmanned aerial vehicle (UAV), vehicle-mounted, conveyor-belt imagery) or high-accuracy/robustness to occlusions (e.g. turn-table scanner or robot arm), we propose a middle-ground that achieves high accuracy with a medium-throughput, highly automated robot. Our design pairs the workspace scalability of a cable-driven parallel robot (CDPR) with the dexterity of a 4 degree-of-freedom (DoF) robot arm to autonomously image many plants from a variety of viewpoints. We describe our robot design and demonstrate it experimentally by collecting daily photographs of 54 plants from 64 viewpoints each. We show that our approach can produce scientifically useful measurements, operate fully autonomously after initial calibration, and produce better reconstructions and plant property estimates than those of over-canopy methods (e.g. UAV). As example applications, we show that our system can successfully estimate plant mass with a Mean Absolute Error (MAE) of 0.586g and, when used to perform hypothesis testing on the relationship between mass and age, produces p-values comparable to ground-truth data (p=0.0020 and p=0.0016, respectively).",
        "primary_area": "",
        "author": "Gerry Chen;Harsh Muriki;Andrew Sharkey;C\u00e9dric Pradalier;Yongsheng Chen;Frank Dellaert;Gerry Chen;Harsh Muriki;Andrew Sharkey;C\u00e9dric Pradalier;Yongsheng Chen;Frank Dellaert",
        "authorids": "/37089000441;/37089894899;/37089895654;/37279005400;/37089895776;/37282902200;/37089000441;/37089894899;/37089895654;/37279005400;/37089895776;/37282902200",
        "aff": "Institute for Robotics and Intelligent Machines, Georgia Tech, Atlanta, USA; Institute for Robotics and Intelligent Machines, Georgia Tech, Atlanta, USA; School of Civil and Environmental Engineering, Georgia Tech, Atlanta, USA; CNRS IRL, Georgia Tech Lorraine, France; School of Civil and Environmental Engineering, Georgia Tech, Atlanta, USA; Institute for Robotics and Intelligent Machines, Georgia Tech, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161045/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1557498144685214056&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Georgia Tech;Georgia Tech Lorraine",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines;School of Civil and Environmental Engineering;CNRS IRL",
        "aff_unique_url": "https://www.gatech.edu;https://www.gatech.edu;https://gtl.gatech.edu",
        "aff_unique_abbr": "Georgia Tech;GT;GTL",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Atlanta;Georgia Tech Lorraine",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "10161020",
        "title": "A Hybrid Quadratic Programming Framework for Real-Time Embedded Safety-Critical Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new framework for implementing real-time embedded safety-critical controllers which utilizes hybrid computing to address the issue of limited computational resources, a problem that is particularly prevalent in microrobotics. In our approach, the nominal stabilizing control algorithm is implemented digitally while the safety-critical quadratic program is solved via a dedicated analog resistor array. We apply this hybrid computing architecture to a simulated collision avoidance task for a micro-aerial vehicle and show the benefit relative to a purely-digital implementation. By leveraging analog quadratic programming on the Crazyflie 2.1 micro quadrotor, a reduction in overall processing time from 8.9 ms to 0.6 ms is estimated for this computationally-limited system. We further display the viability of our proposed safety-critical control framework through real-time flight demonstrations, utilizing a novel prototype analog circuit tethered to the Crazyflie. The flight results confirm the functionality of the control structure and prototype circuit while highlighting the overall capabilities of hybrid computing.",
        "primary_area": "",
        "author": "Ryan M. Bena;Sushmit Hossain;Buyun Chen;Wei Wu;Quan Nguyen;Ryan M. Bena;Sushmit Hossain;Buyun Chen;Wei Wu;Quan Nguyen",
        "authorids": "/37088949435;/37089834125;/37089834616;/37089834846;/37085362091;/37088949435;/37089834125;/37089834616;/37089834846;/37085362091",
        "aff": "Viterbi School of Engineering, University of Southern California, Los Angeles, CA, USA; Viterbi School of Engineering, University of Southern California, Los Angeles, CA, USA; Viterbi School of Engineering, University of Southern California, Los Angeles, CA, USA; Viterbi School of Engineering, University of Southern California, Los Angeles, CA, USA; Viterbi School of Engineering, University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161020/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3325626363769103381&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Viterbi School of Engineering",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160446",
        "title": "A Hybrid Steerable Robot with Magnetic Wrist for Minimally Invasive Epilepsy Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Dexterity is demanded for an endoscopic tool to handle complicated procedures in neurosurgery, e.g., removing diseased tissue from inside the deep brain along a tortuous path. Current robotic tools are either rigid or lack wristed motion ability at the tip, leading to limited usage in minimally invasive procedures. In this paper, a hybrid steerable robot with a magnetic wristed forceps is proposed to provide enhanced dexterity for endoscopic epilepsy surgery. A set of three precurved Nitinol tubes with concentric deployment, called a concentric tube robot (CTR), serves as a 6 degrees-of-freedom (DoF) robotic positioner. The magnetic wristed forceps is composed of a rotational wrist joint, and forceps at the tip, both of which are actuated remotely by magnetic fields. The magnetic wrist and forceps provide an extra rotational DoF and a gripping DoF on top of the CTR, respectively. The magnetic wrist and gripper are designed to have a hollow channel along their common axis, inside which a soft tube is deployed as a second functional tool for irrigation or suction. An electromagnetic navigation system (eMNS) with 8 coils is used to create the quasi-static magnetic fields. Experimental characterization of the robot kinematics is performed and the results show the mean motion error of CTR is 2.8 mm. The workspace is also analyzed and results indicate that the proposed hybrid robot has a significantly larger reachable area compared to the one of the CTR alone. Mock epilepsy procedures are performed on a brain phantom to validate the feasibility of the hybrid robot for neurosurgery applications.",
        "primary_area": "",
        "author": "Changyan He;Robert H. Nguyen;Cameron Forbrigger;James Drake;Thomas Looi;Eric Diller;Changyan He;Robert H. Nguyen;Cameron Forbrigger;James Drake;Thomas Looi;Eric Diller",
        "authorids": "/37086493370;/37089892694;/37086690194;/38512992300;/38498292300;/37542880000;/37086493370;/37089892694;/37086690194;/38512992300;/38498292300;/37542880000",
        "aff": "Microrobotics lab, University of Toronto; PCIGITI lab, Hospital for Sick Children; Microrobotics lab, University of Toronto; PCIGITI lab, Hospital for Sick Children; PCIGITI lab, Hospital for Sick Children; Microrobotics lab, University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160446/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8598365227215542308&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;1;0",
        "aff_unique_norm": "University of Toronto;Hospital for Sick Children",
        "aff_unique_dep": "Microrobotics lab;PCIGITI lab",
        "aff_unique_url": "https://www.utoronto.ca;https://www.sickkids.ca",
        "aff_unique_abbr": "U of T;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161041",
        "title": "A Joint Modeling of Vision-Language-Action for Target-oriented Grasping in Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "We focus on the task of language-conditioned grasping in clutter, in which a robot is supposed to grasp the target object based on a language instruction. Previous works separately conduct visual grounding to localize the target object, and generate a grasp for that object. However, these works require object labels or visual attributes for grounding, which calls for handcrafted rules in planner and restricts the range of language instructions. In this paper, we propose to jointly model vision, language and action with object-centric representation. Our method is applicable under more flexible language instructions, and not limited by visual grounding error. Besides, by utilizing the powerful priors from the pre-trained multi-modal model and grasp model, sample efficiency is effectively improved and the sim2real problem is relived without additional data for transfer. A series of experiments carried out in simulation and real world indicate that our method can achieve better task success rate by less times of motion under more flexible language instructions. Moreover, our method is capable of generalizing better to scenarios with unseen objects and language instructions.",
        "primary_area": "",
        "author": "Kechun Xu;Shuqi Zhao;Zhongxiang Zhou;Zizhang Li;Huaijin Pi;Yifeng Zhu;Yue Wang;Rong Xiong;Kechun Xu;Shuqi Zhao;Zhongxiang Zhou;Zizhang Li;Huaijin Pi;Yifeng Zhu;Yue Wang;Rong Xiong",
        "authorids": "/37088916597;/37089892193;/37088809302;/37089893890;/37088458902;/744149483848105;/37072299700;/37271511300;/37088916597;/37089892193;/37088809302;/37089893890;/37088458902;/744149483848105;/37072299700;/37271511300",
        "aff": "Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; University of Texas at Austin, United States; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161041/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14337741368910256960&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Zhejiang University;University of Texas at Austin",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.utexas.edu",
        "aff_unique_abbr": "ZJU;UT Austin",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Hangzhou;Austin",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160676",
        "title": "A Kinematically Redundant (6+1)-dof Hybrid Parallel Robot for Delicate Physical Environment and Robot Interaction (pERI)",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel kinematically redundant 6+1-degree-of-freedom (dof) spatial hybrid parallel robot is proposed. Each of the two legs of the robot has a fully parallel structure to minimize the moving inertia by mounting actuators on the base. The kinematic model of each leg and overall robot architecture is developed based on the constraint conditions of the robot geometry. The singularity analysis of legs 1 and 2 reveals that their serial and parallel singularities can be avoided by properly dimensioning the robot and sacrificing the edge of the workspace. In addition, it is shown that the type II (parallel) singularities can be completely avoided, resulting in a large orientational workspace. The gripping mechanism is then introduced which is operated by the redundant degree of freedom of the robot. A CAD model of the robot and a computer animation are provided to demonstrate the positioning and orientation of the robot and the gripping function.",
        "primary_area": "",
        "author": "Jehyeok Kim;Cl\u00e9ment Gosselin;Jehyeok Kim;Cl\u00e9ment Gosselin",
        "authorids": "/37089895088;/37293911800;/37089895088;/37293911800",
        "aff": "Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, Qc, Canada; Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, Qc, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160676/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9968851687994799385&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e9 Laval",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ulaval.ca",
        "aff_unique_abbr": "ULaval",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Qu\u00e9bec",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160516",
        "title": "A Linear and Exact Algorithm for Whole-Body Collision Evaluation via Scale Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision evaluation is of essential importance in various applications. However, existing methods are either cumbersome to calculate or not exact. Therefore, considering the cost of implementation, most whole-body planning works, which require evaluating collision between robots and environments, struggle to tradeoff between accuracy and computationally efficiency. In this paper, we propose a zero-gap whole-body collision evaluation that can be formulated as a low-dimensional linear programming. This evaluation can be solved analytically in linear complexity. Moreover, the method provides gradient efficiently, making it accessible to optimization-based applications. Additionally, this method provides support for obstacles represented by either points or hyperplanes. Experiments on the widely used aerial and car-like robots validate the versatility and practicality of our method.",
        "primary_area": "",
        "author": "Qianhao Wang;Zhepei Wang;Liuao Pei;Chao Xu;Fei Gao;Qianhao Wang;Zhepei Wang;Liuao Pei;Chao Xu;Fei Gao",
        "authorids": "/37089197978;/37086601081;/37089894334;/37404060100;/37086045143;/37089197978;/37086601081;/37089894334;/37404060100;/37086045143",
        "aff": "Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160516/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6864606314892101752&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160304",
        "title": "A Little Bit Attention Is All You Need for Person Re-Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Person re-identification plays a key role in applications where a mobile robot needs to track its users over a long period of time, even if they are partially unobserved for some time, in order to follow them or be available on demand. In this context, deep-learning-based real-time feature extraction on a mobile robot is often performed on special-purpose devices whose computational resources are shared for multiple tasks. Therefore, the inference speed has to be taken into account. In contrast, person re-identification is often improved by architectural changes that come at the cost of significantly slowing down inference. Attention blocks are one such example. We will show that some well-performing attention blocks used in the state of the art are subject to inference costs that are far too high to justify their use for mobile robotic applications. As a consequence, we propose an attention block that only slightly affects the inference speed while keeping up with much deeper networks or more complex attention blocks in terms of re-identification accuracy. We perform extensive neural architecture search to derive rules at which locations this attention block should be integrated into the architecture in order to achieve the best trade-off between speed and accuracy. Finally, we confirm that the best performing configuration on a re-identification benchmark also performs well on an indoor robotic dataset.",
        "primary_area": "",
        "author": "Markus Eisenbach;Jannik L\u00fcbberstedt;Dustin Aganian;Horst-Michael Gross;Markus Eisenbach;Jannik L\u00fcbberstedt;Dustin Aganian;Horst-Michael Gross",
        "authorids": "/37318406900;/37089893193;/37088981497;/37270612700;/37318406900;/37089893193;/37088981497;/37270612700",
        "aff": "Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160304/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17334085055754261489&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Ilmenau",
        "aff_unique_dep": "Neuroinformatics and Cognitive Robotics Lab",
        "aff_unique_url": "https://www.tu-ilmenau.de",
        "aff_unique_abbr": "TU Ilmenau",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ilmenau",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160755",
        "title": "A Method to Use Haptic Feedback of Laryngoscope Force Vector for Endotracheal Intubation Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Endotracheal intubation is a mandatory competency for most medical staff. This procedure involves opening the entrance of the patient's upper windpipe using a laryngoscope and then inserting a tube into the windpipe to supply Oxygen to the patient. This time critical intervention requires careful control of the force vector on the tongue to lift it parallel to the jaw than to push the jaw to open the mouth. However, traditional intubation training methods in which novices practice intubation on prostheses lack haptic feedback to improve force control. We designed a sensorised intubation training phantom that can provide trainees with vibrotactile feedback reflecting the laryngoscope's force on the tongue. The critical component of this phantom is a silicon rubber tongue embedded with magnets and hall effect sensors. We calibrated the hall effect sensor readings to predict the force vector exerted on the tongue with errors less than 0.5 N in the lifting and pushing directions. We conducted a controlled experiment, mainly comparing the training results between participants with and without haptic feedback. Results show a statistically significant drop in the undesired forces due to haptic feedback, and the skill is retained when tested after 24 hours without haptic feedback.",
        "primary_area": "",
        "author": "Haonan Zhou;Siyu Yang;Lou Halamek;Thrishantha Nanayakkara;Haonan Zhou;Siyu Yang;Lou Halamek;Thrishantha Nanayakkara",
        "authorids": "/37089895393;/37089894802;/37330294300;/37399134000;/37089895393;/37089894802;/37330294300;/37399134000",
        "aff": "Dyson School of Design Engineering, Imperial College London, London, UK; Dyson School of Design Engineering, Imperial College London, London, UK; Department of Pediatrics - Neonatology, Stanford University, USA; Dyson School of Design Engineering, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160755/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10143329111291701765&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Imperial College London;Stanford University",
        "aff_unique_dep": "Dyson School of Design Engineering;Department of Pediatrics - Neonatology",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.stanford.edu",
        "aff_unique_abbr": "Imperial College;Stanford",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "London;Stanford",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "10160634",
        "title": "A Miniaturised Camera-based Multi-Modal Tactile Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "In conjunction with huge recent progress in cam-era and computer vision technology, camera-based sensors have increasingly shown considerable promise in relation to tactile sensing. In comparison to competing technologies (be they resistive, capacitive or magnetic based), they offer super-high-resolution, while suffering from fewer wiring problems. The human tactile system is composed of various types of mechanoreceptors, each able to perceive and process distinct information such as force, pressure, texture, etc. Camera-based tactile sensors such as GelSight mainly focus on high-resolution geometric sensing on a flat surface, and their force measurement capabilities are limited by the hysteresis and non-linearity of the silicone material. In this paper, we present a miniaturised dome-shaped camera-based tactile sensor that allows accurate force and tactile sensing in a single coherent system. The key novelty of the sensor design is as follows. First, we demonstrate how to build a smooth silicone hemispheric sensing medium with uniform markers on its curved surface. Second, we enhance the illumination of the rounded silicone with diffused LEDs. Third, we construct a force-sensitive mechanical structure in a compact form factor with usage of springs to accurately perceive forces. Our multi-modal sensor is able to acquire tactile information from multi-axis forces, local force distribution, and contact geometry, all in real-time. We apply an end-to-end deep learning method to process all the information.",
        "primary_area": "",
        "author": "Kaspar Althoefer;Yonggen Ling;Wanlin Li;Xinyuan Qian;Wang Wei Lee;Peng Qi;Kaspar Althoefer;Yonggen Ling;Wanlin Li;Xinyuan Qian;Wang Wei Lee;Peng Qi",
        "authorids": "/37265264700;/37090018583;/37087031325;/37086008136;/37085402629;/37085342733;/37265264700;/37090018583;/37087031325;/37086008136;/37085402629;/37085342733",
        "aff": "The Centre for Advanced Robotics @ Queen Mary (ARQ), Queen Mary University of London, London, United Kingdom; Tencent Robotics X Lab, Shenzhen, China; Beijing Institute for General Artificial Intelligence (BIGAI), Beijing, China; The Department of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; Tencent Robotics X Lab, Shenzhen, China; Department of Control Science and Engineering, College of Electronics and Information Engineering, Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160634/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15847210055303845041&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;1;4",
        "aff_unique_norm": "Queen Mary University of London;Tencent Robotics X Lab;Beijing Institute for General Artificial Intelligence;University of Science and Technology Beijing;Tongji University",
        "aff_unique_dep": "Centre for Advanced Robotics @ Queen Mary (ARQ);Robotics;;Department of Computer and Communication Engineering;Department of Control Science and Engineering",
        "aff_unique_url": "https://www.qmul.ac.uk;https://www.tencent.com;http://www.bigmodel.cn/;http://www.ustb.edu.cn;https://www.tongji.edu.cn",
        "aff_unique_abbr": "QMUL;Tencent;BIGAI;USTB;Tongji",
        "aff_campus_unique_index": "0;1;2;2;1;3",
        "aff_campus_unique": "London;Shenzhen;Beijing;Shanghai",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "10160224",
        "title": "A Model-Based Analysis of The Effect of Repeated Unilateral Low Stiffness Perturbations on Human Gait: Toward Robot-Assisted Rehabilitation",
        "track": "main",
        "status": "Poster",
        "abstract": "Human gait is quite complex, especially when considering the irregular and uncertain environments that humans are able to walk in. While unperturbed gait in a controlled environment is understood to a large degree, gait in more unique environments, such as asymmetric compliant terrain, is not understood to the same degree. In this study, we build upon a neuromuscular gait model and extend it to allow for walking on unilaterally compliant (soft) surfaces. This model is then compared to and verified by experimental human data. The model can successfully walk with step length trends similar to human data. Additionally, the model shows similar behaviors with respect to kinematics and muscle activity. We believe this work contributes significantly to a better understanding of the control of human gait and could lead to model-informed, patient-specific rehabilitation strategies that can advance the field of rehabilitation robotics, as well as the development of bio-inspired controllers for bipedal robots that would be able to traverse through dynamic and complaint terrains.",
        "primary_area": "",
        "author": "Vaughn Chambers;Panagiotis Artemiadis;Vaughn Chambers;Panagiotis Artemiadis",
        "authorids": "/37088848452;/38495840200;/37088848452;/38495840200",
        "aff": "Mechanical Engineering Department, University of Delaware, Newark, DE, USA; Mechanical Engineering Department, University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160224/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8253511619521499830&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161323",
        "title": "A Moving Target Tracking System of Quadrotors with Visual-Inertial Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper implements a vision-based moving target tracking system of quadrotors with visual-inertial localization in GNSS-denied indoor environments. We use the visual-inertial odometry to estimate the states of the UAV by minimizing visual and inertial residuals, and estimate the states of the target with extended Kalman Filter from visual detection. This research formulates the target tracking problem as optimization-based trajectory generation where a weighted sum cost function jointly penalizes the tracking error, the control cost of the trajectory and the trajectory length, while enforcing the safety and feasibility constraints. We present a strategy that represents the trajectory as piecewise B\u00e9zier curves using Bernstein polynomial basis. Due to the special properties of B\u00e9zier curves, the position of the entire trajectory and its derivatives can be directly bounded within the safe spaces, thus this facilitating the dynamics of the quadrotor. The proposed strategy can generate smooth and collision-free tracking trajectories and is time and space efficient. We conduct simulations and real-world experiments to validate the effectiveness of our system.",
        "primary_area": "",
        "author": "Ziyue Lin;Wenbo Xu;Wei Wang;Ziyue Lin;Wenbo Xu;Wei Wang",
        "authorids": "/37089508067;/37089505708;/37089502265;/37089508067;/37089505708;/37089502265",
        "aff": "Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161323/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18115327257576740674&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "Institute of Automation",
        "aff_unique_url": "http://www.ia.cas.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160909",
        "title": "A Multi-Agent Approach for Adaptive Finger Cooperation in Learning-based In-Hand Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In-hand manipulation is challenging for a multi-finger robotic hand due to its high degrees of freedom and complex interaction with the object. To enable in-hand manipulation, existing deep reinforcement learning-based approaches mainly focus on training a single robot-structure-specific policy through the centralized learning mechanism, lacking adaptability to changes like robot malfunction. To solve this limitation, this work treats each finger as an individual agent and trains multiple agents to control their assigned fingers to complete the in-hand manipulation task cooperatively. We propose the Multi-Agent Global-Observation Critic and Local-Observation Actor (MAGCLA) method, where the critic can observe all agents' actions globally, and the actor only locally observes its neighbors' actions. Besides, conventional individual experience replay may cause unstable cooperation due to the asynchronous performance increment of each agent, which is critical for in-hand manipulation tasks. To solve this issue, we propose the Synchronized Hindsight Experience Replay (SHER) method to synchronize and efficiently reuse the replayed experience across all agents. The methods are evaluated in two in-hand manipulation tasks on the Shadow dexterous hand. The results show that SHER helps MAGCLA achieve comparable learning efficiency to a single policy, and the MAGCLA approach is more generalizable in different tasks. The trained policies have higher adaptability in the robot malfunction test compared to the baseline multi-agent and single-agent approaches.",
        "primary_area": "",
        "author": "Lingfeng Tao;Jiucai Zhang;Michael Bowman;Xiaoli Zhang;Lingfeng Tao;Jiucai Zhang;Michael Bowman;Xiaoli Zhang",
        "authorids": "/37089191377;/37086672416;/37086937096;/37085581881;/37089191377;/37086672416;/37086937096;/37085581881",
        "aff": "Intelligent Robotics and Systems Lab, Colorado School of Mines, Golden, CO; GAC R&D Center Silicon Valley, Sunnyvale, CA, USA; Intelligent Robotics and Systems Lab, Colorado School of Mines, Golden, CO; Intelligent Robotics and Systems Lab, Colorado School of Mines, Golden, CO",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160909/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2220270125213758342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Colorado School of Mines;GAC R&D Center",
        "aff_unique_dep": "Intelligent Robotics and Systems Lab;R&D",
        "aff_unique_url": "https://www.mines.edu;",
        "aff_unique_abbr": "CSM;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Golden;Silicon Valley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161330",
        "title": "A Multi-step Dynamics Modeling Framework For Autonomous Driving In Multiple Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling dynamics is often the first step to making a vehicle autonomous. While on-road autonomous vehicles have been extensively studied, off-road vehicles pose many challenging modeling problems. An off-road vehicle encounters highly complex and difficult-to-model terrain/vehicle interactions, as well as having complex vehicle dynamics of its own. These complexities can create challenges for effective high-speed control and planning. In this paper, we introduce a framework for multistep dynamics prediction that explicitly handles the accumulation of modeling error and remains scalable for sampling-based controllers. Our method uses a specially-initialized Long Short-Term Memory (LSTM) over a limited time horizon as the learned component in a hybrid model to predict the dynamics of a 4-person seating all-terrain vehicle (Polaris S4 1000 RZR) in two distinct environments. By only having the LSTM predict over a fixed time horizon, we negate the need for long term stability that is often a challenge when training recurrent neural networks. Our framework is flexible as it only requires odometry information for labels. Through extensive experimentation, we show that our method is able to predict millions of possible trajectories in real-time, with a time horizon of five seconds in challenging off road driving scenarios.",
        "primary_area": "",
        "author": "Jason Gibson;Bogdan Vlahov;David Fan;Patrick Spieler;Daniel Pastor;Ali-akbar Agha-mohammadi;Evangelos A. Theodorou;Jason Gibson;Bogdan Vlahov;David Fan;Patrick Spieler;Daniel Pastor;Ali-akbar Agha-mohammadi;Evangelos A. Theodorou",
        "authorids": "/37087413994;/37086612248;/37086010932;/37088504609;/37087323301;/38274170800;/37546007800;/37087413994;/37086612248;/37086010932;/37088504609;/37087323301;/38274170800;/37546007800",
        "aff": "Autonomous Control and Decision Systems Lab, Georgia Institute of Technology, Atlanta, GA, USA; Autonomous Control and Decision Systems Lab, Georgia Institute of Technology, Atlanta, GA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Autonomous Control and Decision Systems Lab, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161330/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3451169911392081259&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;California Institute of Technology",
        "aff_unique_dep": "Autonomous Control and Decision Systems Lab;NASA Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.gatech.edu;https://www.caltech.edu",
        "aff_unique_abbr": "Georgia Tech;Caltech",
        "aff_campus_unique_index": "0;0;1;1;1;1;0",
        "aff_campus_unique": "Atlanta;Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160417",
        "title": "A MySQL Database for the Systematic Configuration Selection of Redundant Manipulators when Path Planning in Confined Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Redundant manipulators offer a continuum of joint configurations which satisfy a specific end-effector pose, an advantage when operating within confined spaces. This, how-ever, challenges a controller to select a single goal configuration from a wide range when path planning. This paper outlines the use of the MySQL database management system for systematic goal selection during redundant manipulator path planning in confined spaces. We outline a sampling method to envelope all configurations of a redundant manipulator and utilise it to generate a complete database of configurations. We demonstrate the application of this method to generate a large data-set of (1 billion) manipulator configurations for a KUKA LBR iiwa 14 equipped with a Robotiq 2F-85 gripper. With this database, the controller systematically selects goal configurations during 50 path planning scenarios within the confined space of a glovebox. We compare this to an iterative method using existing kinematic solvers to select goal configurations as a baseline. The database method achieves a 100% success rate in 42% of the scenarios attempted. In comparison, the baseline method achieves >50% success rate in just 6% of the scenarios attempted. Our proposed method also produces repeatable paths, which are similar in length and link swept area for each attempt of the same scenario, whereas the baseline method generates a different path in every attempt.",
        "primary_area": "",
        "author": "Kat Styles Wood;Thomas B. Scott;Antonia Tzemanaki;Kat Styles Wood;Thomas B. Scott;Antonia Tzemanaki",
        "authorids": "/37089894745;/38092196900;/37085386549;/37089894745;/38092196900;/37085386549",
        "aff": "University of the West of England, UK; Interface Analysis Centre, University of Bristol, UK; Bristol Robotics Laboratory, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160417/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:o_vRY3dAsf4J:scholar.google.com/&scioq=A+MySQL+Database+for+the+Systematic+Configuration+Selection+of+Redundant+Manipulators+when+Path+Planning+in+Confined+Spaces&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of the West of England;University of Bristol",
        "aff_unique_dep": ";Interface Analysis Centre",
        "aff_unique_url": "https://www.uwe.ac.uk;https://www.bristol.ac.uk",
        "aff_unique_abbr": "UWE;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Bristol",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160850",
        "title": "A Negative Imaginary Theory-Based Time-Varying Group Formation Tracking Scheme for Multi-Robot Systems: Applications to Quadcopters",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new methodology to develop a time-varying group formation tracking scheme for a class of multi-agent systems (e.g. different types of multi-robot systems) utilising Negative Imaginary (NI) theory. It offers a two-loop control scheme in which the inner loop deploys an appropriate feedback linearising control law to transform the nonlinear dynamics of each agent into a double integrator system, while the outer loop applies an NI-based time-varying group formation control protocol on the linearised agents. This approach offers greater flexibility in choosing a controller, easy implementation and tuning, reduces the overall complexity of the scheme, and uses only output feedback (hence reduced sensing requirements) to achieve formation control in contrast to the existing formation control schemes. The paper has also provided lab-based experimental validation results to demonstrate the feasibility and usefulness of the proposed scheme. Two experiments were conducted on a group of small-scale quadcopters connected via a network to test the time-varying group formation tracking performance.",
        "primary_area": "",
        "author": "Yu-Hsiang Su;Parijat Bhowmick;Alexander Lanzon;Yu-Hsiang Su;Parijat Bhowmick;Alexander Lanzon",
        "authorids": "/37089446765;/37085780963;/38493292500;/37089446765;/37085780963;/38493292500",
        "aff": "Department of EEE, School of Engineering, University of Manchester, Manchester, UK; Department of EE, IIT, Guwahati, Assam, India; Department of EEE, School of Engineering, University of Manchester, Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160850/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15821742399118224658&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Manchester;Indian Institute of Technology Guwahati",
        "aff_unique_dep": "Department of EEE;Department of Electrical Engineering",
        "aff_unique_url": "https://www.manchester.ac.uk;https://www.iitg.ac.in",
        "aff_unique_abbr": "UoM;IIT Guwahati",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Manchester;Guwahati",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;India"
    },
    {
        "id": "10161347",
        "title": "A New Efficient Eye Gaze Tracker for Robotic Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Gaze estimation provides insight into a person's intent and engagement level, which is helpful in collaborative human-robot applications. With significant advancements in deep learning architectures, appearance-based gaze estimation has gained much attention. Appearance-based methods have shown significant improvement in gaze accuracy and, unlike traditional approaches, they function well in environments where there are no constraints. We present another convolution-based gaze estimation approach to further reduce the angular error. For estimating gaze under extreme conditions such as head variations and distances, full-face images have been shown to be efficient, so we rely on full-face and pay more attention to necessary features. With the proposed architecture, we achieve an accuracy of 3.75\u00b0 on the MPIIFaceGaze dataset and 3.96\u00b0 on the ETH-XGaze open-source dataset. In addition, we test eye gaze tracking in real-time robotic applications, such as attention detection, and pick-and-place.",
        "primary_area": "",
        "author": "Chaitanya Bandi;Ulrike Thomas;Chaitanya Bandi;Ulrike Thomas",
        "authorids": "/37089233962;/37281523200;/37089233962;/37281523200",
        "aff": "Department of Robotics, Human Machine Interaction Lab, Technical university of Chemnitz, Germany; Department of Robotics, Human Machine Interaction Lab, Technical university of Chemnitz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161347/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12973175239404509269&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Chemnitz",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160485",
        "title": "A New Robust Control Framework for Robot Manipulators without Velocity Measurements: A Modified Dual-loop Control Scheme",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new framework for the computed torque method (CTM) of robot manipulators without velocity measurements. We first introduce the Luenberger-observer-based CTM with only position measurements. We then clarify that the external disturbance affects not only the tracking performances with respect to the plant but also the estimation accuracies relevant to the state observer. To address this problem, we establish a new architecture for the so-called dual-loop control scheme, by which both the tracking performances and estimation accuracies can be simultaneously improved, in contrast to its existing structure. A guideline for taking control parameters corresponding to the proposed control structure is also provided with respect to the stabilization of the overall closed-loop systems. Finally, simulation and experimental results are provided to demonstrate the validity and practical feasibility of the developed structure.",
        "primary_area": "",
        "author": "Hae Yeon Park;Jung Hoon Kim;Hae Yeon Park;Jung Hoon Kim",
        "authorids": "/37088945460;/37407273800;/37088945460;/37407273800",
        "aff": "Department of Electrical Engineering, Pohang University of Science and Technology (POSTECR), Pohang, South Korea; Department of Electrical Engineering, Pohang University of Science and Technology (POSTECR), Pohang, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160485/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:lHneOST6aKsJ:scholar.google.com/&scioq=A+New+Robust+Control+Framework+for+Robot+Manipulators+without+Velocity+Measurements:+A+Modified+Dual-loop+Control+Scheme&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160284",
        "title": "A New Sensation: Digital Strain Sensing for Disturbance Detection In Flapping Wing Micro Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Flapping wing micro aerial vehicles face challenges in sensing and reacting to disturbances like wind gusts. This work introduces a new microscale bio-inspired digital strain sensor to detect these perturbations. The sensor is designed to change logic states when a specified strain threshold has been reached. The sensors are 3D printed on a flexible Mylar wing using two-photon polymerization. Three digital sensors with varying strain thresholds demonstrate differences in activation timing due to different design parameters. The sensors are tested at the 25 Hz flapping frequency of a hawkmoth, an insect with comparable wing size. A perturbation was added to the flapping wing by subjecting it to a 3 m/s wind gust. A single digital sensor is able to identify the wind disturbance by comparing the time of the first strain threshold crossing. A separate approach looks at the change in sensor \u2018on\u2019-time for each flap cycle and provides a clear indication of the wind disturbance.",
        "primary_area": "",
        "author": "Regan Kubicek;Mahnoush Babaei;Alison I. Weber;Sarah Bergbreiter;Regan Kubicek;Mahnoush Babaei;Alison I. Weber;Sarah Bergbreiter",
        "authorids": "/37088690293;/37088359355;/37089893749;/37542605000;/37088690293;/37088359355;/37089893749;/37542605000",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Aerospace Engineering and Engineering Mechanics, The University of Texas at Austin, Austin, TX, USA; Department of Biology, University of Washington, Seattle, WA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160284/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9263676073910890476&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Carnegie Mellon University;The University of Texas at Austin;University of Washington",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Aerospace Engineering and Engineering Mechanics;Department of Biology",
        "aff_unique_url": "https://www.cmu.edu;https://www.utexas.edu;https://www.washington.edu",
        "aff_unique_abbr": "CMU;UT Austin;UW",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Pittsburgh;Austin;Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161065",
        "title": "A Non-parametric Skill Representation with Soft Null Space Projectors for Fast Generalization",
        "track": "main",
        "status": "Poster",
        "abstract": "Over the last two decades, the robotics community witnessed the emergence of various motion representations that have been used extensively, particularly in behavorial cloning, to compactly encode and generalize skills. Among these, probabilistic approaches have earned a relevant place, owing to their encoding of variations, correlations and adaptability to new task conditions. Modulating such primitives, however, is often cumbersome due to the need for parameter re-optimization which frequently entails computationally costly operations. In this paper we derive a non-parametric movement primitive formulation that contains a null space projector. We show that such formulation allows for fast and efficient motion generation and adaptation with computational complexity O(n2) without involving matrix inversions, whose complexity is O(n3). This is achieved by using the null space to track secondary targets, with a precision determined by the training dataset. Using a 2D example associated with time input we show that our non-parametric solution compares favourably with a state-of-the-art parametric approach. For demonstrated skills with high-dimensional inputs we show that it permits on-the-fly adaptation as well.",
        "primary_area": "",
        "author": "Jo\u00e3o Silv\u00e9rio;Yanlong Huang;Jo\u00e3o Silv\u00e9rio;Yanlong Huang",
        "authorids": "/37085736048;/37086454561;/37085736048;/37086454561",
        "aff": "German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u03b2ling, Germany; School of Computing, University of Leeds, Leeds, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161065/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3579888940227841659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "German Aerospace Center;University of Leeds",
        "aff_unique_dep": "Robotics and Mechatronics Center;School of Computing",
        "aff_unique_url": "https://www.dlr.de;https://www.leeds.ac.uk",
        "aff_unique_abbr": "DLR;Leeds",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Leeds",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "10161301",
        "title": "A Non-planar Assembly of Modular Tetrahedral-shaped Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new design of aerial vehicles with tetrahedral geometry. We call this design the TetraQuad. The TetraQuad is a fractal modular aerial robot. A characteristic of fractals is that they have a geometric shape that can be assembled to generate the same geometry on a larger scale. Therefore multiple TetraQuad modules can be assembled to produce a larger scaled tetrahedral shaped aerial vehicle. The advantage is to have modular aerial robots that assemble in the vertical direction; this increases the rigidity of the structure, as well as reduces the wake interaction of the elevated propellers in the assembly. This work presents a design and analysis of the TetraQuad module as well as assemblies of multiple modules. A modular controller strategy is discussed. The functionality of the controller is illustrated using simulations. We validate our design with experimental flight tests.",
        "primary_area": "",
        "author": "Obadah Wali;Mohamad T. Shahab;Eric Feron;Obadah Wali;Mohamad T. Shahab;Eric Feron",
        "authorids": "/37089893152;/37086595927;/37283412000;/37089893152;/37086595927;/37283412000",
        "aff": "Robotics, Intelligent Systems, and Control (RISC) Lab, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Robotics, Intelligent Systems, and Control (RISC) Lab, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Robotics, Intelligent Systems, and Control (RISC) Lab, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161301/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17740772251774552811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "King Abdullah University of Science and Technology",
        "aff_unique_dep": "Robotics, Intelligent Systems, and Control (RISC) Lab",
        "aff_unique_url": "https://www.kaust.edu.sa",
        "aff_unique_abbr": "KAUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Thuwal",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Saudi Arabia"
    },
    {
        "id": "10160814",
        "title": "A Novel Concentric Tube Steerable Drilling Robot for Minimally Invasive Treatment of Spinal Tumors Using Cavity and U-shape Drilling Techniques",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the design, fabrication, and evaluation of a novel flexible, yet structurally strong, Concentric Tube Steerable Drilling Robot (CT-SDR) to improve minimally invasive treatment of spinal tumors. Inspired by concentric tube robots, the proposed two degree-of-freedom (DoF) CT-SDR, for the first time, not only allows a surgeon to intuitively and quickly drill smooth planar and out-of-plane J- and U- shape curved trajectories, but it also, enables drilling cavities through a hard tissue in a minimally invasive fashion. We successfully evaluated the performance and efficacy of the proposed CT-SDR in drilling various planar and out-of-plane J-shape branch, U-shape, and cavity drilling scenarios on simulated bone materials.",
        "primary_area": "",
        "author": "Susheela Sharma;Ji H. Park;Jordan P. Amadio;Mohsen Khadem;Farshid Alambeigi;Susheela Sharma;Ji H. Park;Jordan P. Amadio;Mohsen Khadem;Farshid Alambeigi",
        "authorids": "/37089849223;/37089892796;/37089850405;/37085447737;/38542997100;/37089849223;/37089892796;/37089850405;/37085447737;/38542997100",
        "aff": "Department of Mechanical Engineering and the Texas, Robotics at the University of Texas at Austin, Austin, TX, USA; Department of Mechanical Engineering and the Texas, Robotics at the University of Texas at Austin, Austin, TX, USA; Department of Neurosurgery, The University of Texas Dell Medical School, TX, USA; School of Informatics, University of Edinburgh, UK; Department of Mechanical Engineering and the Texas, Robotics at the University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160814/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3840368532250584647&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of Texas at Austin;The University of Texas Dell Medical School;University of Edinburgh",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Neurosurgery;School of Informatics",
        "aff_unique_url": "https://www.utexas.edu;https://dellmed.utexas.edu;https://www.ed.ac.uk",
        "aff_unique_abbr": "UT Austin;UT Dell Med;Edinburgh",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Austin;Edinburgh",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "10160471",
        "title": "A Novel Platform to Control Biofouling in Pearl Oysters Cultivation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a simple yet effective design of a platform to automate the task of shellfish aquaculture, specifically pearl oysters. Compared to traditional methods, our platform can eliminate the tedious task of cleaning the pearl oysters due to fouling. Inspired by the low and high tide characteristics of the intertidal zone, our platform employs an air-water displacement mechanism to periodically float pearl oysters above the water's surface, exposing fouling organisms to air and sunlight. While pearl oysters have developed the ability to stay alive during low tide, these fouling organisms cannot survive after prolonged exposure, thus preventing them from developing. Additionally, the platform provides an alternative approach to grow not only pearl oysters but also various types of shellfish, consequently benefiting the aquaculture industry. We introduce the design of the platform and provide a comprehensive analysis. We also demonstrate the practical deployment of the platform for cultivating pearl oysters.",
        "primary_area": "",
        "author": "Van-Nhan Tran;Quan-Dung Pham;Tan-Sang Ha;Yue Him Wong;Sai-Kit Yeung;Van-Nhan Tran;Quan-Dung Pham;Tan-Sang Ha;Yue Him Wong;Sai-Kit Yeung",
        "authorids": "/37089893911;/37089893032;/37089893761;/37089892508;/37529101500;/37089893911;/37089893032;/37089893761;/37089892508;/37529101500",
        "aff": "Division of Integrative Systems and Design, School of Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong SAR; Division of Integrative Systems and Design, School of Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong SAR; Department of Computer Science and Engineering, School of Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong SAR; Institute for Advanced Study, Shenzhen University, Shenzhen, Guangdong, China; Department of Computer Science and Engineering, School of Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong SAR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160471/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7350048359049696647&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Shenzhen University",
        "aff_unique_dep": "Division of Integrative Systems and Design;Institute for Advanced Study",
        "aff_unique_url": "https://www.ust.hk;https://www.szu.edu.cn",
        "aff_unique_abbr": "HKUST;SZU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160366",
        "title": "A Passivity-based Approach on Relocating High-Frequency Robot Controller to the Edge Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots become more and more intelligent, the complexity of the algorithms behind them is increasing. Since these algorithms require high computation power from the onboard robot controller, the weight of the robot and energy consumption increases. A promising solution to tackle this issue is to relocate the expensive computation to the cloud. In this pioneering work, the possibility of relocating a state-of-the-art nonlinear control is investigated. To this end, the Unified Force-Impedance Controller (UFIC) is relocated to a remote location and high frequency feedback loop is established by including the remote controller in the loop. Passivity analysis is used to ensure the stability of the whole system, comprising the robot in interaction with the environment, the communication channel, as well as the remote controller. The instability associated with the communication channel is resolved by Time Domain Passivity Approach (TDPA). The performance of the proposed framework is experimentally evaluated on a robot arm in interaction with the environment. The results illustrate the stability of the system to a time-varying delay of up to 50 \u00b1 10ms.",
        "primary_area": "",
        "author": "Xiao Chen;Hamid Sadeghian;Lingyun Chen;Mario Tr\u00f6binger;Abadalla Swirkir;Abdeldjallil Naceri;Sami Haddadin;Xiao Chen;Hamid Sadeghian;Lingyun Chen;Mario Tr\u00f6binger;Abadalla Swirkir;Abdeldjallil Naceri;Sami Haddadin",
        "authorids": "/37088992427;/38539589600;/37089198301;/37088863248;/37089894530;/37546043900;/37542865300;/37088992427;/38539589600;/37089198301;/37088863248;/37089894530;/37546043900;/37542865300",
        "aff": "Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Faculty of Engineering, University of Isfahan, Isfahan, Iran; Centre for Tactile Internet with Human-in-the-Loop (CeTI); Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Department of Electrical and Electronic Engineering, Omar Al-Mukhtar University (OMU), Albaida, Libya; Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Centre for Tactile Internet with Human-in-the-Loop (CeTI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160366/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12632459913291319342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;3;0;2",
        "aff_unique_norm": "Technical University of Munich;University of Isfahan;Centre for Tactile Internet with Human-in-the-Loop;Omar Al-Mukhtar University",
        "aff_unique_dep": "Munich Institute of Robotics and Machine Intelligence;Faculty of Engineering;;Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.tum.de;http://www.ui.ac.ir;;",
        "aff_unique_abbr": "TUM;;CeTI;OMU",
        "aff_campus_unique_index": "0;1;0;3;0",
        "aff_campus_unique": "Munich;Isfahan;;Albaida",
        "aff_country_unique_index": "0;1;0;3;0",
        "aff_country_unique": "Germany;Iran;;Libya"
    },
    {
        "id": "10160420",
        "title": "A Performance Optimization Strategy Based on Improved NSGA-II for a Flexible Robotic Fish",
        "track": "main",
        "status": "Poster",
        "abstract": "The high speed and low energy cost are two conflicting objectives in the motion optimization of bio-inspired underwater robots, but playing a very important role. To this end, this paper proposes an optimization strategy for swimming speed and power cost using an improved NSGA-II for a flexible robotic fish. A dynamic model involving flexible deformation is established for speed prediction with the hydrodynamic parameters identified. A back propagation (BP) neural network is applied to perform compensation of power cost prediction with the dynamic model's prediction as input. In particular, an NSGA-II-AMS method is developed to improve the efficiency of solving the two-objective optimization problem based on NSGA-II. Finally, extensive simulations and experimental results demonstrate the effectiveness of the proposed optimization strategy, which offers promising prospects for the flexible robotic fish performing aquatic tasks with different performance constraints.",
        "primary_area": "",
        "author": "Ben Lu;Jian Wang;Xiaocun Liao;Qianqian Zou;Min Tan;Chao Zhou;Ben Lu;Jian Wang;Xiaocun Liao;Qianqian Zou;Min Tan;Chao Zhou",
        "authorids": "/37087244033;/37086447299;/37088950438;/37087244007;/37274596200;/37876898300;/37087244033;/37086447299;/37088950438;/37087244007;/37274596200;/37876898300",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160420/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12526142069982442418&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence",
        "aff_unique_url": "http://www.ucas.ac.cn",
        "aff_unique_abbr": "UCAS",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160659",
        "title": "A Plug-In Weight-Shifting Module That Adds Emotional Expressiveness to Inanimate Objects in Handheld Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "A plug-in weight-shifting module that can be inserted into a variety of objects is presented. The module is equipped with a movable weight inside its body. Three-dimensional weight shifts are presented by controlling one-dimensional translational and two-dimensional rotational movements. To explore the use case of this weight-shifting module, eight weight shift patterns expressing certain emotions were created through a workshop and a qualitative analysis. User tests, to which three different embodiments and scenarios were applied, examined the following three cases: the weight shift patterns were presented to the user by a) a stuffed toy-style robot that mediated human messaging, b) a cushion that made the user relax, and c) a container that enhanced the user's movie-watching experience. User interviews revealed the feasibility of the module and its weight shift patterns for the user's perception of emotions.",
        "primary_area": "",
        "author": "Yohei Noguchi;Yijie Guo;Fumihide Tanaka;Yohei Noguchi;Yijie Guo;Fumihide Tanaka",
        "authorids": "/37086336166;/37089895498;/37273293100;/37086336166;/37089895498;/37273293100",
        "aff": "University of Tsukuba, Tsukuba, Japan; University of Tsukuba, Tsukuba, Japan; University of Tsukuba, Tsukuba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160659/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14596861715925032451&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tsukuba",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tsukuba.ac.jp",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tsukuba",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161079",
        "title": "A Preliminary Study of the Effects of Active Recovery Reflexes on Stumble Recovery in a Swing-Assist Knee Prosthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores the effects of a swing phase stumble recovery controller in a swing-assist prosthesis. The prosthesis detects a stumble event and employs either a lowering recovery response - wherein the user's swing is truncated, and the leg is prepared for loading- or an elevating recovery response - wherein an amplified swing flexion is employed to step over the obstacle causing the perturbation. The controller described in this paper choses which of these responses to use based on the perturbation timing within the gait cycle, where stumble events which occur prior to an estimated 35 percent of the way through swing trigger an elevating response, and later stumbles trigger a lowering response. The potential efficacy of this approach was assessed in a preliminary study with two participants with transfemoral amputation; wherein each participant's walking was perturbed in early, mid, and late swing phase when wearing both their prescribed prosthesis and the swing-assist prosthesis prototype. When wearing the swing- assist device, 0 of the 13 perturbations resulted in falls, with none of the trials being classifiable as \u201cnear falls\u201d. Conversely, when using their prescribed device, one participant had a fall rate of 3 out of 6 perturbations, with 1 of the 3 recoveries being classifiable as a \u201cnear fall\u201d; the second participant had a fall rate of 0 of 3 trials, with 2 of the 3 recoveries being classifiable as \u201cnear falls\u201d. For both participants, when recovery was achieved, it was accompanied by significantly longer periods of irregularity and asymmetry in gait when using their prescribed devices, as compared to the test device. These results suggest the possibility of substantial benefit provided by a low-power, reflex- based stumble recovery feature in knee prostheses.",
        "primary_area": "",
        "author": "Jantzen Lee;Shane King;Maura Eveld;Michael Goldfarb;Jantzen Lee;Shane King;Maura Eveld;Michael Goldfarb",
        "authorids": "/37087995415;/37088801351;/37089196943;/37284476400;/37087995415;/37088801351;/37089196943;/37284476400",
        "aff": "Vanderbilt University, Nashville, TN, USA; Vanderbilt University; Vanderbilt University; Vanderbilt University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161079/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4648295973495050301&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Nashville;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160466",
        "title": "A Probabilistic Framework for Visual Localization in Ambiguous Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual localization allows autonomous robots to relocalize when losing track of their pose by matching their current observation with past ones. However, ambiguous scenes pose a challenge for such systems, as repetitive structures can be viewed from many distinct, equally likely camera poses, which means it is not sufficient to produce a single best pose hypothesis. In this work, we propose a probabilistic framework that for a given image predicts the arbitrarily shaped posterior distribution of its camera pose. We do this via a novel formulation of camera pose regression using variational inference, which allows sampling from the predicted distribution. Our method outperforms existing methods on localization in ambiguous scenes. We open-source our approach and share our recorded data sequence at github.com/efreidun/vapor.",
        "primary_area": "",
        "author": "Fereidoon Zangeneh;Leonard Bruns;Amit Dekel;Alessandro Pieropan;Patric Jensfelt;Fereidoon Zangeneh;Leonard Bruns;Amit Dekel;Alessandro Pieropan;Patric Jensfelt",
        "authorids": "/37089895891;/37087135414;/37088457542;/37077859100;/37281289200;/37089895891;/37087135414;/37088457542;/37077859100;/37281289200",
        "aff": "Univrses AB, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden; Univrses AB, Stockholm, Sweden; Univrses AB, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160466/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6095345187662978632&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Univrses AB;KTH Royal Institute of Technology",
        "aff_unique_dep": ";Division of Robotics, Perception and Learning",
        "aff_unique_url": ";https://www.kth.se",
        "aff_unique_abbr": ";KTH",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Stockholm",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "10161236",
        "title": "A Probabilistic Model of Activity Recognition with Loose Clothing",
        "track": "main",
        "status": "Poster",
        "abstract": "Human activity recognition has become an attractive research area with the development of on-body wearable sensing technology. With comfortable electronic-textiles, sensors can be embedded into clothing so that it is possible to record human movement outside the laboratory for long periods. However, a long-standing issue is how to deal with motion artifact introduced by movement of clothing with respect to the body. Surprisingly, recent empirical findings suggest that cloth-attached sensor can actually achieve higher accuracy of activity recognition than rigid-attached sensor, particularly when predicting from short time-windows. In this work, a probabilistic model is introduced in which this improved accuracy and resposiveness is explained by the increased statistical distance between movements recorded via fabric sensing. The predictions of the model are verified in simulated and real human motion capture experiments, where it is evident that this counterintuitive effect is closely captured.",
        "primary_area": "",
        "author": "Tianchen Shen;Irene Di Giulio;Matthew Howard;Tianchen Shen;Irene Di Giulio;Matthew Howard",
        "authorids": "/37089894652;/37087153072;/37301483600;/37089894652;/37087153072;/37301483600",
        "aff": "Department of Engineering, Centre for Robotics Research, King's College, London, UK; Centre for Human and Applied Physiological Sciences, King's College, London, UK; Department of Engineering, Centre for Robotics Research, King's College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161236/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11301494796202972370&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "King's College London",
        "aff_unique_dep": "Department of Engineering",
        "aff_unique_url": "https://www.kcl.ac.uk",
        "aff_unique_abbr": "KCL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160682",
        "title": "A Probabilistic Rotation Representation for Symmetric Shapes With an Efficiently Computable Bingham Loss Function",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, a deep learning framework has been widely used for object pose estimation. While quaternion is a common choice for rotation representation, it cannot represent the ambiguity of the observation. In order to handle the ambiguity, the Bingham distribution is one promising solution. However, it requires complicated calculation when yielding the negative log-likelihood (NLL) loss. An alternative easy-to-implement loss function has been proposed to avoid complex computations but has difficulty expressing symmetric distribution. In this paper, we introduce a fast-computable and easy-to-implement NLL loss function for Bingham distribution. We also create the inference network and show that our loss function can capture the symmetric property of target objects from their point clouds.",
        "primary_area": "",
        "author": "Hiroya Sato;Takuya Ikeda;Koichi Nishiwaki;Hiroya Sato;Takuya Ikeda;Koichi Nishiwaki",
        "authorids": "/37089448273;/38548213300;/37089658862;/37089448273;/38548213300;/37089658862",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Woven Planet Holdings, Inc., Chuo City, Tokyo, Japan; Woven Planet Holdings, Inc., Chuo City, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160682/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8234837070238967172&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "The University of Tokyo;Woven Planet Holdings, Inc.",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.wovenplanet.com",
        "aff_unique_abbr": "UTokyo;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160294",
        "title": "A Reachability Tree-Based Algorithm for Robot Task and Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel algorithm for robot task and motion planning (TAMP) problems by utilizing a reachability tree. While tree-based algorithms are known for their speed and simplicity in motion planning (MP), they are not well-suited for TAMP problems that involve both abstracted and geometrical state variables. To address this challenge, we propose a hierarchical sampling strategy, which first generates an abstracted task plan using Monte Carlo tree search (MCTS) and then fills in the details with a geometrically feasible motion trajectory. Moreover, we show that the performance of the proposed method can be significantly enhanced by selecting an appropriate reward for MCTS and by using a pre-generated goal state that is guaranteed to be geometrically feasible. A comparative study using TAMP benchmark problems demonstrates the effectiveness of the proposed approach.",
        "primary_area": "",
        "author": "Kanghyun Kim;Daehyung Park;Min Jun Kim;Kanghyun Kim;Daehyung Park;Min Jun Kim",
        "authorids": "/37089892846;/37085429958;/38239144100;/37089892846;/37085429958;/38239144100",
        "aff": "School of Electrical Engineering, Daejeon, Republic of Korea; School of Computing, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160294/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11749028409768555050&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "School of Electrical Engineering;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Electrical Engineering;School of Computing",
        "aff_unique_url": ";https://www.kaist.ac.kr",
        "aff_unique_abbr": ";KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160438",
        "title": "A Robotic Cooperative Network for Localising a Submarine in Distress: Results From REPMUS21",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomy, cooperation and data fusion can increase the performance of robotic networks in many underwater applications. In this paper, we describe a novel occupancy grid (OG) based perception layer, and its use for controlling a network of autonomous underwater vehicles (AUVs), sensorised with passive sonars. Data fusion between the robots' bearing-only measurements (typical of passive sonars) enables the estimate of target position. The developed OG framework exploits networking and the spatial diversity provided by the multi-robot system. The perception layer was integrated in the intelligent Cooperative Autonomous Decision Making Engine (iCADME) control architecture and validated for the first time in the Robotics Experimentation and Prototyping MUS (REPMUS) Exercise, held in Portugal in September 2021. Our robotic network participated in a technical demonstration, whose main objective was to localise a bottomed submarine which emitted a periodic help request acoustically during a simulated distress situation. We report results which are one of the first examples to demonstrate how cooperative robotics, supported by data fusion, can be effective in a passive sonar scenario. They also confirm the viability of adopting such solutions in real-world applications, characterised by poor communications and challenging environments. What was achieved at REPMUS21 clearly demonstrates how a network of cooperative robots can improve search & rescue operations of a submarine.",
        "primary_area": "",
        "author": "Gabriele Ferri;Alessandro Faggiani;Roberto Petroccia;Pietro Stinco;Alessandra Tesei;Gabriele Ferri;Alessandro Faggiani;Roberto Petroccia;Pietro Stinco;Alessandra Tesei",
        "authorids": "/37534206500;/37089300716;/37393305100;/37396710000;/37333438800;/37534206500;/37089300716;/37393305100;/37396710000;/37333438800",
        "aff": "NATO STO Centre for Maritime Research and Experimentation (CMRE), La Spezia (SP), Italy; NATO STO Centre for Maritime Research and Experimentation (CMRE), La Spezia (SP), Italy; NATO STO Centre for Maritime Research and Experimentation (CMRE), La Spezia (SP), Italy; NATO STO Centre for Maritime Research and Experimentation (CMRE), La Spezia (SP), Italy; NATO STO Centre for Maritime Research and Experimentation (CMRE), La Spezia (SP), Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160438/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13851123113209109548&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "NATO Science & Technology Organization Centre for Maritime Research and Experimentation",
        "aff_unique_dep": "Centre for Maritime Research and Experimentation",
        "aff_unique_url": "https://www.natoSTOcmre.org",
        "aff_unique_abbr": "NATO CMRE",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "La Spezia",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10160576",
        "title": "A Sensitivity-Aware Motion Planner (SAMP) to Generate Intrinsically-Robust Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "Closed-loop state sensitivity [1], [2] is a recently introduced notion that can be used to quantify deviations of the closed-loop trajectory of a robot/controller pair against variations of uncertain parameters in the robot model. While local optimization techniques are used in [1], [2] to generate reference trajectories minimizing a sensitivity-based cost, no global planning algorithm considering this metric to compute collision-free motions robust to parametric uncertainties has yet been proposed. The contribution of this paper is to propose a global control-aware motion planner for optimizing a state sensitivity metric and producing collision-free reference motions that are robust against parametric uncertainties for a large class of complex dynamical systems. Given the prohibitively high computational cost of directly minimizing the state sensitivity using asymptotically optimal sampling-based tree planners, the proposed RRT*-based SAMP planner uses an appropriate steering method to first compute a (near) time-optimal and kinodynamically feasible trajectory that is then locally deformed to improve robustness and decrease its sensitivity to uncertainties. The evaluation performed on planar/full-3D quadrotor UAV models shows that the SAMP method produces low sensitivity robust solutions with a much higher performance than a planner directly optimizing the sensitivity.",
        "primary_area": "",
        "author": "Simon Wasiela;Paolo Robuffo Giordano;Juan Cort\u00e9s;Thierry Sim\u00e9on;Simon Wasiela;Paolo Robuffo Giordano;Juan Cort\u00e9s;Thierry Sim\u00e9on",
        "authorids": "/37087245179;/37544316400;/37327428000;/37325350600;/37087245179;/37544316400;/37327428000;/37325350600",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; CNRS, Univ Rennes, Inria, IRISA, Rennes, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160576/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6727654888583978378&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 16,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "LAAS-CNRS;CNRS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.laas.fr/;https://www.cnrs.fr",
        "aff_unique_abbr": "LAAS-CNRS;CNRS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toulouse;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160799",
        "title": "A Sequential Quadratic Programming Approach to the Solution of Open-Loop Generalized Nash Equilibria",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a numerical method for the solution of local generalized Nash equilibria (GNE) for the class of open-loop general-sum dynamic games for agents with nonlinear dynamics and constraints. In particular, we formulate a sequential quadratic programming (SQP) approach which requires only the solution of a single convex quadratic program at each iteration and is locally convergent. Central to the effectiveness of our approach is a non-monotonic line search method and a novel merit function for SQP step acceptance which helps to improve solver convergence beyond the local neighborhood of a GNE. We demonstrate the effectiveness of the algorithm in the context of car racing, where we see up to 32% improvement of success rate when comparing against a recent solution approach for dynamic games. We also make our code available at https://github.com/zhu-edward/DGSQP.",
        "primary_area": "",
        "author": "Edward L. Zhu;Francesco Borrelli;Edward L. Zhu;Francesco Borrelli",
        "authorids": "/37088645903;/37299856800;/37088645903;/37299856800",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160799/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11277980433074582622&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160915",
        "title": "A Silicone-sponge-based Variable-stiffness Device",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft devices employ variable stiffness to ensure safety and improve the robustness in the interaction between robots and objects. Using soft materials is one of the most popular approaches to design a variable-stiffness device, while the use of silicone sponge remains less explored in this field. Here we present a novel silicone-sponge-based variable-stiffness device (SVD). The SVD is easy-to-make and low-cost, and fabricated by an air-tight bellow enclosing a silicone sponge core. This allows easy access to the hyper-elastic response of the porous sponge whilst stiffness tuning of the device via pneumatic pressure difference. A detailed mathematical model of the SVD is proposed, by which the stiffness can be precisely controlled by the pressure difference applied. The stiffness of SVD can be tuned in the range of [\\mathbf{1.55}, \\mathbf{2} \\mathbf{2.82}]\\times \\mathbf{10}^{\\mathbf{3}}\\ \\mathbf{N}/\\mathbf{m}[\\mathbf{1.55}, \\mathbf{2} \\mathbf{2.82}]\\times \\mathbf{10}^{\\mathbf{3}}\\ \\mathbf{N}/\\mathbf{m}, up to 14.7 times increase. The high stiffness is easily triggered by a low pressure difference (\\mathbf{\\Delta} \\boldsymbol{P} < \\mathbf{12}\\mathbf{kPa})(\\mathbf{\\Delta} \\boldsymbol{P} < \\mathbf{12}\\mathbf{kPa}). The SVD is a versatile and compact module, with small axial size (10 mm height) and light weight (14.3 g), making it highly suitable for integration in a wide range of robotics and industrial applications. This, in addition to its easy-to-fabricate and low-cost features, may appeal to the robotics community at large. We further detail its working principle, fabrication processes, mathematical model and automated control methods to show its versatility.",
        "primary_area": "",
        "author": "Tianqi Yue;Tsam Lung You;Hemma Philamore;Hermes Bloomfield-Gad\u00ealha;Jonathan Rossiter;Tianqi Yue;Tsam Lung You;Hemma Philamore;Hermes Bloomfield-Gad\u00ealha;Jonathan Rossiter",
        "authorids": "/37088997424;/37089838444;/37087776246;/37088910937;/37271190700;/37088997424;/37089838444;/37087776246;/37088910937;/37271190700",
        "aff": "Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160915/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17827600049804703836&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Engineering Mathematics",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161168",
        "title": "A Social Referencing Disambiguation Framework for Domestic Service Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The successful integration of domestic service robots into home environments can bring significant services and convenience to the general population and possibly mitigate important societal issues, such as care provision for older adults. However, home environments are complex, dynamic and object-rich. It is, thus, very probable that service robots will encounter ambiguity while interacting with household items. To enable service robots to be more adaptive, we proposed a learning so-cial referencing computational framework and experimentally evaluated the framework on a mobile manipulator robot, Fetch, in object selection scenarios. The framework allows the robot to (1) detect and analyze the ambiguity level based on the robot's view and user's command, (2) assess the human's attention level and attract their attention, (3) disambiguate references to objects using human feedback and (4) learn novel objects after clarification from the user. System evaluation results are presented. The framework is modular and can be applied to different robotic platforms.",
        "primary_area": "",
        "author": "Kevin Fan;Melanie Jouaiti;Ali Noormohammadi-As;Chrystopher L. Nehaniv;Kerstin Dautenhahn;Kevin Fan;Melanie Jouaiti;Ali Noormohammadi-As;Chrystopher L. Nehaniv;Kerstin Dautenhahn",
        "authorids": "/37089767809;/37086578714;/37089893768;/37274194000;/37273834500;/37089767809;/37086578714;/37089893768;/37274194000;/37273834500",
        "aff": "Dept. of Electrical & Computer Engineering, University of Waterloo, ON, Canada; Dept. of Electrical & Computer Engineering, University of Waterloo, ON, Canada; Dept. of Electrical & Computer Engineering, University of Waterloo, ON, Canada; Dept. of Electrical & Computer Engineering, University of Waterloo, ON, Canada; Dept. of Systems Design Engineering, University of Waterloo, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161168/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18304086575543633897&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "Dept. of Electrical & Computer Engineering",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Waterloo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161358",
        "title": "A Soft Hybrid-Actuated Continuum Robot Based on Dual Origami Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft continuum robots have shown tremendous potential for medical and industrial applications owing to their flexibility and continuous deformability. However, their telescopic and bending capabilities and variable stiffness are still limited. This study proposes a novel origami-inspired soft continuum robot to possess large telescopic and bending capabilities while improving stiffness based on the principle of antagonistic actuation. The soft robot consists of dual origami structures. The inner forms an air chamber actuated by pneumatics, and the outer is controlled by nine tendon-driven actuators. The proposed design uses the advantages of a hybrid actuation to achieve motion and stiffness control. The performance of the soft robot is studied experimentally based on single and three robot modules. Results show that the robot has an excellent stretch ratio and a maximum bending angle of 180\u00b0. The robot can also increase stiffness to resist the bending deformation induced by self-weight and loads.",
        "primary_area": "",
        "author": "Jian Tao;Qiqiang Hu;Tianzhi Luo;Erbao Dong;Jian Tao;Qiqiang Hu;Tianzhi Luo;Erbao Dong",
        "authorids": "/37089894286;/37087321729;/37088505772;/37969776300;/37089894286;/37087321729;/37088505772;/37969776300",
        "aff": "CAS Key Laboratory of Mechanical Behavior and Design of Materials, The School of Engineering Science, University of Science and Technology of China, Hefei, China; Department of Biomedical Engineering, City University of Hong Kong, Kowloon, Hong Kong, China; CAS Key Laboratory of Mechanical Behavior and Design of Materials, The School of Engineering Science, University of Science and Technology of China, Hefei, China; CAS Key Laboratory of Mechanical Behavior and Design of Materials, The School of Engineering Science, University of Science and Technology of China, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161358/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10751319687522193262&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Science and Technology of China;City University of Hong Kong",
        "aff_unique_dep": "School of Engineering Science;Department of Biomedical Engineering",
        "aff_unique_url": "http://www.ustc.edu.cn;https://www.cityu.edu.hk",
        "aff_unique_abbr": "USTC;CityU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Hefei;Kowloon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160877",
        "title": "A Soft Robot with Three Dimensional Shape Sensing and Contact Recognition Multi-Modal Sensing via Tunable Soft Optical Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft optical sensing strategies are rapidly developing for soft robotic systems as a means to increase the controllability of soft compliant robots. In this paper, we present a roughness tuning strategy for the fabrication of soft optical sensors to achieve the dual functionality of shape sensing combined with contact recognition within a single multi-modal sensor. The molds used to fabricate the soft sensors are roughened via laser micromachining to achieve asymmetrical sensor responses when bent in opposite directions. We demonstrate the integration of these sensors into a fully soft robotic platform consisting of a multi-directional bending module with integrated 3D shape sensing and a gripper with tip position monitoring along with contact force recognition. We show the accuracy of our sensing strategy in validation experiments and a pick-and-place task is performed to demonstrate the robot's functionality.",
        "primary_area": "",
        "author": "Max McCandless;Frank Juli\u00e1 Wise;Sheila Russo;Max McCandless;Frank Juli\u00e1 Wise;Sheila Russo",
        "authorids": "/37088855254;/37089894997;/38239019900;/37088855254;/37089894997;/38239019900",
        "aff": "Department of Mechanical Engineering, Boston University, Boston, Massachusetts; Department of Mechanical Engineering, Boston University, Boston, Massachusetts; Department of Mechanical Engineering, Boston University, Boston, Massachusetts",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160877/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10211468745088816849&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161061",
        "title": "A Stiffness-Changeable Soft Finger Based on Chain Mail Jamming",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a stiffness-changeable soft finger using chain mail jamming. This finger can achieve adaptive grasping and in-hand manipulation by reshaping and exerting changeable gripping force. The jamming phenomenon happens when particles in a chamber get interlocked where confining pressure is exerted at their boundaries, which is widely used to construct mechanisms with changeable stiffness. Compared with the traditional granular media, chain mail has a lower packing fraction and provides a stronger tensile force. In this paper, we proposed to apply chain mail jamming to the field of robotic finger design. Especially, we propose the design of the finger, the fabrication process, the method of predicting gripping force, and the grasping strategies. The experiments quantitatively verify the model of gripping force prediction. The demonstrations validate the advantages of adaptive grasp by picking a variety of items including foods, goods, and industrial components, and show the application of in-hand manipulation.",
        "primary_area": "",
        "author": "Zhengtao Hu;Abdullah Ahmed;Weiwei Wan;Tetsuyou Watanabe;Kensuke Harada;Zhengtao Hu;Abdullah Ahmed;Weiwei Wan;Tetsuyou Watanabe;Kensuke Harada",
        "authorids": "/37086871315;/37089893035;/37085689483;/37280649900;/37277067400;/37086871315;/37089893035;/37085689483;/37280649900;/37277067400",
        "aff": "Graduate School of Engineering Science, Osaka University.; Graduate School of Engineering Science, Osaka University.; Graduate School of Engineering Science, Osaka University.; Graduate School of Natural Science and Technology, Kanazawa University; National Inst. of AIST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161061/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5845156269977575197&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Osaka University;Kanazawa University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Graduate School of Engineering Science;Graduate School of Natural Science and Technology;",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.kanazawa-u.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Osaka U;KU;AIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Osaka;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161495",
        "title": "A Study into Understanding User Requirements to Inform the Design of Customizable Robotic Pain Management Devices",
        "track": "main",
        "status": "Poster",
        "abstract": "Previous research into using robots for pain man-agement has shown promise. However to date, there seems to have been little research investigating user requirements for robotic pain management devices which could be used by adults living with chronic pain, and how these might be translated into custom products. We carried out a user study comprising online surveys and interviews with people who have lived experience of chronic pain to investigate their perspectives. We had a total of 44 participants in our study. Our research revealed a preference for robotic devices for pain management which have an abstract or animal-like form, noting that contact points with the body should feel soft, warm, and light. Study participants also felt that the user should initiate the interaction and should have control of the robot, as well as the type and intensity of touch. Favored touch types included massaging, rubbing, and stroking. From the emerging requirements, given the diversity of experiences, design-related attributes identified could be used for a form-customization application, such as interactive evolutionary computation (IEC), as a means to personalize the embodiment of robotic devices. Prioritized form factors for customization through included size, weight, and feel.",
        "primary_area": "",
        "author": "Angela Higgins;Alison Llewellyn;Emma Dures;Praminda Caleb-Solly;Angela Higgins;Alison Llewellyn;Emma Dures;Praminda Caleb-Solly",
        "authorids": "/37089893695;/37089895803;/37089893153;/38274363200;/37089893695;/37089895803;/37089893153;/38274363200",
        "aff": "Angela Higgins and Praminda Caleb-Solly are with the School of Computing, University of Nottingham, NG8 IBB, UK; Faculty of Health and Applied Sciences, University of the West of England, UK; Faculty of Health and Applied Sciences, University of the West of England, UK; Angela Higgins and Praminda Caleb-Solly are with the School of Computing, University of Nottingham, NG8 IBB, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161495/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:P1z3ndhx8TQJ:scholar.google.com/&scioq=A+Study+into+Understanding+User+Requirements+to+Inform+the+Design+of+Customizable+Robotic+Pain+Management+Devices&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Nottingham;University of the West of England",
        "aff_unique_dep": "School of Computing;Faculty of Health and Applied Sciences",
        "aff_unique_url": "https://www.nottingham.ac.uk;https://www.uwe.ac.uk",
        "aff_unique_abbr": "UoN;UWE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161387",
        "title": "A System for Generalized 3D Multi-Object Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Searching for objects is a fundamental skill for robots. As such, we expect object search to eventually become an off-the-shelf capability for robots, similar to e.g., object detection and SLAM. In contrast, however, no system for 3D object search exists that generalizes across real robots and environments. In this paper, building upon a recent theoretical framework that exploited the octree structure for representing belief in 3D, we present GenMOS (Generalized Multi-Object Search), the first general-purpose system for multi-object search (MOS) in a 3D region that is robot-independent and environment-agnostic. GenMOS takes as input point cloud observations of the local region, object detection results, and localization of the robot's view pose, and outputs a 6D viewpoint to move to through online planning. In particular, GenMOS uses point cloud observations in three ways: (1) to simulate occlusion; (2) to inform occupancy and initialize octree belief; and (3) to sample a belief-dependent graph of view positions that avoid obstacles. We evaluate our system both in simulation and on two real robot platforms. Our system enables, for example, a Boston Dynamics Spot robot to find a toy cat hidden underneath a couch in under one minute. We further integrate 3D local search with 2D global search to handle larger areas, demonstrating the resulting system in a 25m2 lobby area.",
        "primary_area": "",
        "author": "Kaiyu Zheng;Anirudha Paul;Stefanie Tellex;Kaiyu Zheng;Anirudha Paul;Stefanie Tellex",
        "authorids": "/37087321724;/37089892389;/37402794800;/37087321724;/37089892389;/37402794800",
        "aff": "Department of Computer Science, Brown University, Providence, RI, USA; Department of Computer Science, Brown University, Providence, RI, USA; Department of Computer Science, Brown University, Providence, RI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161387/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4368920217827005486&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Providence",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160879",
        "title": "A Tactile Feedback Insertion Strategy for Peg-in-Hole Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "The Peg-In-Hole (PiH) task performed under un-certain conditions still represents a challenge for autonomous robots. When the peg is not rigidly connected to the robot end-effector, the external forces generated by peg-environment interactions can change the in-hand pose of the peg. This aspect must be taken into account when performing the insertion. This paper deals with this problem and proposes an insertion strategy driven by tactile feedback. In particular, we consider holding the peg using a parallel gripper equipped with tactile sensors, whose measurements are processed to capture in-hand rotations of the peg pose. This information is fed back to the robot controller and used to compensate for changes in the peg orientation and end-point position occurring during the task execution. The approach is validated on a real robot using a two-finger gripper equipped with two capacitive-based tactile sensor arrays hosting 20 tactile elements each. We show that the proposed method achieves an insertion success rate of 38/40 with a 0.1 mm clearance between the peg and hole.",
        "primary_area": "",
        "author": "Oliver Gibbons;Alessandro Albini;Perla Maiolino;Oliver Gibbons;Alessandro Albini;Perla Maiolino",
        "authorids": "/37089894698;/37086271727;/38075724700;/37089894698;/37086271727;/38075724700",
        "aff": "Oxford Robotics Institute (ORI), University of Oxford, UK; Oxford Robotics Institute (ORI), University of Oxford, UK; Oxford Robotics Institute (ORI), University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160879/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10049565519657977061&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161121",
        "title": "A Tactile-enabled Hybrid Rigid-Soft Continuum Manipulator for Forceful Enveloping Grasps via Scale Invariant Design",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a novel hybrid rigid-soft continuum manipulator, which integrates high-resolution tactile sensing in a form factor that is forceful, compliant, inherently safe, and easily controllable. We utilize a hybrid approach motivated by scale-invariant principles to fuse the rigid and soft design domains while addressing their respective challenges. We use Euler-Bernoulli beam theory and geometric inference to design and develop a novel variant of folded flexure hinge (FFH) compliant mechanism, the variable area moment of inertia folded flexure hinge (VAFFH), which deforms logarithmically along its length and thus yields first-order scale-invariant grasp behavior. Finally, we characterize the forcefulness of the manipulator and demonstrate its compliance, adaptability, and tactile sensing capabilities in selected tasks.",
        "primary_area": "",
        "author": "Ian H. Taylor;Maheera Bawa;Alberto Rodriguez;Ian H. Taylor;Maheera Bawa;Alberto Rodriguez",
        "authorids": "/37087390549;/37089892731;/38194796600;/37087390549;/37089892731;/38194796600",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161121/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12635332080753431129&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161458",
        "title": "A Task Allocation Framework for Human Multi-Robot Collaborative Settings",
        "track": "main",
        "status": "Poster",
        "abstract": "The requirements of modern production systems together with more advanced robotic technologies have fostered the integration of teams comprising humans and autonomous robots. While this integration has the potential to provide various benefits, it also raises questions about how to effectively manage these teams, taking into account the different characteristics of the agents involved. This paper presents a framework for task allocation in a human multi-robot collaborative scenario. The proposed solution combines an optimal offline allocation with an online reallocation strategy which accounts for inaccuracies of the offline plan and/or unforeseen events, human subjective preferences and cost of task switching. Experiments with two manipulators cooperating with a human operator in a box filling task are presented.",
        "primary_area": "",
        "author": "Martina Lippi;Paolo Di Lillo;Alessandro Marino;Martina Lippi;Paolo Di Lillo;Alessandro Marino",
        "authorids": "/37086443839;/37086216675;/37390952800;/37086443839;/37086216675;/37390952800",
        "aff": "Roma Tre University, Italy; University of Cassino and Southern, Lazio, Italy; University of Cassino and Southern, Lazio, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161458/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6251296246033574188&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Roma Tre University;University of Cassino and Southern Lazio",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uniroma3.it;",
        "aff_unique_abbr": "Roma Tre;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161082",
        "title": "A Trajectory Planner For Mobile Robots Steering Non-Holonomic Wheelchairs In Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning for mobile robot platforms is one of the long-established research fields in robotics. In this paper, we propose a trajectory planner for mobile holonomic robots to steer non-holonomic conventional passive wheelchairs in dynamic environments. The challenges to overcome when steering a wheelchair are to find smooth feasible trajectories, maintain a fast reactive response to dynamic obstacles and to satisfy a set of additional constraints such as limiting physical forces acting on the wheelchair occupants. Our approach is a variant of the timed-elastic-bands (TEB) planner, which includes a footprint of the wheelchair during optimization, and generates a steering angle which is then consumed by an arm controller to actuate the relative orientation between the wheelchair and the mobile platform. This is realized by posing new non-holonomic and kinodynamic constraints on the TEB planner and an implementation of a suitable real-time dual-arm controller for executing steering commands. We demonstrate our results based on a TEB baseline comparison in simulation using functional models of our robot HoLLiE and a wheelchair.",
        "primary_area": "",
        "author": "Martin Schulze;Friedrich Graaf;Lea Steffen;Arne Roennau;R\u00fcdiger Dillmann;Martin Schulze;Friedrich Graaf;Lea Steffen;Arne Roennau;R\u00fcdiger Dillmann",
        "authorids": "/37086883652;/37089892430;/37086472171;/37590849800;/37280242100;/37086883652;/37089892430;/37086472171;/37590849800;/37280242100",
        "aff": "FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161082/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10339636291960372471&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "FZI Research Center for Information Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.fzi.de",
        "aff_unique_abbr": "FZI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160492",
        "title": "A Unified BEV Model for Joint Learning of 3D Local Features and Overlap Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Pairwise point cloud registration is a critical task for many applications, which heavily depends on finding correct correspondences from the two point clouds. However, the low overlap between input point clouds causes the registration to fail easily, leading to mistaken overlapping and mismatched correspondences, especially in scenes where non-overlapping regions contain similar structures. In this paper, we present a unified bird's-eye view (BEV) model for jointly learning of 3D local features and overlap estimation to fulfill pairwise registration and loop closure. Feature description is performed by a sparse UNet-like network based on BEV representation, and 3D keypoints are extracted by a detection head for 2D locations, and a regression head for heights. For overlap detection, a cross-attention module is applied for interacting contextual information of input point clouds, followed by a classification head to estimate the overlapping region. We evaluate our unified model extensively on the KITTI dataset and Apollo-SouthBay dataset. The experiments demonstrate that our method significantly outperforms existing methods on overlap estimation, especially in scenes with small overlaps. It also achieves top registration performance on both datasets in terms of translation and rotation errors.",
        "primary_area": "",
        "author": "Lin Li;Wendong Ding;Yongkun Wen;Yufei Liang;Yong Liu;Guowei Wan;Lin Li;Wendong Ding;Yongkun Wen;Yufei Liang;Yong Liu;Guowei Wan",
        "authorids": "/37088997380;/37089893675;/37089895064;/37089891897;/37066946100;/37086452958;/37088997380;/37089893675;/37089895064;/37089891897;/37066946100;/37086452958",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Baidu Intelligent Driving Group, Beijing, P. R. China; Baidu Intelligent Driving Group, Beijing, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Baidu Intelligent Driving Group, Beijing, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160492/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3899754162098809174&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;1",
        "aff_unique_norm": "Zhejiang University;Baidu",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;Intelligent Driving Group",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.baidu.com",
        "aff_unique_abbr": "ZJU;Baidu",
        "aff_campus_unique_index": "0;1;1;0;0;1",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161122",
        "title": "A Virtual Reality Framework For Fast Dataset Creation Applied to Cloth Manipulation with Automatic Semantic Labelling",
        "track": "main",
        "status": "Poster",
        "abstract": "Teaching complex manipulation skills, such as folding garments, to a bi-manual robot is a very challenging task, which is often tackled through learning from demon-stration. The few datasets of garment-folding demonstrations available nowadays to the robotics research community have been either gathered from human demonstrations or generated through simulation. The former have the great difficulty of perceiving both cloth state and human action as well as transferring them to the dynamic control of the robot, while the latter require coding human motion into the simulator in open loop, i.e., without incorporating the visual feedback naturally used by people, resulting in far-from-realistic movements. In this article, we present an accurate dataset of human cloth folding demonstrations. The dataset is collected through our novel virtual reality (VR) framework, based on Unity's 3D platform and the use of an HTC Vive Pro system. The framework is capable of simulating realistic garments while allowing users to interact with them in real time through handheld controllers. By doing so, and thanks to the immersive experience, our framework permits exploiting human visual feedback in the demonstrations while at the same time getting rid of the difficulties of capturing the state of cloth, thus simplifying data acquisition and resulting in more realistic demonstrations. We create and make public a dataset of cloth manipulation sequences, whose cloth states are semantically labeled in an automatic way by using a novel low-dimensional cloth representation that yields a very good separation between different cloth configurations.",
        "primary_area": "",
        "author": "J\u00falia Borr\u00e0s;Arnau Boix-Granell;Sergi Foix;Carme Torras;J\u00falia Borr\u00e0s;Arnau Boix-Granell;Sergi Foix;Carme Torras",
        "authorids": "/37544025800;/37089893186;/37546458900;/37354713800;/37544025800;/37089893186;/37546458900;/37354713800",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161122/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16688650270374619056&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.iri.upc.edu/",
        "aff_unique_abbr": "IRI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10161029",
        "title": "A Virtual Reality Planning Environment for High-Risk, High-Latency Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperation of robots in space is challenging due to high latency and limited workspace visibility. Previously, the Interactive Planning and Supervised Execution (IPSE) and Augmented Virtuality systems were developed to reduce failure risk. These tools were visualized on a 3D da Vinci surgical console and operated using the da Vinci manipulators or visualized on conventional monitors and operated with a keyboard and mouse. Experimental studies indicated operator preference for the latter. In this work, we develop a 3D virtual reality (VR) interface for IPSE, implemented on a Meta Quest 2 head-mounted display (HMD), and evaluate it against the prior 2D, keyboard-and-mouse-based interface. The results demonstrate improved operator load with the 3D VR interface, with no decrease in task performance, while also providing cost and portability benefits compared to the conventional 2D interface.",
        "primary_area": "",
        "author": "Will Pryor;Liam J. Wang;Arko Chatterjee;Balazs P. Vagvolgyi;Anton Deguet;Simon Leonard;Louis L. Whitcomb;Peter Kazanzides;Will Pryor;Liam J. Wang;Arko Chatterjee;Balazs P. Vagvolgyi;Anton Deguet;Simon Leonard;Louis L. Whitcomb;Peter Kazanzides",
        "authorids": "/37086104864;/37089893701;/37089894894;/37568674700;/37427184100;/37269567400;/37283591700;/37375173500;/37086104864;/37089893701;/37089894894;/37568674700;/37427184100;/37269567400;/37283591700;/37375173500",
        "aff": "Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161029/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10781342922706431446&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160544",
        "title": "A causal decoupling approach to efficient planning for logistics problems with stateful stochastic demand",
        "track": "main",
        "status": "Poster",
        "abstract": "Future conceptions of agile, just-in-time fabrication, lean and \u201csmart\u201d manufacturing, and a host of allied processes that exploit advanced automation, depend in part on realizing improvements in logistics planning. The present paper hypothesizes that the key to improving flexibility will be the inclusion of sophisticated, time-correlated stochastic models of demand\u2014whether that be demand by end-user consumers directly, or by other down-stream processes. Such dynamic models of demand, unfortunately, can greatly increase the space in which planning occurs when treated, as is common for planning under uncertainty, via the Markov Decision Processes formulation. To tackle this challenge, we identify three aspects that we postulate appear as commonalities in many logistics settings. They lead to an approach for approximate reduction of the planning problem via causal decoupling, which gives a spectrum of solutions where weakening time correlations affords faster optimization. Empirical results on small case studies \u2014in lean manufacturing and commodity routing\u2014show that retaining some limited (but non-zero) amount of temporal structure can provide a useful compromise between quality of the solution obtained and computation required.",
        "primary_area": "",
        "author": "Diptanil Chaudhuri;Dylan A. Shell;Diptanil Chaudhuri;Dylan A. Shell",
        "authorids": "/37088998497;/37269198900;/37088998497;/37269198900",
        "aff": "Dept. of Computer Science & Engineering, Texas A&M University, College Station, TX, USA; Dept. of Computer Science & Engineering, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160544/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5327375634885896215&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160252",
        "title": "A congestion-aware path planning method considering crowd spatial-temporal anomalies for long-term autonomy of mobile robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A congestion-aware path planning method is pre-sented for mobile robots during long-term deployment in human occupied environments. With known spatial-temporal crowd patterns, the robot will navigate to its destination via less congested areas. Traditional traffic-aware routing methods do not consider spatial-temporal anomalies of macroscopic crowd behaviour that can deviate from the predicted crowd spatial distribution. The proposed method improves long-term path planning adaptivity by integrating a partially updated memory (PUM) model that utilizes observed anomalies to generate a multi-layer crowd density map to improve estimation accuracy. Using this map, we are able to generate a path that has less chance to encounter the crowded areas. Simulation results show that our method outperforms the benchmark congestion-aware routing method in terms of reducing the probability of robot's proximity to dense crowds.",
        "primary_area": "",
        "author": "Zijian Ge;Jingjing Jiang;Matthew Coombes;Zijian Ge;Jingjing Jiang;Matthew Coombes",
        "authorids": "/37089893684;/37279090300;/37085426572;/37089893684;/37279090300;/37085426572",
        "aff": "Department of Aeronautical and Automotive Engineering, Loughborough University, Leicestershire, UK; Department of Aeronautical and Automotive Engineering, Loughborough University, Leicestershire, UK; Department of Aeronautical and Automotive Engineering, Loughborough University, Leicestershire, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160252/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2069734785505413490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Loughborough University",
        "aff_unique_dep": "Department of Aeronautical and Automotive Engineering",
        "aff_unique_url": "https://www.lboro.ac.uk",
        "aff_unique_abbr": "Loughborough",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160281",
        "title": "A fast two-stage approach for multi-goal path planning in a fruit tree",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of planning the motion of a drone equipped with a robotic arm, tasked with bringing its end-effector up to many (150+) targets in a fruit tree; to inspect every piece of fruit, for example. The task is complicated by the intersection of a version of Neighborhood TSP (to find an optimal order and a pose to visit every target), and a robotic motion-planning problem through a planning space that features numerous cavities and narrow passages that confuse common techniques. In this contribution, we present a framework that decomposes the problem into two stages: planning approach paths for every target, and quickly planning between the start points of those approach paths. Then, we compare our approach by simulation to a more straightforward method based on multiquery planning, showing that our approach outperforms it in both time and solution cost.",
        "primary_area": "",
        "author": "Werner Kroneman;Jo\u00e3o Valente;A. Frank Van Der Stappen;Werner Kroneman;Jo\u00e3o Valente;A. Frank Van Der Stappen",
        "authorids": "/37089894169;/37088428717;/38559055600;/37089894169;/37088428717;/38559055600",
        "aff": "Department of Engineering, University College Roosevelt, Middelburg, The Netherlands; Information Technology Group, Wageningen University, Wageningen, The Netherlands; Department of Information and Computing Sciences, Utrecht University, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160281/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11262509668330591311&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University College Roosevelt;Wageningen University;Utrecht University",
        "aff_unique_dep": "Department of Engineering;Information Technology Group;Department of Information and Computing Sciences",
        "aff_unique_url": "https://www.ucr.nl;https://www.wageningen.edu;https://www.uu.nl",
        "aff_unique_abbr": "UCR;WU;UU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Middelburg;Wageningen;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10160689",
        "title": "A fluidic actuator with an internal stiffening structure inspired by mammalian erectile tissue",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the biggest problems with soft robots is precisely the fact that they are soft. Indeed the softer they are, the less force they can exert on the environment. Researchers have proposed a number of stiffening methods, but all of them have drawbacks, such as locking the shape of the device in a way that precludes further adjustments. In this paper we propose a stiffening method inspired by the internal structure of the mammalian penis. The soft actuation chamber is divided into small compartments that trap the actuation fluid, leading to locally amplified pressure increase under certain conditions. At the same time, the proposed solution does not affect the actuation mechanism, allowing the actuator to be adjusted in one direction just as if it was in non-stiffened mode, while offering a stiff response in the opposite direction. Our prototype achieves an increase in stiffening of approximately a factor of two. The paper describes the concept, the mathematical justification of the working principle, the prototype design, its implementation and our experimental results.",
        "primary_area": "",
        "author": "Jan Fras;Kaspar Althoefer;Jan Fras;Kaspar Althoefer",
        "authorids": "/37085449560;/37265264700;/37085449560;/37265264700",
        "aff": "Centre of Advanced Robotics @ Queen Mary (ARQ), Faculty of Science and Engineering, Queen Mary University of London, London, UK; Centre of Advanced Robotics @ Queen Mary (ARQ), Faculty of Science and Engineering, Queen Mary University of London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160689/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18435940366877403731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "Faculty of Science and Engineering",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160479",
        "title": "A general class of combinatorial filters that can be minimized efficiently",
        "track": "main",
        "status": "Poster",
        "abstract": "State minimization of combinatorial filters is a fundamental problem that arises, for example, in building cheap, resource-efficient robots. But exact minimization is known to be NP-hard. This paper conducts a more nuanced analysis of this hardness than up till now, and uncovers two factors which contribute to this complexity. We show each factor is a distinct source of the problem's hardness and are able, thereby, to shed some light on the role played by (1) structure of the graph that encodes compatibility relationships, and (2) determinism-enforcing constraints. Just as a line of prior work has sought to introduce additional assumptions and identify sub-classes that lead to practical state reduction, we next use this new, sharper understanding to explore special cases for which exact minimization is efficient. We introduce a new algorithm for constraint repair that applies to a large sub-class of filters, subsuming three distinct special cases for which the possibility of optimal minimization in polynomial time was known earlier. While the efficiency in each of these three cases previously appeared to stem from seemingly dissimilar properties, when seen through the lens of the present work, their commonality now becomes clear. We also provide entirely new families of filters that are efficiently reducible.",
        "primary_area": "",
        "author": "Yulin Zhang;Dylan A. Shell;Yulin Zhang;Dylan A. Shell",
        "authorids": "/37089453389;/37269198900;/37089453389;/37269198900",
        "aff": "Amazon Robotics, North Reading, MA, USA; Dept. of Computer Science & Engineering, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160479/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5298237471640046959&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Amazon Robotics;Texas A&M University",
        "aff_unique_dep": ";Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.amazonrobotics.com;https://www.tamu.edu",
        "aff_unique_abbr": "Amazon Robotics;TAMU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "North Reading;College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160399",
        "title": "A generic diffusion-based approach for 3D human pose prediction in the wild",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting 3D human poses in real-world scenarios, also known as human pose forecasting, is inevitably subject to noisy inputs arising from inaccurate 3D pose estimations and occlusions. To address these challenges, we propose a diffusion-based approach that can predict given noisy observations. We frame the prediction task as a denoising problem, where both observation and prediction are considered as a single sequence containing missing elements (whether in the observation or prediction horizon). All missing elements are treated as noise and denoised with our conditional diffusion model. To better handle long-term forecasting horizon, we present a temporal cascaded diffusion model. We demonstrate the benefits of our approach on four publicly available datasets (Human3.6M, HumanEva-I, AMASS, and 3DPW), outperforming the state-of-the-art. Additionally, we show that our framework is generic enough to improve any 3D pose prediction model as a pre-processing step to repair their inputs and a post-processing step to refine their outputs. The code is available online: https://github.com/vita-epfl/DePOSit.",
        "primary_area": "",
        "author": "Saeed Saadatnejad;Ali Rasekh;Mohammadreza Mofayezi;Yasamin Medghalchi;Sara Rajabzadeh;Taylor Mordan;Alexandre Alahi;Saeed Saadatnejad;Ali Rasekh;Mohammadreza Mofayezi;Yasamin Medghalchi;Sara Rajabzadeh;Taylor Mordan;Alexandre Alahi",
        "authorids": "/37087472056;/37089892911;/37089895675;/37089892290;/37089891936;/37086229048;/37601323900;/37087472056;/37089892911;/37089895675;/37089892290;/37089891936;/37086229048;/37601323900",
        "aff": "EPFL, Lausanne, Switzerland; EPFL; EPFL; EPFL; EPFL; EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160399/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=839962288788595502&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;0;0",
        "aff_unique_norm": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne;Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.epfl.ch;https://www.epfl.ch",
        "aff_unique_abbr": "EPFL;EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161475",
        "title": "A generic power wheelchair lumped model in the sagittal plane: towards realistic self-motion perception in a virtual reality simulator",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a generic power wheelchair dynamic model. As a first contribution, this paper proposes to use a generic model composed of a geometric model and a lumped model in order to be compliant with a wide range of existing commercially available wheelchairs. In this model, a set of essential parameters are enough to accurately replicate the dynamic behavior of a wheelchair. As a second contribution, this paper presents an identification method of a n-wheel type power wheelchair. The presented model is restricted to the sagittal plane only, which is sufficient to study the reliability of the identification and validation methods. Moreover, a Motion Cueing Algorithm based on the proposed model controls a simulator mechanical platform. The generic model has been then validated through a user study with 18 able-bodied participants evaluating the self-motion perception with our multisensory power wheelchair driving simulator. Results show that the simplified model is sufficient to provide accurate sensations to the user with respect to their experience while driving a power wheelchair.",
        "primary_area": "",
        "author": "Fabien Grzeskowiak;Ronan Le Breton;Louise Devigne;Fran\u00e7ois Pasteau;Marie Babel;Sylvain Gu\u00e9gan;Fabien Grzeskowiak;Ronan Le Breton;Louise Devigne;Fran\u00e7ois Pasteau;Marie Babel;Sylvain Gu\u00e9gan",
        "authorids": "/37087526060;/37085874297;/37086083215;/37891636000;/37563684500;/37085800547;/37087526060;/37085874297;/37086083215;/37891636000;/37563684500;/37085800547",
        "aff": "INSA Rennes, Inria, CNRS, IRISA - UMR 6074, Univ Rennes, Rennes, France; Univ Rennes, INSA Rennes, LGCGM, Rennes, France; Univ Rennes, Inria, CNRS, IRISA - UMR 6074, Rennes, France; INSA Rennes, Inria, CNRS, IRISA - UMR 6074, Univ Rennes, Rennes, France; INSA Rennes, Inria, CNRS, IRISA - UMR 6074, Univ Rennes, Rennes, France; Univ Rennes, INSA Rennes, LGCGM, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161475/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:r3E6fP6EeswJ:scholar.google.com/&scioq=A+generic+power+wheelchair+lumped+model+in+the+sagittal+plane:+towards+realistic+self-motion+perception+in+a+virtual+reality+simulator&hl=en&as_sdt=0,33",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;1",
        "aff_unique_norm": "INSA Rennes;University of Rennes",
        "aff_unique_dep": ";INSA Rennes, LGCGM",
        "aff_unique_url": "https://www.insa-rennes.fr;https://www.univ-rennes1.fr",
        "aff_unique_abbr": "INSA Rennes;Univ Rennes",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Rennes",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160652",
        "title": "A hydraulic soft robotic detrusor based on an origami design",
        "track": "main",
        "status": "Poster",
        "abstract": "As a permanent solution for patients who cannot contract their urinary bladder, an artificial detrusor muscle appears a higher outcome approach compared to current sacral neurostimulators featured by severe long-term side effects. In this paper, a novel soft robotic detrusor is presented to overcome the limitations of the state-of-the-art solutions. It is based on two identical origami-based hydraulic actuators, which completely surround the bladder and contract upon water aspiration. Design, manufacturing, and experimental characterization both in terms of contraction capabilities and voiding efficiency on ex vivo swine bladders are reported for two different origami geometries, as well as a proof-of-concept implementation of an autonomous driving circuit as control unit. Results from assisted urination tests outlined very good performances proving an active voiding efficiency of the hydraulic soft robotic detrusor equal to 84.8% \\pm 7.4\\%\\pm 7.4\\% in simulated environment.",
        "primary_area": "",
        "author": "Simone Onorati;Federica Semproni;Linda Patern\u00f2;Giada Casagrande;Veronica Iacovacci;Arianna Menciassi;Simone Onorati;Federica Semproni;Linda Patern\u00f2;Giada Casagrande;Veronica Iacovacci;Arianna Menciassi",
        "authorids": "/37089892229;/37089629972;/37086434429;/37089892674;/37085567922;/37280284800;/37089892229;/37089629972;/37086434429;/37089892674;/37085567922;/37280284800",
        "aff": "The BioRobotics Institute, Scuola Superiore Sant'Anna, Pontedera (Pisa), Italy; The BioRobotics Institute, Scuola Superiore Sant'Anna, Pontedera (Pisa), Italy; The BioRobotics Institute, Scuola Superiore Sant'Anna, Pontedera (Pisa), Italy; The BioRobotics Institute, Scuola Superiore Sant'Anna, Pontedera (Pisa), Italy; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; The BioRobotics Institute, Scuola Superiore Sant'Anna, Pontedera (Pisa), Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160652/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=669950293728593491&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Scuola Superiore Sant'Anna;The Chinese University of Hong Kong",
        "aff_unique_dep": "BioRobotics Institute;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.sssup.it;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "SSSA;CUHK",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Pontedera;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Italy;China"
    },
    {
        "id": "10160310",
        "title": "A lightweight high-voltage boost circuit for soft-actuated micro-aerial-robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Flight is an energetically expensive task. While aerial insects can effortlessly fly through natural environments, achieving power autonomous flights in insect-scale robots remains a major challenge. In prior works, we developed soft-actuated insect-scale aerial robots that demonstrated unique capabilities such as in-flight collision recovery and somersaults. However, the soft dielectric elastomer actuators (DEAs) have low efficiency (< 20%) and require a high driving voltage (>600 V). These properties represent formidable obstacles for soft aerial robots to achieve power autonomous flights. In this work, we developed a 127 mg boost circuit that can convert a 7.7 V DC input into a 600 V and 400 Hz output for driving a 120 mg DEA. It has an equivalent capacitance and resistance of 20 nF and 5 \\mathbf{k}\\Omega\\mathbf{k}\\Omega, respectively. The DEA is assembled into a 158 mg aerial robot, which can demonstrate liftoff while carrying the boost circuit as a payload. Although the robot remains tethered to an off-board power supply, this result represents a first step towards achieving power autonomy in soft aerial robots.",
        "primary_area": "",
        "author": "Zhijian Ren;Jiahui Yang;Suhan Kim;Yi-Hsuan Hsiao;Jeffrey Lang;Yufeng Chen;Zhijian Ren;Jiahui Yang;Suhan Kim;Yi-Hsuan Hsiao;Jeffrey Lang;Yufeng Chen",
        "authorids": "/37088488889;/37089895286;/37087323805;/37086580197;/37276032100;/37085417667;/37088488889;/37089895286;/37087323805;/37086580197;/37276032100;/37085417667",
        "aff": "Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160310/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11265050113858677297&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160789",
        "title": "A method for selecting stumble recovery response in a knee exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "Powered lower-limb exoskeletons have been shown to assist and augment walking, but most such devices do not currently have the ability to explicitly accommodate a stumble perturbation. A major challenge in doing so is identifying a stumble event and selecting in real-time which recovery strategy (elevating or lowering) to employ, particularly since the exoskeleton should ideally select the same strategy selected by the user. In order to do so, the authors conducted experiments involving five young, healthy adults wearing a knee exoskeleton. Each participant underwent a stumble experiment in order to collect an exoskeleton sensor dataset of stumbles throughout swing phase, which was used for stumble detection and recovery strategy identification algorithm development and testing. Overall, the proposed detection and identification algorithms provide improved accuracy with fewer required sensors relative to previous works, and were tested on the largest exoskeleton sensor stumble dataset to date, showing the feasibility of such algorithms for real-time implementation, which is an essential first step in developing lower-limb assistive devices that are robust to stumbles.",
        "primary_area": "",
        "author": "Maura Eveld;Shane King;Karl Zelik;Michael Goldfarb;Maura Eveld;Shane King;Karl Zelik;Michael Goldfarb",
        "authorids": "/37089196943;/37088801351;/37704832000;/37284476400;/37089196943;/37088801351;/37704832000;/37284476400",
        "aff": "Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160789/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6972841900711078280&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161367",
        "title": "A minimum swept-volume metric structure for configuration space",
        "track": "main",
        "status": "Poster",
        "abstract": "Borrowing elementary ideas from solid mechanics and differential geometry, this presentation shows that the volume swept by a regular solid undergoing a wide class of volume-preserving deformations induces a rather natural metric structure with well-defined and computable geodesics on its configuration space. This general result applies to concrete classes of articulated objects such as robot manipulators, and we demonstrate as a proof of concept the computation of geodesic paths for a free flying rod and planar robotic arms as well as their use in path planning with many obstacles.",
        "primary_area": "",
        "author": "Yann de Mont-Marin;Jean Ponce;Jean-Paul Laumond;Yann de Mont-Marin;Jean Ponce;Jean-Paul Laumond",
        "authorids": "/37089892285;/37282647000;/37282134800;/37089892285;/37282647000;/37282134800",
        "aff": "D\u00e9partement d'informatique, L'Ecole normale sup\u00e9rieure (ENS-PSL, CNRS, Inria), France; Center for Data Science and Courant Institue, New York University, United States; D\u00e9partement d'informatique, L'Ecole normale sup\u00e9rieure (ENS-PSL, CNRS, Inria), France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161367/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5813825105515644119&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "L'Ecole normale sup\u00e9rieure;New York University",
        "aff_unique_dep": "D\u00e9partement d'informatique;Center for Data Science",
        "aff_unique_url": "https://www.ens.psl.eu;https://www.nyu.edu",
        "aff_unique_abbr": "ENS;NYU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New York",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "10161194",
        "title": "A real-time dynamic obstacle tracking and mapping system for UAV navigation and collision avoidance with an RGB-D camera",
        "track": "main",
        "status": "Poster",
        "abstract": "The real-time dynamic environment perception has become vital for autonomous robots in crowded spaces. Although the popular voxel-based mapping methods can efficiently represent 3D obstacles with arbitrarily complex shapes, they can hardly distinguish between static and dynamic obstacles, leading to the limited performance of obstacle avoidance. While plenty of sophisticated learning-based dynamic obstacle detection algorithms exist in autonomous driving, the quad-copter's limited computation resources cannot achieve real-time performance using those approaches. To address these issues, we propose a real-time dynamic obstacle tracking and mapping system for quadcopter obstacle avoidance using an RGB-D camera. The proposed system first utilizes a depth image with an occupancy voxel map to generate potential dynamic obstacle regions as proposals. With the obstacle region proposals, the Kalman filter and our continuity filter are applied to track each dynamic obstacle. Finally, the environment-aware trajectory prediction method is proposed based on the Markov chain using the states of tracked dynamic obstacles. We implemented the proposed system with our custom quadcopter and navigation planner. The simulation and physical experiments show that our methods can successfully track and represent obstacles in dynamic environments in real-time and safely avoid obstacles.",
        "primary_area": "",
        "author": "Zhefan Xu;Xiaoyang Zhan;Baihan Chen;Yumeng Xiu;Chenhao Yang;Kenji Shimada;Zhefan Xu;Xiaoyang Zhan;Baihan Chen;Yumeng Xiu;Chenhao Yang;Kenji Shimada",
        "authorids": "/37088810563;/37089893921;/37089893828;/37089895489;/37089892726;/37324632500;/37088810563;/37089893921;/37089893828;/37089895489;/37089892726;/37324632500",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161194/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13354242930801296179&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160734",
        "title": "AANet: Aggregation and Alignment Network with Semi-hard Positive Sample Mining for Hierarchical Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual place recognition (VPR) is one of the research hotspots in robotics, which uses visual information to locate robots. Recently, the hierarchical two-stage VPR methods have become popular in this field due to the trade-off between accuracy and efficiency. These methods retrieve the top-k candidate images using the global features in the first stage, then re-rank the candidates by matching the local features in the second stage. However, they usually require additional al-gorithms (e.g. RANSAC) for geometric consistency verification in re-ranking, which is time-consuming. Here we propose a Dynamically Aligning Local Features (DALF) algorithm to align the local features under spatial constraints. It is significantly more efficient than the methods that need geometric consistency verification. We present a unified network capable of extracting global features for retrieving candidates via an aggregation module and aligning local features for re-ranking via the DALF alignment module. We call this network AANet. Meanwhile, many works use the simplest positive samples in triplet for weakly supervised training, which limits the ability of the network to recognize harder positive pairs. To address this issue, we propose a Semi-hard Positive Sample Mining (ShPSM) strategy to select appropriate hard positive images for training more robust VPR networks. Extensive experiments on four benchmark VPR datasets show that the proposed AANet can outperform several state-of-the-art methods with less time consumption. The code is released at https://github.com/Lu-Feng/AANet.",
        "primary_area": "",
        "author": "Feng Lu;Lijun Zhang;Shuting Dong;Baifan Chen;Chun Yuan;Feng Lu;Lijun Zhang;Shuting Dong;Baifan Chen;Chun Yuan",
        "authorids": "/37088962875;/37068686800;/37089896066;/37600013300;/37289486000;/37088962875;/37068686800;/37089896066;/37600013300;/37289486000",
        "aff": "Peng Cheng Laboratory, Shenzhen, China; Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing, China; Peng Cheng Laboratory, Shenzhen, China; School of Automation, Central South University, Changsha, China; Peng Cheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160734/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13198193868952121498&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Peng Cheng Laboratory;Chinese Academy of Sciences;Central South University",
        "aff_unique_dep": ";Chongqing Institute of Green and Intelligent Technology;School of Automation",
        "aff_unique_url": ";http://www.cas.cn;http://www.csu.edu.cn",
        "aff_unique_abbr": ";CAS;",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "Shenzhen;Chongqing;Changsha",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160451",
        "title": "ADAPT: A 3 Degrees of Freedom Reconfigurable Force Balanced Parallel Manipulator for Aerial Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the ADAPT, a novel reconfigurable force-balanced parallel manipulator for spatial motions and interaction capabilities underneath a drone. The reconfigurable aspect allows different motion-based 3-DoF operation modes like translational, rotational, planar, and so on, without the need for disassembly. For the purpose of this study, the manipulator is used in translation mode only. A kinematic model is developed and validated for the manipulator. The design and motion capabilities are also validated both by conducting dynamics simulations of a simplified model on MSC ADAMS, and experiments on the physical setup. The force-balanced nature of this novel design decouples the motion of the manipulator's end-effector from the base, zeroing the reaction forces, making this design ideally suited for aerial manipulation applications, or generic floating-base applications.",
        "primary_area": "",
        "author": "Kartik Suryavanshi;Salua Hamaza;Volkert van der Wijk;Just Herder;Kartik Suryavanshi;Salua Hamaza;Volkert van der Wijk;Just Herder",
        "authorids": "/37088504794;/37085715218;/37085933904;/37550906200;/37088504794;/37085715218;/37085933904;/37550906200",
        "aff": "Department of Precision & Microsystems Engineering, Faculty of Mechanical Engineering, TU Delft, The Netherlands; Department of Control & Operations, BioMorphic Intelligence Lab, Faculty of Aerospace Engineering, TU Delft, The Netherlands; Department of Precision & Microsystems Engineering, Faculty of Mechanical Engineering, TU Delft, The Netherlands; Department of Precision & Microsystems Engineering, Faculty of Mechanical Engineering, TU Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160451/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6970233036953453657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "TU Delft;Delft University of Technology",
        "aff_unique_dep": "Department of Precision & Microsystems Engineering;Faculty of Aerospace Engineering",
        "aff_unique_url": "https://www.tudelft.nl;https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft;TU Delft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10160326",
        "title": "ADAPT: Action-aware Driving Caption Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "End-to-end autonomous driving has great potential in the transportation industry. However, the lack of transparency and interpretability of the automatic decision-making process hinders its industrial adoption in practice. There have been some early attempts to use attention maps or cost volume for better model explainability which is difficult for ordinary passengers to understand. To bridge the gap, we propose an end-to-end transformer-based architecture, ADAPT (Action-aware Driving cAPtion Transformer), which provides user-friendly natural language narrations and reasoning for each decision making step of autonomous vehicular control and action. ADAPT jointly trains both the driving caption task and the vehicular control prediction task, through a shared video representation. Experiments on BDD-X (Berkeley DeepDrive eXplanation) dataset demonstrate state-of-the-art performance of the ADAPT framework on both automatic metrics and human evaluation. To illustrate the feasibility of the proposed framework in real-world applications, we build a novel deployable system that takes raw car videos as input and outputs the action narrations and reasoning in real time. The code, models and data are available at https://github.com/jxbbb/ADAPT.",
        "primary_area": "",
        "author": "Bu Jin;Xinyu Liu;Yupeng Zheng;Pengfei Li;Hao Zhao;Tong Zhang;Yuhang Zheng;Guyue Zhou;Jingjing Liu;Bu Jin;Xinyu Liu;Yupeng Zheng;Pengfei Li;Hao Zhao;Tong Zhang;Yuhang Zheng;Guyue Zhou;Jingjing Liu",
        "authorids": "/37089893311;/37088418296;/37089892258;/37089893178;/37086217629;/37090018347;/37089892228;/37085489402;/37089894607;/37089893311;/37088418296;/37089892258;/37089893178;/37086217629;/37090018347;/37089892228;/37085489402;/37089894607",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, China; Xidian University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Department of Computer Science and Technology, Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Southern University of Science and Technology, China; School of Mechanical Engineering and Automation, Beihang University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160326/",
        "gs_citation": 90,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1635143606248822617&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;0;0;2;3;0;0",
        "aff_unique_norm": "Tsinghua University;Xidian University;Southern University of Science and Technology;Beihang University",
        "aff_unique_dep": "Institute for AI Industry Research (AIR);;;School of Mechanical Engineering and Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://www.xidian.edu.cn/;https://www.sustech.edu.cn;http://www.buaa.edu.cn",
        "aff_unique_abbr": "Tsinghua;Xidian;SUSTech;Beihang",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161375",
        "title": "AI-Based Multi-Object Relative State Estimation with Self-Calibration Capabilities",
        "track": "main",
        "status": "Poster",
        "abstract": "The capability to extract task specific, semantic information from raw sensory data is a crucial requirement for many applications of mobile robotics. Autonomous inspection of critical infrastructure with Unmanned Aerial Vehicles (UAVs), for example, requires precise navigation relative to the structure that is to be inspected. Recently, Artificial Intelligence (AI)-based methods have been shown to excel at extracting semantic information such as 6 degree-of-freedom (6-DoF) poses of objects from images. In this paper, we propose a method combining a state-of-the-art AI-based pose estimator for objects in camera images with data from an inertial measurement unit (IMU) for 6-DoF multi-object relative state estimation of a mobile robot. The AI-based pose estimator detects multiple objects of interest in camera images along with their relative poses. These measurements are fused with IMU data in a state-of-the-art sensor fusion framework. We illustrate the feasibility of our proposed method with real world experiments for different trajectories and number of arbitrarily placed objects. We show that the results can be reliably reproduced due to the self-calibrating capabilities of our approach.",
        "primary_area": "",
        "author": "Thomas Jantos;Christian Brommer;Eren Allak;Stephan Weiss;Jan Steinbrener;Thomas Jantos;Christian Brommer;Eren Allak;Stephan Weiss;Jan Steinbrener",
        "authorids": "/37089447758;/37086574162;/37086580226;/37535323400;/37087049144;/37089447758;/37086574162;/37086580226;/37535323400;/37087049144",
        "aff": "Control of Networked Systems Group, University of Klagenfurt, Klagenfurt am W\u00f6rthersee, Austria; Control of Networked Systems Group, University of Klagenfurt, Klagenfurt am W\u00f6rthersee, Austria; Control of Networked Systems Group, University of Klagenfurt, Klagenfurt am W\u00f6rthersee, Austria; Control of Networked Systems Group, University of Klagenfurt, Klagenfurt am W\u00f6rthersee, Austria; Control of Networked Systems Group, University of Klagenfurt, Klagenfurt am W\u00f6rthersee, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161375/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=752539477916716053&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Control of Networked Systems Group",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Klagenfurt am W\u00f6rthersee",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "10160336",
        "title": "AIMY: An Open-source Table Tennis Ball Launcher for Versatile and High-fidelity Trajectory Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "To approach the level of advanced human players in table tennis with robots, generating varied ball trajectories in a reproducible and controlled manner is essential. Current ball launchers used in robot table tennis either do not provide an interface for automatic control or are limited in their capabilities to adapt speed, direction, and spin of the ball. For these reasons, we present AIMY, a three-wheeled open-hardware and open-source table tennis ball launcher, which can generate ball speeds and spins of up to 15.4ms\u22121 and 192.0s\u22121, respectively, which are comparable to advanced human players. The wheel speeds, launch orientation and time can be fully controlled via an open Ethernet or Wi-Fi interface. We provide a detailed overview of the core design features, and open-source the software to encourage distribution and duplication within and beyond the robot table tennis research community. We also extensively evaluate the ball launcher's accuracy for different system settings and learn to launch a ball to desired locations. With this ball launcher, we enable long-duration training of robot table tennis approaches where the complexity of the ball trajectory can be automatically adjusted, enabling large-scale real-world online reinforcement learning for table tennis robots.",
        "primary_area": "",
        "author": "Alexander Dittrich;Jan Schneider;Simon Guist;Nico G\u00fcrtler;Heiko Ott;Thomas Steinbrenner;Bernhard Sch\u00f6lkopf;Dieter B\u00fcchler;Alexander Dittrich;Jan Schneider;Simon Guist;Nico G\u00fcrtler;Heiko Ott;Thomas Steinbrenner;Bernhard Sch\u00f6lkopf;Dieter B\u00fcchler",
        "authorids": "/37089894843;/37089892047;/37089628359;/37089894790;/37085813713;/37089895341;/37265889200;/37085812006;/37089894843;/37089892047;/37089628359;/37089894790;/37085813713;/37089895341;/37265889200;/37085812006",
        "aff": "MPI for Intelligent Systems, T\u00fcbingen, Germany; MPI for Intelligent Systems, T\u00fcbingen, Germany; MPI for Intelligent Systems, T\u00fcbingen, Germany; MPI for Intelligent Systems, T\u00fcbingen, Germany; MPI for Intelligent Systems, T\u00fcbingen, Germany; MPI for Intelligent Systems, T\u00fcbingen, Germany; MPI for Intelligent Systems, T\u00fcbingen, Germany; MPI for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160336/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10018908235540820594&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mpituebingen.mpg.de",
        "aff_unique_abbr": "MPI-IS",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161016",
        "title": "ALAN: Autonomously Exploring Robotic Agents in the Real World",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic agents that operate autonomously in the real world need to continuously explore their environment and learn from the data collected, with minimal human supervision. While it is possible to build agents that can learn in such a manner without supervision, current methods struggle to scale to the real world. Thus, we propose ALAN, an autonomously exploring robotic agent, that can perform tasks in the real world with little training and interaction time. This is enabled by measuring environment change, which reflects object movement and ignores changes in the robot position. We use this metric directly as an environment-centric signal, and also maximize the uncertainty of predicted environment change, which provides agent-centric exploration signal. We evaluate our approach on two different real-world play kitchen settings, enabling a robot to efficiently explore and discover manipulation skills, and perform tasks specified via goal images. Videos can be found at https://robo-explorer.github.io/",
        "primary_area": "",
        "author": "Russell Mendonca;Shikhar Bahl;Deepak Pathak;Russell Mendonca;Shikhar Bahl;Deepak Pathak",
        "authorids": "/37089892248;/37086937856;/37085372144;/37089892248;/37086937856;/37085372144",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161016/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12241379293166264621&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161063",
        "title": "AMSwarm: An Alternating Minimization Approach for Safe Motion Planning of Quadrotor Swarms in Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a scalable online algorithm to generate safe and kinematically feasible trajectories for quadrotor swarms. Existing approaches rely on linearizing Euclidean distance-based collision constraints and on axis-wise decoupling of kinematic constraints to reduce the trajectory optimization problem for each quadrotor to a quadratic program (QP). This conservative approximation often fails to find a solution in cluttered environments. We present a novel alternative that handles collision constraints without linearization and kinematic constraints in their quadratic form while still retaining the QP form. We achieve this by reformulating the constraints in a polar form and applying an Alternating Minimization algorithm to the resulting problem. Through extensive simulation results, we demonstrate that, as compared to Sequential Convex Programming (SCP) baselines, our approach achieves on average, a 72% improvement in success rate, a 36% reduction in mission time, and a 42 times faster per-agent computation time. We also show that collision constraints derived from discrete-time barrier functions (BF) can be incorporated, leading to different safety behaviours without significant computational overhead. Moreover, our optimizer outperforms the state-of-the-art optimal control solver ACADO in handling BF constraints with a 31 times faster per-agent computation time and a 44% reduction in mission time on average. We experimentally validated our approach on a Crazyflie quadrotor swarm of up to 12 quadrotors. The code with supplementary material and video are released for reference.",
        "primary_area": "",
        "author": "Vivek K. Adajania;Siqi Zhou;Arun Kumar Singh;Angela P. Schoellig;Vivek K. Adajania;Siqi Zhou;Arun Kumar Singh;Angela P. Schoellig",
        "authorids": "/37088415563;/37086264310;/38237873200;/38488605800;/37088415563;/37086264310;/38237873200;/38488605800",
        "aff": "Vector Institute for Artificial Intelligence; Vector Institute for Artificial Intelligence; University of Tartu, Estonia; Vector Institute for Artificial Intelligence",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161063/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=363492227467375293&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Vector Institute for Artificial Intelligence;University of Tartu",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://vectorinstitute.ai/;https://www.ut.ee",
        "aff_unique_abbr": "Vector Institute;UT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Canada;Estonia"
    },
    {
        "id": "10161403",
        "title": "ANSEL Photobot: A Robot Event Photographer with Semantic Intelligence",
        "track": "main",
        "status": "Poster",
        "abstract": "Our work examines the way in which large language models can be used for robotic planning and sampling in the context of automated photographic documentation. Specifically, we illustrate how to produce a photo-taking robot with an exceptional level of semantic awareness by leveraging recent advances in general purpose language (LM) and vision-language (VLM) models. Given a high-level description of an event we use an LM to generate a natural-language list of photo descriptions that one would expect a photographer to capture at the event. We then use a VLM to identify the best matches to these descriptions in the robot's video stream. The photo portfolios generated by our method are consistently rated as more appropriate to the event by human evaluators than those generated by existing methods.",
        "primary_area": "",
        "author": "Dmitriy Rivkin;Gregory Dudek;Nikhil Kakodkar;David Meger;Oliver Limoyo;Michael Jenkin;Xue Liu;Francois Hogan;Dmitriy Rivkin;Gregory Dudek;Nikhil Kakodkar;David Meger;Oliver Limoyo;Michael Jenkin;Xue Liu;Francois Hogan",
        "authorids": "/37088997535;/37274057100;/37086192057;/37542891800;/37086453462;/37269066400;/37089262500;/37086455261;/37088997535;/37274057100;/37086192057;/37542891800;/37086453462;/37269066400;/37089262500;/37086455261",
        "aff": "Dmitriy Rivkin; Gregory Dudek; Nikhil Kakodkar; David Meger; Oliver Limoyo; Michael Jenkin; Xue Liu; Francois Hogan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161403/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15710218237784969154&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Michael Jenkin",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10160846",
        "title": "ARMBench: An Object-centric Benchmark Dataset for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces Amazon Robotic Manipulation Benchmark (ARMBench), a large-scale, object-centric benchmark dataset for robotic manipulation in the context of a warehouse. Automation of operations in modern warehouses requires a robotic manipulator to deal with a wide variety of objects, unstructured storage, and dynamically changing inventory. Such settings pose challenges in perceiving the identity, physical characteristics, and state of objects during manipulation. Existing datasets for robotic manipulation consider a limited set of objects or utilize 3D models to generate synthetic scenes with limitation in capturing the variety of object properties, clutter, and interactions. We present a large-scale dataset collected in an Amazon warehouse using a robotic manipulator performing object singulation from containers with heterogeneous contents. ARMBench contains images, videos, and metadata that corresponds to 235K+ pick-and-place activities on 190K+ unique objects. The data is captured at different stages of manipulation, i.e., pre-pick, during transfer, and after placement. Benchmark tasks are proposed by virtue of high-quality annotations and baseline performance evaluation are presented on three visual perception challenges, namely 1) object segmentation in clutter, 2) object identification, and 3) defect detection. ARMBench can be accessed at http://armbench.com",
        "primary_area": "",
        "author": "Chaitanya Mitash;Fan Wang;Shiyang Lu;Vikedo Terhuja;Tyler Garaas;Felipe Polido;Manikantan Nambi;Chaitanya Mitash;Fan Wang;Shiyang Lu;Vikedo Terhuja;Tyler Garaas;Felipe Polido;Manikantan Nambi",
        "authorids": "/37086289032;/37089895593;/37086579739;/37089893519;/37696767800;/37085747338;/38230681200;/37086289032;/37089895593;/37086579739;/37089893519;/37696767800;/37085747338;/38230681200",
        "aff": "Amazon Robotics, MA, USA; Amazon Robotics, MA, USA; Computer Science Department, Rutgers University, NJ, USA; Amazon Robotics, MA, USA; Amazon Robotics, MA, USA; Amazon Robotics, MA, USA; Amazon Robotics, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160846/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6428849531968688217&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;0",
        "aff_unique_norm": "Amazon Robotics;Rutgers University",
        "aff_unique_dep": ";Computer Science Department",
        "aff_unique_url": "https://www.amazonrobotics.com;https://www.rutgers.edu",
        "aff_unique_abbr": "Amazon Robotics;Rutgers",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New Brunswick",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160565",
        "title": "ARiADNE: A Reinforcement learning approach using Attention-based Deep Networks for Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "In autonomous robot exploration tasks, a mobile robot needs to actively explore and map an unknown environment as fast as possible. Since the environment is being revealed during exploration, the robot needs to frequently re-plan its path online, as new information is acquired by onboard sensors and used to update its partial map. While state-of-the-art exploration planners are frontier- and sampling-based, encouraged by the recent development in deep reinforcement learning (DRL), we propose ARiADNE, an attention-based neural approach to obtain real-time, non-myopic path planning for autonomous exploration. ARiADNE is able to learn dependencies at multiple spatial scales between areas of the agent's partial map, and implicitly predict potential gains associated with exploring those areas. This allows the agent to sequence movement actions that balance the natural trade-off between exploitation/refinement of the map in known areas and exploration of new areas. We experimentally demonstrate that our method outperforms both learning and non-learning state-of-the-art baselines in terms of average trajectory length to complete exploration in hundreds of simplified 2D indoor scenarios. We further validate our approach in high-fidelity Robot Operating System (ROS) simulations, where we consider a real sensor model and a realistic low-level motion controller, toward deployment on real robots.",
        "primary_area": "",
        "author": "Yuhong Cao;Tianxiang Hou;Yizhuo Wang;Xian Yi;Guillaume Sartoretti;Yuhong Cao;Tianxiang Hou;Yizhuo Wang;Xian Yi;Guillaume Sartoretti",
        "authorids": "/37089893324;/37089893031;/37089894256;/37089894785;/37085791757;/37089893324;/37089893031;/37089894256;/37089894785;/37085791757",
        "aff": "Department of Mechanical Engineering, College of Design and Engineering, National University of Singapore; Department of Mechanical Engineering, College of Design and Engineering, National University of Singapore; Department of Mechanical Engineering, College of Design and Engineering, National University of Singapore; Department of Mechanical Engineering, College of Design and Engineering, National University of Singapore; Department of Mechanical Engineering, College of Design and Engineering, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160565/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1831035108746840292&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160633",
        "title": "ATTACH Dataset: Annotated Two-Handed Assembly Actions for Human Action Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "With the emergence of collaborative robots (cobots), human-robot collaboration in industrial manufacturing is coming into focus. For a cobot to act autonomously and as an assistant, it must understand human actions during assembly. To effectively train models for this task, a dataset containing suitable assembly actions in a realistic setting is cru-cial. For this purpose, we present the ATTACH dataset, which contains 51.6 hours of assembly with 95.2k annotated fine-grained actions monitored by three cameras, which represent potential viewpoints of a cobot. Since in an assembly context workers tend to perform different actions simultaneously with their two hands, we annotated the performed actions for each hand separately. Therefore, in the ATTACH dataset, more than 68% of annotations overlap with other annotations, which is many times more than in related datasets, typically featuring more simplistic assembly tasks. For better generalization with respect to the background of the working area, we did not only record color and depth images, but also used the Azure Kinect body tracking SDK for estimating 3D skeletons of the worker. To create a first baseline, we report the performance of state-of-the-art methods for action recognition as well as action detection on video and skeleton-sequence inputs. The dataset is available at https://www.tu-ilmenau.de/neurob/data-sets-code/attach-dataset.",
        "primary_area": "",
        "author": "Dustin Aganian;Benedict Stephan;Markus Eisenbach;Corinna Stretz;Horst-Michael Gross;Dustin Aganian;Benedict Stephan;Markus Eisenbach;Corinna Stretz;Horst-Michael Gross",
        "authorids": "/37088981497;/37089315589;/37318406900;/37089893091;/37270612700;/37088981497;/37089315589;/37318406900;/37089893091;/37270612700",
        "aff": "Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, TU Ilmenau, Ilmenau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160633/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13513012009571154613&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Ilmenau",
        "aff_unique_dep": "Neuroinformatics and Cognitive Robotics Lab",
        "aff_unique_url": "https://www.tu-ilmenau.de",
        "aff_unique_abbr": "TU Ilmenau",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Ilmenau",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160564",
        "title": "AZTR: Aerial Video Action Recognition with Auto Zoom and Temporal Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel approach for aerial video action recognition. Our method is designed for videos captured using UAVs and can run on edge or mobile devices. We present a learning-based approach that uses customized auto zoom to automatically identify the human target and scale it appropriately. This makes it easier to extract the key features and reduces the computational overhead. We also present an efficient temporal reasoning algorithm to capture the action information along the spatial and temporal domains within a controllable computational cost. Our approach has been implemented and evaluated both on the desktop with high-end GPUs and on the low power Robotics RB5 Platform for robots and drones. In practice, we achieve 6.1-7.4 \\%6.1-7.4 \\% improvement over SOTA in Top-1 accuracy on the RoCoG-v2 dataset, 8.3-10.4% improvement on the UAV-Human dataset and 3.2% improvement on the Drone Action dataset.",
        "primary_area": "",
        "author": "Xijun Wang;Ruiqi Xian;Tianrui Guan;Celso M. de Melo;Stephen M. Nogar;Aniket Bera;Dinesh Manocha;Xijun Wang;Ruiqi Xian;Tianrui Guan;Celso M. de Melo;Stephen M. Nogar;Aniket Bera;Dinesh Manocha",
        "authorids": "/37089893476;/37089896111;/37088414623;/37683411800;/37086354053;/37085393882;/37267825600;/37089893476;/37089896111;/37088414623;/37683411800;/37086354053;/37085393882;/37267825600",
        "aff": "Dept. of Computer Science, University of Maryland, College Park, MD, USA; Dept. of Electrical and Computer Engineering, University of Maryland, College Park, MD, USA; Dept. of Computer Science, University of Maryland, College Park, MD, USA; Computational and Information Sciences Directorate, DEVCOM U.S. Army Research Laboratory, Adelphi, MD, USA; Computational and Information Sciences Directorate, DEVCOM U.S. Army Research Laboratory, Adelphi, MD, USA; Dept. of Computer Science, Purdue University, West Lafayette, IN, USA; Dept. of Computer Science, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160564/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18214306052328061915&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;2;3;0",
        "aff_unique_norm": "University of Maryland;University of Maryland, College Park;U.S. Army Research Laboratory;Purdue University",
        "aff_unique_dep": "Department of Computer Science;Dept. of Electrical and Computer Engineering;Computational and Information Sciences Directorate;Department of Computer Science",
        "aff_unique_url": "https://www/umd.edu;https://www/umd.edu;https://www.arl.army.mil;https://www.purdue.edu",
        "aff_unique_abbr": "UMD;UMD;;Purdue",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "College Park;;West Lafayette",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161018",
        "title": "Accelerating Multi-Agent Planning Using Graph Transformers with Bounded Suboptimality",
        "track": "main",
        "status": "Poster",
        "abstract": "Conflict-Based Search is one of the most popular methods for multi-agent path finding. Though it is complete and optimal, it does not scale well. Recent works have been proposed to accelerate it by introducing various heuristics. However, whether these heuristics can apply to non-grid-based problem settings while maintaining their effectiveness remains an open question. In this work, we find that the answer is prone to be no. To this end, we propose a learning-based component, i.e., the Graph Transformer, as a heuristic function to accelerate the planning. The proposed method is provably complete and bounded-suboptimal with any desired factor. We conduct extensive experiments on two environments with dense graphs. Results show that the proposed Graph Transformer can be trained in problem instances with relatively few agents and generalizes well to a larger number of agents, while achieving better performance than state-of-the-art methods.",
        "primary_area": "",
        "author": "Chenning Yu;Qingbiao Li;Sicun Gao;Amanda Prorok;Chenning Yu;Qingbiao Li;Sicun Gao;Amanda Prorok",
        "authorids": "/37089895585;/37088524830;/37088349203;/37542741000;/37089895585;/37088524830;/37088349203;/37542741000",
        "aff": "Computer Science and Engineering Department, University of California, San Diego; Department of Computer Science and Technology, University of Cam-bridge; Computer Science and Engineering Department, University of California, San Diego; Department of Computer Science and Technology, University of Cam-bridge",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161018/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6136740278875638881&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of California, San Diego;University of Cambridge",
        "aff_unique_dep": "Computer Science and Engineering Department;Department of Computer Science and Technology",
        "aff_unique_url": "https://www.ucsd.edu;https://www.cam.ac.uk",
        "aff_unique_abbr": "UCSD;Cambridge",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "San Diego;Cambridge",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "10160463",
        "title": "Achieving Extensive Trajectory Variation in Impulsive Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots that use impulsive mechanisms to achieve high-speed and high-powered motion are becoming more common and better understood, but control of these systems remains relatively rudimentary. Among robots that use spring actuation to generate motion, robot actuation and mechanisms are usually not controlled intentionally in order to achieve variation in the system's behavior, or they are controlled only roughly via adjustments made to the amount of energy stored in the mechanism. We describe the development, construction, and test of an impulsive catapult mechanism whose design is inspired by the grasshopper leg and for which extensive variation in the projectile trajectory is achieved by force control of the actuator that restrains the spring. As a step toward future controlled jumping robots, we give a detailed model of this system, validate this model experimentally, and explain how the actuator dynamics are critical to our ability to vary the system's trajectory using this approach. This work represents a novel approach to the control of spring actuated robots and illustrates how they can be controlled even under highly limiting actuator constraints.",
        "primary_area": "",
        "author": "Luis Viornery;Chloe Goode;Gregory Sutton;Sarah Bergbreiter;Luis Viornery;Chloe Goode;Gregory Sutton;Sarah Bergbreiter",
        "authorids": "/37089893045;/37089895706;/37089896020;/37542605000;/37089893045;/37089895706;/37089896020;/37542605000",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Life Sciences, University of Lincoln, Lincoln, United Kingdom; Department of Life Sciences, University of Lincoln, Lincoln, United Kingdom; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160463/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17638011655371291346&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Lincoln",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Life Sciences",
        "aff_unique_url": "https://www.cmu.edu;https://www.lincoln.ac.uk",
        "aff_unique_abbr": "CMU;UoL",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Pittsburgh;Lincoln",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "10160593",
        "title": "Active Inference for Autonomous Decision-Making with Contextual Multi-Armed Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "In autonomous robotic decision-making under uncertainty, the tradeoff between exploitation and exploration of available options must be considered. If secondary information associated with options can be utilized, such decision-making problems can often be formulated as contextual multi-armed bandits (CMABs). In this study, we apply active inference, which has been actively studied in the field of neuroscience in recent years, as an alternative action selection strategy for CMABs. Unlike conventional action selection strategies, it is possible to rigorously evaluate the uncertainty of each option when calculating the expected free energy (EFE) associated with the decision agent's probabilistic model, as derived from the free-energy principle. We specifically address the case where a categorical observation likelihood function is used, such that EFE values are analytically intractable. We introduce new approximation methods for computing the EFE based on variational and Laplace approximations. Extensive simulation study results demonstrate that, compared to other strategies, active inference generally requires far fewer iterations to identify optimal options and generally achieves superior cumulative regret, for relatively low extra computational cost.",
        "primary_area": "",
        "author": "Shohei Wakayama;Nisar Ahmed;Shohei Wakayama;Nisar Ahmed",
        "authorids": "/37089479204;/37533152500;/37089479204;/37533152500",
        "aff": "Smead Aerospace Engineering Sciences Department, University of Colorado Boulder, Boulder, CO, USA; Smead Aerospace Engineering Sciences Department, University of Colorado Boulder, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160593/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13100069271183176498&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Smead Aerospace Engineering Sciences Department",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161564",
        "title": "Active Metric-Semantic Mapping by Multiple Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional approaches for active mapping focus on building geometric maps. For most real-world applications, however, actionable information is related to semantically meaningful objects in the environment. We propose an approach to the active metric-semantic mapping problem that enables multiple heterogeneous robots to collaboratively build a map of the environment. The robots actively explore to minimize the uncertainties in both semantic (object classification) and geometric (object modeling) information. We represent the environment using informative but sparse object models, each consisting of a basic shape and a semantic class label, and characterize uncertainties empirically using a large amount of real-world data. Given a prior map, we use this model to select actions for each robot to minimize uncertainties. The performance of our algorithm is demonstrated through multi-robot experiments in diverse real-world environments. The proposed framework is applicable to a wide range of real-world problems, such as precision agriculture, infrastructure inspection, and asset mapping in factories.",
        "primary_area": "",
        "author": "Xu Liu;Ankit Prabhu;Fernando Cladera;Ian D. Miller;Lifeng Zhou;Camillo J. Taylor;Vijay Kumar;Xu Liu;Ankit Prabhu;Fernando Cladera;Ian D. Miller;Lifeng Zhou;Camillo J. Taylor;Vijay Kumar",
        "authorids": "/37086578226;/37089896076;/37089148940;/37086928894;/37086092920;/37277248500;/37280341400;/37086578226;/37089896076;/37089148940;/37086928894;/37086092920;/37277248500;/37280341400",
        "aff": "GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; Department of Electrical and Computer Engineering, Drexel University; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161564/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11834965550816872037&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "University of Pennsylvania;Drexel University",
        "aff_unique_dep": "GRASP Laboratory;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.upenn.edu;https://www.drexel.edu",
        "aff_unique_abbr": "UPenn;Drexel",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Philadelphia;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160530",
        "title": "Active Predictive Coding: Brain-Inspired Reinforcement Learning for Sparse Reward Robotic Control Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article, we propose a backpropagation-free approach to robotic control through the neuro-cognitive computational framework of neural generative coding (NGC), designing an agent completely built from predictive processing circuits that facilitate dynamic, online learning from sparse rewards, embodying the principles of planning-as-inference. Concretely, we craft an adaptive agent system, which we call active predictive coding (ActPC), that balances an internally-generated epistemic signal (meant to encourage intelligent exploration) with an internally-generated instrumental signal (meant to encourage goal-seeking behavior) to learn how to control various simulated robotic systems as well as a complex robotic arm using a realistic simulator, i.e., the Surreal Robotics Suite, for the block lifting task and the can pick-and-place problem. Notably, our results demonstrate that the proposed ActPC agent performs well in the face of sparse (extrinsic) reward signals and is competitive with or outperforms several powerful backpropagation-based reinforcement learning approaches.",
        "primary_area": "",
        "author": "Alexander Ororbia;Ankur Mali;Alexander Ororbia;Ankur Mali",
        "authorids": "/37085512786;/37086831100;/37085512786;/37086831100",
        "aff": "Department of Computer Science, Rochester Institute of Technology, Rochester, NY, USA; Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160530/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15788498216702988799&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Rochester Institute of Technology;University of South Florida",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.rit.edu;https://www.usf.edu",
        "aff_unique_abbr": "RIT;USF",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Rochester;Tampa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161238",
        "title": "Active Probing and Influencing Human Behaviors Via Autonomous Agents",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous agents (robots) face tremendous challenges while interacting with heterogeneous human agents in close proximity. One of these challenges is that the autonomous agent does not have an accurate model tailored to the specific human that the autonomous agent is interacting with, which could sometimes result in inefficient human-robot interaction and suboptimal system dynamics. Developing an online method to enable the autonomous agent to learn information about the human model is therefore an ongoing research goal. Existing approaches position the robot as a passive learner in the environment to observe the physical states and the associated human response. This passive design, however, only allows the robot to obtain information that the human chooses to exhibit, which sometimes doesn't capture the human's full intention. In this work, we present an online optimization-based probing procedure for the autonomous agent to clarify its belief about the human model in an active manner. By optimizing an information radius, the autonomous agent chooses the action that most challenges its current conviction. This procedure allows the autonomous agent to actively probe the human agents to reveal information that's previously unavailable to the autonomous agent. With this gathered information, the autonomous agent can interactively influence the human agent for some designated objectives. Our main contributions include a coherent theoretical framework that unifies the probing and influence procedures and two case studies in autonomous driving that show how active probing can help to create better participant experience during influence, like higher efficiency or less perturbations.",
        "primary_area": "",
        "author": "Shuangge Wang;Yiwei Lyu;John M. Dolan;Shuangge Wang;Yiwei Lyu;John M. Dolan",
        "authorids": "/37089433458;/37088505262;/37283756800;/37089433458;/37088505262;/37283756800",
        "aff": "Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161238/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14055437164483319907&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Southern California;Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.usc.edu;https://www.cmu.edu",
        "aff_unique_abbr": "USC;CMU",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Los Angeles;Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160439",
        "title": "Active Reward Learning from Online Preferences",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot policies need to adapt to human preferences and/or new environments. Human experts may have the domain knowledge required to help robots achieve this adaptation. However, existing works often require costly offline re-training on human feedback, and those feedback usually need to be frequent and too complex for the humans to reliably provide. To avoid placing undue burden on human experts and allow quick adaptation in critical real-world situations, we propose designing and sparingly presenting easy-to-answer pairwise action preference queries in an online fashion. Our approach designs queries and determines when to present them to maximize the expected value derived from the queries' information. We demonstrate our approach with experiments in simulation, human user studies, and real robot experiments. In these settings, our approach outperforms baseline techniques while presenting fewer queries to human experts. Experiment videos, code and appendices are found on our website: http://tinyurl.com/online-active",
        "primary_area": "",
        "author": "Vivek Myers;Erdem B\u0131y\u0131k;Dorsa Sadigh;Vivek Myers;Erdem B\u0131y\u0131k;Dorsa Sadigh",
        "authorids": "/37089895984;/37086082220;/38234464200;/37089895984;/37086082220;/38234464200",
        "aff": "Computer Science, Stanford University; Electrical Engineering, Stanford University; Electrical Engineering, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160439/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11667891008906680437&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160958",
        "title": "Actuator Capabilities Aware Limitation for TDPA Passivity Controller Action",
        "track": "main",
        "status": "Poster",
        "abstract": "Haptic interaction often requires stabilizing controllers for safety. The Time-Domain Passivity Approach guarantees passivity (then stability) by observing and dissipating energy generated from active elements in a network. The dissipating action is performed by a Passivity Controller, whose action is commanded to the physically limited robot actuators. Thus, the controller stabilizing action should be in turn limited in order to command displayable references to the actuators. This problem is rarely taken into account in the literature and when it is, the limitation is neither directly related to the actuator power limits, nor to the robot's current configuration. The limits of the currently adopted strategies leave room for improvement. In this paper, a new strategy to limit the Passivity Controller action is proposed taking into account both the physical limits of the actuators and the robot configuration. This new strategy is experimentally tested against the classical one based on the sampling time. In the experiment, a human interacts with a virtual wall in a Virtual Environment through a haptic interface. The wall induces an unstable behavior passivated with the two limitation strategies. The results clearly state the benefits introduced by the proposed strategy in two relevant cases.",
        "primary_area": "",
        "author": "Francesco Porcini;Alessandro Filippeschi;Massimiliano Solazzi;Carlo Alberto Avizzano;Antonio Frisoli;Francesco Porcini;Alessandro Filippeschi;Massimiliano Solazzi;Carlo Alberto Avizzano;Antonio Frisoli",
        "authorids": "/37087121821;/37640067200;/37293907000;/37274154300;/37297504100;/37087121821;/37640067200;/37293907000;/37274154300;/37297504100",
        "aff": "PERCRO Laboratory, Scuola Superiore Sant'Anna, IIM Institute, Pisa, Italy; Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, Pisa, Italy; Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, Pisa, Italy; Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, Pisa, Italy; Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, Pisa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160958/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14786856363813483137&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Scuola Superiore Sant'Anna",
        "aff_unique_dep": "PERCRO Laboratory",
        "aff_unique_url": "https://www.sssup.it",
        "aff_unique_abbr": "SSSUP",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pisa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161140",
        "title": "AdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the impressive results achieved by many existing Structure from Motion (SfM) approaches, there is still a need to improve the robustness, accuracy, and efficiency on large-scale scenes with many outlier matches and sparse view graphs. In this paper, we propose AdaSfM: a coarse-to-fine adaptive SfM approach that is scalable to large-scale and challenging datasets. Our approach first does a coarse global SfM which improves the reliability of the view graph by leveraging measurements from low-cost sensors such as Inertial Measurement Units (IMUs) and wheel encoders. Subsequently, the view graph is divided into sub-scenes that are refined in parallel by a fine local incremental SfM regularised by the result from the coarse global SfM to improve the camera registration accuracy and alleviate scene drifts. Finally, our approach uses a threshold-adaptive strategy to align all local reconstructions to the coordinate frame of global SfM. Extensive experiments on large-scale benchmark datasets show that our approach achieves state-of-the-art accuracy and efficiency. [Project Page]",
        "primary_area": "",
        "author": "Yu Chen;Zihao Yu;Shu Song;Tianning Yu;Jianming Li;Gim Hee Lee;Yu Chen;Zihao Yu;Shu Song;Tianning Yu;Jianming Li;Gim Hee Lee",
        "authorids": "/38067539500;/37089892680;/37089894447;/37089895389;/37089894663;/37860021400;/38067539500;/37089892680;/37089894447;/37089895389;/37089894663;/37860021400",
        "aff": "School of Computing, National University of Singapore; Segway-Ninebot Robotics Co., Ltd; Segway-Ninebot Robotics Co., Ltd; Navimow B.V. Co., Ltd; Navimow B.V. Co., Ltd; School of Computing, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161140/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12504079746347795429&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;2;0",
        "aff_unique_norm": "National University of Singapore;Segway-Ninebot Robotics;Navimow B.V. Co., Ltd",
        "aff_unique_dep": "School of Computing;;",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.segway.com.cn;",
        "aff_unique_abbr": "NUS;Segway-Ninebot;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;2;2;0",
        "aff_country_unique": "Singapore;China;Netherlands"
    },
    {
        "id": "10160521",
        "title": "Adaptive Heading for Perception-Aware Trajectory Following",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Jonatan Scharff Willners;Sean Katagiri;Shida Xu;Tomasz \u0141uczy\u0144ski;Joshua Roe;Yvan Petillot;Jonatan Scharff Willners;Sean Katagiri;Shida Xu;Tomasz \u0141uczy\u0144ski;Joshua Roe;Yvan Petillot",
        "authorids": "/37086222444;/37089300142;/37089197042;/37085646043;/37089303114;/37282015500;/37086222444;/37089300142;/37089197042;/37085646043;/37089303114;/37282015500",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160521/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11636458869321554154&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12
    },
    {
        "id": "10161207",
        "title": "Adaptive Keyframe Generation based LiDAR Inertial Odometry for Complex Underground Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a LiDAR Inertial Odometry (LIO) algorithm utilizing adaptive keyframe generation which achieves fast and accurate state estimation for aerial and ground robots. It is known that keyframe generation significantly affects the performance of Simultaneous Localization and Mapping (SLAM) algorithms. Unlike existing SLAM algorithms that generate keyframes based on fixed conditions, we propose to use adaptive keyframe generation conditions considering characteristics of surrounding environment using real-time LiDAR scans. When a keyframe is generated, the keyframe and the corresponding LiDAR measurements are stored in our novel data structure designed for efficient sub- map generation. The scan to sub-map matching module then uses the Generalized Iterative Closest Point (GICP) algorithm to adjust estimated states at a global scale, producing more accurate and globally consistent state estimation results even in large-scale underground environments. Experimental results from diverse types of underground environments show that the proposed method outperforms the existing state-of-the-art LIO algorithms in various metrics such as computational speed, CPU usage, and accuracy.",
        "primary_area": "",
        "author": "Boseong Kim;Chanyoung Jung;D. Hyunchul Shim;Ali\u2013akbar Agha\u2013mohammadi;Boseong Kim;Chanyoung Jung;D. Hyunchul Shim;Ali\u2013akbar Agha\u2013mohammadi",
        "authorids": "/37089501813;/37086555962;/37281960000;/38274170800;/37089501813;/37086555962;/37281960000;/38274170800",
        "aff": "Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Yuseong-gu, Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Yuseong-gu, Daejeon, Republic of Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Yuseong-gu, Daejeon, Republic of Korea; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161207/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7172005295669487975&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;California Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering;NASA Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.caltech.edu",
        "aff_unique_abbr": "KAIST;Caltech",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Daejeon;Pasadena",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "10161048",
        "title": "Adaptive Optimal Electrical Resistance Tomography for Large-Area Tactile Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "It is critical to perceive physical contact for intelligent robots to safely interact in dynamic, unstructured environments. As physical contacts can occur at any location, a well-performing tactile sensing system should be able to deploy a large area on robotic surface. Some researchers have implemented large-area tactile sensors by using sensing arrays, but it is challenging to deploy many sensing elements. Electrical resistance tomography (ERT) has recently been introduced into tactile sensing to overcome some of the limitations with conventional tactile sensing arrays, and good results have been achieved for some robotic applications. However, a particular challenge is that spatial resolution is low. Although various attempts have been made to improve the performance of ERT-based tactile sensors, the intrinsic resolution issue remains unsolved. In this paper, we propose a novel adaptive optimal drive strategy for efficient ERT-based large-area tactile sensing for robotic applications, which can adaptively select the current injection and voltage measurement pattern for optimal tactile stimulus. In particular, regions of tactile contacts are preliminarily detected and localized by a base scanning pattern with only a few measurement data. According to this detected region, the adaptive strategy can select the optimal current injection and voltage measurement pattern to improve the sensing performance by maximizing the current density. To verify the effectiveness of the proposed strategy, the proposed method is comprehensively evaluated by simulation and experiments. The results revealed that the optimal strategy can effectively improve both spatial and temporal resolution.",
        "primary_area": "",
        "author": "Wendong Zheng;Huaping Liu;Di Guo;Wuqiang Yang;Wendong Zheng;Huaping Liu;Di Guo;Wuqiang Yang",
        "authorids": "/37086864223;/37310126400;/37085360957;/37276966000;/37086864223;/37310126400;/37085360957;/37276966000",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; the State Key Laboratory of Intelligent Technology and Systems, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161048/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17992512009085846935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Tsinghua University;Beijing University of Posts and Telecommunications;The University of Manchester",
        "aff_unique_dep": "Department of Computer Science and Technology;School of Artificial Intelligence;Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://www.bupt.edu.cn/;https://www.manchester.ac.uk",
        "aff_unique_abbr": "THU;BUPT;UoM",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Beijing;Manchester",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10160324",
        "title": "Adaptive Risk-Tendency: Nano Drone Navigation in Cluttered Environments with Distributional Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling the capability of assessing risk and making risk-aware decisions is essential to applying reinforcement learning to safety-critical robots like drones. In this paper, we investigate a specific case where a nano quadcopter robot learns to navigate an apriori-unknown cluttered environment under partial observability. We present a distributional reinforcement learning framework to generate adaptive risk-tendency policies. Specifically, we propose to use lower tail conditional variance of the learnt return distribution as intrinsic uncertainty estimation, and use exponentially weighted average forecasting (EWAF) to adapt the risk-tendency in accordance with the estimated uncertainty. In simulation and real-world empirical results, we show that (1) the most effective risk-tendency varies across states, (2) the agent with adaptive risk-tendency achieves superior performance compared to risk-neutral policy or risk-averse policy baselines. Code and video can be found in this repository: https://github.com/tudelft/risk-sensitive-rl.git",
        "primary_area": "",
        "author": "Cheng Liu;Erik-Jan van Kampen;Guido C.H.E. de Croon;Cheng Liu;Erik-Jan van Kampen;Guido C.H.E. de Croon",
        "authorids": "/37089895188;/37085732454;/37698062600;/37089895188;/37085732454;/37698062600",
        "aff": "Delft University of Technology; Delft University of Technology; Delft University of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160324/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15047907597022196237&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10160395",
        "title": "Adaptive Sampling-based Particle Filter for Visual-inertial Gimbal in the Wild",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a Computer Vision (CV) based tracking and fusion algorithm, dedicated to a 3D printed gimbal system on drones flying in nature. The whole gimbal system can stabilize the camera orientation robustly in challenging environments by using skyline and ground plane as references. Our main contributions are the following: a) a light-weight Resnet-18 backbone network model was trained from scratch, and deployed onto the Jetson Nano platform to segment the image specifically into binary parts (ground and sky); b) our geometry assumption from the skyline and ground cues delivers the potential for robust visual tracking in the wild by using the skyline and ground plane as references; c) a manifold surface-based adaptive particle sampling can fuse orientation from multiple sensor sources flexibly. The whole algorithm pipeline is tested on our 3D-printed gimbal module with Jetson Nano. The experiments were performed on top of a building in a real landscape. The public code link: https://github.com/alexandor91/gimbal-fusion.git.",
        "primary_area": "",
        "author": "Xueyang Kang;Ariel Herrera;Henry Lema;Esteban Valencia;Patrick Vandewalle;Xueyang Kang;Ariel Herrera;Henry Lema;Esteban Valencia;Patrick Vandewalle",
        "authorids": "/37089892746;/37089894880;/37086858209;/37089022713;/37284653900;/37089892746;/37089894880;/37086858209;/37089022713;/37284653900",
        "aff": "PSI Department of Electrical Engineering, (ESAT), KU Leuven, Belgium; Department of Mechanical Engineering, Escuela Politecnica Nacional (EPN), Ecuador; Department of Mechanical Engineering, Escuela Politecnica Nacional (EPN), Ecuador; Department of Mechanical Engineering, Escuela Politecnica Nacional (EPN), Ecuador; PSI Department of Electrical Engineering, (ESAT), KU Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160395/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14803074750051495657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "KU Leuven;Escuela Politecnica Nacional",
        "aff_unique_dep": "Department of Electrical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kuleuven.be;https://www.epn.edu.ec",
        "aff_unique_abbr": "KU Leuven;EPN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "Belgium;Ecuador"
    },
    {
        "id": "10160371",
        "title": "Adaptive and Explainable Deployment of Navigation Skills via Hierarchical Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "For robotic vehicles to navigate robustly and safely in unseen environments, it is crucial to decide the most suitable navigation policy. However, most existing deep reinforcement learning based navigation policies are trained with a hand-engineered curriculum and reward function which are difficult to be deployed in a wide range of real-world scenarios. In this paper, we propose a framework to learn a family of low-level navigation policies and a high-level policy for deploying them. The main idea is that, instead of learning a single navigation policy with a fixed reward function, we simultaneously learn a family of policies that exhibit different behaviors with a wide range of reward functions. We then train the high-level policy which adaptively deploys the most suitable navigation skill. We evaluate our approach in simulation and the real world and demonstrate that our method can learn diverse navigation skills and adaptively deploy them. We also illustrate that our proposed hierarchical learning framework presents explainability by providing semantics for the behavior of an autonomous agent.",
        "primary_area": "",
        "author": "Kyowoon Lee;Seongun Kim;Jaesik Choi;Kyowoon Lee;Seongun Kim;Jaesik Choi",
        "authorids": "/37089894565;/37089195779;/37085412501;/37089894565;/37089195779;/37085412501",
        "aff": "Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, Ulsan, Republic of Korea; Graduate School of Artificial Intelligence, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Graduate School of Artificial Intelligence, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160371/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1332715860185960247&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering;Graduate School of Artificial Intelligence",
        "aff_unique_url": "https://www.unist.ac.kr;https://www.kaist.ac.kr",
        "aff_unique_abbr": "UNIST;KAIST",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Ulsan;Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161090",
        "title": "Adaptive approximation of dynamics gradients via interpolation to speed up trajectory optimisation",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory optimisation methods for robotic motion planning often require the use of first order derivatives of the dynamics of the system with respect to the states and controls of the system. Particularly when multi-contact dynamics are present, these derivatives are often numerically approximated by a method such as finite-differencing. Finite-differencing whilst using an expensive physics simulator is usually the bottleneck in these trajectory optimisation algorithms. Since these dynamics derivatives do not change substantially over certain time inter-vals, we propose that trajectory optimisers can compute the dy-namics derivatives less often and then interpolate approximations to the derivatives in between calculated derivatives, gaining a sig-nificant speed up for overall optimisation time with no observable degradation in the generated behaviour. We investigate different methods of interpolating approximations as well as propose an adaptive method to detect when to compute the derivatives with finite-differencing. We find a speed-up of planning times on average by 60% in a contact-based manipulation task.",
        "primary_area": "",
        "author": "David Russell;Rafael Papallas;Mehmet Dogar;David Russell;Rafael Papallas;Mehmet Dogar",
        "authorids": "/37089892760;/37086603559;/37591140400;/37089892760;/37086603559;/37591140400",
        "aff": "School of Computing, University of Leeds, UK; School of Computing, University of Leeds, UK; School of Computing, University of Leeds, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161090/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1311002887760618317&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Leeds",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.leeds.ac.uk",
        "aff_unique_abbr": "Leeds",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161008",
        "title": "Adaptive based Assist-as-needed control strategy for Ankle movement assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "Stroke affects a large number of people every year. One consequence is the weakness of ambulatory muscles resulting in a paretic gait. Actuated ankle foot orthoses can be a solution to assist paretic patients to dorsiflex and/or plantar flex their ankle joint during the gait phases. To assist the wearer following a predefined ankle joint desired trajectory, an adaptive active disturbance rejection controller is proposed in this study. The human muscular torque and estimation errors are estimated through a nonlinear disturbance observer based on the estimated model. This estimated torque is compensated within the proposed projection based adaptive controller combined to a saturated proportional derivative term. The purposes of using this controller are: i) the no need of prior system's parameter identification due to the adaptive structure, ii) the assistance-as-needed of the wearer through the rejection term and iii) the avoidance of the actuator saturation by including projection and saturation functions. This controller is tested in real time using an actuated ankle-foot-orthosis (AAFO) in lab environment with three healthy subjects to show its effectiveness.",
        "primary_area": "",
        "author": "R. Jradi;H. Rifa\u00ef;Y. Amirat;S. Mohammed;R. Jradi;H. Rifa\u00ef;Y. Amirat;S. Mohammed",
        "authorids": "/37089895715;/37568738000;/37274109900;/38580067500;/37089895715;/37568738000;/37274109900;/38580067500",
        "aff": "Univ Paris Est Creteil, LISSI, Vitry, France; Univ Paris Est Creteil, LISSI, Vitry, France; Univ Paris Est Creteil, LISSI, Vitry, France; Univ Paris Est Creteil, LISSI, Vitry, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161008/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9256672654328766982&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University Paris-Est Cr\u00e9teil",
        "aff_unique_dep": "LISSI",
        "aff_unique_url": "https://www.univ-pec.fr",
        "aff_unique_abbr": "UPEC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Vitry",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160551",
        "title": "Adaptive-SpikeNet: Event-based Optical Flow Estimation using Spiking Neural Networks with Learnable Neuronal Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Event-based cameras have recently shown great potential for high-speed motion estimation owing to their ability to capture temporally rich information asynchronously. Spiking Neural Networks (SNNs), with their neuro-inspired event-driven processing can efficiently handle such asynchronous data, while neuron models such as the leaky-integrate and fire (LIF) can keep track of the quintessential timing information contained in the inputs. SNNs achieve this by maintaining a dynamic state in the neuron memory, retaining important information while forgetting redundant data over time. Thus, we posit that SNNs would allow for better performance on sequential regression tasks compared to similarly sized Analog Neural Networks (ANNs). However, deep SNNs are difficult to train due to vanishing spikes at later layers. To that effect, we propose an adaptive fully-spiking framework with learnable neuronal dynamics to alleviate the spike vanishing problem. We utilize surrogate gradient-based backpropagation through time (BPTT) to train our deep SNNs from scratch. We validate our approach for the task of optical flow estimation on the Multi-Vehicle Stereo Event-Camera (MVSEC) dataset and the DSEC-Flow dataset. Our experiments on these datasets show an average reduction of \u223c 13% in average endpoint error (AEE) compared to state-of-the-art ANNs. We also explore several down-scaled models and observe that our SNN models consistently outperform similarly sized ANNs offering \u223c10%-16% lower AEE. These results demonstrate the importance of SNNs for smaller models and their suitability at the edge. In terms of efficiency, our SNNs offer substantial savings in network parameters (\u223c 48.3 \u00d7) and computational energy (\u223c 10.2 \u00d7) while attaining \u223c 10% lower EPE compared to the state-of-the-art ANN implementations.",
        "primary_area": "",
        "author": "Adarsh Kumar Kosta;Kaushik Roy;Adarsh Kumar Kosta;Kaushik Roy",
        "authorids": "/37087935885;/37274519700;/37087935885;/37274519700",
        "aff": "Purdue University, West Lafayette, USA; Purdue University, West Lafayette, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160551/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16674214678691569722&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160751",
        "title": "Advanced Skills through Multiple Adversarial Motion Priors in Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) has emerged as a powerful approach for locomotion control of highly articulated robotic systems. However, one major challenge is the tedious process of tuning the reward function to achieve the desired motion style. To address this issue, imitation learning approaches such as adversarial motion priors have been proposed, which encourage a pre-defined motion style. In this work, we present an approach to enhance the concept of adversarial motion prior-based RL, allowing for multiple, discretely switchable motion styles. Our approach demonstrates that multiple styles and skills can be learned simultaneously without significant performance differences, even in combination with motion data-free skills. We conducted several real-world experiments using a wheeled-legged robot to validate our approach. The experiments involved learning skills from existing RL controllers and trajectory optimization, such as ducking and walking, as well as novel skills, such as switching between a quadrupedal and humanoid configuration. For the latter skill, the robot was required to stand up, navigate on two wheels, and sit down. Instead of manually tuning the sit-down motion, we found that a reverse playback of the stand-up movement helped the robot discover feasible sit-down behaviors and avoided the need for tedious reward function tuning.",
        "primary_area": "",
        "author": "Eric Vollenweider;Marko Bjelonic;Victor Klemm;Nikita Rudin;Joonho Lee;Marco Hutter;Eric Vollenweider;Marko Bjelonic;Victor Klemm;Nikita Rudin;Joonho Lee;Marco Hutter",
        "authorids": "/37089339703;/37085993346;/37086934117;/37089291474;/37086264321;/37545251000;/37089339703;/37085993346;/37086934117;/37089291474;/37086264321;/37545251000",
        "aff": "Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160751/",
        "gs_citation": 85,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=489772760122496025&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10160852",
        "title": "AeriaLPiPS: A Local Planner for Aerial Vehicles with Geometric Collision Checking",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time navigation in non-trivial environments by micro aerial vehicles (MAVs) predominantly relies on modelling the MAV with idealized geometry, such as a sphere. Simplified, conservative representations increase the likelihood of a planner failing to identify valid paths. That likelihood increases the more a robot's geometry differs from the idealized version. Few current approaches consider these situations; we are unaware of any that do so using perception space representations. This work introduces the egocan, a perception space obstacle representation using line-of-sight free space estimates, and 3D Gap, a perception space approach to gap finding for identifying goal-directed, collision-free directions of travel through 3D space. Both are integrated, with real-time considerations in mind, to define a local planner module of a hierarchical navigation system. The result is Aerial Local Planning in Perception Space (AeriaLPiPS). AeriaLPiPS is shown to be capable of safely navigating a MAV with non-idealized geometry through various environments, including those impassable by traditional real-time approaches. The open source implementation of this work is available at github.com/ivaROS/AeriaLPiPS.",
        "primary_area": "",
        "author": "Justin S. Smith;Patricio Vela;Justin S. Smith;Patricio Vela",
        "authorids": "/37085636293;/37329553400;/37085636293;/37329553400",
        "aff": "School of Electrical and Computer Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160852/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:G8M51pzg8KcJ:scholar.google.com/&scioq=AeriaLPiPS:+A+Local+Planner+for+Aerial+Vehicles+with+Geometric+Collision+Checking&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160704",
        "title": "Agile and Versatile Robot Locomotion via Kernel-based Residual Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This work developed a kernel-based residual learning framework for quadrupedal robotic locomotion. Ini-tially, a kernel neural network is trained with data collected from an MPC controller. Alongside a frozen kernel network, a residual controller network is trained using reinforcement learning to acquire generalized locomotion skills and robust-ness against external perturbations. The proposed framework successfully learns a robust quadrupedal locomotion controller with high sample efficiency and controllability, which can provide omnidirectional locomotion at continuous velocities. We validated its versatility and robustness on unseen terrains that the expert MPC controller failed to traverse. Furthermore, the learned kernel can produce a range of functional locomotion behaviors and can generalize to unseen gaits.",
        "primary_area": "",
        "author": "Milo Carroll;Zhaocheng Liu;Mohammadreza Kasaei;Zhibin Li;Milo Carroll;Zhaocheng Liu;Mohammadreza Kasaei;Zhibin Li",
        "authorids": "/37089894795;/37089896127;/37089894512;/37857029500;/37089894795;/37089896127;/37089894512;/37857029500",
        "aff": "School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; Department of Computer Science, University College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160704/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15016586403977261250&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Edinburgh;University College London",
        "aff_unique_dep": "School of Informatics;Department of Computer Science",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Edinburgh;UCL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160627",
        "title": "AirTrack: Onboard Deep Learning Framework for Long-Range Aircraft Detection and Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Detect-and-Avoid (DAA) capabilities are critical for safe operations of unmanned aircraft systems (UAS). This paper introduces, AirTrack, a real-time vision-only detect and tracking framework that respects the size, weight, and power (SWaP) constraints of sUAS systems. Given the low Signal-to-Noise ratios (SNR) of far away aircraft, we propose using full resolution images in a deep learning framework that aligns successive images to remove ego-motion. The aligned images are then used downstream in cascaded primary and secondary classifiers to improve detection and tracking performance on multiple metrics. We show that AirTrack outperforms state-of-the art baselines on the Amazon Airborne Object Tracking (AOT) Dataset. Multiple real world flight tests with a Cessna 182 interacting with general aviation traffic and additional near-collision flight tests with a Bell helicopter flying towards a UAS in a controlled setting showcase that the proposed approach satisfies the newly introduced ASTM F3442/F3442M standard for DAA. Empirical evaluations show that our system has a probability of track of more than 95% up to a range of 700m. [Video]11Video: https://youtu.be/bMw5nUGL5GQ",
        "primary_area": "",
        "author": "Sourish Ghosh;Jay Patrikar;Brady Moon;Milad Moghassem Hamidi;Sebastian Scherer;Sourish Ghosh;Jay Patrikar;Brady Moon;Milad Moghassem Hamidi;Sebastian Scherer",
        "authorids": "/37086085841;/37086449345;/37086448648;/37089892740;/37584159000;/37086085841;/37086449345;/37086448648;/37089892740;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160627/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11397853973329761023&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161261",
        "title": "Aligning Human Preferences with Baseline Objectives in Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Practical implementations of deep reinforcement learning (deep RL) have been challenging due to an amplitude of factors, such as designing reward functions that cover every possible interaction. To address the heavy burden of robot reward engineering, we aim to leverage subjective human preferences gathered in the context of human-robot interaction, while taking advantage of a baseline reward function when available. By considering baseline objectives to be designed beforehand, we are able to narrow down the policy space, solely requesting human attention when their input matters the most. To allow for control over the optimization of different objectives, our approach contemplates a multi-objective setting. We achieve human-compliant policies by sequentially training an optimal policy from a baseline specification and collecting queries on pairs of trajectories. These policies are obtained by training a reward estimator to generate Pareto optimal policies that include human preferred behaviours. Our approach ensures sample efficiency and we conducted a user study to collect real human preferences, which we utilized to obtain a policy on a social navigation environment.",
        "primary_area": "",
        "author": "Daniel Marta;Simon Holk;Christian Pek;Jana Tumova;Iolanda Leite;Daniel Marta;Simon Holk;Christian Pek;Jana Tumova;Iolanda Leite",
        "authorids": "/37089163297;/37089031576;/37085906854;/38230312900;/38576988500;/37089163297;/37089031576;/37085906854;/38230312900;/38576988500",
        "aff": "Digital Futures; Digital Futures; Digital Futures; Digital Futures; Digital Futures",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161261/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9917270035230435360&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Digital Futures",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10160649",
        "title": "Allowing Safe Contact in Robotic Goal-Reaching: Planning and Tracking in Operational and Null Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, impressive results have been achieved in robotic manipulation. While many efforts focus on generating collision-free reference signals, few allow safe contact between the robot bodies and the environment. However, in human's daily manipulation, contact between arms and obstacles is prevalent and even necessary. This paper investigates the benefit of allowing safe contact during robotic manipulation and advocates generating and tracking compliance reference signals in both operational and null spaces. In addition, to optimize the collision-allowed trajectories, we present a hybrid solver that integrates sampling- and gradient-based approaches. We evaluate the proposed method on a goal-reaching task in five simulated and real-world environments with different collisional conditions. We show that allowing safe contact improves goal-reaching efficiency and provides feasible solutions in highly collisional scenarios where collision-free constraints cannot be enforced. Moreover, we demonstrate that planning in null space, in addition to operational space, improves trajectory safety. Further information is available at https://rolandzhu.github.io/ContactReach/.",
        "primary_area": "",
        "author": "Xinghao Zhu;Wenzhao Lian;Bodi Yuan;C. Daniel Freeman;Masayoshi Tomizuka;Xinghao Zhu;Wenzhao Lian;Bodi Yuan;C. Daniel Freeman;Masayoshi Tomizuka",
        "authorids": "/37087322158;/37088998889;/37086375844;/37089894129;/37281933000;/37087322158;/37088998889;/37086375844;/37089894129;/37281933000",
        "aff": "X, The Moonshot Factory, CA, USA; Intrinsic Innovation LLC, CA, USA; X, The Moonshot Factory, CA, USA; Google Research, CA, USA; Mechanical Systems Control Lab, Mechanical Engineering, UC Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160649/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2201085529215785379&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;3",
        "aff_unique_norm": "X Development LLC;Intrinsic Innovation LLC;Google Research;University of California, Berkeley",
        "aff_unique_dep": "The Moonshot Factory;;Google Research;Mechanical Engineering",
        "aff_unique_url": "https://xdevllc.com;;https://research.google;https://www.berkeley.edu",
        "aff_unique_abbr": "X;;Google Research;UC Berkeley",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Mountain View;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161070",
        "title": "An Active Learning Based Robot Kinematic Calibration Framework Using Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "Future NASA lander missions to icy moons will require completely automated, accurate, and data efficient calibration methods for the robot manipulator arms that sample icy terrains in the lander's vicinity. To support this need, this paper presents a Gaussian Process (GP) approach to the classical manipulator kinematic calibration process. Instead of identifying a corrected set of Denavit-Hartenberg kinematic parameters, a set of GPs models the residual kinematic error of the arm over the workspace. More importantly, this modeling framework allows a Gaussian Process Upper Confident Bound (GP-UCB) algorithm to efficiently and adaptively select the calibration's measurement points so as to minimize the number of experiments, and therefore minimize the time needed for recalibration. The method is demonstrated in simulation on a simple 2-DOF arm, a 6 DOF arm whose geometry is a candidate for a future NASA mission, and a 7 DOF Barrett WAM arm.",
        "primary_area": "",
        "author": "Ersin Da\u015f;Joel W. Burdick;Ersin Da\u015f;Joel W. Burdick",
        "authorids": "/37089251949;/37265975700;/37089251949;/37265975700",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161070/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9925227648614164973&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161325",
        "title": "An Analysis of Unified Manipulation with Robot Arms and Dexterous Hands via Optimization-based Motion Synthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot manipulation today generally focuses on motions exclusively with a robot arm or a dexterous hand, but usually not a combination of both. However, complex manipulation tasks can require coordinating arm and hand motions that leverage capabilities of both, much like the coordinated arm and hand motions carried out by humans to perform everyday tasks. In this work, we evaluate unified manipulation with robot arms and dexterous hands, using a motion optimization framework that synthesizes a series of configuration states over the entire manipulation system. We characterize the possible benefits of unifying arm and dexterous hand capabilities within a single model via metrics such as pose accuracy, manipulability, joint-space smoothness, distance to joint-limits, distance to collisions, and more. Several arm-hand combinations are quantitatively compared in simulation on a variety of experiment tasks and performance measures. Our results suggest that combining motions from robot arms and dexterous hands indeed has compelling benefits, highlighting the exciting potential of continued progress in unified arm-hand motion synthesis for robotics applications.",
        "primary_area": "",
        "author": "Vatsal V. Patel;Daniel Rakita;Aaron M. Dollar;Vatsal V. Patel;Daniel Rakita;Aaron M. Dollar",
        "authorids": "/37086366220;/37085893032;/37604732600;/37086366220;/37085893032;/37604732600",
        "aff": "Department of Mechanical Engineering & Materials Science, Yale University, USA; Department of Computer Science, Yale University, USA; Department of Mechanical Engineering & Materials Science, Yale University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161325/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4664432000023888467&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Yale University",
        "aff_unique_dep": "Department of Mechanical Engineering & Materials Science",
        "aff_unique_url": "https://www.yale.edu",
        "aff_unique_abbr": "Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161021",
        "title": "An Architecture for Reactive Mobile Manipulation On-The-Move",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a generalised architecture for reactive mobile manipulation while a robot's base is in motion toward the next objective in a high-level task. By performing tasks on-the-move, overall cycle time is reduced compared to methods where the base pauses during manipulation. Reactive control of the manipulator enables grasping objects with unpredictable motion while improving robustness against perception errors, environmental disturbances, and inaccurate robot control compared to open-loop, trajectory-based planning approaches. We present an example implementation of the architecture and investigate the performance on a series of pick and place tasks with both static and dynamic objects and compare the performance to baseline methods. Our method demonstrated a real-world success rate of over 99%, failing in only a single trial from 120 attempts with a physical robot system. The architecture is further demonstrated on other mobile manipulator platforms in simulation. Our approach reduces task time by up to 48%, while also improving reliability, gracefulness, and predictability compared to existing architectures for mobile manipulation. See benburgesslimerick.github.io/ManipulationOnTheMove for supplementary materials.",
        "primary_area": "",
        "author": "Ben Burgess-Limerick;Chris Lehnert;J\u00fcrgen Leitner;Peter Corke;Ben Burgess-Limerick;Chris Lehnert;J\u00fcrgen Leitner;Peter Corke",
        "authorids": "/37089449320;/37546443200;/37885671300;/37279654600;/37089449320;/37546443200;/37885671300;/37279654600",
        "aff": "the Queensland University of Technology Centre for Robotics (QCR), Brisbane, Australia; the Queensland University of Technology Centre for Robotics (QCR), Brisbane, Australia; LYRO Robotics, Brisbane, Australia; the Queensland University of Technology Centre for Robotics (QCR), Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161021/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4424576607226387463&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Queensland University of Technology;LYRO Robotics",
        "aff_unique_dep": "Centre for Robotics;",
        "aff_unique_url": "https://www.qut.edu.au;",
        "aff_unique_abbr": "QUT;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10161110",
        "title": "An Open Approach to Energy-Efficient Autonomous Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous mobile robots (AMRs) have the capability to execute a wide range of tasks with minimal human intervention. However, one of the major limitations of AMRs is their limited battery life, which often results in interruptions to their task execution and the need to reach the nearest charging station. Optimizing energy consumption in AMRs has become a critical challenge in their deployment. Through empirical studies on real AMRs, we have identified a lack of coordination between computation and control as a major source of energy inefficiency. In this paper, we propose a comprehensive energy prediction model that provides real-time energy consumption for each component of the AMR. Additionally, we propose three path models to address the obstacle avoidance problem for AMRs. To evaluate the performance of our energy prediction and path models, we have developed a customized AMR called Donkey, which has the capability for fine-grained (millisecond-level) end-to-end power profiling. Our energy prediction model demonstrated an accuracy of over 90% in our evaluations. Finally, we applied our energy prediction model to obstacle avoidance and guided energy-efficient path selection, resulting in up to a 44.8% reduction in energy consumption compared to the baseline.",
        "primary_area": "",
        "author": "Liangkai Liu;Ren Zhong;Aaron Willcock;Nathan Fisher;Weisong Shi;Liangkai Liu;Ren Zhong;Aaron Willcock;Nathan Fisher;Weisong Shi",
        "authorids": "/37086424671;/37088831568;/37086052595;/37297162600;/37278937600;/37086424671;/37088831568;/37086052595;/37297162600;/37278937600",
        "aff": "Department of Computer Science, Wayne State University; Department of Computer Science, Wayne State University; Department of Computer Science, Wayne State University; Department of Computer Science, Wayne State University; Department of Computer and Information Sciences, University of Delaware",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161110/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17019197201609767189&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Wayne State University;University of Delaware",
        "aff_unique_dep": "Department of Computer Science;Department of Computer and Information Sciences",
        "aff_unique_url": "https://wayne.edu;https://www.udel.edu",
        "aff_unique_abbr": "WSU;UD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160493",
        "title": "An Optimal Open-Loop Strategy for Handling a Flexible Beam with a Robot Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast and safe manipulation of flexible objects with a robot manipulator necessitates measures to cope with vibrations. Existing approaches either increase the task execution time or require complex models and/or additional instrumentation to measure vibrations. This paper develops a model-based method that overcomes these limitations. It relies on a simple pendulum-like model for modeling the beam, open-loop optimal control for suppressing vibrations, and does not require any exteroceptive sensors. We experimentally show that the proposed method drastically reduces residual vibrations \u2013 at least 90% \u2013 and outperforms the commonly used input shaping (IS) for trajectories with the same execution time. Besides, our method can also execute the task faster than IS with a minor reduction in vibration suppression performance, thereby facilitating the development of new solutions for flexible object manipulation tasks.",
        "primary_area": "",
        "author": "Shamil Mamedov;Alejandro Astudillo;Daniele Ronzani;Wilm Decr\u00e9;Jean-Philippe No\u00ebl;Jan Swevers;Shamil Mamedov;Alejandro Astudillo;Daniele Ronzani;Wilm Decr\u00e9;Jean-Philippe No\u00ebl;Jan Swevers",
        "authorids": "/37086569321;/37089308153;/37090018076;/37571970600;/37089895806;/37322616700;/37086569321;/37089308153;/37090018076;/37571970600;/37089895806;/37322616700",
        "aff": "The DMMS Lab, Leuven, Belgium; The DMMS Lab, Leuven, Belgium; The DMMS Lab, Leuven, Belgium; The DMMS Lab, Leuven, Belgium; The MECO Research Team, KU Leuven, Leuven, Belgium; The DMMS Lab, Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160493/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7610803142433735139&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "KU Leuven",
        "aff_unique_dep": "DMMS Lab",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Leuven",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "10161115",
        "title": "An Optimized Portable Cable-Driven Haptic Robot Enables Free Motion and Hard Contact",
        "track": "main",
        "status": "Poster",
        "abstract": "Task-oriented training with haptic rendering can boost robot-aided motor learning to tasks with similar dynamics. Although multi-DOF robots better match the rendering of real task scenarios, single-DOF haptic robots show great potential for home use with enhanced task rendering performance. This study presents our attempts to optimize and develop a single-DOF cable-driven robot with appropriate workspace and force rendering capacity. The core technologies consist of two aspects: 1) a multi-objective optimization method was adopted to obtain optimal configuration of the haptic robot; and 2) a slider-crank-mechanism-based portable cable-driven robot was developed. Performance evaluation experiments demonstrated that 1) the robot has a workspace larger than 300 mm; 2) the robot can achieve 40 N force output and 40 N. mm-1stiffness for hard contact; 3) the root mean square of the resistance during free motion is 0.93 N; 4) in the purely passive case (without motor compensation), the average resistance to back drive the motor is 2.5 N. These lead us to believe that the developed robot holds the promise to serve as a robotic rehabilitation training platform for home use on the neurological-impaired patients.",
        "primary_area": "",
        "author": "Changqi Zhang;Cui Wang;Qingkai Yang;Mingming Zhang;Changqi Zhang;Cui Wang;Qingkai Yang;Mingming Zhang",
        "authorids": "/37089196581;/37089892269;/37089895264;/37085459780;/37089196581;/37089892269;/37089895264;/37085459780",
        "aff": "Department of Biomedical Engineering, Guangdong Provincial Key Laboratory of Advanced Biomaterials, Southern University of Science and Technology, Shenzhen, China; Department of Biomedical Engineering, Guangdong Provincial Key Laboratory of Advanced Biomaterials, Southern University of Science and Technology, Shenzhen, China; Department of Biomedical Engineering, Guangdong Provincial Key Laboratory of Advanced Biomaterials, Southern University of Science and Technology, Shenzhen, China; Department of Biomedical Engineering, Guangdong Provincial Key Laboratory of Advanced Biomaterials, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161115/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:7U5evb8dUTgJ:scholar.google.com/&scioq=An+Optimized+Portable+Cable-Driven+Haptic+Robot+Enables+Free+Motion+and+Hard+Contact&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160331",
        "title": "An Underwater Jet-Propulsion Soft Robot with High Flexibility Driven by Water Hydraulics",
        "track": "main",
        "status": "Poster",
        "abstract": "Compared with rigid robots, soft robots have the advantages of inherent compliance, high adaptability, and impact tolerance. Many researchers are very interested in the motion design of soft robot underwater. In this paper, inspired by the method of octopus propulsion, a jet propulsion unit with 80% soft materials driven by pressure is designed. It can change the volume of its cavity to absorb and eject the fluid medium to make the robot move. According to the working characteristics of the jet unit, corresponding experiments are designed to analyze its force output, deformation, ejection flow, and pressure response characteristics. In order to expand the motion space of the robot, a buoyancy unit is designed to control the depth of the robot in the water. Three jet units and a buoyancy element are combined into a tetrahedron robot - jet soft robot (JSR). The feasibility of its motion is verified by experiments. Compared with other similar jet robots, the biggest feature of this robot is that the drive unit can bend or twist roughly along the centerline, which can prevent accidental collision and damage.",
        "primary_area": "",
        "author": "Siqing Chen;He Xu;Xiao Xiong;Ben Lu;Siqing Chen;He Xu;Xiao Xiong;Ben Lu",
        "authorids": "/37088504226;/37291049500;/37089892686;/37087244033;/37088504226;/37291049500;/37089892686;/37087244033",
        "aff": "College of Mechanical and Electrical Engineering, Harbin Engineering University, China; College of Mechanical and Electrical Engineering, Harbin Engineering University, China; College of Mechanical and Electrical Engineering, Harbin Engineering University, China; Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160331/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1299560117065672179&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Harbin Engineering University;Chinese Academy of Sciences",
        "aff_unique_dep": "College of Mechanical and Electrical Engineering;Institute of Automation",
        "aff_unique_url": ";http://www.ia.cas.cn",
        "aff_unique_abbr": ";CAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160611",
        "title": "An equivalent two section method for calculating the workspace of multi-segment continuum robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Obtaining the shape and size of a robot's workspace is essential for both its design and control. However, determining the accurate workspace of a multi-segment continuum robot by graphic or analytical methods is a challenging task due to its inherent flexibility and complex structure. Existing numerical methods have limitations when applied to a continuum robot. This paper presents an Equivalent Two Section (ETS) method for calculating the workspace of multi-segment continuum robots. This method is based on the forward kinematics and a piecewise constant curvature (PCC) model to determine the boundaries of the workspace. In order to verify the proposed method, simulation experiments are conducted using six different maximum bending angles and seven different number of segments. Results of the ETS method are compared to the true workspaces of these configurations estimated by an exhaustive approach. The results show that the proposed ETS method is both efficient and accurate, and has small estimation errors. Discussions on the advantages and limitations of the proposed ETS method are also presented.",
        "primary_area": "",
        "author": "Yeman Fan;Dikai Liu;Yeman Fan;Dikai Liu",
        "authorids": "/37089647364;/37290601500;/37089647364;/37290601500",
        "aff": "Robotics Institute, University of Technology Sydney, Sydney, NSW, Australia; Robotics Institute, University of Technology Sydney, Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160611/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16127285562290150464&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160527",
        "title": "Analysing the Safety and Security of a UV-C Disinfection Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is paramount for robots used in environments they share with humans. In such scenarios, security is also growing in importance. However, conventional approaches to analysing safety requirements are aimed at identifying hazards only. Security-related aspects such as cyber threats, cyber attacks and vulnerabilities have hardly been integrated into analysis and design methods to date. The methods available so far for the joint analysis of safety and security are based on established methods of safety engineering, where the amount of information is very large and usually stored in text- and table-based documents. This makes it challenging for engineers to systematically assess and maintain safety and security information. Thus, adequate tool support for robot engineers is required to cope with the increased complexity and to manage the safety and security risks. In this paper, we demonstrate that robot's safety and security information can be expressed, stored, analysed and queried in a knowledge graph representation paving the way to automated analysis. More specifically, we apply an integrated, systems-oriented safety and security co-analysis approach, namely STPA-Safesec, to a robot performing disinfection tasks in domestic environments. By querying the resulting graph of safety and security artefacts, we automatically retrieve hazardous scenarios, identify gaps in the analysis and increase our understanding of the overall risks of the robot.",
        "primary_area": "",
        "author": "Desiana Nurchalifah;Sebastian Blumenthal;Luigi Lo Iacono;Nico Hochgeschwender;Desiana Nurchalifah;Sebastian Blumenthal;Luigi Lo Iacono;Nico Hochgeschwender",
        "authorids": "/37089774022;/37968357600;/37992108600;/38228828900;/37089774022;/37968357600;/37992108600;/38228828900",
        "aff": "Department of Computer Science, Bonn-Rhein-Sieg University of Applied Sciences, Germany; KELO Robotics GmbH, Germany; Department of Computer Science, Bonn-Rhein-Sieg University of Applied Sciences, Germany; Department of Computer Science, Bonn-Rhein-Sieg University of Applied Sciences, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160527/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6935076658179374703&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Bonn-Rhein-Sieg University of Applied Sciences;KELO Robotics GmbH",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.bonn-rhein-sieg.de;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160825",
        "title": "Analytical Approach to Inverse Kinematics of Single Section Mobile Continuum Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel mathematical solution to solve the inverse kinematics (IK) of single section mobile continuum manipulators (SSMCMs). Thus, to achieve a given pose of the end-effector (EE), the proposed mathematical solution consists in determining the position and orientation parameters of the mobile platform and of a single section of the continuum manipulator. As advantages, the proposed mathematical solution eliminates the EE pose errors when the dynamic parameters are neglected and the continuum manipulator is cylindrical in shape. A simulation and an experiment validate the proposed approach.",
        "primary_area": "",
        "author": "Audrey Hyacinthe Bouyom Boutchouang;Achille Melingui;J.J.B. Mvogo Ahanda;Xinrui Yang;Othman Lakhal;Frederic Biya Motto;Rochdi Merzouki;Audrey Hyacinthe Bouyom Boutchouang;Achille Melingui;J.J.B. Mvogo Ahanda;Xinrui Yang;Othman Lakhal;Frederic Biya Motto;Rochdi Merzouki",
        "authorids": "/37089895832;/38469049400;/37086431082;/37088924993;/37085396104;/37087988398;/37299569900;/37089895832;/38469049400;/37086431082;/37088924993;/37085396104;/37087988398;/37299569900",
        "aff": "Dept. Electrical and Telecommunications Engineering, University of Yaounde I, Yaounde, Cameroon; Dept Electrical and Power Engineering, University of Ebolowa, Ebolowa, Cameroon; Dept Electrical and Power Engineering, University of Ebolowa, Ebolowa, Cameroon; CRIStAL Laboratory, CNRS-UMR, Villeneuve d'Ascq, France; CRIStAL Laboratory, CNRS-UMR, Villeneuve d'Ascq, France; Dept. Physic's, University of Yaounde I, Yaounde, Cameroon; CRIStAL Laboratory, CNRS-UMR, Villeneuve d'Ascq, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160825/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17978308702298299209&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;2;2;0;2",
        "aff_unique_norm": "University of Yaounde I;University of Ebolowa;CRIStAL Laboratory",
        "aff_unique_dep": "Dept. Electrical and Telecommunications Engineering;Dept Electrical and Power Engineering;CNRS-UMR",
        "aff_unique_url": ";;",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Yaounde;Ebolowa;",
        "aff_country_unique_index": "0;0;0;1;1;0;1",
        "aff_country_unique": "Cameroon;France"
    },
    {
        "id": "10161027",
        "title": "Analyzing Infrastructure LiDAR Placement with Realistic LiDAR Simulation Library",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, Vehicle-to-Everything (V2X) cooperative perception has attracted increasing attention. Infrastructure sensors play a critical role in this research field; however, how to find the optimal placement of infrastructure sensors is rarely studied. In this paper, we investigate the problem of infrastructure sensor placement and propose a pipeline that can efficiently and effectively find optimal installation positions for infrastructure sensors in a realistic simulated environment. To better simulate and evaluate LiDAR place-ment, we establish a Realistic LiDAR Simulation library that can simulate the unique characteristics of different popular LiDARs and produce high-fidelity LiDAR point clouds in the CARLA simulator. Through simulating point cloud data in different LiDAR placements, we can evaluate the perception accuracy of these placements using multiple detection models. Then, we analyze the correlation between the point cloud distribution and perception accuracy by calculating the density and uniformity of regions of interest. Experiments show that when using the same number and type of LiDAR, the placement scheme optimized by our proposed method improves the average precision by 15%, compared with the conventional placement scheme in the standard lane scene. We also analyze the correlation between perception performance in the region of interest and LiDAR point cloud distribution and validate that density and uniformity can be indicators of performance. Both the RLS Library and related code will be released at https://github.com/PJLab-ADG/LiDARSimLib-and-Placement-Evaluation.",
        "primary_area": "",
        "author": "Xinyu Cai;Wentao Jiang;Runsheng Xu;Wenquan Zhao;Jiaqi Ma;Si Liu;Yikang Li;Xinyu Cai;Wentao Jiang;Runsheng Xu;Wenquan Zhao;Jiaqi Ma;Si Liu;Yikang Li",
        "authorids": "/37089661769;/37088456431;/37089002744;/37089726608;/37085693088;/37406043500;/37089161200;/37089661769;/37088456431;/37089002744;/37089726608;/37085693088;/37406043500;/37089161200",
        "aff": "Autonomous Driving Group, Shanghai AI Laboratory, China; Institute of Artificial Intelligence, Beihang University; University of California, Los Angeles, USA; Autonomous Driving Group, Shanghai AI Laboratory, China; University of California, Los Angeles, USA; Institute of Artificial Intelligence, Beihang University; Autonomous Driving Group, Shanghai AI Laboratory, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161027/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5550385504831536620&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;2;1;0",
        "aff_unique_norm": "Shanghai AI Laboratory;Beihang University;University of California, Los Angeles",
        "aff_unique_dep": "Autonomous Driving Group;Institute of Artificial Intelligence;",
        "aff_unique_url": ";http://www.buaa.edu.cn;https://www.ucla.edu",
        "aff_unique_abbr": ";Beihang;UCLA",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;0;1;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10161488",
        "title": "Anchoring Sagittal Plane Templates in a Spatial Quadruped",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a new controller that stabilizes the motion of a spatial quadruped around sagittal-plane templates. It enables highly dynamic gaits and transitional maneuvers formed from parallel and sequential compositions of such planar templates in settings that require significant out-of-plane reactivity. The controller admits formal guarantees of stability with some modest assumptions. Experimental results validate the reliable execution of those planar template-based maneuvers, even in the face of large lateral, yaw, and roll incurring disturbances. This spatial anchor, fixed in parallel composition with a variety of different parallel and sequential compositions of sagittal plane templates, illustrates the robust portability of provably interoperable modular control components across a variety of hardware platforms and behaviors.",
        "primary_area": "",
        "author": "Timothy Greco;Daniel E. Koditschek;Timothy Greco;Daniel E. Koditschek",
        "authorids": "/37089893620;/37275653000;/37089893620;/37275653000",
        "aff": "GRASP Lab, University of Pennsylvania, Philadelphia, PA; GRASP Lab, University of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161488/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2526742251249157088&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161448",
        "title": "Annotating Covert Hazardous Driving Scenarios Online: Utilizing Drivers' Electroencephalography (EEG) Signals",
        "track": "main",
        "status": "Poster",
        "abstract": "As autonomous driving systems prevail, it is becoming increasingly critical that the systems learn from databases containing fine-grained driving scenarios. Most databases currently available are human-annotated; they are expensive, time-consuming, and subject to behavioral biases. In this paper, we provide initial evidence supporting a novel technique utilizing drivers' electroencephalography (EEG) signals to implicitly label hazardous driving scenarios while passively viewing recordings of real-road driving, thus sparing the need for manual annotation and avoiding human annotators' behavioral biases during explicit report. We conducted an EEG experiment using real-life and animated recordings of driving scenarios and asked participants to report danger explicitly whenever necessary. Behavioral results showed the participants tended to report danger only when overt hazards (e.g., a vehicle or a pedestrian appearing unexpectedly from behind an occlusion) were in view. By contrast, their EEG signals were enhanced at the sight of both an overt hazard and a covert hazard (e.g., an occlusion signalling possible appearance of a vehicle or a pedestrian from behind). Thus, EEG signals were more sensitive to driving hazards than explicit reports. Further, the Time-Series AI (TSAI, [1]) successfully classified EEG signals corresponding to overt and covert hazards. We discuss future steps necessary to materialize the technique in real life.",
        "primary_area": "",
        "author": "Chen Zheng;Muxiao Zi;Wenjie Jiang;Mengdi Chu;Yan Zhang;Jirui Yuan;Guyue Zhou;Jiangtao Gong;Chen Zheng;Muxiao Zi;Wenjie Jiang;Mengdi Chu;Yan Zhang;Jirui Yuan;Guyue Zhou;Jiangtao Gong",
        "authorids": "/37089892683;/37089893084;/37089892679;/37089895833;/37089895762;/37089538852;/37085489402;/37089661527;/37089892683;/37089893084;/37089892679;/37089895833;/37089895762;/37089538852;/37085489402;/37089661527",
        "aff": "Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China; Institute for AI Industry Research, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161448/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15215564284240017404&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Institute for AI Industry Research",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161507",
        "title": "Anomaly Detection For Robust Autonomous Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Human drivers are remarkably robust against various unexpected occurring variations and corruptions by understanding temporal changes and traffic scenes. In contrast, the neural network based autonomous navigation system can be easily affected by sensor data anomaly, like occlusion, sensor noise, challenging weather and illumination conditions. Such external disturbances are inevitable in practical driving applications. In this paper, we develop a semi-supervised anomaly detection module to detect the corrupted data while extracting the traffic scenario features. We further introduce an end-to-end robust autonomous navigation framework based on the idea that the consecutive frames of clean data depict a similar traffic scenario and the differences among the sequential data imply the dynamic state changes. By taking into consideration both spatial traffic scenario and temporal environmental variation, the model is able to achieve robust navigation against sensor data corruptions. We conduct experiments in CARLA platform and the evaluation results show the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Kefan Jin;Fan Mu;Xingyao Han;Guangming Wang;Zhe Liu;Kefan Jin;Fan Mu;Xingyao Han;Guangming Wang;Zhe Liu",
        "authorids": "/37088963780;/37089893070;/37089125837;/37086937116;/38505849700;/37088963780;/37089893070;/37089125837;/37086937116;/38505849700",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161507/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12131717680494366615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "MoE Key Lab of Artificial Intelligence, AI Institute",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161390",
        "title": "Anthropomorphic robot hand using the principle of sweat and fingerprints of human hands",
        "track": "main",
        "status": "Poster",
        "abstract": "In our daily life, when a small amount of sweat or water forms on a person's hand, we can empirically feel that the friction force of the hand increases, and the objects are gripped well. However, if sweat or water forms heavily, we can feel the friction decrease when holding an object. In this study, we analyzed the degree to which fingerprints and sweat present on a person's hand can affect the friction force between the hand and the gripping object. We fabricated an anthropomorphic robot hand with a fingerprint structure to set up an environment similar to that of the human hand, and performed object-holding and friction-change experiments by changing the amount of sweat to verify that this phenomenon can be applied to a robot hand. Furthermore, we for the first time proposed and developed a variable friction system using fluids and microstructures to solve the difficulty of anthropomorphic robot hand force control. By applying the manufactured variable friction system and performing an active friction control performance test and an object grip test of the robot hand, we validated that the fingerprint and sweat of a human hand can affect the grip of an actual object.",
        "primary_area": "",
        "author": "Donghyun Kim;Junmo Yang;Dongwon Yun;Donghyun Kim;Junmo Yang;Dongwon Yun",
        "authorids": "/37090059072;/37088366064;/37589762000;/37090059072;/37088366064;/37589762000",
        "aff": "Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161390/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17920167087054298216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": "Department of Robotics and Mechatronics Engineering",
        "aff_unique_url": "https://www.dgist.ac.kr",
        "aff_unique_abbr": "DGIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daegu",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161286",
        "title": "Anticipation and Delayed Estimation of Sagittal Plane Human Hip Moments using Deep Learning and a Robotic Hip Exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating human joint moments using wearable sensors has utility for personalized health monitoring and generalized exoskeleton control. Data-driven models have potential to map wearable sensor data to human joint moments, even with a reduced sensor suite and without subject-specific calibration. In this study, we quantified the RMSE and R2 of a temporal convolutional network (TCN), trained to estimate human hip moments in the sagittal plane using exoskeleton sensor data (i.e., a hip encoder and thigh- and pelvis-mounted inertial measurement units). We conducted three analyses in which we iteratively retrained the network while: 1) varying the input sequence length of the model, 2) incorporating noncausal data into the input sequence, thus delaying the network estimates, and 3) time shifting the labels to train the model to anticipate (i.e., predict) human hip moments. We found that 930 ms of causal input data maintained model performance while minimizing input sequence length (validation RMSE and R2 of 0.141\u00b10.014 Nm/kg and 0.883\u00b10.025, respectively). Further, delaying the model estimate by up to 200 ms significantly improved model performance compared to the best causal estimators (p<0.05), improving estimator fidelity in use cases where delayed estimates are acceptable (e.g., in personalized health monitoring or diagnoses). Finally, we found that anticipating hip moments further in time linearly increased model RMSE and decreased R2 (p<0.05); however, performance remained strong (R2>0.85) when predicting up to 200 ms ahead.",
        "primary_area": "",
        "author": "Dean D. Molinaro;Ethan O. Park;Aaron J. Young;Dean D. Molinaro;Ethan O. Park;Aaron J. Young",
        "authorids": "/37088534493;/37089892294;/38021039000;/37088534493;/37089892294;/38021039000",
        "aff": "Institute for Robotics and Intelligent Machines (IRIM), Georgia Institute of Technology, Atlanta, GA, USA; Grainger College of Engineering, University of Illinois Urbana-Champaign, Urbana, IL, USA; Institute for Robotics and Intelligent Machines (IRIM), Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161286/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1648477490087948444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines (IRIM);Grainger College of Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://illinois.edu",
        "aff_unique_abbr": "Georgia Tech;UIUC",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Atlanta;Urbana",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160260",
        "title": "Anticipatory Planning: Improving Long-Lived Planning by Estimating Expected Cost of Future Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider a service robot in a household environment given a sequence of high-level tasks one at a time. Most existing task planners, lacking knowledge of what they may be asked to do next, solve each task in isolation and so may unwittingly introduce side effects that make subsequent tasks more costly. In order to reduce the overall cost of completing all tasks, we consider that the robot must anticipate the impact its actions could have on future tasks. Thus, we propose anticipatory planning: an approach in which estimates of the expected future cost, from a graph neural network, augment model-based task planning. Our approach guides the robot towards behaviors that encourage preparation and organization, reducing overall costs in long-lived planning scenarios. We evaluate our method on blockworld environments and show that our approach reduces the overall planning costs by 5% as compared to planning without anticipatory planning. Additionally, if given an opportunity to prepare the environment in advance (a special case of anticipatory planning), our planner improves overall cost by 11%.",
        "primary_area": "",
        "author": "Roshan Dhakal;Md Ridwan Hossain Talukder;Gregory J. Stein;Roshan Dhakal;Md Ridwan Hossain Talukder;Gregory J. Stein",
        "authorids": "/37086195273;/37089893570;/37085348859;/37086195273;/37089893570;/37085348859",
        "aff": "CS Department, George Mason University, Fairfax, VA; CS Department, George Mason University, Fairfax, VA; CS Department, George Mason University, Fairfax, VA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160260/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11366173224702479299&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "George Mason University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.gmu.edu",
        "aff_unique_abbr": "GMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Fairfax",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160219",
        "title": "Approximating Discontinuous Nash Equilibrial Values of Two-Player General-Sum Differential Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Finding Nash equilibrial policies for two-player differential games requires solving Hamilton-Jacobi-Isaacs (HJI) PDEs. Self-supervised learning has been used to approximate solutions of such PDEs while circumventing the curse of dimensionality. However, this method fails to learn discontinuous PDE solutions due to its sampling nature, leading to poor safety performance of the resulting controllers in robotics applications when player rewards are discontinuous. This paper investigates two potential solutions to this problem: a hybrid method that leverages both supervised Nash equilibria and the HJI PDE, and a value-hardening method where a sequence of HJIs are solved with a gradually hardening reward. We compare these solutions using the resulting generalization and safety performance in two vehicle interaction simulation studies with 5D and 9D state spaces, respectively. Results show that with informative supervision (e.g., collision and near-collision demonstrations) and the low cost of self-supervised learning, the hybrid method achieves better safety performance than the supervised, self-supervised, and value hardening approaches on equal computational budget. Value hardening fails to generalize in the higher-dimensional case without informative supervision. Lastly, we show that the neural activation function needs to be continuously differentiable for learning PDEs and its choice can be case dependent.",
        "primary_area": "",
        "author": "Lei Zhang;Mukesh Ghimire;Wenlong Zhang;Zhe Xu;Yi Ren;Lei Zhang;Mukesh Ghimire;Wenlong Zhang;Zhe Xu;Yi Ren",
        "authorids": "/37088999564;/37089514743;/37085823780;/37086071442;/37086861024;/37088999564;/37089514743;/37085823780;/37086071442;/37086861024",
        "aff": "Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA; Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA; Polytechnic School, Ira A. Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA; Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA; Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160219/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15808325764913221060&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Tempe;Mesa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160912",
        "title": "Approximation Algorithms for Robot Tours in Random Fields with Guaranteed Estimation Accuracy",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the sample placement and shortest tour problem for robots tasked with mapping environmental phenomena modeled as stationary random fields. The objective is to minimize the resources used (samples or tour length) while guaranteeing estimation accuracy. We give approximation algorithms for both problems in convex environments. These improve previously known results, both in terms of theoretical guarantees and in simulations. In addition, we disprove an existing claim in the literature on a lower bound for a solution to the sample placement problem.",
        "primary_area": "",
        "author": "Shamak Dutta;Nils Wilde;Pratap Tokekar;Stephen L. Smith;Shamak Dutta;Nils Wilde;Pratap Tokekar;Stephen L. Smith",
        "authorids": "/37086099895;/37086453460;/37546532700;/37335139700;/37086099895;/37086453460;/37546532700;/37335139700",
        "aff": "Department of Electrical and Computer Engineering, University of Waterloo, Canada; Cognitive Robotics Department, Delft University of Technology, Netherlands; Department of Computer Science, University of Maryland; Department of Electrical and Computer Engineering, University of Waterloo, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160912/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10481175056429742117&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Waterloo;Delft University of Technology;University of Maryland",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Cognitive Robotics Department;Department of Computer Science",
        "aff_unique_url": "https://uwaterloo.ca;https://www.tudelft.nl;https://www/umd.edu",
        "aff_unique_abbr": "UW;TU Delft;UMD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Canada;Netherlands;United States"
    },
    {
        "id": "10161494",
        "title": "Aquarium: A Fully Differentiable Fluid-Structure Interaction Solver for Robotics Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Aquarium, a differentiable fluid-structure interaction solver for robotics that offers stable simulation, accurately coupled fluid-robot physics in two dimensions, and full differentiability with respect to fluid and robot states and parameters. Aquarium achieves stable simulation with accurate flow physics by directly integrating over the incompressible Navier-Stokes equations using a fully implicit Crank-Nicolson scheme with a second-order finite-volume spa-tial discretization. The fluid and robot physics are coupled using the immersed-boundary method by formulating the no-slip condition as an equality constraint applied directly to the Navier-Stokes system. This choice of coupling allows the fluid-structure interaction to be posed and solved as a nonlinear optimization problem. This optimization-based formulation is then exploited using the implicit-function theorem to compute derivatives. Derivatives can then be passed to downstream gradient-based optimization or learning algorithms. We demon-strate Aquarium's ability to accurately simulate coupled fluid-robot physics with numerous 2D examples, including a cylinder in free stream and a soft robotic fish tail with hardware validation. We also demonstrate Aquarium's ability to provide analytical gradients by performing gradient-based shape-and-gait optimization of an oscillating diamond foil to maximize its generated thrust.",
        "primary_area": "",
        "author": "Jeong Hun Lee;Mike Y. Michelis;Robert Katzschmann;Zachary Manchester;Jeong Hun Lee;Mike Y. Michelis;Robert Katzschmann;Zachary Manchester",
        "authorids": "/37089896131;/37089338268;/37085423557;/37086011525;/37089896131;/37089338268;/37085423557;/37086011525",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; ETH Zurich, Soft Robotics Lab, Zurich, Switzerland; ETH Zurich, Soft Robotics Lab, Zurich, Switzerland; The Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161494/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16049145820004756431&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Carnegie Mellon University;ETH Zurich",
        "aff_unique_dep": "The Robotics Institute;Soft Robotics Lab",
        "aff_unique_url": "https://www.cmu.edu;https://www.ethz.ch",
        "aff_unique_abbr": "CMU;ETHZ",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Pittsburgh;Zurich",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "10160226",
        "title": "Are All Point Clouds Suitable for Completion? Weakly Supervised Quality Evaluation Network for Point Cloud Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "In the practical application of point cloud completion tasks, real data quality is usually much worse than the CAD datasets used for training. A small amount of noisy data will usually significantly impact the overall system's accuracy. In this paper, we propose a quality evaluation network to score the point clouds and help judge the quality of the point cloud before applying the completion model. We believe our scoring method can help researchers select more appropriate point clouds for subsequent completion and reconstruction and avoid manual parameter adjustment. Moreover, our evaluation model is fast and straightforward and can be directly inserted into any model's training or use process to facilitate the automatic selection and post-processing of point clouds. We propose a complete dataset construction and model evaluation method based on ShapeNet. We verify our network using detection and flow estimation tasks on KITTI, a real-world dataset for autonomous driving. The experimental results show that our model can effectively distinguish the quality of point clouds and help in practical tasks.",
        "primary_area": "",
        "author": "Jieqi Shi;Peiliang Li;Xiaozhi Chen;Shaojie Shen;Jieqi Shi;Peiliang Li;Xiaozhi Chen;Shaojie Shen",
        "authorids": "/37088457112;/37086229175;/37085505385;/37954847200;/37088457112;/37086229175;/37085505385;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology; Dji Co; Dji Co; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160226/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4766569671734665303&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;DJI",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;",
        "aff_unique_url": "https://www.ust.hk;https://www.dji.com",
        "aff_unique_abbr": "HKUST;DJI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161004",
        "title": "Asking for Help: Failure Prediction in Behavioral Cloning through Value Approximation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent progress in end-to-end Imitation Learning approaches has shown promising results and generalization capabilities on mobile manipulation tasks. Such models are seeing increasing deployment in real-world settings, where scaling up requires robots to be able to operate with high autonomy, i.e. requiring as little human supervision as possible. In order to avoid the need for one-on-one human supervision, robots need to be able to detect and prevent policy failures ahead of time, and ask for help, allowing a remote operator to supervise multiple robots and help when needed. However, the black-box nature of end-to-end Imitation Learning models such as Behavioral Cloning, as well as the lack of an explicit state-value representation, make it difficult to predict failures. To this end, we introduce Behavioral Cloning Value Approximation (BCVA), an approach to learning a state value function based on and trained jointly with a Behavioral Cloning policy that can be used to predict failures. We demonstrate the effectiveness of BCVA by applying it to the challenging mobile manipulation task of latched-door opening, showing that we can identify failure scenarios with with 86% precision and 81 % recall, evaluated on over 2000 real world runs, improving upon the baseline of simple failure classification by 10 percentage-points.",
        "primary_area": "",
        "author": "Cem Gokmen;Daniel Ho;Mohi Khansari;Cem Gokmen;Daniel Ho;Mohi Khansari",
        "authorids": "/37089895357;/37267934200;/37088456107;/37089895357;/37267934200;/37088456107",
        "aff": "Everyday Robots, Mountain View, CA; Waymo; Everyday Robots, Mountain View, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161004/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11946280104972568439&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Everyday Robots;Waymo",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.waymo.com",
        "aff_unique_abbr": ";Waymo",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161269",
        "title": "Asynchronous State Estimation of Simultaneous Ego-motion Estimation and Multiple Object Tracking for LiDAR-Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose LiDAR-Inertial Odometry via Simultaneous EGo-motion estimation and Multiple Object Tracking (LIO-SEGMOT), an optimization-based odometry approach targeted for dynamic environments. LIO-SEGMOT is formulated as a state estimation approach with asynchronous state update of the odometry and the object tracking. That is, LIO-SEGMOT can provide continuous object tracking results while preserving the keyframe selection mechanism in the odometry system. Meanwhile, a hierarchical criterion is designed to properly couple odometry and object tracking, preventing system instability due to poor detections. We compare LIO-SEGMOT against the baseline model LIO-SAM, a state-of-the-art LIO approach, under dynamic environments of the KITTI raw dataset and the self-collected Hsinchu dataset. The former experiment shows that LIO-SEGMOT obtains an average improvement 1.61% and 5.41% of odometry accuracy in terms of absolute translational and rotational trajectory errors. The latter experiment also indicates that LIO-SEGMOT obtains an average improvement 6.97% and 4.21% of odometry accuracy.",
        "primary_area": "",
        "author": "Yu-Kai Lin;Wen-Chieh Lin;Chieh-Chih Wang;Yu-Kai Lin;Wen-Chieh Lin;Chieh-Chih Wang",
        "authorids": "/37086458256;/37291223500;/37088493330;/37086458256;/37291223500;/37088493330",
        "aff": "Institute of Multimedia Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Multimedia Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Mechanical and Mechatronics Systems Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161269/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16921866042851551403&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "National Yang Ming Chiao Tung University;Industrial Technology Research Institute",
        "aff_unique_dep": "Institute of Multimedia Engineering;Mechanical and Mechatronics Systems Research Laboratories",
        "aff_unique_url": "https://www.nycu.edu.tw;https://www.itri.org.tw",
        "aff_unique_abbr": "NYCU;ITRI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161087",
        "title": "Atomic-level Tracking and Analyzing of Quantum-dot Motion Steered by an Electrostatic Field Positioned by a Nanorobotic Manipulation Tip",
        "track": "main",
        "status": "Poster",
        "abstract": "Field-control-based nanorobotic manipulation of ions at the single atomic level is an enabling technique for such applications as in-situ prototyping and characterization for fundamental research and rapid product development of nanoscale and quantum devices such as sensors, batteries, neuromorphic devices, and neuro/brain interfaces. Taking the motion of quantum dots (QDs) manipulated by an electrostatic field steered by a probe tip on a target surface as an example, here we show a deep-learning-based approach for their global motion tracking via the individual atoms both on the surface and inside the body. Transmission electron graphs, element analysis, and crystal topology acquired from an aberration-corrected transmission electron microscope (Cs-TEM) are used to identify the positions, types, and structures of the atoms to understand their kinematics. The results show the feasibility of multi-target tracking of homogeneous atoms by their spatial structure projection, which is very encouraging for further extension to the tracking and regulation of crystalline grains, swarms of ions, ion filaments, and single ions.",
        "primary_area": "",
        "author": "Zhi Qu;Wenqi Zhang;Lixin Dong;Zhi Qu;Wenqi Zhang;Lixin Dong",
        "authorids": "/37089271788;/37087030507;/37275019100;/37089271788;/37087030507;/37275019100",
        "aff": "Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161087/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Too57AoXcF0J:scholar.google.com/&scioq=Atomic-level+Tracking+and+Analyzing+of+Quantum-dot+Motion+Steered+by+an+Electrostatic+Field+Positioned+by+a+Nanorobotic+Manipulation+Tip&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "City University of Hong Kong",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.cityu.edu.hk",
        "aff_unique_abbr": "CityU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160285",
        "title": "Augmented Reality-Assisted Robot Learning Framework for Minimally Invasive Surgery Task",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an Augmented Reality (AR)assisted robot learning framework for Minimally Invasive Surgery (MIS) tasks. The proposed framework exploits an external optical tracking system to collect human demonstration. Gaussian Mixture Model (GMM) and Gaussian Mixture Regression (GMR) are utilized to encode and generate a robust desired trajectory for transferring to the real robot for the MIS task. The HoloLens 2 Head-Mounted-Display (HMD) is integrated for intuitive visualization of the robot configuration under the constraint of a small incision on the patient's abdominal cavity during the demonstration phase. Experiments are conducted to verify the feasibility and performance of the proposed framework and compared it with the kinesthetic teaching-based modality in a tumor resection MIS task. The results illustrate that the proposed AR-assisted robot learning framework requires lower workload demand, achieves higher performance and efficiency, and ensures the feasibility of the learned results for reproduction on a real robot for MIS tasks.",
        "primary_area": "",
        "author": "Junling Fu;Maria Chiara Palumbo;Elisa Iovene;Qingsheng Liu;Ilaria Burzo;Alberto Redaelli;Giancarlo Ferrigno;Elena De Momi;Junling Fu;Maria Chiara Palumbo;Elisa Iovene;Qingsheng Liu;Ilaria Burzo;Alberto Redaelli;Giancarlo Ferrigno;Elena De Momi",
        "authorids": "/37088953289;/37089432452;/37089846796;/37089894092;/37089895561;/37664942800;/37294130300;/37947344300;/37088953289;/37089432452;/37089846796;/37089894092;/37089895561;/37664942800;/37294130300;/37947344300",
        "aff": "Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; College of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160285/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=134717246748784799&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;0;0;0;0",
        "aff_unique_norm": "Politecnico di Milano;Ocean University of China",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering;College of Information Science and Engineering",
        "aff_unique_url": "https://www.polimi.it;http://www.ouc.edu.cn",
        "aff_unique_abbr": "Politecnico di Milano;OUC",
        "aff_campus_unique_index": "0;0;0;1;0;0;0;0",
        "aff_campus_unique": "Milan;Qingdao",
        "aff_country_unique_index": "0;0;0;1;0;0;0;0",
        "aff_country_unique": "Italy;China"
    },
    {
        "id": "10161376",
        "title": "Auto-Assembly: a framework for automated robotic assembly directly from CAD",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a framework called Auto-Assembly for automated robotic assembly from design files and demonstrate a practical implementation on modular parts joined by fastening using a robotic cell consisting of two robots. We show the flexibility of the approach by testing it on different input designs. Auto-Assembly consists of several parts: design analysis, assembly sequence generation, bill-of-process (BOP) generation, conversion of the BOP to control code, path planning, simulation, and execution of the control code to assemble parts in the physical environment.",
        "primary_area": "",
        "author": "Fedor Chervinskii;Sergei Zobov;Aleksandr Rybnikov;Danil Petrov;Komal Vendidandi;Fedor Chervinskii;Sergei Zobov;Aleksandr Rybnikov;Danil Petrov;Komal Vendidandi",
        "authorids": "/37089894100;/37089893739;/37089893281;/37089893371;/37089892378;/37089894100;/37089893739;/37089893281;/37089893371;/37089892378",
        "aff": "\u039b \u0393 \u0393 I V \u039b L; \u039b \u0393 \u0393 I V \u039b L; \u039b \u0393 \u0393 I V \u039b L; \u039b \u0393 \u0393 I V \u039b L; \u039b \u0393 \u0393 I V \u039b L",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161376/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4969644857228933503&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10161402",
        "title": "AutoBag: Learning to Open Plastic Bags and Insert Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Thin plastic bags are ubiquitous in retail stores, healthcare, food handling, recycling, homes, and school lunchrooms. They are challenging both for perception (due to specularities and occlusions) and for manipulation (due to the dynamics of their 3D deformable structure). We formulate the task of \u201cbagging:\u201d manipulating common plastic shopping bags with two handles from an unstructured initial state to an open state where at least one solid object can be inserted into the bag and lifted for transport. We propose a self-supervised learning framework where a dual-arm robot learns to recognize the handles and rim of plastic bags using UV-fluorescent markings; at execution time, the robot does not use UV markings or UV light. We propose the AutoBag algorithm, where the robot uses the learned perception model to open a plastic bag through iterative manipulation. We present novel metrics to evaluate the quality of a bag state and new motion primitives for reorienting and opening bags based on visual observations. In physical experiments, a YuMi robot using AutoBag is able to open bags and achieve a success rate of 16/30 for inserting at least one item across a variety of initial bag configurations. Supplementary material is available at https://sites.google.com/view/autobag.",
        "primary_area": "",
        "author": "Lawrence Yunliang Chen;Baiyu Shi;Daniel Seita;Richard Cheng;Thomas Kollar;David Held;Ken Goldberg;Lawrence Yunliang Chen;Baiyu Shi;Daniel Seita;Richard Cheng;Thomas Kollar;David Held;Ken Goldberg",
        "authorids": "/37089447531;/37089848502;/37086012763;/37086493605;/37402789000;/37408101800;/37273026700;/37089447531;/37089848502;/37086012763;/37086493605;/37402789000;/37408101800;/37273026700",
        "aff": "The AUTOLab, UC Berkeley, United States; The AUTOLab, UC Berkeley, United States; The Robotics Institute at Carnegie Mellon University, United States; Toyota Research Institute, Los Altos, USA; Toyota Research Institute, Los Altos, USA; The Robotics Institute at Carnegie Mellon University, United States; The AUTOLab, UC Berkeley, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161402/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16418146579107718472&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;2;1;0",
        "aff_unique_norm": "University of California, Berkeley;Carnegie Mellon University;Toyota Research Institute",
        "aff_unique_dep": "The AUTOLab;The Robotics Institute;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.cmu.edu;https://www.tri.global",
        "aff_unique_abbr": "UC Berkeley;CMU;TRI",
        "aff_campus_unique_index": "0;0;2;2;0",
        "aff_campus_unique": "Berkeley;;Los Altos",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161503",
        "title": "AutoCharge: Autonomous Charging for Perpetual Quadrotor Missions",
        "track": "main",
        "status": "Poster",
        "abstract": "Battery endurance represents a key challenge for long-term autonomy and long-range operations, especially in the case of aerial robots. In this paper, we propose AutoCharge, an autonomous charging solution for quadrotors that combines a portable ground station with a flexible, lightweight charging tether and is capable of universal, highly efficient, and robust charging. We design and manufacture a pair of circular magnetic connectors to ensure a precise orientation-agnostic electrical connection between the ground station and the charging tether. Moreover, we supply the ground station with an electromagnet that largely increases the tolerance to localization and control errors during the docking maneuver, while still guaranteeing smooth un-docking once the charging process is completed. We demonstrate AutoCharge on a perpetual 10 hours quadrotor flight experiment and show that the docking and un-docking performance is solidly repeatable, enabling perpetual quadrotor flight missions.",
        "primary_area": "",
        "author": "Alessandro Saviolo;Jeffrey Mao;Roshan Balu T M B;Vivek Radhakrishnan;Giuseppe Loianno;Alessandro Saviolo;Jeffrey Mao;Roshan Balu T M B;Vivek Radhakrishnan;Giuseppe Loianno",
        "authorids": "/37089311932;/37089195746;/37089894165;/37089659053;/37085496544;/37089311932;/37089195746;/37089894165;/37089659053;/37085496544",
        "aff": "New York University, Tandon School of Engineering, Brooklyn, NY, USA; New York University, Tandon School of Engineering, Brooklyn, NY, USA; New York University, Tandon School of Engineering, Brooklyn, NY, USA; Autonomous Robotics Research Center, Technology Innovation Institute, Abu Dhabi, UAE; New York University, Tandon School of Engineering, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161503/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9668045997747207889&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "New York University;Technology Innovation Institute",
        "aff_unique_dep": "Tandon School of Engineering;Autonomous Robotics Research Center",
        "aff_unique_url": "https://www.nyu.edu;",
        "aff_unique_abbr": "NYU;",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Brooklyn;Abu Dhabi",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;United Arab Emirates"
    },
    {
        "id": "10161364",
        "title": "Automated Action Evaluation for Robotic Imitation Learning via Siamese Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite recent advances in video-guided robotic imitation learning, many methods still rely on human experts to provide sparse rewards that indicate whether robots have successfully completed tasks. The challenge of enabling robots to autonomously evaluate whether their actions can complete complex, multi-stage tasks remains unresolved. In this work, we propose an efficient few-shot robotic learning algorithm that centres around learning and evaluating from a third-person perspective to address the aforementioned challenge. We develop a novel Siamese neural network-based robotic action-state evaluation system, named \u201cBehavior-Outcome Dual Assessment\u201d (BODA), in our robotic imitation learning system, so as to replace artificial evaluations from human experts in multi-stage imitation learning processes and to improve learning efficiency. In this way, one video demonstration of a target task is divided into several stages. For each stage, we design two Siamese neural network-based evaluation modules in BODA: One module focuses on action changes, and the other handles working environment changes. The two modules work together to provide a comprehensive assessment of the robot's completion of each stage from the view of both the action and working environment changes. Then, BODA is integrated within a model-based reinforcement learning framework to enable the completion of our imitation learning cycle. Extensive experiments demonstrate that the evaluation processes of BODA can automatically and accurately evaluate task completion status without human intervention. In contrast to conventional methods, BODA is able to keep the accumulation of errors within acceptable limits through self-assessment in stages.",
        "primary_area": "",
        "author": "Xiang Chang;Fei Chao;Changjing Shang;Qiang Shen;Xiang Chang;Fei Chao;Changjing Shang;Qiang Shen",
        "authorids": "/37088518528;/38467011600;/37356805200;/37272041100;/37088518528;/38467011600;/37356805200;/37272041100",
        "aff": "Department of Computer Science, Institute of Mathematics, Physics and Computer Science, Aberystwyth University, UK; Department of Computer Science, Institute of Mathematics, Physics and Computer Science, Aberystwyth University, UK; Department of Computer Science, Institute of Mathematics, Physics and Computer Science, Aberystwyth University, UK; Department of Computer Science, Institute of Mathematics, Physics and Computer Science, Aberystwyth University, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161364/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Pg3d_QeCmrUJ:scholar.google.com/&scioq=Automated+Action+Evaluation+for+Robotic+Imitation+Learning+via+Siamese+Neural+Networks&hl=en&as_sdt=0,33",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Aberystwyth University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.aber.ac.uk",
        "aff_unique_abbr": "Aberystwyth",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161043",
        "title": "Automatic Cell Rotation Method Based on Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Cell rotation is widely used to adjust cell posture in sub-cellular micromanipulations. The trajectory planning of the injection micropipette is needed, so that the cells can be rotated with the minimum deformation to reduce cell damage and keep cell viability. Due to the uncertainty of cell properties and manipulation environment, it is difficult to identify the parameters of the mechanical models in traditional robotic cell rotation methods. In this paper, deep reinforcement learning is introduced into cell manipulation for the first time to perform trajectory planning of the micropipette. We first abstract the cell rotation process by using the mechanical model and microscopic vision techniques and build a cell rotation simulation environment. Then we design a reward function by combining various factors of cell rotation and implement a reinforcement learning framework based on deep Q-learning (DQL). Finally, we train the cell rotation process based on the deep reinforcement learning algorithm. The simulation results indicate the proposed DQL agent achieved an average success rate of 97% without useless exploration. Moreover, the proposed method rotated the cells in a way that causes less mechanical damage than humans, demonstrating the DRL ability for cell rotation with high efficiency and low cell damage.",
        "primary_area": "",
        "author": "Huiying Gong;Yujie Zhang;Yaowei Liu;Qili Zhao;Xin Zhao;Mingzhu Sun;Huiying Gong;Yujie Zhang;Yaowei Liu;Qili Zhao;Xin Zhao;Mingzhu Sun",
        "authorids": "/37088941945;/37088982585;/37086173893;/37085425276;/37293143500;/37536498500;/37088941945;/37088982585;/37086173893;/37085425276;/37293143500;/37536498500",
        "aff": "the Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; the Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; the Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; the Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; the Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China; the Institute of Intelligence Technology and Robotic Systems, Shenzhen Research Institute of Nankai University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161043/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17746304969600162582&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Nankai University",
        "aff_unique_dep": "Institute of Intelligence Technology and Robotic Systems",
        "aff_unique_url": "http://www.nankai.edu.cn",
        "aff_unique_abbr": "Nankai",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160409",
        "title": "Automatic Generation of Robot Facial Expressions with Preferences",
        "track": "main",
        "status": "Poster",
        "abstract": "The capability of humanoid robots to generate facial expressions is crucial for enhancing interactivity and emotional resonance in human-robot interaction. However, humanoid robots vary in mechanics, manufacturing, and ap-pearance. The lack of consistent processing techniques and the complexity of generating facial expressions pose significant challenges in the field. To acquire solutions with high confidence, it is necessary to enable robots to explore the solution space automatically based on performance feedback. To this end, we designed a physical robot with a human-like appearance and developed a general framework for automatic expression generation using the MAP-Elites algorithm. The main advan-tage of our framework is that it does not only generate facial expressions automatically but can also be customized according to user preferences. The experimental results demonstrate that our framework can efficiently generate realistic facial expressions without hard coding or prior knowledge of the robot kinematics. Moreover, it can guide the solution-generation process in accordance with user preferences, which is desirable in many real-world applications.",
        "primary_area": "",
        "author": "Bing Tang;Rongyun Cao;Rongya Chen;Xiaoping Chen;Bei Hua;Feng Wu;Bing Tang;Rongyun Cao;Rongya Chen;Xiaoping Chen;Bei Hua;Feng Wu",
        "authorids": "/37089893291;/37089893397;/37089895897;/37439596700;/37683385300;/37272892600;/37089893291;/37089893397;/37089895897;/37439596700;/37683385300;/37272892600",
        "aff": "School of Computer Science and Technology, University of Science and Technology of China; School of Computer Science and Technology, University of Science and Technology of China; Institute of Advanced Technology, University of Science and Technology of China; School of Computer Science and Technology, University of Science and Technology of China; School of Computer Science and Technology, University of Science and Technology of China; School of Computer Science and Technology, University of Science and Technology of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160409/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16780902405549856080&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160966",
        "title": "Automating Vascular Shunt Insertion with the dVRK Surgical Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Vascular shunt insertion is a fundamental surgical procedure used to temporarily restore blood flow to tissues. It is often performed in the field after major trauma. We formulate a problem of automated vascular shunt insertion and propose a pipeline to perform Automated Vascular Shunt Insertion (AVSI) using a da Vinci Research Kit. The pipeline uses a learned visual model to estimate the locus of the vessel rim, plans a grasp on the rim, and moves to grasp at that point. The first robot gripper then pulls the rim to stretch open the vessel with a dilation motion. The second robot gripper then proceeds to insert a shunt into the vessel phantom (a model of the blood vessel) with a chamfer tilt followed by a screw motion. Results suggest that AVSI achieves a high success rate even with tight tolerances and varying vessel orientations up to 30\u00b0. Supplementary material, dataset, videos, and visualizations can be found at https://sites.google.com/berkeley.edu/autolab-avsi.",
        "primary_area": "",
        "author": "Karthik Dharmarajan;Will Panitch;Muyan Jiang;Kishore Srinivas;Baiyu Shi;Yahav Avigal;Huang Huang;Thomas Low;Danyal Fer;Ken Goldberg;Karthik Dharmarajan;Will Panitch;Muyan Jiang;Kishore Srinivas;Baiyu Shi;Yahav Avigal;Huang Huang;Thomas Low;Danyal Fer;Ken Goldberg",
        "authorids": "/37089579801;/37089578472;/37089895913;/37089579249;/37089848502;/37088504860;/37088985585;/37532299200;/37086541068;/37273026700;/37089579801;/37089578472;/37089895913;/37089579249;/37089848502;/37088504860;/37088985585;/37532299200;/37086541068;/37273026700",
        "aff": "The AUTOLab, UC Berkeley, United States; The AUTOLab, UC Berkeley, United States; The AUTOLab, UC Berkeley, United States; The AUTOLab, UC Berkeley, United States; The AUTOLab, UC Berkeley, United States; The AUTOLab, UC Berkeley, United States; The AUTOLab, UC Berkeley, United States; SRI International, USA; UC San Francisco Medical School, United States; The AUTOLab, UC Berkeley, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160966/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8866099561664232992&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;1;2;0",
        "aff_unique_norm": "University of California, Berkeley;SRI International;University of California, San Francisco",
        "aff_unique_dep": "The AUTOLab;;Medical School",
        "aff_unique_url": "https://www.berkeley.edu;https://www.sri.com;https://www.ucsf.edu",
        "aff_unique_abbr": "UC Berkeley;SRI;UCSF",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;2;0",
        "aff_campus_unique": "Berkeley;;San Francisco",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161578",
        "title": "Autonomous Control for Orographic Soaring of Fixed-Wing UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel controller for fixed-wing UAVs that enables autonomous soaring in an orographic wind field, extending flight endurance. Our method identifies soaring regions and addresses position control challenges by introducing a target gradient line (TGL) on which the UAV achieves an equilibrium soaring position, where sink rate and updraft are balanced. Experimental testing validates the controller's effectiveness in maintaining autonomous soaring flight without using any thrust in a non-static wind field. We also demonstrate a single degree of control freedom in a soaring position through manipulation of the TGL.",
        "primary_area": "",
        "author": "Tom Suys;Sunyou Hwang;Guido C.H.E. De Croon;Bart D.W. Remes;Tom Suys;Sunyou Hwang;Guido C.H.E. De Croon;Bart D.W. Remes",
        "authorids": "/37089892823;/37089894151;/37698062600;/37846204400;/37089892823;/37089894151;/37698062600;/37846204400",
        "aff": "Department of Control and Operations, MAVLab, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Department of Control and Operations, MAVLab, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Department of Control and Operations, MAVLab, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Department of Control and Operations, MAVLab, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161578/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11025138103324766485&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Faculty of Aerospace Engineering",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10161370",
        "title": "Autonomous Drifting with 3 Minutes of Data via Learned Tire Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Near the limits of adhesion, the forces generated by a tire are nonlinear and intricately coupled. Efficient and accurate modelling in this region could improve safety, especially in emergency situations where high forces are required. To this end, we propose a novel family of tire force models based on neural ordinary differential equations and a neural-ExpTanh parameterization. These models are designed to satisfy physically insightful assumptions while also having sufficient fidelity to capture higher-order effects directly from vehicle state measurements. They are used as drop-in replacements for an analytical brush tire model in an existing nonlinear model predictive control framework. Experiments with a customized Toyota Supra show that scarce amounts of driving data \u2013 less than three minutes \u2013 is sufficient to achieve high-performance autonomous drifting on various trajectories with speeds up to 45mph. Comparisons with the benchmark model show a 4x improvement in tracking performance, smoother control inputs, and faster and more consistent computation time.",
        "primary_area": "",
        "author": "Franck Djeumou;Jonathan Y.M. Goh;Ufuk Topcu;Avinash Balachandran;Franck Djeumou;Jonathan Y.M. Goh;Ufuk Topcu;Avinash Balachandran",
        "authorids": "/37088921957;/37085853085;/37299604900;/37085568648;/37088921957;/37085853085;/37299604900;/37085568648",
        "aff": "University of Texas at Austin, Austin, TX, USA; Toyota Research Institute, Los Altos, CA, USA; University of Texas at Austin, Austin, TX, USA; Toyota Research Institute, Los Altos, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161370/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17580893258089078037&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of Texas at Austin;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.tri.global",
        "aff_unique_abbr": "UT Austin;TRI",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Austin;Los Altos",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161383",
        "title": "Autonomous Drone Racing: Time-Optimal Spatial Iterative Learning Control within a Virtual Tube",
        "track": "main",
        "status": "Poster",
        "abstract": "It is often necessary for drones to complete delivery, photography, and rescue in the shortest time to increase efficiency. Many autonomous drone races provide platforms to pursue algorithms to finish races as quickly as possible for the above purpose. Unfortunately, existing methods often fail to keep training and racing time short in drone racing competitions. This motivates us to develop a high-efficient learning method by imitating the training experience of top racing drivers. Unlike traditional iterative learning control methods for accurate tracking, the proposed approach iteratively learns a trajectory online to finish the race as quickly as possible. Simulations and experiments using different models show that the proposed approach is model-free and is able to achieve the optimal result with low computation requirements. Furthermore, this approach surpasses some state-of-the-art methods in racing time on a benchmark drone racing platform. An experiment on a real quadcopter is also performed to demonstrate its effectiveness.",
        "primary_area": "",
        "author": "Shuli Lv;Yan Gao;Jiaxing Che;Quan Quan;Shuli Lv;Yan Gao;Jiaxing Che;Quan Quan",
        "authorids": "/37089892104;/37088986380;/37601946300;/37406014700;/37089892104;/37088986380;/37601946300;/37406014700",
        "aff": "School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161383/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14709746873969160914&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Automation Science and Electrical Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160510",
        "title": "Autonomous Endoscope Control Algorithm with Visibility and Joint Limits Avoidance Constraints for da Vinci Research Kit Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel autonomous endoscope control method for the dVRK's Endoscopic Camera Manipulator (ECM), which allows the camera to track the surgical instruments on the Patient Side Manipulator (PSM). An Image-based Visual Servoing (IBVS) is enforced by the addition of a visibility constraint that ensures the identified surgical tool remains in the camera's Field Of View (FOV) for the continued availability of image feedback and a joint limits avoidance constraint that prevents the ECM from exceeding its joint limits. The work relies on an optimization approach, with constraints performed using the Control Barrier Functions concept (CBFs). The goal is to minimize the surgeon's cognitive and physical workload by removing the time-consuming job of camera reorientation, offering an enforced method compared to the traditional IBVS endoscopic camera controller.",
        "primary_area": "",
        "author": "Rocco Moccia;Fanny Ficuciello;Rocco Moccia;Fanny Ficuciello",
        "authorids": "/37087325268;/37594404000;/37087325268;/37594404000",
        "aff": "Department of Information Technology and Electrical Engineering, Universit\u00e0 degli Studi di Napoli Federico II, Napoli, Italy; Department of Information Technology and Electrical Engineering, Universit\u00e0 degli Studi di Napoli Federico II, Napoli, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160510/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7592221036829052525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Napoli Federico II",
        "aff_unique_dep": "Department of Information Technology and Electrical Engineering",
        "aff_unique_url": "https://www.unina.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Napoli",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161505",
        "title": "Autonomous Intelligent Navigation for Flexible Endoscopy Using Monocular Depth Guidance and 3-D Shape Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advancements toward perception and decision-making of flexible endoscopes have shown great potential in computer-aided surgical interventions. However, owing to modeling uncertainty and inter-patient anatomical variation in flexible endoscopy, the challenge remains for efficient and safe navigation in patient-specific scenarios. This paper presents a novel data-driven framework with self-contained visual-shape fusion for autonomous intelligent navigation of flexible endoscopes requiring no priori knowledge of system models and global environments. A learning-based adaptive visual servoing controller is proposed to online update the eye-in-hand vision-motor configuration and steer the endoscope, which is guided by monocular depth estimation via a vision transformer (ViT). To prevent unnecessary and excessive interactions with surrounding anatomy, an energy-motivated shape planning algorithm is introduced through entire endoscope 3-D proprioception from embedded fiber Bragg grating (FBG) sensors. Furthermore, a model predictive control (MPC) strategy is developed to minimize the elastic potential energy flow and simultaneously optimize the steering policy. Dedicated navigation experiments on a robotic-assisted flexible endoscope with an FBG fiber in several phantom environments demonstrate the effectiveness and adaptability of the proposed framework.",
        "primary_area": "",
        "author": "Yiang Lu;Ruofeng Wei;Bin Li;Wei Chen;Jianshu Zhou;Qi Dou;Dong Sun;Yun-hui Liu;Yiang Lu;Ruofeng Wei;Bin Li;Wei Chen;Jianshu Zhou;Qi Dou;Dong Sun;Yun-hui Liu",
        "authorids": "/37086614250;/37088701950;/37089266122;/37086608021;/37086011742;/37085465414;/37277362800;/37279412600;/37086614250;/37088701950;/37089266122;/37086608021;/37086011742;/37085465414;/37277362800;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Hong Kong Center for Logistics Robotics, Hong Kong; Hong Kong Center for Logistics Robotics, Hong Kong; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong; Hong Kong Center for Logistics Robotics, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161505/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18441363902511815338&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;2;2;1;2",
        "aff_unique_norm": "The Chinese University of Hong Kong;City University of Hong Kong;Hong Kong Center for Logistics Robotics",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Department of Biomedical Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.cityu.edu.hk;",
        "aff_unique_abbr": "CUHK;CityU;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161151",
        "title": "Autonomous Needle Navigation in Retinal Microsurgery: Evaluation in ex vivo Porcine Eyes",
        "track": "main",
        "status": "Poster",
        "abstract": "Important challenges in retinal microsurgery in-clude prolonged operating time, inadequate force feedback, and poor depth perception due to a constrained top-down view of the surgery. The introduction of robot-assisted technology could potentially deal with such challenges and improve the surgeon's performance. Motivated by such challenges, this work develops a strategy for autonomous needle navigation in retinal microsurgery aiming to achieve precise manipulation, reduced end-to-end surgery time, and enhanced safety. This is accomplished through real-time geometry estimation and chance-constrained Model Predictive Control (MPC) resulting in high positional accuracy while keeping scleral forces within a safe level. The robotic system is validated using both open-sky and intact (with lens and partial vitreous removal) ex vivo porcine eyes. The experimental results demonstrate that the generation of safe control trajectories is robust to small motions associated with head drift. The mean navigation time and scleral force for MPC navigation experiments are 7.208 s and 11.97 mN, which can be considered efficient and well within acceptable safe limits. The resulting mean errors along lateral directions of the retina are below 0.06 mm, which is below the typical hand tremor amplitude in retinal microsurgery.",
        "primary_area": "",
        "author": "Peiyao Zhang;Ji Woong Kim;Peter Gehlbach;Iulian Iordachita;Marin Kobilarov;Peiyao Zhang;Ji Woong Kim;Peter Gehlbach;Iulian Iordachita;Marin Kobilarov",
        "authorids": "/37089280568;/37088506784;/37547001700;/37330620500;/37546944400;/37089280568;/37088506784;/37547001700;/37330620500;/37546944400",
        "aff": "Department of Mechanical Engineering, Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, MD, USA; Wilmer Eye Institute, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161151/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13117313617997191901&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161180",
        "title": "Autonomous Task Planning for Heterogeneous Multi-Agent Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a solution to the automatic task planning problem for multi-agent systems. A formal frame-work is developed based on Nondeterministic Finite Automata with \u220a-transitions, where given the capabilities, constraints and failure modes of the agents involved, any initial state of the system and a task specification, an optimal solution is generated that satisfies the system constraints and the task specification. The resulting solution is guaranteed to be complete and optimal; moreover a heuristic solution that offers significant reduction of the computational requirements while relaxing the completeness and optimality requirements is proposed. The constructed system model is independent from the initial conditions and the task specifications, eliminating the need to repeat the costly pre-processing cycle, while allowing the incorporation of failure modes on-the-fly. A case study is provided to demonstrate the effectiveness and validity of the methodology.",
        "primary_area": "",
        "author": "Anatoli A. Tziola;Savvas G. Loizou;Anatoli A. Tziola;Savvas G. Loizou",
        "authorids": "/37089892458;/37282081200;/37089892458;/37282081200",
        "aff": "Department of Mechanical Engineering and Ma-terials Science and Engineering, Cyprus University of Technology, Limassol, Cyprus; Department of Mechanical Engineering and Ma-terials Science and Engineering, Cyprus University of Technology, Limassol, Cyprus",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161180/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16902173200410333907&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cyprus University of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science and Engineering",
        "aff_unique_url": "https://www.cut.ac.cy",
        "aff_unique_abbr": "CUT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Limassol",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Cyprus"
    },
    {
        "id": "10160272",
        "title": "Autonomous Underwater Docking using Flow State Estimation and Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a navigation framework to perform autonomous underwater docking to a wave energy converter (WEC) under various ocean conditions by incorporating flow state estimation into the design of model predictive control (MPC). Existing methods lack the ability to perform dynamic rendezvous and autonomously dock in energetic conditions. The use of exteroceptive sensors or high performing acoustic sensors have been previously investigated to obtain or estimate the flow states. However, the use of such sensors increases the overall cost of the system and expects the vehicle to navigate close to the seafloor or other landmarks. To overcome these limitations, our method couples an active perception framework with MPC to estimate the flow states simultaneously while moving towards the dock. Our simulation results demonstrate the robustness and reliability of the proposed framework for autonomous docking under various ocean conditions. Furthermore, we conducted laboratory trials with a BlueROV2 docking with an oscillating dock and achieved a greater than 70% success rate.",
        "primary_area": "",
        "author": "Rakesh Vivekanandan;Dongsik Chang;Geoffrey A. Hollinger;Rakesh Vivekanandan;Dongsik Chang;Geoffrey A. Hollinger",
        "authorids": "/37089906234;/37086937241;/37543482700;/37089906234;/37086937241;/37543482700",
        "aff": "Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA; CoRIS, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160272/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16813157245561399762&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute (CoRIS)",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160458",
        "title": "Autotuning Symbolic Optimization Fabrics for Trajectory Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an automated parameter optimization method for trajectory generation. We formulate parameter optimization as a constrained optimization problem that can be effectively solved using Bayesian optimization. While the approach is generic to any trajectory generation method, we showcase it using optimization fabrics. Optimization fabrics are a geometric trajectory generation method based on non-Riemannian geometry. By symbolically pre-solving the structure of the tree of fabrics, we obtain a parameterized trajectory generator, called symbolic fabrics. We show that autotuned symbolic fabrics reach expert-level performance in a few trials. Additionally, we show that tuning transfers across different robots, motion planning problems and between simulation and real world. Finally, we qualitatively showcase that the framework could be used for coupled mobile manipulation.",
        "primary_area": "",
        "author": "Max Spahn;Javier Alonso-Mora;Max Spahn;Javier Alonso-Mora",
        "authorids": "/37088998268;/38271697300;/37088998268;/38271697300",
        "aff": "Department of Cognitive Robotics, Delft University of Technology, Delft, The Netherlands; Department of Cognitive Robotics, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160458/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15857130678570017393&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Department of Cognitive Robotics",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10161572",
        "title": "Avatarm: an Avatar With Manipulation Capabilities for the Physical Metaverse",
        "track": "main",
        "status": "Poster",
        "abstract": "Metaverse is an immersive shared space that remote users can access through virtual and augmented reality interfaces, enabling their avatars to interact with each other and the surrounding. Although digital objects can be manipulated, physical objects cannot be touched, grasped, or moved within the metaverse due to the lack of a suitable interface. This work proposes a solution to overcome this limitation by introducing the concept of a Physical Metaverse enabled by a new interface named \u201cAvatarm\u201d. The Avatarm consists in an avatar enhanced with a robotic arm that performs physical manipulation tasks while remaining entirely hidden in the metaverse. The users have the illusion that the avatar is directly manipulating objects without the mediation by a robot. The Avatarm is the first step towards a new metaverse, the \u201cPhysical Metaverse,\u201d where users can physically interact each other and with the environment.",
        "primary_area": "",
        "author": "A. Villani;G. Cortigiani;B. Brogi;N. D'Aurizio;T. Lisini Baldi;D. Prattichizzo;A. Villani;G. Cortigiani;B. Brogi;N. D'Aurizio;T. Lisini Baldi;D. Prattichizzo",
        "authorids": "/37088529127;/37089891953;/37089894975;/37088396379;/37085368775;/37276309600;/37088529127;/37089891953;/37089894975;/37088396379;/37085368775;/37276309600",
        "aff": "Department of Information Engineering and Mathematics, University of Siena, Siena, Italy; Department of Information Engineering and Mathematics, University of Siena, Siena, Italy; Department of Information Engineering and Mathematics, University of Siena, Siena, Italy; Department of Information Engineering and Mathematics, University of Siena, Siena, Italy; Department of Humanoids and Human Centered Mechatronics (HHCM), Istituto Italiano di Tecnologia, Genova, Italy; Department of Humanoids and Human Centered Mechatronics (HHCM), Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161572/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14635254724327330132&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;1",
        "aff_unique_norm": "University of Siena;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Information Engineering and Mathematics;Department of Humanoids and Human Centered Mechatronics (HHCM)",
        "aff_unique_url": "https://www.unisi.it;https://www.iit.it",
        "aff_unique_abbr": ";IIT",
        "aff_campus_unique_index": "0;0;0;0;1;1",
        "aff_campus_unique": "Siena;Genova",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161097",
        "title": "AvoidBench: A high-fidelity vision-based obstacle avoidance benchmarking suite for multi-rotors",
        "track": "main",
        "status": "Poster",
        "abstract": "Obstacle avoidance is an essential topic in the field of autonomous drone research. When choosing an avoidance algorithm, many different options are available, each with their advantages and disadvantages. As there is currently no consensus on testing methods, it is quite challenging to compare the performance between algorithms. In this paper, we propose AvoidBench, a benchmarking suite which can evaluate the performance of vision-based obstacle avoidance algorithms by subjecting them to a series of tasks. Thanks to the high fidelity of multi-rotors dynamics from RotorS and virtual scenes of Unity3D, AvoidBench can realize realistic simulated flight experiments. Compared to current drone simulators, we propose and implement both performance and environment metrics to reveal the suitability of obstacle avoidance algorithms for environments of different complexity. To illustrate AvoidBench's usage, we compare three algorithms: Ego-planner, MBPlanner, and Agile-autonomy. The trends observed are validated with real-world obstacle avoidance experiments. Code is available at: https://github.com/tudelft/AvoidBench",
        "primary_area": "",
        "author": "Hang Yu;Guido C. H. E de Croon;Christophe De Wagter;Hang Yu;Guido C. H. E de Croon;Christophe De Wagter",
        "authorids": "/37089893065;/37698062600;/37862967200;/37089893065;/37698062600;/37862967200",
        "aff": "Faculty of Aerospace Engineering, Delft University of Technology, Delft, HS, The Netherlands; Faculty of Aerospace Engineering, Delft University of Technology, Delft, HS, The Netherlands; Faculty of Aerospace Engineering, Delft University of Technology, Delft, HS, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161097/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14941329259531438082&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Faculty of Aerospace Engineering",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10160905",
        "title": "BAMF-SLAM: Bundle Adjusted Multi-Fisheye Visual-Inertial SLAM Using Recurrent Field Transforms",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present BAMF-SLAM, a novel multi-fisheye visual-inertial SLAM system that utilizes Bundle Adjustment (BA) and recurrent field transforms (RFT) to achieve accurate and robust state estimation in challenging scenarios. First, our system directly operates on raw fisheye images, enabling us to fully exploit the wide Field-of-View (FoV) of fisheye cameras. Second, to overcome the low-texture challenge, we explore the tightly-coupled integration of multi-camera inputs and complementary inertial measurements via a unified factor graph and jointly optimize the poses and dense depth maps. Third, for global consistency, the wide FoV of the fisheye camera allows the system to find more potential loop closures, and powered by the broad convergence basin of RFT, our system can perform very wide baseline loop closing with little overlap. Furthermore, we introduce a semi-pose-graph BA method to avoid the expensive full global BA. By combining relative pose factors with loop closure factors, the global states can be adjusted efficiently with modest memory footprint while maintaining high accuracy. Evaluations on TUM-VI, Hilti-Oxford and Newer College datasets show the superior performance of the proposed system over prior works. In the Hilti SLAM Challenge 2022, our VIO version achieves second place. In a subsequent submission, our complete system, including the global BA backend, outperforms the winning approach.",
        "primary_area": "",
        "author": "Wei Zhang;Sen Wang;Xingliang Dong;Rongwei Guo;Norbert Haala;Wei Zhang;Sen Wang;Xingliang Dong;Rongwei Guo;Norbert Haala",
        "authorids": "/37089892909;/37089938747;/37086811389;/37089893929;/37688184900;/37089892909;/37089938747;/37086811389;/37089893929;/37688184900",
        "aff": "Audiovisual Lab, Huawei Munich Research Center, Germany; CAMP, Technical University of Munich, Germany; Huawei 2012 Laboratories, Central Media Technology Institute, China; Huawei 2012 Laboratories, Central Media Technology Institute, China; Institute for Photogrammetry, University of Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160905/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3152726344860776537&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;3",
        "aff_unique_norm": "Huawei Munich Research Center;Technical University of Munich;Huawei 2012 Laboratories;University of Stuttgart",
        "aff_unique_dep": "Audiovisual Lab;CAMP;Central Media Technology Institute;Institute for Photogrammetry",
        "aff_unique_url": "https://www.huawei.com/en/;https://www.tum.de;https://www.huawei.com;https://www.iap.uni-stuttgart.de",
        "aff_unique_abbr": "HMR;TUM;Huawei;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "10160968",
        "title": "BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-sensor fusion is essential for an accurate and reliable autonomous driving system. Recent approaches are based on point-level fusion: augmenting the LiDAR point cloud with camera features. However, the camera-to-LiDAR projection throws away the semantic density of camera features, hindering the effectiveness of such methods, especially for semantic-oriented tasks (such as 3D scene segmentation). In this paper, we propose BEVFusion, an efficient and generic multi-task multi-sensor fusion framework. It unifies multi-modal features in the shared bird's-eye view (BEV) representation space, which nicely preserves both geometric and semantic information. To achieve this, we diagnose and lift the key efficiency bottlenecks in the view transformation with optimized BEV pooling, reducing latency by more than \\mathbf{40}\\times\\mathbf{40}\\times. BEVFusion is fundamentally task-agnostic and seamlessly supports different 3D perception tasks with almost no architectural changes. It establishes the new state of the art on the nuScenes benchmark, achieving 1.3% higher mAP and NDS on 3D object detection and 13.6% higher mIoU on BEV map segmentation, with 1.9\u00d7 lower computation cost. Code to reproduce our results is available at https://github.com/mit-han-lab/bevfusion.",
        "primary_area": "",
        "author": "Zhijian Liu;Haotian Tang;Alexander Amini;Xinyu Yang;Huizi Mao;Daniela L. Rus;Song Han;Zhijian Liu;Haotian Tang;Alexander Amini;Xinyu Yang;Huizi Mao;Daniela L. Rus;Song Han",
        "authorids": "/37087231394;/37089195801;/37086454594;/37089893643;/37085669332;/37279652300;/37086460117;/37087231394;/37089195801;/37086454594;/37089893643;/37085669332;/37279652300;/37086460117",
        "aff": "Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; OmniML, San Jose, CA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160968/",
        "gs_citation": 1130,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16717580745172756782&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;OmniML",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.mit.edu;",
        "aff_unique_abbr": "MIT;",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Cambridge;San Jose",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161167",
        "title": "BITS: Bi-level Imitation for Traffic Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulation is the key to scaling up validation and verification for robotic systems such as autonomous vehicles. Despite advances in high-fidelity physics and sensor simulation, a critical gap remains in simulating realistic behaviors of road users. This is because devising first principle models for human-like behaviors is generally infeasible. In this work, we take a data-driven approach to generate traffic behaviors from real-world driving logs. The method achieves high sample efficiency and behavior diversity by exploiting the bi-level hierarchy of high-level intent inference and low-level driving behavior imitation. The method also incorporates a planning module to obtain stable long-horizon behaviors. We empirically validate our method with scenarios from two large-scale driving datasets and show our method achieves balanced traffic simulation performance in realism, diversity, and long-horizon stability. We also explore ways to evaluate behavior realism and introduce a suite of evaluation metrics for traffic simulation. Finally, as part of our core contributions, we develop and open source a software tool that unifies data formats across different driving datasets and converts scenes from existing datasets into interactive simulation environments. For video results and code release, see https://bit.ly/3L9uzj3.",
        "primary_area": "",
        "author": "Danfei Xu;Yuxiao Chen;Boris Ivanovic;Marco Pavone;Danfei Xu;Yuxiao Chen;Boris Ivanovic;Marco Pavone",
        "authorids": "/37086228189;/37088427220;/37086527859;/37307912900;/37086228189;/37088427220;/37086527859;/37307912900",
        "aff": "Georgia Institute of Technology and NVIDIA research; NVIDIA research; NVIDIA research; Stanford University and with NVIDIA Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161167/",
        "gs_citation": 92,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15390374060414625559&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Georgia Institute of Technology;NVIDIA Corporation;Stanford University",
        "aff_unique_dep": ";NVIDIA Research;",
        "aff_unique_url": "https://www.gatech.edu;https://www.nvidia.com/research;https://www.stanford.edu",
        "aff_unique_abbr": "Georgia Tech;NVIDIA;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160570",
        "title": "BO-ICP: Initialization of Iterative Closest Point Based on Bayesian Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Typical algorithms for point cloud registration such as Iterative Closest Point (ICP) require a favorable initial transform estimate between two point clouds in order to perform a successful registration. State-of-the-art methods for choosing this starting condition rely on stochastic sampling or global optimization techniques such as branch and bound. In this work, we present a new method based on Bayesian optimization for finding the critical initial ICP transform. We provide three different configurations for our method which highlights the versatility of the algorithm to both find rapid results and refine them in situations where more runtime is available such as offline map building. Experiments are run on popular data sets and we show that our approach outperforms state-of-the-art methods when given similar computation time. Furthermore, it is compatible with other improvements to ICP, as it focuses solely on the selection of an initial transform, a starting point for all ICP-based methods.",
        "primary_area": "",
        "author": "Harel Biggie;Andrew Beathard;Christoffer Heckman;Harel Biggie;Andrew Beathard;Christoffer Heckman",
        "authorids": "/37086290254;/37089895113;/37086032368;/37086290254;/37089895113;/37086032368",
        "aff": "Autonomous Robotics and Perception Group, University of Colorado Boulder, Boulder, Colorado, USA; Autonomous Robotics and Perception Group, University of Colorado Boulder, Boulder, Colorado, USA; Autonomous Robotics and Perception Group, University of Colorado Boulder, Boulder, Colorado, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160570/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9354555548925533169&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Autonomous Robotics and Perception Group",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160923",
        "title": "Balancing Efficiency and Unpredictability in Multi-robot Patrolling: A MARL-Based Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Patrolling with multiple robots is a challenging task. While the robots collaboratively and repeatedly cover the regions of interest in the environment, their routes should satisfy two often conflicting properties: i) (efficiency) the time intervals between two consecutive visits to the regions are small; ii) (unpredictability) the patrolling trajectories are random and unpredictable. We manage to strike a balance between the two goals by i) recasting the original patrolling problem as a Graph Deep Learning problem; ii) directly solving this problem on the graph in the framework of cooperative multi-agent reinforcement learning. Treating the decisions of a team of agents as a sequence input, our model outputs the agents' actions in order by an autoregressive mechanism. Extensive simulation studies show that our approach has comparable performance with existing algorithms in terms of efficiency and outperforms them in terms of unpredictability. To our knowledge, this is the first work that successfully solves the patrolling problem with reinforcement learning on a graph.",
        "primary_area": "",
        "author": "Lingxiao Guo;Haoxuan Pan;Xiaoming Duan;Jianping He;Lingxiao Guo;Haoxuan Pan;Xiaoming Duan;Jianping He",
        "authorids": "/37089894845;/37089893757;/37085555527;/38239084800;/37089894845;/37089893757;/37085555527;/38239084800",
        "aff": "Department of Civil Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160923/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17484831670517134287&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Civil Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160606",
        "title": "Bayesian deep learning for affordance segmentation in images",
        "track": "main",
        "status": "Poster",
        "abstract": "Affordances are a fundamental concept in robotics since they relate available actions for an agent depending on its sensory-motor capabilities and the environment. We present a novel Bayesian deep network to detect affordances in images, at the same time that we quantify the distribution of the aleatoric and epistemic variance at the spatial level. We adapt the Mask-RCNN architecture to learn a probabilistic representation using Monte Carlo dropout. Our results outperform the state-of-the-art of deterministic networks. We attribute this improvement to a better probabilistic feature space representation on the encoder and the Bayesian variability induced at the mask generation, which adapts better to the object contours. We also introduce the new Probability-based Mask Quality measure that reveals the semantic and spatial differences on a probabilistic instance segmentation model. We modify the existing Probabilistic Detection Quality metric by comparing the binary masks rather than the predicted bounding boxes, achieving a finer-grained evaluation of the probabilistic segmentation. We find aleatoric variance in the contours of the objects due to the camera noise, while epistemic variance appears in visual challenging pixels.",
        "primary_area": "",
        "author": "Lorenzo Mur-Labadia;Ruben Martinez-Cantin;Jose J. Guerrero;Lorenzo Mur-Labadia;Ruben Martinez-Cantin;Jose J. Guerrero",
        "authorids": "/37089894762;/38357177400;/37533721000;/37089894762;/38357177400;/37533721000",
        "aff": "Instituto de Ingenieria de Aragon (I3A), Universidad de Zaragoza, Espa\u00f1a; Instituto de Ingenieria de Aragon (I3A), Universidad de Zaragoza, Espa\u00f1a; Instituto de Ingenieria de Aragon (I3A), Universidad de Zaragoza, Espa\u00f1a",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160606/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1151284186368935343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Instituto de Ingenieria de Aragon (I3A)",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "UniZar",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10161535",
        "title": "Bayesian inference of fog visibility from LiDAR point clouds and correlation with probabilities of detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Degraded visual environments have strong impacts on the quality of LiDAR data. Experiments in artificial fog conditions show that noise points caused by water particles present various distance distributions which depend on visibility. This article introduces a mathematical framework based on Bayesian inference and Markov Chain Monte-Carlo sampling to infer optical visibility from point clouds. The visibility estimation is cast as a classification problem based on the identification of the distance distributions. Contrary to deep learning methods, our approach is model-based and focuses on the design of a full probabilistic framework, more comprehensible, which is critical for autonomous driving. Ultimately, the impact of the optical visibility on the probability of detection of standard targets is assessed, which can yield improvements on autonomous vehicles performances in adverse weather conditions.",
        "primary_area": "",
        "author": "Karl Montalban;Christophe Reymann;Dinesh Atchuthan;Paul-Edouard Dupouy;Nicolas Rivi\u00e8re;Simon Lacroix;Karl Montalban;Christophe Reymann;Dinesh Atchuthan;Paul-Edouard Dupouy;Nicolas Rivi\u00e8re;Simon Lacroix",
        "authorids": "/37089891944;/37085620336;/37086525970;/37089893006;/37089654927;/37278650100;/37089891944;/37085620336;/37086525970;/37089893006;/37089654927;/37278650100",
        "aff": "LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; EasyMile, Toulouse, France; EasyMile, Toulouse, France; ONERA/DOTA, Universite de Toulouse, Toulouse, France; ONERA/DOTA, Universite de Toulouse, Toulouse, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161535/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9214926909736929&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;2;0",
        "aff_unique_norm": "LAAS-CNRS;EasyMile;ONERA",
        "aff_unique_dep": ";;DOTA",
        "aff_unique_url": "https://www.laas.fr/;;https://www.onera.fr",
        "aff_unique_abbr": "LAAS-CNRS;;ONERA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toulouse;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160885",
        "title": "Benchmarking Potential Based Rewards for Learning Humanoid Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "The main challenge in developing effective reinforcement learning (RL) pipelines is often the design and tuning the reward functions. Well-designed shaping reward can lead to significantly faster learning. Naively formulated rewards, however, can conflict with the desired behavior and result in overfitting or even erratic performance if not properly tuned. In theory, the broad class of potential based reward shaping (PBRS) can help guide the learning process without affecting the optimal policy. Although several studies have explored the use of potential based reward shaping to accelerate learning convergence, most have been limited to grid-worlds and low-dimensional systems, and RL in robotics has predominantly relied on standard forms of reward shaping. In this paper, we benchmark standard forms of shaping with PBRS for a humanoid robot. We find that in this high-dimensional system, PBRS has only marginal benefits in convergence speed. However, the PBRS reward terms are significantly more robust to scaling than typical reward shaping approaches, and thus easier to tune.",
        "primary_area": "",
        "author": "Se Hwan Jeon;Steve Heim;Charles Khazoom;Sangbae Kim;Se Hwan Jeon;Steve Heim;Charles Khazoom;Sangbae Kim",
        "authorids": "/37089446754;/37086397602;/37086876458;/37537397200;/37089446754;/37086397602;/37086876458;/37537397200",
        "aff": "Biomimetic Robotics Lab, MIT; Biomimetic Robotics Lab, MIT; Biomimetic Robotics Lab, MIT; Biomimetic Robotics Lab, MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160885/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7078288646713542069&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Biomimetic Robotics Lab",
        "aff_unique_url": "http://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160583",
        "title": "Benchmarking Reinforcement Learning Techniques for Autonomous Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (RL) has brought many successes for autonomous robot navigation. However, there still exists important limitations that prevent real-world use of RL-based navigation systems. For example, most learning approaches lack safety guarantees; and learned navigation systems may not generalize well to unseen environments. Despite a variety of recent learning techniques to tackle these challenges in general, a lack of an open-source benchmark and reproducible learning methods specifically for autonomous navigation makes it difficult for roboticists to choose what learning methods to use for their mobile robots and for learning researchers to identify current shortcomings of general learning methods for autonomous navigation. In this paper, we identify four major desiderata of applying deep RL approaches for autonomous navigation: (D1) reasoning under uncertainty, (D2) safety, (D3) learning from limited trial-and-error data, and (D4) generalization to diverse and novel environments. Then, we explore four major classes of learning techniques with the purpose of achieving one or more of the four desiderata: memory-based neural network architectures (D1), safe RL (D2), model-based RL (D2, D3), and domain randomization (D4). By deploying these learning techniques in a new open-source large-scale navigation benchmark and real-world environments, we perform a comprehensive study aimed at establishing to what extent can these techniques achieve these desiderata for RL-based navigation systems.",
        "primary_area": "",
        "author": "Zifan Xu;Bo Liu;Xuesu Xiao;Anirudh Nair;Peter Stone;Zifan Xu;Bo Liu;Xuesu Xiao;Anirudh Nair;Peter Stone",
        "authorids": "/37089000983;/37088429909;/37086258082;/37088999799;/37269574900;/37089000983;/37088429909;/37086258082;/37088999799;/37269574900",
        "aff": "Department of Computer Science, University of Texas at Austin; Department of Computer Science, University of Texas at Austin; Everyday Robots; Department of Computer Science, University of Texas at Austin; Sony AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160583/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17857018528201897958&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "University of Texas at Austin;Everyday Robots;Sony",
        "aff_unique_dep": "Department of Computer Science;;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.everydayrobots.com;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;;Sony AI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "10161335",
        "title": "Bi-Manual Manipulation of Multi-Component Garments towards Robot-Assisted Dressing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a strategy for robot-assisted dressing with multi-component garments, such as gloves. Most studies in robot-assisted dressing usually experiment with single-component garments, such as sleeves, while multi-component tasks are often approached as sequential single-component problems. In dressing scenarios with more complex garments, robots should estimate the alignment of the human body to the manipulated garments, and revise their dressing strategy. In this paper, we focus on a glove dressing scenario and propose a decision process for selecting dressing action primitives on the different components of the garment, based on a hierarchical representation of the task and a set of environmental conditions. To complement this process, we propose a set of bi-manual control strategies, based on hybrid position, visual, and force feedback, in order to execute the dressing action primitives with the deformable object. The experimental results validate our method, enabling the Baxter robot to dress a mannequin's hand with a gardening glove.",
        "primary_area": "",
        "author": "Stelios Kotsovolis;Yiannis Demiris;Stelios Kotsovolis;Yiannis Demiris",
        "authorids": "/37089892689;/37296338900;/37089892689;/37296338900",
        "aff": "Department of Electrical and Electronic Engineering, Personal Robotics Lab, Imperial College London, London, U.K.; Department of Electrical and Electronic Engineering, Personal Robotics Lab, Imperial College London, London, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161335/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17638267961096309869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160361",
        "title": "Bidirectional Generalised Rigid Point Set Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "In medical robotics and image-guided surgery (IGS), registration is needed in order to align together the coordinate frames of robots, medical imaging modalities, surgical tools, and patients. Existing registration algorithms often assume one point set to be a noise-free model while the other to contain noise and outliers. However, in real scenarios, noise and outliers can exist in both point sets to be registered. To eliminate the above-mentioned challenge, in this paper, we formally formulate the Bi-directional Generalised Rigid Point Set Registration (Bi-GRPSR) problem where normal vectors are adopted, bi-directional probability density function (PDFs) and Hybrid Mixture Models (HMMs) are constructed to derive the objective function. Bi-GRPSR considering anisotropic positional noise is thus cast as a maximum likelihood estimation (MLE) problem, which is solved by the proposed Bi-directional Generalised Anisotropic Coherent Point Drift (Bi-AGCPD) where spatially nearby points are considered to move coherently and iterative expectation maximization (EM) steps are involved. Experimental results on two human bone point sets, under different settings of noise, outliers, and overlapping ratios, validate the effectiveness and improvements of Bi-AGCPD over existing probabilistic and learning-based methods.",
        "primary_area": "",
        "author": "Ang Zhang;Zhe Min;Li Liu;Max Q.-H. Meng;Ang Zhang;Zhe Min;Li Liu;Max Q.-H. Meng",
        "authorids": "/37087246928;/37086002886;/37089938707;/37274117000;/37087246928;/37086002886;/37089938707;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Wellcome/EPSRC Centre for Surgical and Interventional Sciences, University College, London, UK; Department of Electronic Engineering, The Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Shenzhen Research Institute of the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160361/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17959742959043472053&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "The Chinese University of Hong Kong;University College London;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering;Wellcome/EPSRC Centre for Surgical and Interventional Sciences;Shenzhen Research Institute",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.ucl.ac.uk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK;UCL;CUHK",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "N.T.;London;Shenzhen",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10161300",
        "title": "Big data approach for synthesizing a spatial linkage mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel two-step method for synthesizing spatial linkage mechanisms. Compared with planar mechanisms, the main challenge in synthesizing spatial mechanisms is that the generating motion varies depending on its mechanism topologies. Therefore, we propose a big data approach to determine the topology of spatial mechanisms. We adopt a three-dimensional (3D) spring-connected rigid block model to represent the topology of the spatial mechanism and project 3D motion onto three orthogonal planes to determine the mechanism topology with big data. In addition, a gradient-based dimension synthesis procedure was carried out to determine a detailed dimension using already determined mechanism topology by mechanism big data. Also, several successful case studies by the proposed approach are presented to support the effectiveness of the proposed synthesis method.",
        "primary_area": "",
        "author": "Neung Hwan Yim;Jegyeong Ryu;Yoon Young Kim;Neung Hwan Yim;Jegyeong Ryu;Yoon Young Kim",
        "authorids": "/37089894707;/37089679735;/37066710800;/37089894707;/37089679735;/37066710800",
        "aff": "Seoul National University, Seoul, Republic of Korea; Korea Institute of Science and Technology, Seoul, Republic of Korea; Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161300/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=738271559156028326&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Seoul National University;Korea Institute of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.kist.re.kr",
        "aff_unique_abbr": "SNU;KIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161137",
        "title": "Bilateral asymmetric hip stiffness applied by a robotic hip exoskeleton elicits kinematic and kinetic adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Wearable robotic exoskeletons hold great promise for gait rehabilitation as portable, accessible tools. However, a better understanding of the potential for exoskeletons to elicit neural adaptation-a critical component of neurological gait rehabilitation-is needed. In this study, we investigated whether humans adapt to bilateral asymmetric stiffness perturbations applied by a hip exoskeleton, taking inspiration from the asymmetry augmentation strategies used in split-belt treadmill training. During walking, we applied torques about the hip joints to repel the thigh away from a neutral position on the left side and attract the thigh toward a neutral position on the right side. Six participants performed an adaptation walking trial on a treadmill while wearing the exoskeleton. The exoskeleton elicited time-varying changes and aftereffects in step length and propulsive/braking ground reaction forces, indicating behavioral signatures of neural adaptation. These responses resemble typical responses to split-belt treadmill training, suggesting that the proposed intervention with a robotic hip exoskeleton may be an effective approach to (re)training symmetric gait.",
        "primary_area": "",
        "author": "Banu Abdikadirova;Mark Price;Jonaz Moreno Jaramillo;Wouter Hoogkamer;Meghan E. Huber;Banu Abdikadirova;Mark Price;Jonaz Moreno Jaramillo;Wouter Hoogkamer;Meghan E. Huber",
        "authorids": "/37088537667;/37085821829;/37089663331;/37089661883;/37085363999;/37088537667;/37085821829;/37089663331;/37089661883;/37085363999",
        "aff": "Department of Mechanical and Industrial Engineering, University of Massachusetts Amherst, Amherst, MA, USA; Department of Kinesiology, University of Massachusetts Amherst, Amherst, MA, USA; Department of Kinesiology, University of Massachusetts Amherst, Amherst, MA, USA; Department of Kinesiology, University of Massachusetts Amherst, Amherst, MA, USA; Department of Mechanical and Industrial Engineering, University of Massachusetts Amherst, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161137/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13397476073858259330&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "Department of Mechanical and Industrial Engineering",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160895",
        "title": "Bimanual Rope Manipulation Skill Synthesis through Context Dependent Correction Policy Learning from Human Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from demonstration (LfD) with behavior cloning is attractive for its simplicity; however, compounding errors in long and complex skills can be a hindrance. Considering a target skill as a sequence of motor primitives is helpful in this respect. Then the requirement that a motor primitive ends in a state that allows the successful execution of the subsequent primitive must be met. In this study, we focus on this problem by proposing to learn an explicit correction policy when the expected transition state between primitives is not achieved. The correction policy is learned via behavior cloning by the use of Conditional Neural Motor Primitives (CNMPs) that can generate correction trajectories in a context-dependent way. The advantage of the proposed system over learning the complete task as a single action is shown with a table-top setup in simulation, where an object has to be pushed through a corridor in two steps. Then, the applicability of the proposed method to bi-manual knotting in the real world is shown by equipping an upper-body humanoid robot with the skill of making knots over a bar in 3D space.",
        "primary_area": "",
        "author": "Baturhan Akbulut;Tuba Girgin;Arash Mehrabi;Minoru Asada;Emre Ugur;Erhan Oztop;Baturhan Akbulut;Tuba Girgin;Arash Mehrabi;Minoru Asada;Emre Ugur;Erhan Oztop",
        "authorids": "/37089894329;/37089892959;/37089894140;/37276874800;/37947264700;/37295409300;/37089894329;/37089892959;/37089894140;/37276874800;/37947264700;/37295409300",
        "aff": "Deparment of Computer Engineering, Bogazici University, Istanbul, Turkey; Deparment of Computer Engineering, Bogazici University, Istanbul, Turkey; Deparment of Computer Engineering, Ozyegin University, Istanbul, Turkey; International Professional University of Technology in Osaka, Osaka, Japan; Deparment of Computer Engineering, Bogazici University, Istanbul, Turkey; Symbiotic Intelligent Systems Research Center, Institute for Open and Transdisciplinary, Research Initiatives, Osaka University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160895/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10115269101816228143&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;3",
        "aff_unique_norm": "Bogazici University;Ozyegin University;International Professional University of Technology;Osaka University",
        "aff_unique_dep": "Department of Computer Engineering;Department of Computer Engineering;;Symbiotic Intelligent Systems Research Center",
        "aff_unique_url": "https://www.boun.edu.tr;https://www.ozyegin.edu.tr;;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "BU;;;",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Istanbul;Osaka;",
        "aff_country_unique_index": "0;0;0;1;0;1",
        "aff_country_unique": "Turkey;Japan"
    },
    {
        "id": "10160316",
        "title": "Biodegradable Origami Gripper Actuated with Gelatin Hydrogel for Aerial Sensor Attachment to Tree Branches",
        "track": "main",
        "status": "Poster",
        "abstract": "Forest canopies are vital ecosystems, but remain understudied due to difficult access. Forests could be monitored with a network of biodegradable sensors that break down into environmentally friendly substances at the end of their life. As a first step in this direction, this paper details the development of a biodegradable origami gripper to attach conventional sensors to branches, deployable with an aerial robot. Through exposure to sufficient moisture the gripper loses contractile force, dropping the sensor to the ground for easier collection. The origami design of the gripper as well as biodegradable materials selection is detailed, allowing for further extensions utilizing biodegradable origami. Both the gripper and the gelatin hydrogel used as an actuating elastic element for generating the grasping force are experimentally characterized, with the gripper demonstrating a maximum holding force of 1 N. Additionally, the degradation of the gripper until failure in the presence of moisture is also investigated, where the gripper can absorb up to 10 ml of water before falling off a branch. Finally, deployment of the gripper on a tree branch with an aerial robot is demonstrated. Overall, the biodegradable origami gripper represents a first step towards a more scalable and environmentally sustainable approach for ecosystem monitoring.",
        "primary_area": "",
        "author": "Christian Geckeler;Benito Armas Pizzani;Stefano Mintchev;Christian Geckeler;Benito Armas Pizzani;Stefano Mintchev",
        "authorids": "/37086453068;/37089894262;/37085587624;/37086453068;/37089894262;/37085587624",
        "aff": "Swiss Federal Institute for Forest, Snow and Landscape Research (WSL), Birmensdorf, Switzerland; Swiss Federal Institute for Forest, Snow and Landscape Research (WSL), Birmensdorf, Switzerland; Swiss Federal Institute for Forest, Snow and Landscape Research (WSL), Birmensdorf, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160316/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17790432579537400297&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Swiss Federal Institute for Forest, Snow and Landscape Research",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "WSL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Birmensdorf",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161292",
        "title": "Bioinspired tearing manipulation with a robotic fish",
        "track": "main",
        "status": "Poster",
        "abstract": "We present SunBot, a robotic system for the study and implementation of fish-inspired tearing manipulations. Various fish species\u2013such as the sunburst butterflyfish-feed on prey fixed to substrates, a maneuver previously not demonstrated by robotic fish which typically specialize for open water swimming and surveillance. Biological studies indicate that a dynamic \u201chead flick\u201d behavior may play a role in tearing off soft prey during such feeding. In this work, we study whether the robotic tail is an effective means to generate such head motions for ungrounded tearing manipulations in water. We describe the function of SunBot and compare the forces that it applies to a fixed prey in the lab while varying tail speeds and ranges of motion. A simplified dynamic template model for the tail-driven head flick maneuver matches peak force magnitudes from experiments, indicating that inertial effects of the fish's body play a substantial role. Finally, we demonstrate a tearing scenario and evaluate a free-swimming trial of SunBot \u2013 this is important to show that the actuator that enables swimming also provides the new dual purpose of forceful tearing manipulation.",
        "primary_area": "",
        "author": "Stanley J. Wang;Juan Romero;Monica S. Li;Peter C. Wainwright;Hannah S. Stuart;Stanley J. Wang;Juan Romero;Monica S. Li;Peter C. Wainwright;Hannah S. Stuart",
        "authorids": "/37089894759;/37089895324;/37087043201;/37089894642;/37085437460;/37089894759;/37089895324;/37087043201;/37089894642;/37085437460",
        "aff": "Dept. of Mechanical Engineering, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, University of California Berkeley, Berkeley, CA, USA; Dept. of Evolution and Ecology, University of California Davis, Davis, CA, USA; Dept. of Mechanical Engineering, University of California Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161292/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1432805110188809788&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;University of California, Davis",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Evolution and Ecology",
        "aff_unique_url": "https://www.berkeley.edu;https://www.ucdavis.edu",
        "aff_unique_abbr": "UC Berkeley;UC Davis",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Berkeley;Davis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160278",
        "title": "Bipedal Robot Walking Control Using Human Whole-Body Dynamic Telelocomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "For humanoids to be deployed in demanding situations, such as search and rescue, highly intelligent decision making and proficient sensorimotor skill is expected. A promising solution is to leverage human prowess by interconnecting robot and human via teleoperation. Towards creating seamless operation, this paper presents a dynamic telelocomotion framework that synchronizes the gait of a human pilot with the walking of a bipedal robot. First, we introduce a method to generate a virtual human walking model from the stepping behavior of a human pilot which serves as a reference for the robot to walk. Second, the dynamics of the walking reference and robot walking are synchronized by applying forces to the human pilot and the robot to achieve dynamic similarity between the two systems. This enables the human pilot to continuously perceive and cancel any asynchrony between the walking reference and robot. A consistent step placement strategy for the robot is derived to maintain dynamic similarity through step transitions. Using our human-machine-interface, we demonstrate that the human pilot can achieve stable and synchronous teleoperation of a simulated robot through stepping-in-place, walking, and disturbance rejection experiments. This work provides a fundamental step towards transferring human intelligence and reflexes to humanoid robots.",
        "primary_area": "",
        "author": "Guillermo Colin;Youngwoo Sim;Joao Ramos;Guillermo Colin;Youngwoo Sim;Joao Ramos",
        "authorids": "/37089894656;/37086326431;/37085375922;/37089894656;/37086326431;/37085375922",
        "aff": "Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160278/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17485427616044689563&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Science and Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161038",
        "title": "BogieCopter: A Multi-Modal Aerial-Ground Vehicle for Long-Endurance Inspection Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of Micro Aerial Vehicles (MAVs) for inspection and surveillance missions has proved to be extremely useful, however, their usability is negatively impacted by the large power requirements and the limited operating time. This work describes the design and development of a novel hybrid aerial-ground vehicle, enabling multi-modal mobility and long operating time, suitable for long-endurance inspection and monitoring applications. The design consists of a MAV with two tiltable axles and four independent passive wheels, allowing it to fly, approach, land and move on flat and inclined surfaces, while using the same set of actuators for all modes of locomotion. In comparison to existing multi-modal designs with passive wheels, the proposed design enables a higher ground locomotion efficiency, provides a higher payload capacity, and presents one of the lowest mass increases due to the ground actuation mechanism. The vehicle's performance is evaluated through a series of real experiments, demonstrating its flying, ground locomotion and wall-climbing capabilities, and the energy consumption for all modes of locomotion is evaluated.",
        "primary_area": "",
        "author": "Teodoro Dias;Meysam Basiri;Teodoro Dias;Meysam Basiri",
        "authorids": "/37089892941;/37403004200;/37089892941;/37403004200",
        "aff": "Institute for Systems and Robotics of the Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal; Institute for Systems and Robotics of the Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161038/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1285908319923666685&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universidade de Lisboa",
        "aff_unique_dep": "Institute for Systems and Robotics",
        "aff_unique_url": "https://www IST Lisbon",
        "aff_unique_abbr": "IST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "10161411",
        "title": "Boosting 3D Point Cloud Registration by Transferring Multi-modality Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent multi-modality models have achieved great performance in many vision tasks because the extracted features contain the multi-modality knowledge. However, most of the current registration descriptors have only concentrated on local geometric structures. This paper proposes a method to boost point cloud registration accuracy by transferring the multi-modality knowledge of pre-trained multi-modality model to a new descriptor neural network. Different to the previous multi-modality methods that requires both modalities, the proposed method only requires point clouds during inference. Specifically, we propose an ensemble descriptor neural network combining pre-trained sparse convolution branch and a new point-based convolution branch. By fine-tuning on a single modality data, the proposed method achieves new state-of-the-art results on 3DMatch and competitive accuracy on 3DLoMatch and KITTI. The code and the trained model will be released at https://github.com/phdymz/DBENet.git.",
        "primary_area": "",
        "author": "Mingzhi Yuan;Xiaoshui Huang;Kexue Fu;Zhihao Li;Manning Wang;Mingzhi Yuan;Xiaoshui Huang;Kexue Fu;Zhihao Li;Manning Wang",
        "authorids": "/37089352638;/37085703737;/37088761414;/37089882589;/37539566600;/37089352638;/37085703737;/37088761414;/37089882589;/37539566600",
        "aff": "Shanghai Key Laboratory of Medical Image Computing and Computer Assisted Intervention, Shanghai, China; Shanghai artificial intelligence Lab., China; Shanghai Key Laboratory of Medical Image Computing and Computer Assisted Intervention, Shanghai, China; Shanghai Key Laboratory of Medical Image Computing and Computer Assisted Intervention, Shanghai, China; Shanghai Key Laboratory of Medical Image Computing and Computer Assisted Intervention, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161411/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11077612815893171718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Shanghai Key Laboratory of Medical Image Computing and Computer Assisted Intervention;Shanghai Artificial Intelligence Lab",
        "aff_unique_dep": "Medical Image Computing and Computer Assisted Intervention;",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161561",
        "title": "Boosting Performance of a Baseline Visual Place Recognition Technique by Predicting the Maximally Complementary Technique",
        "track": "main",
        "status": "Poster",
        "abstract": "One recent promising approach to the Visual Place Recognition (VPR) problem has been to fuse the place recognition estimates of multiple complementary VPR techniques using methods such as shared representative appearance learning (SRAL) and multi-process fusion. These approaches come with a substantial practical limitation: they require all potential VPR methods to be brute-force run before they are selectively fused. The obvious solution to this limitation is to predict the viable subset of methods ahead of time, but this is challenging because it requires a predictive signal within the imagery itself that is indicative of high performance methods. Here we propose an alternative approach that instead starts with a known single base VPR technique, and learns to predict the most complementary additional VPR technique to fuse with it, that results in the largest improvement in performance. The key innovation here is to use a dimensionally reduced difference vector between the query image and the top-retrieved reference image using this baseline technique as the predictive signal of the most complementary additional technique, both during training and inference. We demonstrate that our approach can train a single network to select performant, complementary technique pairs across datasets which span multiple modes of transportation (train, car, walking) as well as to generalise to unseen datasets, outperforming multiple baseline strategies for manually selecting the best technique pairs based on the same training data.",
        "primary_area": "",
        "author": "Connor Malone;Stephen Hausler;Tobias Fischer;Michael Milford;Connor Malone;Stephen Hausler;Tobias Fischer;Michael Milford",
        "authorids": "/37089294843;/37086694610;/37085784700;/37283633100;/37089294843;/37086694610;/37085784700;/37283633100",
        "aff": "The QUT Centre for Robotics, School of Electrical Engineering and Robotics, QUT, Brisbane, Australia; The QUT Centre for Robotics, School of Electrical Engineering and Robotics, QUT, Brisbane, Australia; The QUT Centre for Robotics, School of Electrical Engineering and Robotics, QUT, Brisbane, Australia; The QUT Centre for Robotics, School of Electrical Engineering and Robotics, QUT, Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161561/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7580122321999276490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "School of Electrical Engineering and Robotics",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160579",
        "title": "Bootstrapping the Dynamic Gait Controller of the Soft Robot Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel dynamic gait controller for the repetitive behavior of soft robot manipulators performing routine tasks. Compliance with soft robots is advantageous when the robot interacts with living organisms and other fragile objects. However, predicting and controlling repetitive behavior is challenging because of hysteresis and non-linear dynamics governing the interactions. Existing priorfree methods track the dynamic state using recurrent neural networks or rely on known generalized coordinates describing the robot's state. We propose to model the interaction induced by the repetitive behavior as gait dynamics and represent the dynamic state with Central Pattern Generator (CPG) tracking the motion phase and thus reduce the complexity of the robot's forward model. The proposed method bootstraps an ensemble of the forward models exploring multiple dynamic contexts that are expanded as it searches for repetitive motion producing the target repetitive behavior. The proposed approach is experimentally validated on a pneumatically actuated soft robot arm I-Support, where the method infers gaits for different targets.",
        "primary_area": "",
        "author": "Rudolf Szadkowski;Muhammad Sunny Nazeer;Matteo Cianchetti;Egidio Falotico;Jan Faigl;Rudolf Szadkowski;Muhammad Sunny Nazeer;Matteo Cianchetti;Egidio Falotico;Jan Faigl",
        "authorids": "/37088516456;/37089837581;/38355861700;/37679918000;/37540566100;/37088516456;/37089837581;/38355861700;/37679918000;/37540566100",
        "aff": "Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; The BioRobotics Institute, Scuola Superiore Sant', Anna, Italy; The BioRobotics Institute, Scuola Superiore Sant', Anna, Italy; The BioRobotics Institute, Scuola Superiore Sant', Anna, Italy; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160579/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10304224704794082112&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Czech Technical University in Prague;Scuola Superiore Sant'Anna",
        "aff_unique_dep": "Faculty of Electrical Engineering;The BioRobotics Institute",
        "aff_unique_url": "https://www.cvut.cz;https://www.sssup.it",
        "aff_unique_abbr": "CTU;SSSUP",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Prague;",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "Czech Republic;Italy"
    },
    {
        "id": "10160843",
        "title": "Boundary Conditions in Geodesic Motion Planning for Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "In dynamic environments, robotic manipulators and especially cobots must be able to react to changing circumstances while in motion. This substantiates the need for quick trajectory planning algorithms that are able to cope with arbitrary velocity and acceleration boundary conditions. Apart from dynamic re-planning, being able to seamlessly join trajectories together opens the door for divide-and-conquer-type algorithms to focus on the individual parts of a motion separately. While geodesic motion planning has proven that it can produce very smooth and efficient actuator movement, the problem of incorporating non-zero boundary conditions has not been addressed yet. We show how a set of generalized coordinates can be used to transition between boundary conditions and free movement in an optimal way while still retaining the known advantages of geodesic planners. We also outline, how our approach can be combined with the family of time-scaling algorithms for further improvement of the generated trajectories.",
        "primary_area": "",
        "author": "Mario Laux;Andreas Zell;Mario Laux;Andreas Zell",
        "authorids": "/37089000145;/37276583400;/37089000145;/37276583400",
        "aff": "Department of Computer Science, Chair of Cognitive Systems, University of T\u00fcbingen, T\u00fcbingen, Germany; Department of Computer Science, Chair of Cognitive Systems, University of T\u00fcbingen, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160843/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:BYGMhogSJ50J:scholar.google.com/&scioq=Boundary+Conditions+in+Geodesic+Motion+Planning+for+Manipulators&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of T\u00fcbingen",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uni-tuebingen.de",
        "aff_unique_abbr": "Uni T\u00fcbingen",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160818",
        "title": "Bounded Compensation with Friction Estimation for Accurate Motion Tracking and Compliant Behavior of Industrial Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a control structure for accurate tracking and compliant behavior of industrial manipulators without additional sensors. To achieve control objectives, friction, one of the biggest causes of performance degradation, should be compensated. For tracking performance, the estimated friction cancels most friction effects as a feed-forward, and the modified robust control structure eliminates the remaining friction uncertainty, which was originally equivalent to the disturbance observer. For compliant behavior, the compensation force fed to the real plant is bounded in contrast to the conventional disturbance observer structure. The compensation bound could be determined through the experiments. The proposed method is validated by experiments with a 6-DOF collaborative industrial manipulator.",
        "primary_area": "",
        "author": "Dongwoo Ko;Donghyeon Lee;Wan Kyun Chung;Keehoon Kim;Dongwoo Ko;Donghyeon Lee;Wan Kyun Chung;Keehoon Kim",
        "authorids": "/37086549660;/37677365900;/37280299100;/37066398600;/37086549660;/37677365900;/37280299100;/37066398600",
        "aff": "Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160818/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14969222157451967651&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160871",
        "title": "Bridging the Domain Gap for Multi-Agent Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing multi-agent perception algorithms usually select to share deep neural features extracted from raw sensing data between agents, achieving a trade-off between accuracy and communication bandwidth limit. However, these methods assume all agents have identical neural networks, which might not be practical in the real world. The transmitted features can have a large domain gap when the models differ, leading to a dramatic performance drop in multi-agent perception. In this paper, we propose the first lightweight framework to bridge such domain gaps for multi-agent perception, which can be a plug-in module for most of the existing systems while maintaining confidentiality. Our framework consists of a learnable feature resizer to align features in multiple dimensions and a sparse cross-domain transformer for domain adaption. Extensive experiments on the public multi-agent perception dataset V2XSet have demonstrated that our method can effectively bridge the gap for features from different domains and outperform other baseline methods significantly by at least 8% for point-cloud-based 3D object detection.",
        "primary_area": "",
        "author": "Runsheng Xu;Jinlong Li;Xiaoyu Dong;Hongkai Yu;Jiaqi Ma;Runsheng Xu;Jinlong Li;Xiaoyu Dong;Hongkai Yu;Jiaqi Ma",
        "authorids": "/37089002744;/37089447894;/37089716223;/37085502264;/37085693088;/37089002744;/37089447894;/37089716223;/37085502264;/37085693088",
        "aff": "UCLA Mobility Lab., University of California, Los Angeles; Cleveland Vision & AI Lab., Cleveland State University; Northwestern University; Cleveland Vision & AI Lab., Cleveland State University; UCLA Mobility Lab., University of California, Los Angeles",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160871/",
        "gs_citation": 77,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10459899951076543975&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "University of California, Los Angeles;Cleveland State University;Northwestern University",
        "aff_unique_dep": "UCLA Mobility Lab.;Cleveland Vision & AI Lab.;",
        "aff_unique_url": "https://www.ucla.edu;https://www.csuohio.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "UCLA;;NU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Los Angeles;Cleveland;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160589",
        "title": "Buoyancy enabled autonomous underwater construction with cement blocks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the first free-floating autonomous underwater construction system capable of using active bal-lasting to transport cement building blocks efficiently. It is the first free-floating autonomous construction robot to use a paired set of resources: compressed air for buoyancy and a battery for thrusters. In construction trials, our system built structures of up to 12 components and weighing up to 100 Kg (75 Kg in water). Our system achieves this performance by combining a novel one-degree-of-freedom manipulator, a novel two-component cement block construction system that corrects errors in placement, and a simple active ballasting system combined with compliant placement and grasp behaviors. The passive error correcting components of the system minimize the required complexity in sensing and control. We also explore the problem of buoyancy allocation for building structures at scale by defining a convex program which allocates buoyancy to minimize the predicted energy cost for transporting blocks.",
        "primary_area": "",
        "author": "Samuel Lensgraf;Devin Balkcom;Alberto Quattrini Li;Samuel Lensgraf;Devin Balkcom;Alberto Quattrini Li",
        "authorids": "/37085783558;/37324093200;/37085808885;/37085783558;/37324093200;/37085808885",
        "aff": "Dartmouth College; Dartmouth College; Dartmouth College",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160589/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11288248706226574580&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Dartmouth College",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.dartmouth.edu",
        "aff_unique_abbr": "Dartmouth",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160443",
        "title": "Burst Stimulation for Enhanced Locomotion Control of Terrestrial Cyborg Insects",
        "track": "main",
        "status": "Poster",
        "abstract": "Terrestrial cyborg insects are biohybrid systems integrating living insects as mobile platforms. The insects' locomotion is controlled by the electrical stimulation of their sensory, muscular, or neural systems, in which continuous pulse trains are usually chosen as the stimulation waveform. Although this waveform is easy to generate and can elicit graded responses from the insects, its locomotion control efficiency has not been consistent among existing literature. This study demonstrates an improvement in locomotion control by using a new stimulation protocol, named Burst Stimulation, to stimulate a cyborg beetle's antennae (Zophobas morio). Modulating the continuous pulse train into multiple bursts enhanced the beetle's turning responses. At the same stimulation intensity (amplitude, pulse width, and active duration), the Burst Stimulation improved the turning angle by up to 50% compared to the continuous waveform. Moreover, the beetle's graded response was preserved. Increasing the stimulation frequency from 10 Hz to 40 Hz raised the turning rate by 40 deg/s. In addition, the initial implementation of this protocol in the feedback control-based navigation achieved a success rate of 81%, suggesting its potential use to optimize further the autonomous navigation of terrestrial cyborg insects.",
        "primary_area": "",
        "author": "H. Duoc Nguyen;Hirotaka Sato;T. Thang Vo-Doan;H. Duoc Nguyen;Hirotaka Sato;T. Thang Vo-Doan",
        "authorids": "/37088420358;/37085396364;/37087700624;/37088420358;/37085396364;/37087700624",
        "aff": "School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; Institute of Biology I, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160443/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3725679342614584791&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Nanyang Technological University;University of Freiburg",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering;Institute of Biology I",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.uni-freiburg.de",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Singapore;Germany"
    },
    {
        "id": "10160512",
        "title": "CAHIR: Co-Attentive Hierarchical Image Representations for Visual Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust visual place recognition (VPR) against significant appearance changes is crucial for the life-long operation of mobile robots. Focusing on this task, we propose a Co-Attentive Hierarchical Image Representations (CAHIR) framework for VPR, which unifies attention-sharing global and local descriptor generation into one encoding pipeline. The hierarchical descriptors are applied to a coarse-to-fine VPR system with global retrieval and local geometric verification. To explore high-quality local matches between task-relevant visual elements, a cross-attention mutual enhancement layer is introduced to strengthen the information interaction between the local descriptors. Through the proposed selective matching distillation, the mutual enhancement layer can learn from state-of-the-art local matchers in a distillation manner. After weighted cross-matching of the enhanced local descriptors, geometric verification is applied to evaluate the spatial consistency of the compared image pair. Experiments show CAHIR outperforms the existing global and local representations for VPR in terms of performance and efficiency. Quantitatively, it achieves state-of-the-art results on three city-scale benchmark datasets. Qualitatively, CAHIR proves to attach great importance to task-relevant visual elements and excels at finding local correspondences that are discriminative to the VPR task.",
        "primary_area": "",
        "author": "Guohao Peng;Heshan Li;Yifeng Huang;Jun Zhang;Mingxing Wen;Singh Rahul;Danwei Wang;Guohao Peng;Heshan Li;Yifeng Huang;Jun Zhang;Mingxing Wen;Singh Rahul;Danwei Wang",
        "authorids": "/37087049757;/37089315207;/37087470827;/37086009222;/37086451677;/37089895233;/37279547600;/37087049757;/37089315207;/37087470827;/37086009222;/37086451677;/37089895233;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Continental Automotive Singapore Pte Ltd., Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160512/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14738243845855688423&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Nanyang Technological University;Continental Automotive",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.continental-automotive.com",
        "aff_unique_abbr": "NTU;CAS",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160502",
        "title": "CAROM Air - Vehicle Localization and Traffic Scene Reconstruction from Aerial Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Road traffic scene reconstruction from videos has been desirable by road safety regulators, city planners, researchers, and autonomous driving technology developers. However, it is expensive and unnecessary to cover every mile of the road with cameras mounted on the road infrastructure. This paper presents a method that can process aerial videos to vehicle trajectory data so that a traffic scene can be automatically reconstructed and accurately re-simulated using computers. On average, the vehicle localization error is about 0.1 m to 0.3 m using a consumer-grade drone flying at 120 meters. This project also compiles a dataset of 50 reconstructed road traffic scenes from about 100 hours of aerial videos to enable various downstream traffic analysis applications and facilitate further road traffic related research. The dataset is available at https://github.com/duolu/CAROM.",
        "primary_area": "",
        "author": "Duo Lu;Eric Eaton;Matt Weg;Wei Wang;Steven Como;Jeffrey Wishart;Hongbin Yu;Yezhou Yang;Duo Lu;Eric Eaton;Matt Weg;Wei Wang;Steven Como;Jeffrey Wishart;Hongbin Yu;Yezhou Yang",
        "authorids": "/37086105021;/37671820200;/37089892202;/37089895530;/37088999441;/37086206905;/37401028700;/37086004333;/37086105021;/37671820200;/37089892202;/37089895530;/37088999441;/37086206905;/37401028700;/37086004333",
        "aff": "Rider University; Rider University; Rider University; Arizona State University; Arizona State University; Arizona State University; Arizona State University; Arizona State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160502/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16098018198213554367&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;1;1;1;1",
        "aff_unique_norm": "Rider University;Arizona State University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.rider.edu;https://www.asu.edu",
        "aff_unique_abbr": "Rider;ASU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160402",
        "title": "CDFI: Cross Domain Feature Interaction for Robust Bronchi Lumen Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Endobronchial intervention is increasingly used as a minimally invasive means for the treatment of pulmonary diseases. In order to reduce the difficulty of manipulation in complex airway networks, robust lumen detection is essential for intraoperative guidance. However, these methods are sensitive to visual artifacts which are inevitable during the surgery. In this work, a cross domain feature interaction (CDFI) network is proposed to extract the structural features of lumens, as well as to provide artifact cues to characterize the visual features. To effectively extract the structural and artifact features, the Quadruple Feature Constraints (QFC) module is designed to constrain the intrinsic connections of samples with various imaging-quality. Furthermore, we design a Guided Feature Fusion (GFF) module to supervise the model for adaptive feature fusion based on different types of artifacts. Results show that the features extracted by the proposed method can preserve the structural information of lumen in the presence of large visual variations, bringing much-improved lumen detection accuracy.",
        "primary_area": "",
        "author": "Jiasheng Xu;Tianyi Zhang;Yangqian Wu;Jie Yang;Guang\u2013Zhong Yang;Yun Gu;Jiasheng Xu;Tianyi Zhang;Yangqian Wu;Jie Yang;Guang\u2013Zhong Yang;Yun Gu",
        "authorids": "/37089894516;/37089894746;/37089894587;/37280203600;/37276270800;/37085529079;/37089894516;/37089894746;/37089894587;/37280203600;/37276270800;/37085529079",
        "aff": "MOE Key Laboratory of System Control and Information Processing, Shanghai, P.R. China; MOE Key Laboratory of System Control and Information Processing, Shanghai, P.R. China; MOE Key Laboratory of System Control and Information Processing, Shanghai, P.R. China; MOE Key Laboratory of System Control and Information Processing, Shanghai, P.R. China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, CHINA; Shanghai Center for Brain Science and Brain-Inspired Technology, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160402/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6788387199526715425&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "MOE Key Laboratory of System Control and Information Processing;Shanghai Jiao Tong University;Shanghai Center for Brain Science and Brain-Inspired Technology",
        "aff_unique_dep": "System Control and Information Processing;Institute of Medical Robotics;",
        "aff_unique_url": ";https://www.sjtu.edu.cn;",
        "aff_unique_abbr": ";SJTU;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161287",
        "title": "CEAFFOD: Cross-Ensemble Attention-based Feature Fusion Architecture Towards a Robust and Real-time UAV-based Object Detection in Complex Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Deploying object detectors in embedded devices such as unmanned aerial vehicles (UAVs) comes with many challenges. This is due to both the UAV itself having low embedded resources in terms of computation and memory, and also due to the nature of the captured visual data with the variations in objects' scale, orientation, density, viewpoint, distribution, shape, context and others. It is crucial for the object detector to be robust with high accuracy, real-time with fast inference and light-weight to be applicable. Inspired by YOLO architecture, we propose a novel single-stage detection architecture. Our contributions are, first, feature fusion spatial pyramid pooling (FFSPP) block that applies attention-based feature fusion across both time and space utilizing the information of subsequent frames and scales in an efficient manner. Secondly, we introduce a multi-dilated attention-based cross-stage partial connection (MDACSP) block that helps in increasing the receptive field and producing per-channel modulation weights after aggregating the feature maps across their spatial domain. Third, scaled feature fusion head (SFFH) fuses both the FFSPP block features and the connected MDACSP block features specific for this head. For a more robust result across different scenarios, we perform cross-ensembling with three of the top UAV/traffic surveillance datasets: UAVDT, UA-DETRAC and VisDrone. Our ablation study shows how every contribution improves over the baseline. Our approach yielded the state-of-the-art results in all the aforementioned datasets achieving 89.3% mAP, 93.5% mAP, and 42.9% mAP respectively. Testing the model performance on NVIDIA Jetson Xavier NX board shows a desirable balance between the inference time and the memory cost. We also show qualitatively the model robustness and efficiency across the diverse complex scenarios of these datasets. We hope this work facilitates the advancement of the UAV-based perception in such crucial industrial applications. Show More",
        "primary_area": "",
        "author": "Ahmed Elhagry;Hang Dai;Abdulmotaleb El Saddik;Wail Gueaieb;Giulia De Masi;Ahmed Elhagry;Hang Dai;Abdulmotaleb El Saddik;Wail Gueaieb;Giulia De Masi",
        "authorids": "/37089892985;/37086004737;/37267318000;/37294232300;/37089895784;/37089892985;/37086004737;/37267318000;/37294232300;/37089895784",
        "aff": "Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), Masdar City, Abu Dhabi, United Arab Emirates; Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), Masdar City, Abu Dhabi, United Arab Emirates; University of Ottawa, Canada; University of Ottawa, Canada; Technology Innovation Institute (TII), Masdar City, Abu Dhabi, United Arab Emirates",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161287/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10990610370269026220&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;2",
        "aff_unique_norm": "Mohamed Bin Zayed University of Artificial Intelligence;University of Ottawa;Technology Innovation Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.mbzuai.ac.ae;https://www.uottawa.ca;",
        "aff_unique_abbr": "MBZUAI;U Ottawa;TII",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Masdar City;",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United Arab Emirates;Canada"
    },
    {
        "id": "10160525",
        "title": "CFVS: Coarse-to-Fine Visual Servoing for 6-DoF Object-Agnostic Peg-In-Hole Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic peg-in-hole assembly remains a challenging task due to its high accuracy demand. Previous work tends to simplify the problem by restricting the degree of freedom of the end-effector, or limiting the distance between the target and the initial pose position, which prevents them from being deployed in real-world manufacturing. Thus, we present a Coarse-to-Fine Visual Servoing (CFVS) peg-in-hole method, achieving 6-DoF end-effector motion control based on 3D visual feedback. CFVS can handle arbitrary tilt angles and large initial alignment errors through a fast pose estimation before refinement. Furthermore, by introducing a confidence map to ignore the irrelevant contour of objects, CFVS is robust against noise and can deal with various targets beyond training data. Extensive experiments show CFVS outperforms state-of-the-art methods and obtains 100%, 91%, and 82% average success rates in 3-DoF, 4-DoF, and 6-DoF peg-in-hole, respectively.",
        "primary_area": "",
        "author": "Bo-Siang Lu;Tung-I Chen;Hsin-Ying Lee;Winston H. Hsu;Bo-Siang Lu;Tung-I Chen;Hsin-Ying Lee;Winston H. Hsu",
        "authorids": "/37089894575;/37089195262;/37089613229;/37272584600;/37089894575;/37089195262;/37089613229;/37272584600",
        "aff": "National Taiwan University; National Taiwan University; National Taiwan University; Mobile Drive Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160525/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8149412798371316464&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "National Taiwan University;Mobile Drive Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ntu.edu.tw;",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "10160664",
        "title": "CIOT: Constraint-Enhanced Inertial-Odometric Tracking for Articulated Dump Trucks in GNSS-Denied Mining Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The ongoing electrification in all domains relies on strong increase in raw material extraction. Autonomous dump trucks are key to facilitating this. The automation requires the development of new localization approaches, as deep open-pit mines are challenging for satellite-based localization systems. Deep funnel-shaped mines reduce the sky-view angle from a certain position onward so that few to no satellites are visible. Therefore, we introduce a new wheel-odometry-aided navigation filter for articulated vehicles that fuses measurements from an inertial measurement unit (IMU), global navigation satellite systems (GNSS), and wheel encoders. Non-holonomic constraints are incorporated by assuming the lateral velocity of each wheel to be zero. We present two different measurement models that either use the wheel encoder signals of the rear wheels or all wheels of the articulated vehicle. This approach enables articulated vehicles to cope with the challenges of open-pit mines. The developed navigation filter is evaluated experimentally with an articulated dumper in two scenarios: A paved parking lot and a gravel pit. With the proposed method, we achieved a mean position error of 0.21 m during a 190 s test drive in the gravel pit with a simulated GNSS interruption of 90 s. This is an improvement of 64 m compared to a state-of-the-art navigation filter that fuses only inertial and GNSS measurements.",
        "primary_area": "",
        "author": "David Benz;Jonathan Weseloh;Dirk Abel;Heike Vallery;David Benz;Jonathan Weseloh;Dirk Abel;Heike Vallery",
        "authorids": "/37089583254;/37089892713;/37547195500;/37568746400;/37089583254;/37089892713;/37547195500;/37568746400",
        "aff": "Institute of Automatic Control, RWTH Aachen University, Aachen, Germany; Institute of Automatic Control, RWTH Aachen University, Aachen, Germany; Institute of Automatic Control, RWTH Aachen University, Aachen, Germany; Institute of Automatic Control, RWTH Aachen University, Aachen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160664/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14221323653998643342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "RWTH Aachen University",
        "aff_unique_dep": "Institute of Automatic Control",
        "aff_unique_url": "https://www.rwth-aachen.de",
        "aff_unique_abbr": "RWTH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Aachen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160440",
        "title": "CLIO: a Novel Robotic Solution for Exploration and Rescue Missions in Hostile Mountain Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Rescue missions in mountain environments are hardly achievable by standard legged robots\u2014because of the high slopes\u2014or by flying robots\u2014because of limited payload capacity. We present a concept for a rope-aided climbing robot which can negotiate up-to-vertical slopes and carry heavy payloads. The robot is attached to the mountain through a rope, and it is equipped with a leg to push against the mountain and initiate jumping maneuvers. Between jumps, a hoist is used to wind/unwind the rope to move vertically and affect the lateral motion. This simple (yet effective) two-fold actuation allows the system to achieve high safety and energy efficiency. Indeed, the rope prevents the robot from falling while compensating for most of its weight, drastically reducing the effort required by the leg actuator. We also present an optimal control strategy to generate point-to-point trajectories overcoming an obstacle. We achieve fast computation time (<1 s) thanks to the use of a custom simplified robot model. We validated the generated optimal movements in Gazebo simulations with a complete robot model with a < 5% error on a 16\\ m16\\ m long jump, showing the effectiveness of the proposed approach, and confirming the interest of our concept. Finally, we performed a reachability analysis showing that the region of achievable targets is strongly affected by the friction properties of the foot-wall contact.",
        "primary_area": "",
        "author": "Michele Focchi;Mohamed Bensaadallah;Marco Frego;Angelika Peer;Daniele Fontanelli;Andrea Del Prete;Luigi Palopoli;Michele Focchi;Mohamed Bensaadallah;Marco Frego;Angelika Peer;Daniele Fontanelli;Andrea Del Prete;Luigi Palopoli",
        "authorids": "/37542633600;/37089895883;/37085896446;/37547817000;/37398642200;/37085422921;/37268097200;/37542633600;/37089895883;/37085896446;/37547817000;/37398642200;/37085422921;/37268097200",
        "aff": "Dipartimento di Ingegneria and Scienza dell'Informazione (DISI), University of Trento; Department of Electronics, University of Batna 2, Algeria; Faculty of Science and Technology, Free University of Bozen-Bolzano; Faculty of Science and Technology, Free University of Bozen-Bolzano; Dipartimento di Ingegneria Industriale (DII), University of Trento; Dipartimento di Ingegneria Industriale (DII), University of Trento; Dipartimento di Ingegneria and Scienza dell'Informazione (DISI), University of Trento",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160440/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7332575145293808560&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;0;0;0",
        "aff_unique_norm": "University of Trento;University of Batna 2;Free University of Bozen-Bolzano",
        "aff_unique_dep": "Dipartimento di Ingegneria and Scienza dell'Informazione (DISI);Department of Electronics;Faculty of Science and Technology",
        "aff_unique_url": "https://www.unitn.it;;https://www.unibz.it",
        "aff_unique_abbr": "UniTN;;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0;0;0",
        "aff_country_unique": "Italy;Algeria"
    },
    {
        "id": "10161481",
        "title": "CMG-Net: An End-to-End Contact-based Multi-Finger Dexterous Grasping Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel representation for grasping using contacts between multi-finger robotic hands and objects to be manipulated. This representation significantly reduces the prediction dimensions and accelerates the learning process. We present an effective end-to-end network, CMG-Net, for grasping unknown objects in a cluttered environment by efficiently predicting multi-finger grasp poses and hand configurations from a single-shot point cloud. Moreover, we create a synthetic grasp dataset that consists of five thousand cluttered scenes, 80 object categories, and 20 million annotations. We perform a comprehensive empirical study and demonstrate the effectiveness of our grasping representation and CMG-Net. Our work significantly outperforms the state-of-the-art for three-finger robotic hands. We also demonstrate that the model trained using synthetic data perform very well for real robots.",
        "primary_area": "",
        "author": "Mingze Wei;Yaomin Huang;Zhiyuan Xu;Ning Liu;Zhengping Che;Xinyu Zhang;Chaomin Shen;Feifei Feng;Chun Shan;Jian Tang;Mingze Wei;Yaomin Huang;Zhiyuan Xu;Ning Liu;Zhengping Che;Xinyu Zhang;Chaomin Shen;Feifei Feng;Chun Shan;Jian Tang",
        "authorids": "/37089895061;/37089894465;/37086054471;/37085839703;/37085548246;/37558390400;/37829584900;/37089534869;/37086690979;/37276758700;/37089895061;/37089894465;/37086054471;/37085839703;/37085548246;/37558390400;/37829584900;/37089534869;/37086690979;/37276758700",
        "aff": "School of Software Engineering, East China Normal University, China; School of Computer Science, East China Normal University, China; Midea Group, China; Midea Group, China; Midea Group, China; School of Software Engineering, East China Normal University, China; School of Computer Science, East China Normal University, China; Midea Group, China; School of Electronics and Information, Guangdong Polytechnic Normal University, China; Midea Group, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161481/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7859309918658203588&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;1;1;1;0;0;1;2;1",
        "aff_unique_norm": "East China Normal University;Midea Group;Guangdong Polytechnic Normal University",
        "aff_unique_dep": "School of Software Engineering;;School of Electronics and Information",
        "aff_unique_url": "http://www.ecnu.edu.cn;https://www.mideaglobal.com;",
        "aff_unique_abbr": "ECNU;Midea;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160635",
        "title": "CNN-based Visual Servoing for Simultaneous Positioning and Flattening of Soft Fabric Parts",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes CNN-based visual servoing for simultaneous positioning and flattening of a soft fabric part placed on a table by a dual manipulator system. We propose a network for multimodal data processing of grayscale images captured by a camera and force/torque applied to force sensors. The training dataset is collected by moving the real manipulators, which enables the network to map the captured images and force/torque to the manipulator's motion in Cartesian space. We apply structured lighting to emphasize the features of the surface of the fabric part since the surface shape of the non-textured fabric part is difficult to recognize by a single grayscale image. Through experiments, we show that the fabric part with unseen wrinkles can be positioned and flattened by the proposed visual servoing scheme.",
        "primary_area": "",
        "author": "Fuyuki Tokuda;Akira Seino;Akinari Kobayashi;Kazuhiro Kosuge;Fuyuki Tokuda;Akira Seino;Akinari Kobayashi;Kazuhiro Kosuge",
        "authorids": "/37087245052;/37089937892;/37086309766;/37278595800;/37087245052;/37089937892;/37086309766;/37278595800",
        "aff": "Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong SAR; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong SAR; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong SAR; Department of Electrical and Electronic Engineering, Faculty of Engineering, The University of Hong Kong, Hong Kong SAR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160635/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14626457357653601823&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "The University of Hong Kong",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.hku.hk",
        "aff_unique_abbr": "HKU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160539",
        "title": "COLA: COarse LAbel pre-training for 3D semantic segmentation of sparse LiDAR datasets",
        "track": "main",
        "status": "Poster",
        "abstract": "Transfer learning is a proven technique in 2D computer vision to leverage the large amount of data available and achieve high performance with datasets limited in size due to the cost of acquisition or annotation. In 3D, annotation is known to be a costly task; nevertheless, pre-training methods have only recently been investigated. Due to this cost, unsupervised pretraining has been heavily favored. In this work, we tackle the case of real-time 3D semantic segmentation of sparse autonomous driving LiDAR scans. Such datasets have been increasingly released, but each has a unique label set. We propose here an intermediate-level label set called coarse labels, which can easily be used on any existing and future autonomous driving datasets, thus allowing all the data available to be leveraged at once without any additional manual labeling. This way, we have access to a larger dataset, alongside a simple task of semantic segmentation. With it, we introduce a new pretraining task: coarse label pre-training, also called COLA. We thoroughly analyze the impact of COLA on various datasets and architectures and show that it yields a noticeable performance improvement, especially when only a small dataset is available for the finetuning task.",
        "primary_area": "",
        "author": "Jules Sanchez;Jean-Emmanuel Deschaud;Fran\u00e7ois Goulette;Jules Sanchez;Jean-Emmanuel Deschaud;Fran\u00e7ois Goulette",
        "authorids": "/37089894220;/38519215400;/37402879500;/37089894220;/38519215400;/37402879500",
        "aff": "Centre for Robotics, Mines Paris - PSL, PSL University, Paris, France; Centre for Robotics, Mines Paris - PSL, PSL University, Paris, France; Centre for Robotics, Mines Paris - PSL, PSL University, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160539/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8778396303954573396&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Mines Paris - PSL",
        "aff_unique_dep": "Centre for Robotics",
        "aff_unique_url": "https://www.mines-paris.psl.eu",
        "aff_unique_abbr": "Mines Paris - PSL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160938",
        "title": "COVINS-G: A Generic Back-end for Collaborative Visual-Inertial SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative SLAM is at the core of perception in multi-robot systems as it enables the co-localization of the team of robots in a common reference frame, which is of vital importance for any coordination amongst them. The paradigm of a centralized architecture is well established, with the robots (i.e. agents) running Visual-Inertial Odometry (VIO) onboard while communicating relevant data, such as e.g. Keyframes (KFs), to a central back-end (i.e. server), which then merges and optimizes the joint maps of the agents. While these frameworks have proven to be successful, their capability and performance are highly dependent on the choice of the VIO front-end, thus limiting their flexibility. In this work, we present COVINSG, a generalized back-end building upon the COVINS [1] framework, enabling the compatibility of the server-back-end with any arbitrary VIO front-end, including, for example, off-the-shelf cameras with odometry capabilities, such as the Realsense T265. The COVINS-G back-end deploys a multi-camera relative pose estimation algorithm for computing the loop-closure constraints allowing the system to work purely on 2D image data. In the experimental evaluation, we show on-par accuracy with state-of-the-art multi-session and collaborative SLAM systems, while demonstrating the flexibility and generality of our approach by employing different front-ends onboard collaborating agents within the same mission. The COVINS-G codebase along with a generalized front-end wrapper to allow any existing VIO front-end to be readily used in combination with the proposed collaborative back-end is open-sourced. Video- https://youtu.be/FoJfXCfaYDw",
        "primary_area": "",
        "author": "Manthan Patel;Marco Karrer;Philipp B\u00e4nninger;Margarita Chli;Manthan Patel;Marco Karrer;Philipp B\u00e4nninger;Margarita Chli",
        "authorids": "/37089700059;/37086206672;/37089381818;/37546501900;/37089700059;/37086206672;/37089381818;/37546501900",
        "aff": "ETH Zurich, Vision for Robotics Lab, Switzerland; ETH Zurich, Vision for Robotics Lab, Switzerland; ETH Zurich, Vision for Robotics Lab, Switzerland; ETH Zurich, Vision for Robotics Lab, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160938/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13626383472105813301&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Vision for Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10160705",
        "title": "CPSeg: Cluster-free Panoptic Segmentation of 3D LiDAR Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "A fast and accurate panoptic segmentation system for LiDAR point clouds is crucial for autonomous driving vehicles to understand the surrounding objects and scenes. Existing approaches usually rely on proposals or clustering to segment foreground instances. As a result, they struggle to achieve real-time performance. In this paper, we propose a novel real-time end-to-end panoptic segmentation network for LiDAR point clouds, called CPSeg. In particular, CPSeg comprises a shared encoder, a dual-decoder, and a cluster-free instance segmentation head, which is able to dynamically pillarize foreground points according to the learned embedding. Then, it acquires instance labels by finding connected pillars with a pairwise embedding comparison. Thus, the conventional proposal-based or clustering-based instance segmentation is transformed into a binary segmentation problem on the pairwise embedding comparison matrix. To help the network regress instance embedding, a fast and deterministic depth completion algorithm is proposed to calculate the surface normal of each point cloud in real-time. The proposed method is benchmarked on two large-scale autonomous driving datasets: SemanticKITTI and nuScenes. Notably, extensive experimental results show that CPSeg achieves state-of-the-art results among real-time approaches on both datasets.",
        "primary_area": "",
        "author": "Enxu Li;Ryan Razani;Yixuan Xu;Bingbing Liu;Enxu Li;Ryan Razani;Yixuan Xu;Bingbing Liu",
        "authorids": "/37089013811;/37086404456;/37089448639;/38572992400;/37089013811;/37086404456;/37089448639;/38572992400",
        "aff": "University of Toronto; Huawei Noah's Ark Lab; University of Toronto; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160705/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2654374010863688444&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of Toronto;Huawei",
        "aff_unique_dep": ";Noah's Ark Lab",
        "aff_unique_url": "https://www.utoronto.ca;https://www.huawei.com",
        "aff_unique_abbr": "U of T;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "10160942",
        "title": "CPnP: Consistent Pose Estimator for Perspective-n-Point Problem with Bias Elimination",
        "track": "main",
        "status": "Poster",
        "abstract": "The Perspective-n-Point (PnP) problem has been widely studied in both computer vision and photogrammetry societies. With the development of feature extraction techniques, a large number of feature points might be available in a single shot. It is promising to devise a consistent estimator, i.e., the estimate can converge to the true camera pose as the number of points increases. To this end, we propose a consistent PnP solver, named CPnP, with bias elimination. Specifically, linear equations are constructed from the original projection model via measurement model modification and variable elimination, based on which a closed-form least-squares solution is obtained. We then analyze and subtract the asymptotic bias of this solution, resulting in a consistent estimate. Additionally, Gauss-Newton (GN) iterations are executed to refine the consistent solution. Our proposed estimator is efficient in terms of computations\u2014it has O(n)O(n) time complexity. Simulations and real dataset tests show that our proposed estimator is superior to some well-known ones for images with dense visual features, in terms of estimation precision and computing time.",
        "primary_area": "",
        "author": "Guangyang Zeng;Shiyu Chen;Biqiang Mu;Guodong Shi;Junfeng Wu;Guangyang Zeng;Shiyu Chen;Biqiang Mu;Guodong Shi;Junfeng Wu",
        "authorids": "/37086618333;/37089895482;/38540863300;/37529174400;/37085446840;/37086618333;/37089895482;/38540863300;/37529174400;/37085446840",
        "aff": "School of Data Science, Chinese University of Hong Kong, Shenzhen, P. R. China; School of Data Science, Chinese University of Hong Kong, Shenzhen, P. R. China; Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, P. R. China; Mechanical and Mechatronic Engineering, The University of Sydney, Sydney; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), Shenzhen, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160942/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14637477584445602868&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "Chinese University of Hong Kong;Chinese Academy of Sciences;The University of Sydney;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "School of Data Science;Academy of Mathematics and Systems Science;Mechanical and Mechatronic Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.cn;http://www.cas.cn;https://www.sydney.edu.au;",
        "aff_unique_abbr": "CUHK;CAS;USYD;AIRS",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Shenzhen;Beijing;Sydney",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "10161282",
        "title": "CUREE: A Curious Underwater Robot for Ecosystem Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "The current approach to exploring and monitoring complex underwater ecosystems, such as coral reefs, is to conduct surveys using diver-held or static cameras, or deploying sensor buoys. These approaches often fail to capture the full variation and complexity of interactions between different reef organisms and their habitat. The CUREE platform presented in this paper provides a unique set of capabilities in the form of robot behaviors and perception algorithms to enable scientists to explore different aspects of an ecosystem. Examples of these capabilities include low-altitude visual surveys, soundscape surveys, habitat characterization, and animal following. We demonstrate these capabilities by describing two field deployments on coral reefs in the US Virgin Islands. In the first deployment, we show that CUREE can identify the preferred habitat type of snapping shrimp in a reef through a combination of a visual survey, habitat characterization, and a soundscape survey. In the second deployment, we demonstrate CUREE's ability to follow arbitrary animals by separately following a barracuda and stingray for several minutes each in midwater and benthic environments, respectively.",
        "primary_area": "",
        "author": "Yogesh Girdhar;Nathan McGuire;Levi Cai;Stewart Jamieson;Seth McCammon;Brian Claus;John E. San Soucie;Jessica E. Todd;T. Aran Mooney;Yogesh Girdhar;Nathan McGuire;Levi Cai;Stewart Jamieson;Seth McCammon;Brian Claus;John E. San Soucie;Jessica E. Todd;T. Aran Mooney",
        "authorids": "/37546414900;/37086938310;/37086935575;/37086936061;/37086071053;/37923986300;/37088507468;/37089895495;/37088835302;/37546414900;/37086938310;/37086935575;/37086936061;/37086071053;/37923986300;/37088507468;/37089895495;/37088835302",
        "aff": "Woods Hole Oceanographic Institution (WHOI); Woods Hole Oceanographic Institution (WHOI); MIT-WHOI Joint Program in Oceanography/Applied Ocean Science and Engineering; MIT-WHOI Joint Program in Oceanography/Applied Ocean Science and Engineering; Woods Hole Oceanographic Institution (WHOI); Woods Hole Oceanographic Institution (WHOI); MIT-WHOI Joint Program in Oceanography/Applied Ocean Science and Engineering; MIT-WHOI Joint Program in Oceanography/Applied Ocean Science and Engineering; Woods Hole Oceanographic Institution (WHOI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161282/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11754814596641968097&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;1;0;0;1;1;0",
        "aff_unique_norm": "Woods Hole Oceanographic Institution;Massachusetts Institute of Technology",
        "aff_unique_dep": ";Joint Program in Oceanography/Applied Ocean Science and Engineering",
        "aff_unique_url": "https://www.whoi.edu;https://web.mit.edu/",
        "aff_unique_abbr": "WHOI;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161528",
        "title": "CabiNet: Scaling Neural Collision Detection for Object Rearrangement with Procedural Scene Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the important problem of generalizing robotic rearrangement to clutter without any explicit object models. We first generate over 650K cluttered scenes-orders of magnitude more than prior work-in diverse everyday environments, such as cabinets and shelves. We render synthetic partial point clouds from this data and use it to train our CabiNet model architecture. CabiNet is a collision model that accepts object and scene point clouds, captured from a single-view depth observation, and predicts collisions for SE(3) object poses in the scene. Our representation has a fast inference speed of 7\u03bcs/query with nearly 20% higher performance than baseline approaches in challenging environments. We use this collision model in conjunction with a Model Predictive Path Integral (MPPI) planner to generate collision-free trajectories for picking and placing in clutter. CabiNet also predicts waypoints, computed from the scene's signed distance field (SDF), that allows the robot to navigate tight spaces during rearrangement. This improves rearrangement performance by nearly 35% compared to baselines. We systematically evaluate our approach, procedurally generate simulated experiments, and demonstrate that our approach directly transfers to the real world, despite training exclusively in simulation. Supplementary material and videos of robot experiments in completely unknown scenes are available at: cabinet-object-rearrangement.github.io.",
        "primary_area": "",
        "author": "Adithyavairavan Murali;Arsalan Mousavian;Clemens Eppner;Adam Fishman;Dieter Fox;Adithyavairavan Murali;Arsalan Mousavian;Clemens Eppner;Adam Fishman;Dieter Fox",
        "authorids": "/37085349840;/37085404794;/37571607800;/37088690696;/37284329000;/37085349840;/37085404794;/37571607800;/37088690696;/37284329000",
        "aff": "NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161528/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14459052711368479133&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "NVIDIA Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161069",
        "title": "Cable Routing and Assembly using Tactile-driven Motion Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulating cables is challenging for robots because of the infinite degrees of freedom of the cables and frequent occlusion by the gripper and the environment. These challenges are further complicated by the dexterous nature of the operations required for cable routing and assembly, such as weaving and inserting, hampering common solutions with vision-only sensing. In this paper, we propose to integrate tactile-guided low-level motion control with high-level vision- based task parsing for a challenging task: cable routing and assembly on a reconfigurable task board. Specifically, we build a library of tactile-guided motion primitives using a fingertip GelSight sensor, where each primitive reliably accomplishes an operation such as cable following and weaving. The overall task is inferred via visual perception given a goal configuration image, and then used to generate the primitive sequence. Experiments demonstrate the effectiveness of individual tactile- guided primitives and the integrated end-to-end solution, sig- nificantly outperforming the method without tactile sensing. Our reconfigurable task setup and proposed baselines provide a benchmark for future research in cable manipulation.",
        "primary_area": "",
        "author": "Achu Wilson;Helen Jiang;Wenzhao Lian;Wenzhen Yuan;Achu Wilson;Helen Jiang;Wenzhao Lian;Wenzhen Yuan",
        "authorids": "/37089894873;/37089663930;/37088998889;/37085486405;/37089894873;/37089663930;/37088998889;/37085486405",
        "aff": "Carnegie Mellon University, PA, USA; Carnegie Mellon University, PA, USA; Intrinsic Innovation LLC, CA, USA; Carnegie Mellon University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161069/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=66422575335603083&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Intrinsic Innovation LLC",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;",
        "aff_unique_abbr": "CMU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161575",
        "title": "CalibDepth: Unifying Depth Map Representation for Iterative LiDAR-Camera Online Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR-Camera online calibration is of great significance for building a stable autonomous driving perception system. For online calibration, a key challenge lies in constructing a unified and robust representation between multi-modal sensor data. Most methods extract features manually or implicitly with an end-to-end deep learning method. The former suffers poor robustness, while the latter has poor interpretability. In this paper, we propose CalibDepth, which uses depth maps as the unified representation for image and LiDAR point cloud. CalibDepth introduces a sub-network for monocular depth estimation to assist online calibration tasks. To further improve the performance, we regard online calibration as a sequence prediction problem, and introduce global and local losses to optimize the calibration results. CalibDepth shows excellent performance in different experimental setups. Code is open-sourced at https://github.com/Brickzhuantou/CalibDepth.",
        "primary_area": "",
        "author": "Jiangtong Zhu;Jianru Xue;Pu Zhang;Jiangtong Zhu;Jianru Xue;Pu Zhang",
        "authorids": "/37089893413;/37402347300;/37087232429;/37089893413;/37402347300;/37087232429",
        "aff": "National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, China; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, China; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161575/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3089187767821610536&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Xi'an Jiaotong University",
        "aff_unique_dep": "Institute of Artificial Intelligence and Robotics",
        "aff_unique_url": "http://www.xjtu.edu.cn",
        "aff_unique_abbr": "XJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160769",
        "title": "Calibration and Uncertainty Characterization for Ultra-Wideband Two-Way-Ranging Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultra-Wideband (UWB) systems are becoming increasingly popular for indoor localization, where range measurements are obtained by measuring the time-of-flight of radio signals. However, the range measurements typically suffer from a systematic error or bias that must be corrected for high-accuracy localization. In this paper, a ranging protocol is proposed alongside a robust and scalable antenna-delay calibration procedure to accurately and efficiently calibrate antenna delays for many UWB tags. Additionally, the bias and uncertainty of the measurements are modelled as a function of the received-signal power. The full calibration procedure is presented using experimental training data of 3 aerial robots fitted with 2 UWB tags each, and then evaluated on 2 test experiments. A localization problem is then formulated on the experimental test data, and the calibrated measurements and their modelled uncertainty are fed into an extended Kalman filter (EKF). The proposed calibration is shown to yield an average of 46% improvement in localization accuracy. Lastly, the paper is accompanied by an open-source UWB-calibration Python library, which can be found at https://github.com/decargroup/uwb_calibration.",
        "primary_area": "",
        "author": "Mohammed Ayman Shalaby;Charles Champagne Cossette;James Richard Forbes;Jerome Le Ny;Mohammed Ayman Shalaby;Charles Champagne Cossette;James Richard Forbes;Jerome Le Ny",
        "authorids": "/37089049261;/37087407589;/37543396800;/37546028800;/37089049261;/37087407589;/37543396800;/37546028800",
        "aff": "department of Mechanical Engineering, McGill University, Montreal, QC, Canada; department of Mechanical Engineering, McGill University, Montreal, QC, Canada; department of Mechanical Engineering, McGill University, Montreal, QC, Canada; department of Electrical Engineering, Polytechnique Montreal, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160769/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3807857676666990388&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "McGill University;Polytechnique Montreal",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical Engineering",
        "aff_unique_url": "https://www.mcgill.ca;https://www.polymtl.ca",
        "aff_unique_abbr": "McGill;Polytechnique",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161497",
        "title": "Can Machines Garden? Systematically Comparing the AlphaGarden vs. Professional Horticulturalists",
        "track": "main",
        "status": "Poster",
        "abstract": "The AlphaGarden is an automated testbed for indoor polyculture farming which combines a first-order plant simulator, a gantry robot, a seed planting algorithm, plant phenotyping and tracking algorithms, irrigation sensors and algorithms, and custom pruning tools and algorithms. In this paper, we systematically compare the performance of the AlphaGarden to professional horticulturalists on the staff of the UC Berkeley Oxford Tract Greenhouse. The humans and the machine tend side-by-side polyculture gardens with the same seed arrangement. We compare performance in terms of canopy coverage, plant diversity, and water consumption. Results from two 60-day cycles suggest that the automated AlphaGarden performs comparably to professional horticulturalists in terms of coverage and diversity, and reduces water consumption by as much as 44%. Code, videos, and datasets are available at https//sites.google.com/berkeley.edulsystematiccomparison",
        "primary_area": "",
        "author": "Simeon Adebola;Rishi Parikh;Mark Presten;Satvik Sharma;Shrey Aeron;Ananth Rao;Sandeep Mukherjee;Tomson Qu;Christina Wistrom;Eugen Solowjow;Ken Goldberg;Simeon Adebola;Rishi Parikh;Mark Presten;Satvik Sharma;Shrey Aeron;Ananth Rao;Sandeep Mukherjee;Tomson Qu;Christina Wistrom;Eugen Solowjow;Ken Goldberg",
        "authorids": "/37089005515;/37088997522;/37088525753;/37089000005;/37089440079;/37089895153;/37089000421;/37089895676;/37089895707;/37947855300;/37273026700;/37089005515;/37088997522;/37088525753;/37089000005;/37089440079;/37089895153;/37089000421;/37089895676;/37089895707;/37947855300;/37273026700",
        "aff": "The AUTOLab at UC Berkeley (automation.berkeley.edu); The AUTOLab at UC Berkeley (automation.berkeley.edu); The AUTOLab at UC Berkeley (automation.berkeley.edu); The AUTOLab at UC Berkeley (automation.berkeley.edu); The AUTOLab at UC Berkeley (automation.berkeley.edu); The AUTOLab at UC Berkeley (automation.berkeley.edu); The AUTOLab at UC Berkeley (automation.berkeley.edu); The AUTOLab at UC Berkeley (automation.berkeley.edu); Berkeley GreenHouse; Siemens Research Lab, Berkeley, CA; The AUTOLab at UC Berkeley (automation.berkeley.edu)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161497/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5670924352838212342&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Siemens",
        "aff_unique_dep": "AUTOLab;Research Lab",
        "aff_unique_url": "https://www.berkeley.edu;https://www.siemens.com",
        "aff_unique_abbr": "UC Berkeley;Siemens",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160722",
        "title": "Can We Use Diffusion Probabilistic Models for 3D Motion Prediction?",
        "track": "main",
        "status": "Poster",
        "abstract": "After many researchers observed fruitfulness from the recent diffusion probabilistic model, its effectiveness in image generation is actively studied these days. In this paper, our objective is to evaluate the potential of diffusion probabilistic models for 3D human motion-related tasks. To this end, this pa-per presents a study of employing diffusion probabilistic models to predict future 3D human motion(s) from the previously observed motion. Based on the Human 3.6M and HumanEva-I datasets, our results show that diffusion probabilistic models are competitive for both single (deterministic) and multiple (stochastic) 3D motion prediction tasks, after finishing a single training process. In addition, we find out that diffusion probabilistic models can offer an attractive compromise, since they can strike the right balance between the likelihood and diversity of the predicted future motions. Our code is publicly available on the project website: https://sites.google.com/view/diffusion-motion-prediction.",
        "primary_area": "",
        "author": "Hyemin Ahn;Esteve Valls Mascaro;Dongheui Lee;Hyemin Ahn;Esteve Valls Mascaro;Dongheui Lee",
        "authorids": "/37085492273;/37089661581;/37068725100;/37085492273;/37089661581;/37068725100",
        "aff": "Artificial Intelligence Graduate School (AIGS), Ulsan National Institute of Science and Technology (UNIST), Ulsan, Korea; Autonomous Systems, Technische Universit\u00e4t Wien (TU Wien), Vienna, Austria; Institute of Robotics and Mechatronics (DLR), German Aerospace Center, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160722/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2744284689909929930&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;Technische Universit\u00e4t Wien;German Aerospace Center",
        "aff_unique_dep": "Artificial Intelligence Graduate School (AIGS);Autonomous Systems;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.unist.ac.kr;https://www.tuwien.ac.at;https://www.dlr.de",
        "aff_unique_abbr": "UNIST;TU Wien;DLR",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Ulsan;Vienna;Wessling",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "South Korea;Austria;Germany"
    },
    {
        "id": "10160677",
        "title": "Carrying the uncarriable: a deformation-agnostic and human-cooperative framework for unwieldy objects using multiple robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This manuscript introduces an object deformability-agnostic framework for co-carrying tasks that are shared between a person and multiple robots. Our approach allows the full control of the co-carrying trajectories by the person while sharing the load with multiple robots depending on the size and the weight of the object. This is achieved by merging the haptic information transferred through the object and the human motion information obtained from a motion capture system. One important advantage of the framework is that no strict internal communication is required between the robots, regardless of the object size and deformation characteristics. We validate the framework with two challenging real-world scenarios: co-transportation of a wooden rigid closet and a bulky box on top of forklift moving straps, with the latter characterizing deformable objects. In order to evaluate the generalizability of the proposed framework, a heterogenous team of two mobile manipulators that consist of an Omni-directional mobile base and a collaborative robotic arm with different DoFs is chosen for the experiments. The qualitative comparison between our controller and the baseline controller (i.e., an admittance controller) during these experiments demonstrated the effectiveness of the proposed framework especially when co-carrying deformable objects. Furthermore, we believe that the performance of our framework during the experiment with the lifting straps offers a promising solution for the co-transportation of bulky and ungraspable objects.",
        "primary_area": "",
        "author": "Doganay Sirintuna;Idil Ozdamar;Arash Ajoudani;Doganay Sirintuna;Idil Ozdamar;Arash Ajoudani",
        "authorids": "/37088505677;/37088339091;/37945239900;/37088505677;/37088339091;/37945239900",
        "aff": "Dept. of Informatics, Bioengineering, Robotics, and System Engineering, University of Genoa, Genoa, Italy; Dept. of Informatics, Bioengineering, Robotics, and System Engineering, University of Genoa, Genoa, Italy; Human-Robot Interfaces and Interaction Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160677/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16308379800454574415&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Genoa;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dept. of Informatics, Bioengineering, Robotics, and System Engineering;Human-Robot Interfaces and Interaction Laboratory",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": "UniGe;IIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161193",
        "title": "Category-Level Global Camera Pose Estimation with Multi-Hypothesis Point Cloud Correspondences",
        "track": "main",
        "status": "Poster",
        "abstract": "Correspondence search is an essential step in rigid point cloud registration algorithms. Most methods maintain a single correspondence at each step and gradually remove wrong correspondances. However, building one-to-one correspondence with hard assignments is extremely difficult, especially when matching two point clouds with many locally similar features. This paper proposes an optimization method that retains all possible correspondences for each keypoint when matching a partial point cloud to a complete point cloud. These uncertain correspondences are then gradually updated with the estimated rigid transformation by considering the matching cost. More-over, we propose a new point feature descriptor that measures the similarity between local point cloud regions. Extensive experiments show that our method outperforms the state-of-the-art (SoTA) methods even when matching different objects within the same category. Notably, our method outperforms the SoTA methods when registering real-world noisy depth images to a template shape by up to 20% performance.",
        "primary_area": "",
        "author": "Jun\u2013Jee Chao;Selim Engin;Nicolai H\u00e4ni;Volkan Isler;Jun\u2013Jee Chao;Selim Engin;Nicolai H\u00e4ni;Volkan Isler",
        "authorids": "/37089893089;/37086938133;/37086198436;/37298487800;/37089893089;/37086938133;/37086198436;/37298487800",
        "aff": "Department of Computer Science, University of Minnesota, USA; Department of Computer Science, University of Minnesota, USA; Department of Computer Science, University of Minnesota, USA; Department of Computer Science, University of Minnesota, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161193/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15149715588441989954&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.minnesota.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161221",
        "title": "Category-level Shape Estimation for Densely Cluttered Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately estimating the shape of objects in dense clutters makes important contribution to robotic packing, because the optimal object arrangement requires the robot planner to acquire shape information of all existed objects. However, the objects for packing are usually piled in dense clutters with severe occlusion, and the object shape varies significantly across different instances for the same category. They respectively cause large object segmentation errors and inaccurate shape recovery on unseen instances, which both degrade the performance of shape estimation during deployment. In this paper, we propose a category-level shape estimation method for densely cluttered objects. Our framework partitions each object in the clutter via the multi-view visual information fusion to achieve high segmentation accuracy, and the instance shape is recovered by deforming the category templates with diverse geometric transformations to obtain strengthened generalization ability. Specifically, we first collect the multi-view RGB-D images of the object clutters for point cloud reconstruction. Then we fuse the feature maps representing the visual information of multi-view RGB images and the pixel affinity learned from the clutter point cloud, where the acquired instance segmentation masks of multi-view RGB images are projected to partition the clutter point cloud. Finally, the instance geometry information is obtained from the partially observed instance point cloud and the corresponding category template, and the deformation parameters regarding the template are predicted for shape estimation. Experiments in the simulated environment and real world show that our method achieves high shape estimation accuracy for densely cluttered everyday objects with various shapes.",
        "primary_area": "",
        "author": "Zhenyu Wu;Ziwei Wang;Jiwen Lu;Haibin Yan;Zhenyu Wu;Ziwei Wang;Jiwen Lu;Haibin Yan",
        "authorids": "/37597233600;/37086179280;/37404390100;/37958629300;/37597233600;/37086179280;/37404390100;/37958629300",
        "aff": "School of Automation, Beijing University of Posts and Telecommunications, Beijing, China; Department of Automation, Tsinghua University, and Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; Department of Automation, Tsinghua University, and Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; School of Automation, Beijing University of Posts and Telecommunications, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161221/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9332736753062875669&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Beijing University of Posts and Telecommunications;Tsinghua University",
        "aff_unique_dep": "School of Automation;Department of Automation",
        "aff_unique_url": "http://www.bupt.edu.cn/;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "BUPT;Tsinghua",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160311",
        "title": "Causal Inference for De-biasing Motion Estimation from Robotic Observational Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot data collected in complex real-world scenarios are often biased due to safety concerns, human preferences, and mission or platform constraints. Consequently, robot learning from such observational data poses great challenges for accurate parameter estimation. We propose a principled causal inference framework for robots to learn the parameters of a stochastic motion model using observational data. Specifically, we leverage the de-biasing functionality of the potential-outcome causal inference framework, the Inverse Propensity Weighting (IPW), and the Doubly Robust (DR) methods, to obtain a better parameter estimation of the robot's stochastic motion model. The IPW is a re-weighting approach to ensure unbiased estimation, and the DR approach further combines any two estimators to strengthen the unbiased result even if one of these estimators is biased. We then develop an approximate policy iteration algorithm using the bias-eliminated estimated state transition function. We validate our framework using both simulation and real-world experiments, and the results have revealed that the proposed causal inference-based navigation and control framework can correctly and efficiently learn the parameters from biased observational data.",
        "primary_area": "",
        "author": "Junhong Xu;Kai Yin;Jason M. Gregory;Lantao Liu;Junhong Xu;Kai Yin;Jason M. Gregory;Lantao Liu",
        "authorids": "/37089503523;/37088447981;/37086090183;/37085785167;/37089503523;/37088447981;/37086090183;/37085785167",
        "aff": "Luddy School of Informatics, Computing, and Engineering at Indiana University, Bloomington, IN, USA; Expedia Group.; U.S. Army Research Laboratory, Adelphi, MD; Luddy School of Informatics, Computing, and Engineering at Indiana University, Bloomington, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160311/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6038647258245761302&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Indiana University;Expedia Group;U.S. Army Research Laboratory",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering;;",
        "aff_unique_url": "https://www.indiana.edu;https://www.expediagroup.com;https://www.arl.army.mil",
        "aff_unique_abbr": "IU;Expedia Group;ARL",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Bloomington;;Adelphi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160960",
        "title": "Cautious Planning with Incremental Symbolic Perception: Designing Verified Reactive Driving Maneuvers",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a step towards utilizing incrementally-improving symbolic perception knowledge of the robot's surroundings for provably correct reactive control synthesis applied to an autonomous driving problem. Combining abstract models of motion control and information gathering, we show that assume-guarantee specifications (a subclass of Linear Temporal Logic) can be used to define and resolve traffic rules for cautious planning. We propose a novel representation called symbolic refinement tree for perception that captures the incremental knowledge about the environment and embodies the relationships between various symbolic perception inputs. The incremental knowledge is leveraged for synthesizing verified reactive plans for the robot. The case studies demonstrate the efficacy of the proposed approach in synthesizing control inputs even in case of partially occluded environments.",
        "primary_area": "",
        "author": "Disha Kamale;Sofie Haesaert;Cristian-Ioan Vasile;Disha Kamale;Sofie Haesaert;Cristian-Ioan Vasile",
        "authorids": "/37088526999;/37072993800;/37085532895;/37088526999;/37072993800;/37085532895",
        "aff": "Mechanical Engineering and Mechanics Department, Lehigh University, Bethlehem, PA, Israel; Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; Mechanical Engineering and Mechanics Department, Lehigh University, Bethlehem, PA, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160960/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13429344689899170054&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Lehigh University;Eindhoven University of Technology",
        "aff_unique_dep": "Mechanical Engineering and Mechanics Department;Department of Electrical Engineering",
        "aff_unique_url": "https://www.lehigh.edu;https://www.tue.nl",
        "aff_unique_abbr": "Lehigh;TU/e",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Bethlehem;Eindhoven",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Netherlands"
    },
    {
        "id": "10160616",
        "title": "Center Feature Fusion: Selective Multi-Sensor Fusion of Center-based Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Leveraging multi-modal fusion, especially between camera and LiDAR, has become essential for building accurate and robust 3D object detection systems for autonomous vehicles. Until recently, point decorating approaches, in which point clouds are augmented with camera features, have been the dominant approach in the field. However, these approaches fail to utilize the higher resolution images from cameras. Recent works projecting camera features to the bird's-eye-view (BEV) space for fusion have also been proposed, however they require projecting millions of pixels, most of which only contain background information. In this work, we propose a novel approach Center Feature Fusion (CFF), in which we leverage center-based detection networks in both the camera and LiDAR streams to identify relevant object locations. We then use the center-based detection to identify the locations of pixel features relevant to object locations, a small fraction of the total number in the image. These are then projected and fused in the BEV frame. On the nuScenes dataset, we outperform the LiDAR-only baseline by 4.9% mAP while fusing up to 100x fewer features than other fusion methods.",
        "primary_area": "",
        "author": "Philip Jacobson;Yiyang Zhou;Wei Zhan;Masayoshi Tomizuka;Ming C. Wu;Philip Jacobson;Yiyang Zhou;Wei Zhan;Masayoshi Tomizuka;Ming C. Wu",
        "authorids": "/37089273378;/37088504087;/37067099600;/37281933000;/37277236100;/37089273378;/37088504087;/37067099600;/37281933000;/37277236100",
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160616/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4350870423042251460&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161508",
        "title": "CenterLineDet: CenterLine Graph Detection for Road Lanes with Vehicle-mounted Sensors by Transformer for HD Map Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "With the fast development of autonomous driving technologies, there is an increasing demand for high-definition (HD) maps, which provide reliable and robust prior information about the static part of the traffic environments. As one of the important elements in HD maps, road lane centerline is critical for downstream tasks, such as prediction and planning. Manually annotating centerlines for road lanes in HD maps is labor-intensive, expensive and inefficient, severely restricting the wide applications of autonomous driving systems. Previous work seldom explores the lane centerline detection problem due to the complicated topology and severe overlapping issues of lane centerlines. In this paper, we propose a novel method named CenterLineDet to detect lane centerlines for automatic HD map generation. Our CenterLineDet is trained by imitation learning and can effectively detect the graph of centerlines with vehicle-mounted sensors (i.e., six cameras and one LiDAR) through iterations. Due to the use of the DETR-like transformer network, CenterLineDet can handle complicated graph topology, such as lane intersections. The proposed approach is evaluated on the large-scale public dataset NuScenes. The superiority of our CenterLineDet is demonstrated by the comparative results. Our code, supplementary materials, and video demonstrations are available at https://tonyxuqaq.github.io/projects/CenterLineDet/.",
        "primary_area": "",
        "author": "Zhenhua Xu;Yuxuan Liu;Yuxiang Sun;Ming Liu;Lujia Wang;Zhenhua Xu;Yuxuan Liu;Yuxiang Sun;Ming Liu;Lujia Wang",
        "authorids": "/37088656714;/37088664461;/37085435479;/37085398677;/37406752700;/37088656714;/37088664461;/37085435479;/37085398677;/37406752700",
        "aff": "The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; The Hong Kong Polytechnic University, Kowloon, Hong Kong; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian, Shenzhen, China; The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161508/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11744907285227670129&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;The Hong Kong Polytechnic University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ust.hk;https://www.polyu.edu.hk",
        "aff_unique_abbr": "HKUST;PolyU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160486",
        "title": "Cerberus: Low-Drift Visual-Inertial-Leg Odometry For Agile Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an open-source Visual-Inertial-Leg Odometry (VILO) state estimation solution for legged robots, called Cerberus, which precisely estimates position on various terrains in real-time using a set of standard sensors, including stereo cameras, IMU, joint encoders, and contact sensors. In addition to estimating robot states, we perform online kinematic parameter calibration and outlier rejection to substantially reduce position drift. Hardware experiments in various indoor and outdoor environments validate that online calibration of kinematic parameters can reduce estimation drift to less than 1% during long-distance, high-speed locomotion. Our drift results are better than those of any other state estimation method using the same set of sensors reported in the literature. Moreover, our state estimator performs well even when the robot experiences large impacts and camera occlusion. The implementation of the state estimator, along with the datasets used to compute our results, is available at https://github.com/ShuoYangRobotics/Cerberus.",
        "primary_area": "",
        "author": "Shuo Yang;Zixin Zhang;Zhengyu Fu;Zachary Manchester;Shuo Yang;Zixin Zhang;Zhengyu Fu;Zachary Manchester",
        "authorids": "/37088996427;/37089893190;/37089894911;/37086011525;/37088996427;/37089893190;/37089894911;/37086011525",
        "aff": "Department of Mechanical Engineering, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160486/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13900273070717274487&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160940",
        "title": "Chance-Constrained Motion Planning with Event-Triggered Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of motion and communication planning under uncertainty with limited information from a remote sensor network. Because the remote sensors are power and bandwidth limited, we use event-triggered (ET) estimation to manage communication costs. We introduce a fast and efficient sampling-based planner which computes motion plans coupled with ET communication strategies that minimize communication costs, while satisfying constraints on the probability of reaching the goal region and the point-wise probability of collision. We derive a novel method for offline propagation of the expected state distribution, and corresponding bounds on this distribution. These bounds are used to evaluate the chance constraints in the algorithm. Case studies establish the validity of our approach and demonstrate computational efficiency and asymptotic optimality of the planner.",
        "primary_area": "",
        "author": "Anne Theurkauf;Qi Heng Ho;Roland Ilyes;Nisar Ahmed;Morteza Lahijanian;Anne Theurkauf;Qi Heng Ho;Roland Ilyes;Nisar Ahmed;Morteza Lahijanian",
        "authorids": "/37089678649;/37087321977;/37089678587;/37533152500;/37398443600;/37089678649;/37087321977;/37089678587;/37533152500;/37398443600",
        "aff": "Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160940/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8956102066760119874&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161396",
        "title": "Characterisation of Antagonistically Actuated, Stiffness-Controllable Joint-Link Units for Cobots",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotic structures may play a major role in the 4th industrial revolution. Researchers have successfully demonstrated the advantages of soft robotics over traditional robots made of rigid links and joints in many application areas. Variable stiffness links (VSL) and joints (VSJ) have been investigated to achieve on-demand forces and, at the same time, be inherently safe in interactions with humans. However, a thorough characterisation of soft and rigid robotic components is still required. This paper investigates the influence of antagonistically actuated, stiffness-controllable joint-link units (JLUs) on the performance of collaborative robots (i.e. stiffness, load capacity, repetitive precision) and characterizes the difference compared with rigid units. A JLU is made of a combination of a VSL, a VSJ, and their rigid counterparts. Experimental results show that the VSL has minor differences in terms of stiffness (0.62 \u223c 0.95), output force (0.93 \u223c 0.94), and repetitive precision compared with the rigid link. For the VSJ, our results show a significant gap compared with the servo motor with regards to maximum stiffness (0.14 \u223c 0.21) and repetitive position precision (0.07 \u223c 0.25). However, similar performance on repetitive force precision and better performance on the maximum output force (1.54 \u223c 1.55 times) are demonstrated.",
        "primary_area": "",
        "author": "Wenlong Gaozhang;Jialei Shi;Yue Li;Agostino Stilli;Helge Wurdemann;Wenlong Gaozhang;Jialei Shi;Yue Li;Agostino Stilli;Helge Wurdemann",
        "authorids": "/37089372538;/37088996767;/37089295976;/37085447649;/37991827000;/37089372538;/37088996767;/37089295976;/37085447649;/37991827000",
        "aff": "Department of Mechanical Engineering, University College London, UK; Department of Mechanical Engineering, University College London, UK; School of Biomedical Engineering & Imaging Sciences (BMEIS), King's College, London, UK; Department of Medical Physics and Biomedical Engineering, University College London, UK; Department of Mechanical Engineering, University College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161396/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3259823821217975677&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University College London;King's College London",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Biomedical Engineering & Imaging Sciences",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.kcl.ac.uk",
        "aff_unique_abbr": "UCL;KCL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161434",
        "title": "Chronos and CRS: Design of a miniature car-like robot and a software framework for single and multi-agent robotics and control",
        "track": "main",
        "status": "Poster",
        "abstract": "From both an educational and research point of view, experiments on hardware are a key aspect of robotics and control. In the last decade, many open-source hardware and software frameworks for wheeled robots have been presented, mainly in the form of unicycles and car-like robots, with the goal of making robotics accessible to a wider audience and to support control systems development. Unicycles are usually small and inexpensive, and therefore facilitate experiments in a larger fleet, but they are not suited for high-speed motion. Car-like robots are more agile, but they are usually larger and more expensive, thus requiring more resources in terms of space and money. In order to bridge this gap, we present Chronos, a new car-like 1/28th scale robot with customized open-source electronics, and CRS, an open-source software framework for control and robotics. The CRS software framework includes the implementation of various state-of-the-art algorithms for control, estimation, and multi-agent coordination. With this work, we aim to provide easier access to hardware and reduce the engineering time needed to start new educational and research projects.",
        "primary_area": "",
        "author": "Andrea Carron;Sabrina Bodmer;Lukas Vogel;Ren\u00e9 Zurbr\u00fcgg;David Helm;Rahel Rickenbach;Simon Muntwiler;Jerome Sieber;Melanie N. Zeilinger;Andrea Carron;Sabrina Bodmer;Lukas Vogel;Ren\u00e9 Zurbr\u00fcgg;David Helm;Rahel Rickenbach;Simon Muntwiler;Jerome Sieber;Melanie N. Zeilinger",
        "authorids": "/38547450500;/37089892576;/37089405586;/37089455679;/37089893039;/37089893627;/37089228591;/37088902751;/37398798800;/38547450500;/37089892576;/37089405586;/37089455679;/37089893039;/37089893627;/37089228591;/37088902751;/37398798800",
        "aff": "Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161434/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2702372725463548535&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute of Dynamic Systems and Control",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161546",
        "title": "Cloth Funnels: Canonicalized-Alignment for Multi-Purpose Garment Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Automating garment manipulation is challenging due to extremely high variability in object configurations. To reduce this intrinsic variation, we introduce the task of \u201ccanonicalized-alignment\u201d that simplifies downstream applications by reducing the possible garment configurations. This task can be considered as \u201ccloth state funnel\u201d that manipulates arbitrarily configured clothing items into a predefined deformable configuration (i.e. canonicalization) at an appropriate rigid pose (i.e. alignment). In the end, the cloth items will result in a compact set of structured and highly visible configurations - which are desirable for downstream manipulation skills. To enable this task, we propose a novel canonicalized-alignment objective that effectively guides learning to avoid adverse local minima during learning. Using this objective, we learn a multi-arm, multi-primitive policy that strategically chooses between dynamic flings and quasi-static pick and place actions to achieve efficient canonicalized-alignment. We evaluate this approach on a real-world ironing and folding system that relies on this learned policy as the common first step. Empirically, we demonstrate that our task-agnostic canonicalized-alignment can enable even simple manually -designed policies to work well where they were pre-viously inadequate, thus bridging the gap between automated non-deformable manufacturing and deformable manipulation.",
        "primary_area": "",
        "author": "Alper Canberk;Cheng Chi;Huy Ha;Benjamin Burchfiel;Eric Cousineau;Siyuan Feng;Shuran Song;Alper Canberk;Cheng Chi;Huy Ha;Benjamin Burchfiel;Eric Cousineau;Siyuan Feng;Shuran Song",
        "authorids": "/37088997829;/37089314569;/37089893430;/37086580390;/37085493778;/37089892613;/37085613509;/37088997829;/37089314569;/37089893430;/37086580390;/37085493778;/37089892613;/37085613509",
        "aff": "Columbia University; Columbia University; Columbia University; Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; Columbia University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161546/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8939830990706412392&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;0",
        "aff_unique_norm": "Columbia University;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.columbia.edu;https://www.tri.global",
        "aff_unique_abbr": "Columbia;TRI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160268",
        "title": "Clothes Grasping and Unfolding Based on RGB-D Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Clothes grasping and unfolding is a core step in robotic-assisted dressing. Most existing works leverage depth images of clothes to train a deep learning-based model to recognize suitable grasping points. These methods often utilize physics engines to synthesize depth images to reduce the cost of real labeled data collection. However, the natural domain gap between synthetic and real images often leads to poor performance of these methods on real data. Furthermore, these approaches often struggle in scenarios where grasping points are occluded by the clothing item itself. To address the above challenges, we propose a novel Bi-directional Fractal Cross Fusion Network (BiFCNet) for semantic segmentation, enabling recognition of graspable regions in order to provide more possibilities for grasping. Instead of using depth images only, we also utilize RGB images with rich color features as input to our network in which the Fractal Cross Fusion (FCF) module fuses RGB and depth data by considering global complex features based on fractal geometry. To reduce the cost of real data collection, we further propose a data augmentation method based on an adversarial strategy, in which the color and geometric transformations simultaneously process RGB and depth data while maintaining the label correspondence. Finally, we present a pipeline for clothes grasping and unfolding from the perspective of semantic segmentation, through the addition of a strategy for grasp point selection from segmentation regions based on clothing flatness measures, while taking into account the grasping direction. We evaluate our BiFCNet on the public dataset NYUDv2 and obtained comparable performance to current state-of-the-art models. We also deploy our model on a Baxter robot, running extensive grasping and unfolding experiments as part of our ablation studies, achieving an 84% success rate.",
        "primary_area": "",
        "author": "Xingyu Zhu;Xin Wang;Jonathan Freer;Hyung Jin Chang;Yixing Gao;Xingyu Zhu;Xin Wang;Jonathan Freer;Hyung Jin Chang;Yixing Gao",
        "authorids": "/37089893295;/37089920237;/37089300175;/37293111600;/37086207679;/37089893295;/37089920237;/37089300175;/37293111600;/37086207679",
        "aff": "Engineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China; Engineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China; School of Computer Science, University of Birmingham, UK; School of Computer Science, University of Birmingham, UK; Engineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160268/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15502782318256982419&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Engineering Research Center of Knowledge-Driven Human-Machine Intelligence;University of Birmingham",
        "aff_unique_dep": "Ministry of Education;School of Computer Science",
        "aff_unique_url": ";https://www.birmingham.ac.uk",
        "aff_unique_abbr": ";UoB",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Birmingham",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10160623",
        "title": "CoGrasp: 6-DoF Grasp Generation for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot grasping is an actively studied area in robotics, mainly focusing on the quality of generated grasps for object manipulation. However, despite advancements, these methods do not consider the human-robot collaboration settings where robots and humans will have to grasp the same objects concurrently. Therefore, generating robot grasps compatible with human preferences of simultaneously holding an object becomes necessary to ensure a safe and natural collaboration experience. In this paper, we propose a novel, deep neural network-based method called CoGrasp that generates human-aware robot grasps by contextualizing human preference mod-els of object grasping into the robot grasp selection pro-cess. We validate our approach against existing state-of-the-art robot grasping methods through simulated and real-robot experiments and user studies. In real robot experiments, our method achieves about 88% success rate in producing stable grasps that also allow humans to interact and grasp objects simultaneously in a socially compliant manner. Furthermore, our user study with 10 independent participants indicated our approach enables a safe, natural, and socially-aware human-robot objects' co-grasping experience compared to a standard robot grasping technique.",
        "primary_area": "",
        "author": "Abhinav K. Keshari;Hanwen Ren;Ahmed H. Qureshi;Abhinav K. Keshari;Hanwen Ren;Ahmed H. Qureshi",
        "authorids": "/37089892205;/37089896070;/37086070898;/37089892205;/37089896070;/37086070898",
        "aff": "Purdue University; Purdue University; Purdue University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160623/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5631680051390321093&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161141",
        "title": "Coarse-to-Fine Point Cloud Registration with SE(3)-Equivariant Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Point cloud registration is a crucial problem in computer vision and robotics. Existing methods either rely on matching local geometric features, which are sensitive to the pose differences, or leverage global shapes, which leads to inconsistency when facing distribution variances such as partial overlapping. Combining the advantages of both types of methods, we adopt a coarse-to-fine pipeline that concurrently handles both issues. We first reduce the pose differences between input point clouds by aligning global features; then we match the local features to further refine the inaccurate alignments resulting from distribution variances. As global feature alignment requires the features to preserve the poses of input point clouds and local feature matching expects the features to be invariant to these poses, we propose an SE(3)-equivariant feature extractor to simultaneously generate two types of features. In this feature extractor, representations that preserve the poses are first encoded by our novel SE(3)-equivariant network and then converted into pose-invariant ones by a pose-detaching module. Experiments demonstrate that our proposed method increases the recall rate by 20% compared to state-of-the-art methods when facing both pose differences and distribution variances.",
        "primary_area": "",
        "author": "Cheng-Wei Lin;Tung-I Chen;Hsin-Ying Lee;Wen-Chin Chen;Winston H. Hsu;Cheng-Wei Lin;Tung-I Chen;Hsin-Ying Lee;Wen-Chin Chen;Winston H. Hsu",
        "authorids": "/37090058392;/37089195262;/37089613229;/37088230745;/37272584600;/37090058392;/37089195262;/37089613229;/37088230745;/37272584600",
        "aff": "National Taiwan University; National Taiwan University; National Taiwan University; National Taiwan University; Mobile Drive Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161141/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1504071606312503565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "National Taiwan University;Mobile Drive Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ntu.edu.tw;",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "10161064",
        "title": "Coaxial Modular Aerial System and the Reconfiguration Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a coaxial modular aerial system (CMAS) formed by homogeneous modules driven by their center of mass. CMAS is designed to perform independent and cooperative flight with or without payload. Properties of the modularity concept allow the system to adapt to different situations and/or tasks by adding/removing modules to/from a configuration. The CMAS module is based on a coaxial motor and a two degree-of-freedom mechanism that transfers its center of mass from one side to another to make the module navigate around. The magnetic-based connector mechanism allows the module to be attached to other modules and to different metallic surfaces. A decentralized and asynchronous 3D path planning algorithm is implemented to avoid the trajectories of other modules/obstacles and ensures safe reconfiguration of the modules. Simulations within various environments show the applicability of the reconfiguration algorithm.",
        "primary_area": "",
        "author": "Jos\u00e9 Baca;Syed Izzat Ullah;Pablo Rangel;Jos\u00e9 Baca;Syed Izzat Ullah;Pablo Rangel",
        "authorids": "/37592344100;/37088880311;/443550242963949;/37592344100;/37088880311;/443550242963949",
        "aff": "Department of Engineering, College of Engineering, Texas A&M University, Corpus Christi, TX, USA; College of Engineering, Texas A&M University, Corpus Christi, TX, USA; Department of Engineering, College of Engineering, Texas A&M University, Corpus Christi, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161064/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16651647553659242708&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Engineering",
        "aff_unique_url": "https://www.tamucc.edu",
        "aff_unique_abbr": "TAMU-CC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corpus Christi",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160591",
        "title": "Code as Policies: Language Model Programs for Embodied Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Large language models (LLMs) trained on code-completion have been shown to be capable of synthesizing simple Python programs from docstrings [1]. We find that these code-writing LLMs can be re-purposed to write robot policy code, given natural language commands. Specifically, policy code can express functions or feedback loops that process perception outputs (e.g., from object detectors [2], [3]) and parameterize control primitive APIs. When provided as input several example language commands (formatted as comments) followed by corresponding policy code (via few-shot prompting), LLMs can take in new commands and autonomously re-compose API calls to generate new policy code respectively. By chaining classic logic structures and referencing third-party libraries (e.g., NumPy, Shapely) to perform arithmetic, LLMs used in this way can write robot policies that (i) exhibit spatial-geometric reasoning, (ii) generalize to new instructions, and (iii) prescribe precise values (e.g., velocities) to ambiguous descriptions (\u2018faster\u2019) depending on context (i.e., behavioral commonsense). This paper presents Code as Policies: a robot-centric formulation of language model generated programs (LMPs) that can represent reactive policies (e.g., impedance controllers), as well as waypoint-based policies (vision-based pick and place, trajectory-based control), demonstrated across multiple real robot platforms. Central to our approach is prompting hierarchical code-gen (recursively defining undefined functions), which can write more complex code and also improves state-of-the-art to solve 39.8% of problems on the HumanEval [1] benchmark. Code and videos are available at https://code-as-policies.github.io",
        "primary_area": "",
        "author": "Jacky Liang;Wenlong Huang;Fei Xia;Peng Xu;Karol Hausman;Brian Ichter;Pete Florence;Andy Zeng;Jacky Liang;Wenlong Huang;Fei Xia;Peng Xu;Karol Hausman;Brian Ichter;Pete Florence;Andy Zeng",
        "authorids": "/37088504798;/37089893063;/37089893973;/37089895866;/37077039600;/37086034185;/37085786926;/37086217185;/37088504798;/37089893063;/37089893973;/37089895866;/37077039600;/37086034185;/37085786926;/37086217185",
        "aff": "Jacky Liang; Wenlong Huang; Fei Xia; Peng Xu; Karol Hausman; Brian Ichter; Pete Florence; Andy Zeng",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160591/",
        "gs_citation": 1040,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12996700922335668599&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Fei Xia",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10161007",
        "title": "CogniDaVinci: Towards Estimating Mental Workload Modulated by Visual Delays During Telerobotic Surgery - An EEG-based Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Communication latency in any delicate telerobotic operation (such as remote surgery over distance) would impose a significant challenge due to the temporal degradation of visual perception and can substantially affect the outcomes. Less is known, however, about the neurophysiological basis of how operators adapt/react to delayed visual feedback. Identification of such neural markers might provide novel ways for future applications to monitor the mental workload (MW). In this study, we recorded electroencephalography (EEG) data from nine users while performing a peg transfer task using the da Vinci Research Kit with three levels of induced visual delay in the video feedback. Our results suggest that spectral EEG-based features can provide markers of the operator's MW modulated by arbitrary visual delay. We also show that the exposure to different visual delays could be successfully classified/detected solely from EEG data, using a Riemannian geometry-based classifier, which highlights the utility of EEG signals for detecting the effect of visual delay on brain activity.",
        "primary_area": "",
        "author": "Satyam Kumar;Deland H. Liu;Frigyes S. Racz;Manuel Retana;Susheela Sharma;Fumiaki Iwane;Braden P. Murphy;Rory O'Keeffe;S. Farokh Atashzar;Farshid Alambeigi;Jos\u00e9 del R. Mill\u00e1n;Satyam Kumar;Deland H. Liu;Frigyes S. Racz;Manuel Retana;Susheela Sharma;Fumiaki Iwane;Braden P. Murphy;Rory O'Keeffe;S. Farokh Atashzar;Farshid Alambeigi;Jos\u00e9 del R. Mill\u00e1n",
        "authorids": "/37086602294;/37088512704;/37089840667;/37089432355;/37089849223;/37086424755;/37089895201;/37089605766;/37592440100;/38542997100;/37085491499;/37086602294;/37088512704;/37089840667;/37089432355;/37089849223;/37086424755;/37089895201;/37089605766;/37592440100;/38542997100;/37085491499",
        "aff": "Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Neurology, The University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, Texas Robotics, The University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, Texas Robotics, The University of Texas at Austin, Austin, TX, USA; Department of Neurology, The University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, Texas Robotics, The University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering and Department of Mechanical and Aerospace Engineering, New York University, NY, USA; Department of Electrical and Computer Engineering and Department of Mechanical and Aerospace Engineering, New York University, NY, USA; Walker Department of Mechanical Engineering, Texas Robotics, The University of Texas at Austin, Austin, TX, USA; Department of Neurology, The University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161007/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10854151668944455295&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;1;1;0;0",
        "aff_unique_norm": "The University of Texas at Austin;New York University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.utexas.edu;https://www.nyu.edu",
        "aff_unique_abbr": "UT Austin;NYU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;1;1;0;0",
        "aff_campus_unique": "Austin;NY",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161414",
        "title": "Collaborative Control Based on Payload- leading for the Multi-quadrotor Transportation Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a collaborative control method based on payload-leading for the multi-quadrotor transportation systems. The goal is to keep the relative distance between the quadrotors and the payload as constant as possible during the transportation, so as to ensure the stable attitude of the payload. The control mechanism consists of a guidance control law that generates the common desired velocity for the quadrotors, an internal feedback controller for each quadrotor, and a decentralized formation controller. The stability of the control structure is proved by Lyapunov theory. Finally, the experimental platform of the multi-quadrotor transportation system is built to verify the effectiveness of the control method. Experimental results show that the proposed method has an excellent control effect.",
        "primary_area": "",
        "author": "Yuan Ping;Mingming Wang;Juntong Qi;Chong Wu;Jinjin Guo;Yuan Ping;Mingming Wang;Juntong Qi;Chong Wu;Jinjin Guo",
        "authorids": "/37089937784;/37088497193;/37286763500;/37087047216;/37088498108;/37089937784;/37088497193;/37286763500;/37087047216;/37088498108",
        "aff": "School of Electrical and Information Engineering, Tianjin University, Tianjin, CHN; School of Electrical and Information Engineering, Tianjin University, Tianjin, CHN; Institute of Artificial Intelligence, Shanghai University, Shanghai, CHN; EFY Intelligent Control (Tianjin) Technology Co., Ltd, Tianjin, CHN; School of Electrical and Information Engineering, Tianjin University, Tianjin, CHN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161414/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1465987330391357374&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Tianjin University;Shanghai University;EFY Intelligent Control (Tianjin) Technology Co., Ltd",
        "aff_unique_dep": "School of Electrical and Information Engineering;Institute of Artificial Intelligence;",
        "aff_unique_url": "http://www.tju.edu.cn;https://www.shu.edu.cn;",
        "aff_unique_abbr": "Tianjin University;SHU;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Tianjin;Shanghai;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161377",
        "title": "Collaborative Robotic Biopsy with Trajectory Guidance and Needle Tip Force Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "The diagnostic value of biopsies is highly dependent on the placement of needles. Robotic trajectory guidance has been shown to improve needle positioning, but feedback for real-time navigation is limited. Haptic display of needle tip forces can provide rich feedback for needle navigation by enabling localization of tissue structures along the insertion path. We present a collaborative robotic biopsy system that combines trajectory guidance with kinesthetic feedback to assist the physician in needle placement. The robot aligns the needle while the insertion is performed in collaboration with a medical expert who controls the needle position on site. We present a needle design that senses forces at the needle tip based on optical coherence tomography and machine learning for real-time data processing. Our robotic setup allows operators to sense deep tissue interfaces independent of frictional forces to improve needle placement relative to a desired target structure. We first evaluate needle tip force sensing in ex-vivo tissue in a phantom study. We characterize the tip forces during insertions with constant velocity and demonstrate the ability to detect tissue interfaces in a collaborative user study. Participants are able to detect 91 percent of ex-vivo tissue interfaces based on needle tip force feedback alone. Finally, we demonstrate that even smaller, deep target structures can be accurately sampled by performing post-mortem in situ biopsies of the pancreas.",
        "primary_area": "",
        "author": "Robin Mieling;Maximilian Neidhardt;Sarah Latus;Carolin Stapper;Stefan Gerlach;Inga Kniep;Axel Heinemann;Benjamin Ondruschka;Alexander Schlaefer;Robin Mieling;Maximilian Neidhardt;Sarah Latus;Carolin Stapper;Stefan Gerlach;Inga Kniep;Axel Heinemann;Benjamin Ondruschka;Alexander Schlaefer",
        "authorids": "/37089306055;/37087027018;/37086123026;/37089894640;/37089307201;/37089307399;/37088970267;/37089305843;/37542342300;/37089306055;/37087027018;/37086123026;/37089894640;/37089307201;/37089307399;/37088970267;/37089305843;/37542342300",
        "aff": "Institute of Medical Technology and Intelligent Systems, Hamburg University of Technology, Hamburg, Germany; Institute of Medical Technology and Intelligent Systems, Hamburg University of Technology, Hamburg, Germany; Institute of Medical Technology and Intelligent Systems, Hamburg University of Technology, Hamburg, Germany; Institute of Medical Technology and Intelligent Systems, Hamburg University of Technology, Hamburg, Germany; Institute of Medical Technology and Intelligent Systems, Hamburg University of Technology, Hamburg, Germany; Institute of Legal Medicine, University Medical Center Hamburg-Eppendorf, Hamburg, Germany; Institute of Legal Medicine, University Medical Center Hamburg-Eppendorf, Hamburg, Germany; Institute of Legal Medicine, University Medical Center Hamburg-Eppendorf, Hamburg, Germany; Institute of Medical Technology and Intelligent Systems, Hamburg University of Technology, Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161377/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10719280348656329221&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;1;1;0",
        "aff_unique_norm": "Hamburg University of Technology;University Medical Center Hamburg-Eppendorf",
        "aff_unique_dep": "Institute of Medical Technology and Intelligent Systems;Institute of Legal Medicine",
        "aff_unique_url": "https://www.tuhh.de/;https://www.uke.de",
        "aff_unique_abbr": "TUHH;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hamburg",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161502",
        "title": "Collaborative Scheduling with Adaptation to Failure for Heterogeneous Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative scheduling is an essential ability for a team of heterogeneous robots to collaboratively complete complex tasks, e.g., in a multi-robot assembly application. To enable collaborative scheduling, two key problems should be addressed, including allocating tasks to heterogeneous robots and adapting to robot failures in order to guarantee the completion of all tasks. In this paper, we introduce a novel approach that integrates deep bipartite graph matching and imitation learning for heterogeneous robots to complete complex tasks as a team. Specifically, we use a graph attention network to represent attributes and relationships of the tasks. Then, we formulate collaborative scheduling with failure adaptation as a new deep learning-based bipartite graph matching problem, which learns a policy by imitation to determine task scheduling based on the reward of potential task schedules. During normal execution, our approach generates robot-task pairs as potential allocations. When a robot fails, our approach identifies not only individual robots but also subteams to replace the failed robot. We conduct extensive experiments to evaluate our approach in the scenarios of collaborative scheduling with robot failures. Experimental results show that our approach achieves promising, generalizable and scalable results on collaborative scheduling with robot failure adaptation.",
        "primary_area": "",
        "author": "Peng Gao;Sriram Siva;Anthony Micciche;Hao Zhang;Peng Gao;Sriram Siva;Anthony Micciche;Hao Zhang",
        "authorids": "/37089501844;/37086453331;/37089895640;/37085545929;/37089501844;/37086453331;/37089895640;/37085545929",
        "aff": "Department of Computer Science, University of Maryland, College Park, MD, USA; Department of Computer Science, Colorado School of Mines, Golden, CO, USA; Manning College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA; Manning College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161502/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3145259855268797823&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "University of Maryland;Colorado School of Mines;University of Massachusetts Amherst",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;Manning College of Information and Computer Sciences",
        "aff_unique_url": "https://www/umd.edu;https://www.mines.edu;https://www.umass.edu",
        "aff_unique_abbr": "UMD;CSM;UMass Amherst",
        "aff_campus_unique_index": "0;1;2;2",
        "aff_campus_unique": "College Park;Golden;Amherst",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160661",
        "title": "Collision Detection and Contact Point Estimation Using Virtual Joint Torque Sensing Applied to a Cobot",
        "track": "main",
        "status": "Poster",
        "abstract": "In physical human-robot interaction (pHRI) it is essential to reliably estimate and localize contact forces between the robot and the environment. In this paper, a complete contact detection, isolation, and reaction scheme is presented and tested on a new 6-dof industrial collaborative robot. We combine two popular methods, based on monitoring energy and generalized momentum, to detect and isolate collisions on the whole robot body in a more robust way. The experimental results show the effectiveness of our implementation on the LARA 5 cobot, that only relies on motor current and joint encoder measurements. For validation purposes, contact forces are also measured using an external GTE CoboSafe sensor. After a successful collision detection, the contact point location is isolated using a combination of the residual method based on the generalized momentum with a contact particle filter (CPF) scheme. We show for the first time a successful implementation of such combination on a real robot, without relying on joint torque sensor measurements.",
        "primary_area": "",
        "author": "Dario Zurlo;Tom Heitmann;Merlin Morlock;Alessandro De Luca;Dario Zurlo;Tom Heitmann;Merlin Morlock;Alessandro De Luca",
        "authorids": "/37089894731;/37089893650;/37085681461;/37269180600;/37089894731;/37089893650;/37085681461;/37269180600",
        "aff": "Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universit\u00e0 di Roma, Rome, Italy; NEURA Robotics GmbH, Metzingen, Germany; NEURA Robotics GmbH, Metzingen, Germany; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universit\u00e0 di Roma, Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160661/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2919098517150403486&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Sapienza Universit\u00e0 di Roma;NEURA Robotics GmbH",
        "aff_unique_dep": "Dipartimento di Ingegneria Informatica, Automatica e Gestionale;",
        "aff_unique_url": "https://www.uniroma1.it;",
        "aff_unique_abbr": "Sapienza;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Rome;",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "10160359",
        "title": "Collision-aware In-hand 6D Object Pose Estimation using Multiple Vision-based Tactile Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the problem of estimating the in-hand 6D pose of an object in contact with multiple vision-based tactile sensors. We reason on the possible spatial configurations of the sensors along the object surface. Specifically, we filter contact hypotheses using geometric reasoning and a Convolutional Neural Network (CNN), trained on simulated object-agnostic images, to promote those that better comply with the actual tactile images from the sensors. We use the selected sensors configurations to optimize over the space of 6D poses using a Gradient Descent-based approach. We finally rank the obtained poses by penalizing those that are in collision with the sensors. We carry out experiments in simulation using the DIGIT vision-based sensor with several objects, from the standard YCB model set. The results demonstrate that our approach estimates object poses that are compatible with actual object-sensor contacts in 87.5% of cases while reaching an average positional error in the order of 2 centimeters. Our analysis also includes qualitative results of experiments with a real DIGIT sensor.",
        "primary_area": "",
        "author": "Gabriele M. Caddeo;Nicola A. Piga;Fabrizio Bottarel;Lorenzo Natale;Gabriele M. Caddeo;Nicola A. Piga;Fabrizio Bottarel;Lorenzo Natale",
        "authorids": "/37089894768;/37088341326;/37086601105;/37542770000;/37089894768;/37088341326;/37086601105;/37542770000",
        "aff": "DIBRIS, Universit\u00e0 di Genova, Genoa, Italy; Humanoid Sensing and Perception, Istituto Italiano di Tecnologia, Genoa, Italy; Humanoid Sensing and Perception, Istituto Italiano di Tecnologia, Genoa, Italy; Humanoid Sensing and Perception, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160359/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7149759488209059035&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Universit\u00e0 di Genova;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "DIBRIS;Humanoid Sensing and Perception",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": ";IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10160621",
        "title": "Collision-free Coverage Path Planning for the Variable-speed Curvature-constrained Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Dubins coverage has been extensively researched to address the coverage path planning (CPP) problem of a known environment for the curvature-constrained robot. However, its fixed-speed assumption prevents the robot from accelerating to reduce the time and limits its flexibility to avoid obstacles. Therefore, this paper presents a collision-free CPP approach (CFC) for the obstacle-constrained environment, which enhances time efficiency by constructing the variable-speed Dubins paths and ensures robot safety by building a risk potential surface for representing the possibility of collision. Furthermore, CFC models the CPP problem as an asymmetric traveling salesman problem (ATSP) and utilizes a graph pruning strategy to reduce the computational cost. Comparison tests with other Dubins coverage methods demonstrate that CFC provides shorter coverage times and better runtimes than the other Dubins coverage methods while preventing collision risk between the robot and obstacles. Physical experiments in a laboratory setting demonstrate the applicability of CFC to the physical robot.",
        "primary_area": "",
        "author": "Lin Li;Dianxi Shi;Songchang Jin;Yixuan Sun;Xing Zhou;Shaowu Yang;Hengzhu Liu;Lin Li;Dianxi Shi;Songchang Jin;Yixuan Sun;Xing Zhou;Shaowu Yang;Hengzhu Liu",
        "authorids": "/37088699622;/37401070600;/37088362311;/37089892386;/37085540568;/37085409104;/37405272000;/37088699622;/37401070600;/37088362311;/37089892386;/37085540568;/37085409104;/37405272000",
        "aff": "Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China; Artificial Intelligence Research Center (AIRC), Defense Innovation Institute, Beijing, China; Artificial Intelligence Research Center (AIRC), Defense Innovation Institute, Beijing, China; College of Computer, National University of Defense Technology, Changsha, Hunan, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, Hunan, China; College of Computer, National University of Defense Technology, Changsha, Hunan, China; College of Computer, National University of Defense Technology, Changsha, Hunan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160621/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6801081969587307518&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;2;2;2;2",
        "aff_unique_norm": "Tianjin Artificial Intelligence Innovation Center;Defense Innovation Institute;National University of Defense Technology",
        "aff_unique_dep": ";Artificial Intelligence Research Center (AIRC);College of Computer",
        "aff_unique_url": ";;",
        "aff_unique_abbr": "TAIIC;;",
        "aff_campus_unique_index": "0;1;1;2;2;2;2",
        "aff_campus_unique": "Tianjin;Beijing;Changsha",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160908",
        "title": "Combining Motion and Appearance for Robust Probabilistic Object Segmentation in Real Time",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a robust method to visually segment scenes into objects based on motion and appearance. Both these cues provide complementary information that we fuse using two interconnected recursive estimators: One estimates object segmentation from motion as a probabilistic clustering of tracked 3D points, and the other estimates object segmentation from appearance as a probabilistic image segmentation. The interconnected estimators provide a probabilistic and consistent object segmentation in real time, which makes them well suited for many downstream robotic tasks. We evaluate our method on one such task, kinematic structure estimation, on a dataset of interactions with articulated objects and show that our fusion improves object segmentation by 70% and in turn estimated kinematic joints by 26% over a purely motion-based approach. Furthermore, we show the necessity of probabilistic modeling for downstream robotic tasks, achieving 339% of the performance of a recent multimodal but deterministic RNN for object segmentation on the estimation of kinematic structure.",
        "primary_area": "",
        "author": "Vito Mengers;Aravind Battaje;Manuel Baum;Oliver Brock;Vito Mengers;Aravind Battaje;Manuel Baum;Oliver Brock",
        "authorids": "/37089895018;/37089354195;/37085674996;/37279727100;/37089895018;/37089354195;/37085674996;/37279727100",
        "aff": "Science of Intelligence (SCIoI), Cluster of Excellence, Berlin, Germany; Science of Intelligence (SCIoI), Cluster of Excellence, Berlin, Germany; Science of Intelligence (SCIoI), Cluster of Excellence, Berlin, Germany; Science of Intelligence (SCIoI), Cluster of Excellence, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160908/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16381191737066581291&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Science of Intelligence",
        "aff_unique_dep": "Cluster of Excellence",
        "aff_unique_url": "",
        "aff_unique_abbr": "SCIoI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160317",
        "title": "Combining Scene Coordinate Regression and Absolute Pose Regression for Visual Relocalization",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual relocalization is a fundamental problem in computer vision and robotics. Recently, regression-based methods become popular and they can be categorized into two classes: absolute pose regression and scene coordinate regression. In this work, we present a combined regression network that jointly learns scene coordinate regression and absolute pose regression for single-image visual relocalization. The proposed network composes of a feature encoder and two regression branches with uncertainty modeling. In particular, we design a deep feature conditioning module, aiming at propagating the coarse pose information in absolute pose regression to inform the predictions in scene coordinate regression. The proposed network is trained in an end-to-end fashion to learn both regression tasks. Moreover, we propose an uncertainty-driven RANSAC algorithm that incorporates the predicted scene coordinates and their uncertainties to solve the camera pose during inference. To the best of our knowledge, this work is the first to combine scene coordinate regression and pose regression in a hierarchical framework for visual relocalization. Experiments on indoor and outdoor benchmarks demonstrate the effectiveness and the superiority of the proposed method over the state-of-the-art methods.",
        "primary_area": "",
        "author": "Jiahao Ruan;Li He;Yisheng Guan;Hong Zhang;Jiahao Ruan;Li He;Yisheng Guan;Hong Zhang",
        "authorids": "/37089895989;/37086300847;/37402001000;/37280789900;/37089895989;/37086300847;/37402001000;/37280789900",
        "aff": "School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Department of Electrical and Electronic Engineering, Shenzhen Key - Laboratory of Robotics and Computer Vision, Southern University of Science and Technology, Shenzhen, China; School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Department of Electrical and Electronic Engineering, Shenzhen Key - Laboratory of Robotics and Computer Vision, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160317/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14416859940901769189&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Guangdong University of Technology;Southern University of Science and Technology",
        "aff_unique_dep": "School of Electromechanical Engineering;Department of Electrical and Electronic Engineering",
        "aff_unique_url": ";https://www.sustech.edu.cn",
        "aff_unique_abbr": ";SUSTech",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Guangzhou;Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160880",
        "title": "Communication-Critical Planning via Multi-Agent Trajectory Exchange",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the task of joint multi-agent perception and planning, especially as it relates to the real-world challenge of collision-free navigation for connected self-driving vehicles. For this task, several communication-enabled vehicles must navigate through a busy intersection while avoiding collisions with each other and with obstacles. To this end, this paper proposes a learnable costmap-based planning mechanism, given raw perceptual data, that is (1) distributed, (2) uncertainty-aware, and (3) bandwidth-efficient. Our method produces a costmap and uncertainty-aware entropy map to sort and fuse candidate trajectories as evaluated across multiple-agents. The proposed method demonstrates several favorable performance trends on a suite of open-source overhead datasets as well as within a novel communication-critical simulator. It produces accurate semantic occupancy forecasts as an intermediate perception output, attaining a 72.5% average pixel-wise classification accuracy. By selecting the top trajectory, the multi-agent method scales well with the number of agents, reducing the hard collision rate by up to 57% with eight agents compared to the single-agent version.",
        "primary_area": "",
        "author": "Nathaniel Moore Glaser;Zsolt Kira;Nathaniel Moore Glaser;Zsolt Kira",
        "authorids": "/37088459369;/37681676600;/37088459369;/37681676600",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160880/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5867175066552736185&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160983",
        "title": "Comparison of Model-Based and Model-Free Reinforcement Learning for Real-World Dexterous Robotic Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Model Free Reinforcement Learning (MFRL) has shown significant promise for learning dexterous robotic manipulation tasks, at least in simulation. However, the high number of samples, as well as the long training times, prevent MFRL from scaling to complex real-world tasks. Model- Based Reinforcement Learning (MBRL) emerges as a potential solution that, in theory, can improve the data efficiency of MFRL approaches. This could drastically reduce the training time of MFRL, and increase the application of RL for real- world robotic tasks. This article presents a study on the feasibility of using the state-of-the-art MBRL to improve the training time for two real-world dexterous manipulation tasks. The evaluation is conducted on a real low-cost robot gripper where the predictive model and the control policy are learned from scratch. The results indicate that MBRL is capable of learning accurate models of the world, but does not show clear improvements in learning the control policy in the real world as prior literature suggests should be expected.",
        "primary_area": "",
        "author": "David Valencia;John Jia;Raymond Li;Alex Hayashi;Megan Lecchi;Reuel Terezakis;Trevor Gee;Minas Liarokapis;Bruce A. MacDonald;Henry Williams;David Valencia;John Jia;Raymond Li;Alex Hayashi;Megan Lecchi;Reuel Terezakis;Trevor Gee;Minas Liarokapis;Bruce A. MacDonald;Henry Williams",
        "authorids": "/37089892441;/37089895691;/37089892524;/37089892523;/37089896049;/37089893454;/37089893597;/38558084100;/37300950400;/38467483900;/37089892441;/37089895691;/37089892524;/37089892523;/37089896049;/37089893454;/37089893597;/38558084100;/37300950400;/38467483900",
        "aff": "Centre for Automation and Robotic Engineering Science, The University of Auckland, New Zealand; Centre for Automation and Robotic Engineering Science, The University of Auckland, New Zealand; Centre for Automation and Robotic Engineering Science, The University of Auckland, New Zealand; New Dexterity Research Group, The University of Auckland, New Zealand; New Dexterity Research Group, The University of Auckland, New Zealand; New Dexterity Research Group, The University of Auckland, New Zealand; Centre for Automation and Robotic Engineering Science, The University of Auckland, New Zealand; New Dexterity Research Group, The University of Auckland, New Zealand; Centre for Automation and Robotic Engineering Science, The University of Auckland, New Zealand; Centre for Automation and Robotic Engineering Science, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160983/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12765359546161705040&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "The University of Auckland",
        "aff_unique_dep": "Centre for Automation and Robotic Engineering Science",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "10160464",
        "title": "Completely Rational $\\text{SO}(n)$ Orthonormalization",
        "track": "main",
        "status": "Poster",
        "abstract": "The rotation orthonormalization on the special orthogonal group \\text{SO}(n)\\text{SO}(n), also known as the high dimensional nearest rotation problem, has been revisited. A new generalized simple iterative formula has been proposed that solves this problem in a completely rational manner. Rational operations allow for efficient implementation on various platforms and also significantly simplify the synthesis of large-scale circuitization. The developed scheme is also capable of designing efficient fundamental rational algorithms, for example, quaternion normalization, which outperforms long-exisiting solvers. Furthermore, an \\text{SO}(n)\\text{SO}(n) neural network has been developed for further learning purpose on the rotation group. Simulation results verify the effectiveness of the proposed scheme and show the superiority against existing representatives. Applications show that the proposed orthonormalizer is of potential in robotic pose estimation problems, e.g., hand-eye calibration.",
        "primary_area": "",
        "author": "Jin Wu;Soheil Sarabandi;Jianhao Jiao;Huaiyang Huang;Bohuan Xue;Ruoyu Geng;Lujia Wang;Ming Liu;Jin Wu;Soheil Sarabandi;Jianhao Jiao;Huaiyang Huang;Bohuan Xue;Ruoyu Geng;Lujia Wang;Ming Liu",
        "authorids": "/37085846883;/37086445507;/37086552343;/37087103064;/37087244661;/37089001275;/37406752700;/37085398677;/37085846883;/37086445507;/37086552343;/37087103064;/37087244661;/37089001275;/37406752700;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Research Center \u201cE.Piaggio\u201d, School of Engineering, University of Pisa, Italy; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160464/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;University of Pisa",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;School of Engineering",
        "aff_unique_url": "https://www.ust.hk;https://www.unipi.it",
        "aff_unique_abbr": "HKUST;UNipi",
        "aff_campus_unique_index": "0;0;0;0;0;0;2",
        "aff_campus_unique": "Hong Kong SAR;;Shenzhen",
        "aff_country_unique_index": "0;1;0;0;0;0;0;0",
        "aff_country_unique": "China;Italy"
    },
    {
        "id": "10160353",
        "title": "Compliant Finger Joint with Controlled Variable Stiffness based on Twisted Strings Actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "Underactuated tendon-driven fingers are a simple, yet effective solution, for realizing robotic grippers and hands. The lack of controllable degrees of actuation and precise sensing is compensated by the deformable structure of the finger, which is able to adapt to the objects to be grasped and manipulated, and also to implement grasping strategies based on environmental constraint exploitation. One of the main drawbacks of these robotic fingers is that, due to the limited number of actuators, they can only realize a limited number of movements. Finger closure motion realized by activating the tendon depends on finger mechanical properties, and in particular on elastic joint stiffness. In this paper, we introduce a passive elastic joint to be implemented in monolithic fingers in which the stiffness can be actively regulated by applying a pre-compression to the structure, controlled by a twisted-string actuator (TSA). The paper describes the working principle of the joint, investigates the relationship between pre-compression and flexural stiffness, and finally shows its application to a robotic finger composed of three phalanges.",
        "primary_area": "",
        "author": "Mihai Dragusanu;Danilo Troisi;Domenico Prattichizzo;Monica Malvezzi;Mihai Dragusanu;Danilo Troisi;Domenico Prattichizzo;Monica Malvezzi",
        "authorids": "/37086132491;/37089551790;/37276309600;/37550800700;/37086132491;/37089551790;/37276309600;/37550800700",
        "aff": "Department of Information Engineering and Mathematics, University of Siena, Siena, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy; Department of Information Engineering and Mathematics, University of Siena, Siena, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160353/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17368441267339518928&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Siena;University of Pisa;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Information Engineering and Mathematics;Department of Information Engineering;Department of Advanced Robotics",
        "aff_unique_url": "https://www.unisi.it;https://www.unipi.it;https://www.iit.it",
        "aff_unique_abbr": ";UNIP;IIT",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Siena;Pisa;Genova",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10160797",
        "title": "Compliant microgripper using soft polymer actuator",
        "track": "main",
        "status": "Poster",
        "abstract": "Miniaturization of robotic grippers enables precise manipulation of small-size objects. However, most microgrippers are actuated by rigid actuators, and thus retain challenges such as micro-fabrication, complex structure, and lack of compliance. Here, we present a compliant microgripper driven by a soft polymer actuator. The proposed millimeter-scale soft polymer actuator can produce a linear displacement and output force with a fast operation. Then, we designed the gripper linkage to convert the linear displacement of the actuator into a gripping motion. Fabricated compliant microgripper has a size of \\boldsymbol{10\\times 10\\times 10}\\ \\mathbf{mm}^{3}\\boldsymbol{10\\times 10\\times 10}\\ \\mathbf{mm}^{3} and a weight of 0.36 g, with a maximum gripping width of 8 mm. Demonstration of the gripper shows the feasibility of gripping various sub-millimeter scale objects regardless of their shape owing to its compliance.",
        "primary_area": "",
        "author": "Jung-Hwan Youn;Je-sung Koh;Ki-Uk Kyung;Jung-Hwan Youn;Je-sung Koh;Ki-Uk Kyung",
        "authorids": "/37088689454;/37404124500;/37283149200;/37088689454;/37404124500;/37283149200",
        "aff": "Electronics and Telecommunications Research Institute, South Korea; Ajou University, South Korea; Korea Advanced Institute of Science and Technology, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160797/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2040693795831622169&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Electronics and Telecommunications Research Institute;Ajou University;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.etri.re.kr;https://www.ajou.ac.kr;https://www.kaist.ac.kr",
        "aff_unique_abbr": "ETRI;Ajou;KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160584",
        "title": "Computational Design of 3D-Printable Compliant Mechanisms with Bio-Inspired Sliding Joints",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a computational approach for designing fully-integrated compliant mechanisms with bio-inspired joints that are stabilized and actuated by elastic elements. Similar to human knees or finger phalanges, our mechanisms leverage sliding between pairs of contacting surfaces to generate complex motions. Due to the vast design space, however, finding surface shapes that lead to ideal approximations of given target motions is a challenging and time-consuming task. To assist users in this process, our computational design tool combines forward and inverse simulation strategies that allow for guided and automated exploration of the parameter space. We demonstrate the potential of our method on a set of compliant mechanism with different joint geometries and validate our simulation results on 3D-printed prototypes.",
        "primary_area": "",
        "author": "Felipe Velasquez;Bernhard Thomaszewski;Stelian Coros;Felipe Velasquez;Bernhard Thomaszewski;Stelian Coros",
        "authorids": "/37089891856;/37087059770;/37077396200;/37089891856;/37087059770;/37077396200",
        "aff": "ETH Z\u00fcrich; ETH Z\u00fcrich; ETH Z\u00fcrich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160584/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17196158377464586560&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161209",
        "title": "Computational Design of Closed-Chain Linkages: Hopping Robot Driven by Morphological Computation",
        "track": "main",
        "status": "Poster",
        "abstract": "The main advantages of legged robots over wheeled ones are their abilities to traverse on uneven terrain due to the use of intermittent contacts and an ability to shift the center of mass relative to the contact location. A robot's leg design can be implemented by using an open-chain mechanism actuated with high-density torque actuators though this solution needs a vast energy budget. An alternative way to design a leg mechanism is the application of morphological computation principle. According to the principle, most of the desired robot's behavior can be delegated to the mechanics with minimum control effort needed to excite, stabilize or augment it. Within this paper, we have proposed a method to synthesize a leg for hopping robots. Due to optimization of mechanical structure, geometric parameters, mass distribution, and elasticity allocation, our method allows getting an energy-efficient robot with minimal control system complexity, which is accomplished via series elastic allocation and active variable length link. Based on this approach, we have designed a hopping robot with two low performance actuators that can achieve hopping, running, and, in the case of a biped or quadruped robot, walking motion. The paper describes a synthesized leg linkage and overviews prototype design, control strategy, and test results of a physical prototype.",
        "primary_area": "",
        "author": "Kirill V. Nasonov;Dmitriy V. Ivolga;Ivan I. Borisov;Sergey A. Kolyubin;Kirill V. Nasonov;Dmitriy V. Ivolga;Ivan I. Borisov;Sergey A. Kolyubin",
        "authorids": "/37089892288;/37089446944;/37086250938;/37887676700;/37089892288;/37089446944;/37086250938;/37887676700",
        "aff": "Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161209/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14960267778637043508&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ITMO University",
        "aff_unique_dep": "Biomechatronics and Energy-Efficient Robotics Lab",
        "aff_unique_url": "https://www.itmo.ru",
        "aff_unique_abbr": "ITMO",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Saint Petersburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Russia"
    },
    {
        "id": "10160808",
        "title": "Computational Methods to Support Prototyping of an Adaptive Robot Joystick Controller for Children with Upper Limb Impairments",
        "track": "main",
        "status": "Poster",
        "abstract": "Between 2% to 5% of children are affected by Developmental Coordination Disorders in Canada and have been diagnosed with upper limb impairments, which affect their daily lives and reduces their autonomy. Motor impairments can be part of progressive disorders, so despite regular therapy, progress remains fleeting. Affected individuals therefore consistently face many barriers, including entertainment opportunities, as availability of off-the-shelf inclusive technology is very limited. Our long-term goal is to develop a play-mediator robot, which would facilitate play between children with motor impairments and their peers or family members. Here, games that the robot can play are remotely controlled by the participants, using appropriate interfaces (e.g. joysticks). In this paper, we take the first step towards that goal and develop an adaptive joystick controller that can compensate for individual deficits. We monitor movement statistics to determine if re-calibration of the controller is necessary. Moreover, we propose a computational model of data \u2018distortion\u2019, as a tool for developers to test their technology in the very early stages of prototype development, without requiring access to participants. This work is validated with data from healthy adults and children with upper limb impairments.",
        "primary_area": "",
        "author": "Melanie Jouaiti;Negin Azizi;Kerstin Dautenhahn;Melanie Jouaiti;Negin Azizi;Kerstin Dautenhahn",
        "authorids": "/37086578714;/37089551597;/37273834500;/37086578714;/37089551597;/37273834500",
        "aff": "Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160808/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16929548090487613886&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Waterloo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160802",
        "title": "Computational Modeling in System with Non-Circular Timing Pulleys",
        "track": "main",
        "status": "Poster",
        "abstract": "We analyze and model a belt transmission system with non-circular timing pulleys. Using a 3D printer as a proof-of-concept device, experiments consisting of tracking the pose data of a printer nozzle and its pulleys are conducted. A computational model from our previous work is validated with the experimental data and expanded to model more complex systems with multiple non-circular timing pulleys as well as slippage and non-ideal tensions. Finally, an example with two non-circular timing pulleys is presented and simulated utilizing the proposed method.",
        "primary_area": "",
        "author": "Renzo Caballero;Angelica Coronado;Eric Feron;Renzo Caballero;Angelica Coronado;Eric Feron",
        "authorids": "/37088375012;/37089895454;/37283412000;/37088375012;/37089895454;/37283412000",
        "aff": "Computer, Electrical and Mathematical Sciences and Engineering division, King Abdullah University of Science and Technology, Thuwal, Kingdom of Saudi Arabia; Computer, Electrical and Mathematical Sciences and Engineering division, King Abdullah University of Science and Technology, Thuwal, Kingdom of Saudi Arabia; Computer, Electrical and Mathematical Sciences and Engineering division, King Abdullah University of Science and Technology, Thuwal, Kingdom of Saudi Arabia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160802/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6948062072412911713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "King Abdullah University of Science and Technology",
        "aff_unique_dep": "Computer, Electrical and Mathematical Sciences and Engineering division",
        "aff_unique_url": "https://www.kast.kau.edu.sa",
        "aff_unique_abbr": "KAUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Thuwal",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Kingdom of Saudi Arabia"
    },
    {
        "id": "10161372",
        "title": "Computational Tradeoff in Minimum Obstacle Displacement Planning for Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we look into the minimum obstacle displacement (MOD) planning problem from a mobile robot motion planning perspective. This problem finds an optimal path to goal by displacing movable obstacles when no path exists due to collision with obstacles. However this problem is computationally expensive and grows exponentially in the size of number of movable obstacles. This work looks into approximate solutions that are computationally less intensive and differ from the optimal solution by a factor of the optimal cost.",
        "primary_area": "",
        "author": "Antony Thomas;Giulio Ferro;Fulvio Mastrogiovanni;Michela Robba;Antony Thomas;Giulio Ferro;Fulvio Mastrogiovanni;Michela Robba",
        "authorids": "/37088419281;/37085623105;/37546428500;/37267233300;/37088419281;/37085623105;/37546428500;/37267233300",
        "aff": "Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy; Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy; Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy; Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161372/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10143573726248248013&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Genoa",
        "aff_unique_dep": "Department of Informatics, Bioengineering, Robotics, and Systems Engineering",
        "aff_unique_url": "https://www.unige.it",
        "aff_unique_abbr": "UniGe",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10160410",
        "title": "ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via Regularized Domain Concatenation",
        "track": "main",
        "status": "Poster",
        "abstract": "Transferring knowledge learned from the labeled source domain to the raw target domain for unsupervised domain adaptation (UDA) is essential to the scalable deployment of autonomous driving systems. State-of-the-art methods in UDA often employ a key idea: utilizing joint supervision signals from both source and target domains for self-training. In this work, we improve and extend this aspect. We present ConDA, a concatenation-based domain adaptation framework for LiDAR segmentation that: 1) constructs an intermediate domain consisting of fine-grained interchange signals from both source and target domains without destabilizing the semantic coherency of objects and background around the ego-vehicle; and 2) utilizes the intermediate domain for self-training. To improve the network training on the source domain and self-training on the intermediate domain, we propose an anti-aliasing regularizer and an entropy aggregator to reduce the negative effect caused by the aliasing artifacts and noisy pseudo labels. Through extensive studies, we demonstrate that ConDA significantly outperforms prior arts in mitigating domain gaps.",
        "primary_area": "",
        "author": "Lingdong Kong;Niamul Quader;Venice Erin Liong;Lingdong Kong;Niamul Quader;Venice Erin Liong",
        "authorids": "/37086560752;/38282231400;/37990606800;/37086560752;/38282231400;/37990606800",
        "aff": "Motional, Singapore; Motional, Singapore; Motional, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160410/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10012095535663521712&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Motional",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.motional.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160286",
        "title": "Concentration of Measure Phenomenon and its Implications for Sample-based Planning Algorithms in Very-High Dimensional Configuration Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "In very high-dimensional (\u226b10)(\\gg 10) spaces, a collection of points generated uniformly at random will concentrate very tightly about its expected value - defying intuition developed in low-dimensional spaces. This paper explores the implications of this for two major classes of sample-based robot motion planning algorithms: Rapidly Exploring Random Trees (RRTs) and Probabilistic Road Maps (PRMs). First we show that the graph vertices concentrate in a thin-shelled hyper-sphere, with almost none near the origin nor at the edges of the workspace. Next we examine how varying one of the algorithms' parameters - the maximum edge length- can dramatically alter the algorithms' complexity and the connectivity of the resulting graph. Finally, we explore how the position of the initial node, often placed arbitrarily, can impact the shape of the graph. While the contributions of this paper are largely theoretical, many robotic applications of practical interest have extremely high-dimensional configuration spaces including humanoids, swarms and soft (a.k.a. continuum) robotics.",
        "primary_area": "",
        "author": "Joel M. Esposito;Joel M. Esposito",
        "authorids": "/37294554800;/37294554800",
        "aff": "Robotics and Control Engineering, United States Naval Academy, Annapolis, Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160286/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5775847839902305410&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "United States Naval Academy",
        "aff_unique_dep": "Robotics and Control Engineering",
        "aff_unique_url": "https://www.usna.edu",
        "aff_unique_abbr": "USNA",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Annapolis",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161526",
        "title": "Concept Design of a New XY Compliant Parallel Manipulator With Spatial Configuration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes the concept design of a novel XY compliant parallel manipulator (CPM) with spatial configuration, which is beneficial to promote the performance of the XY CPM. Evolved from a planar configuration, a spatial compliant parallelogram flexure is devised as the basic module structure. Then, a mirror-symmetric XY CPM adopting spatial layout is proposed based on four-prismatic-prismatic (4-PP) parallel mechanism. The prototypes are fabricated by 3D printing for testing. The performance analysis and verification is conducted through theoretical modeling, finite element simulation, and experimental study. For comparison study, a planar XY CPM with similar mechanism is also developed. Results show that the proposed XY CPM with spatial configuration provides the benefits of smaller plane footprint, large working stroke, and enhanced load-bearing capacity as compared to the planar one. It is appropriate for precise positioning scenarios, like soft-contact lithography, which require high loading capacity and great compactness.",
        "primary_area": "",
        "author": "Zekui Lyu;Qingsong Xu;Zekui Lyu;Qingsong Xu",
        "authorids": "/37089023087;/37290823000;/37089023087;/37290823000",
        "aff": "Department of Electromechanical Engineering, Faculty of Science and Technology, University of Macau, Macau, China; Department of Electromechanical Engineering, Faculty of Science and Technology, University of Macau, Macau, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161526/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9998035410512699736&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Macau",
        "aff_unique_dep": "Department of Electromechanical Engineering",
        "aff_unique_url": "https://www.um.edu.mo",
        "aff_unique_abbr": "UMacau",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Macau",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160646",
        "title": "Conditional GANs for Sonar Image Filtering with Applications to Underwater Occupancy Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater robots typically rely on acoustic sensors like sonar to perceive their surroundings. However, these sensors are often inundated with multiple sources and types of noise, which makes using raw data for any meaningful inference with features, objects, or boundary returns very difficult. While several conventional methods of dealing with noise exist, their success rates are unsatisfactory. This paper presents a novel application of conditional Generative Adversarial Networks (cGANs) to train a model to produce noise-free sonar images, outperforming several conventional filtering methods. Estimating free space is crucial for autonomous robots performing active exploration and mapping. Thus, we apply our approach to the task of underwater occupancy mapping and show superior free and occupied space inference when compared to conventional methods.",
        "primary_area": "",
        "author": "Tianxiang Lin;Akshay Hinduja;Mohamad Qadri;Michael Kaess;Tianxiang Lin;Akshay Hinduja;Mohamad Qadri;Michael Kaess",
        "authorids": "/37089894487;/37086454167;/37089659857;/37324200400;/37089894487;/37086454167;/37089659857;/37324200400",
        "aff": "The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160646/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4666021609950317150&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160698",
        "title": "Conflict-constrained Multi-agent Reinforcement Learning Method for Parking Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated Valet Parking (AVP) has been exten-sively researched as an important application of autonomous driving. Considering the high dynamics and density of real parking lots, a system that considers multiple vehicles simultaneously is more robust and efficient than a single vehicle setting as in most studies. In this paper, we propose a dis-tributed Multi-agent Reinforcement Learning(MARL) method for coordinating multiple vehicles in the framework of an AVP system. This method utilizes traditional trajectory planning to accelerate the learning process and introduces collision conflict constraints for policy optimization to mitigate the path conflict problem. In contrast to other centralized multi-agent path finding methods, the proposed approach is scalable, distributed, and adapts to dynamic stochastic scenarios. We train the models in random scenarios and validate in several artificially designed complex parking scenarios where vehicles are always disturbed by dynamic and static obstacles. Experimental results show that our approach mitigates path conflicts and excels in terms of success rate and efficiency.",
        "primary_area": "",
        "author": "Siyuan Chen;Meiling Wang;Yi Yang;Wenjie Song;Siyuan Chen;Meiling Wang;Yi Yang;Wenjie Song",
        "authorids": "/37088403177;/37406965500;/37899921700;/37085743528;/37088403177;/37406965500;/37899921700;/37085743528",
        "aff": "School of Automation, Beijing Institute of Technology, Beijing, P.R. China; School of Automation, Beijing Institute of Technology, Beijing, P.R. China; School of Automation, Beijing Institute of Technology, Beijing, P.R. China; School of Automation, Beijing Institute of Technology, Beijing, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160698/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18303833075415994203&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "http://www.bit.edu.cn/",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161554",
        "title": "Congestion Prediction for Large Fleets of Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a deep learning (DL) approach to predicting congestion delays in large multi-robot systems. The problem is motivated by real-world problems in modern logistics automation, such as a warehouse with hundreds to thousands of coordinated mobile robots. Here, the large scale, the complexity of the control software, and the uncertainties of the robots' dynamics make direct (simulated) prediction of future robot states impractical. We propose predicting delays associated with future spatiotemporal locations, and we show this is useful for improving system performance via incorporating the predictions into path planning and travel time estimation. Our DL model uses convolutional long short-term memory (ConvLSTM) as the core structure, takes the historical congestion condition and planned paths as input, and generates the delays across all nodes in the spatial planning graph for a set of future time windows. When using predictions in a modified path planner, simulation experiments using production data show 4.4% average improvement in throughput performance versus without predictions.",
        "primary_area": "",
        "author": "Ge Yu;Michael T. Wolf;Ge Yu;Michael T. Wolf",
        "authorids": "/37089893958;/37089894878;/37089893958;/37089894878",
        "aff": "Applied Scientist in Amazon Robotics; Applied Scientist in Amazon Robotics",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161554/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=781207560477412537&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Amazon Robotics",
        "aff_unique_dep": "Amazon Robotics",
        "aff_unique_url": "https://www.amazonrobotics.com",
        "aff_unique_abbr": "Amazon Robotics",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160308",
        "title": "Constant Distance and Orientation Following of an Unknown Surface with a Cable-Driven Parallel Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Cable-Driven Parallel Robots (CDPRs) are well-adapted to large workspaces since they replace rigid links by cables. However, they lack in positioning accuracy and new control methods are necessary to achieve profile-following tasks. This paper presents a control scheme designed for these tasks, relying on a combination of accurate boarded distance sensors and of a less accurate remote camera. The profile-following task is divided into two subtasks that are partially conflicting: maintaining a parallel orientation and a constant distance with the surface to follow, and following a trajectory between two points on the surface. The data fusion to solve the redundancy is based on the Gradient Projection Method. This control scheme is validated experimentally on a CDPR prototype and shown to provide the expected behaviour.",
        "primary_area": "",
        "author": "Thomas Rousseau;Nicol\u00f2 Pedemonte;St\u00e9phane Caro;Fran\u00e7ois Chaumette;Thomas Rousseau;Nicol\u00f2 Pedemonte;St\u00e9phane Caro;Fran\u00e7ois Chaumette",
        "authorids": "/37089895986;/37086037541;/37589701400;/37265186700;/37089895986;/37086037541;/37589701400;/37265186700",
        "aff": "CNRS, LS2N, UMR, Nantes Universit\u00e9, \u00c9cole Centrale Nantes, Nantes, France; IRT Jules Verne, Nantes, France; CNRS, LS2N, UMR, CNRS at LS2N, Nantes Universit\u00e9, Ecole Centrale Nantes, Nantes, France; CNRS, IRISA, Inria, Univ Rennes, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160308/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5731789889846246092&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "Nantes Universit\u00e9;IRT Jules Verne;CNRS",
        "aff_unique_dep": ";;LS2N",
        "aff_unique_url": "https://www.univ-nantes.fr;;https://www.cnrs.fr",
        "aff_unique_abbr": "Nantes Universit\u00e9;;CNRS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nantes;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10161024",
        "title": "Constraint Manifolds for Robotic Inference and Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a manifold optimization approach for solving constrained inference and planning problems. The approach employs a framework that transforms an arbitrary nonlinear equality constrained optimization problem into an unconstrained manifold optimization problem. The core of the transformation process is the formulation of constraint manifolds that represent sets of variables subject to equality constraints. We propose various approaches to define the tan-gent spaces and retraction operations of constraint manifolds, which are crucial for manifold optimization. We evaluate our constraint manifold optimization approach on multiple constrained inference and planning problems, and show that it generates strictly feasible results with increased efficiency as compared to state-of-the-art constrained optimization methods.",
        "primary_area": "",
        "author": "Yetong Zhang;Fan Jiang;Gerry Chen;Varun Agrawal;Adam Rutkowski;Frank Dellaert;Yetong Zhang;Fan Jiang;Gerry Chen;Varun Agrawal;Adam Rutkowski;Frank Dellaert",
        "authorids": "/37088998216;/37089893798;/37089000441;/37086571187;/37089884777;/37282902200;/37088998216;/37089893798;/37089000441;/37086571187;/37089884777;/37282902200",
        "aff": "College of Computing, Georgia Institute of Technology, Atlanta, USA; College of Computing, Georgia Institute of Technology, Atlanta, USA; College of Computing, Georgia Institute of Technology, Atlanta, USA; College of Computing, Georgia Institute of Technology, Atlanta, USA; Munitions Directorate, Air Force Research Laboratory, USA; College of Computing, Georgia Institute of Technology, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161024/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13926807341758974144&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Air Force Research Laboratory",
        "aff_unique_dep": "College of Computing;Munitions Directorate",
        "aff_unique_url": "https://www.gatech.edu;https://www.afrl.af.mil/",
        "aff_unique_abbr": "Georgia Tech;AFRL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Atlanta;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161241",
        "title": "Contact Based Turning Gait of a Novel Legged-Wheeled Quadruped",
        "track": "main",
        "status": "Poster",
        "abstract": "How does a wheeled robot move and turn? The answer is straightforward for a conventional wheeled robot, but it is not so easy for a robot with a discrete wheel design. Regular wheeled robots always have four contact points, resulting in static stability during locomotion. However, QuadRunner's novel leg mechanism provides only a semi-circular wheel shape, and proper gait planning is needed to go straight or turn. Therefore, this paper presents a dual frequency gait planning method which controls the robot's gait cycle's duty factor and generates unique turning gait patterns for wheel locomotion. Describing requirements and limitations, we found sets of solutions that can achieve turning. Results show that the smallest turning radius QuadRunner achieved is 1.05m, and the biggest is 1.86m. In addition, detailed experiments were made to observe the performance and stability of straight and turning wheel behaviors. Finally, a gait verification is made using high-speed cameras.",
        "primary_area": "",
        "author": "Alper Yeldan;Abhimanyu Arora;Gim Song Soh;Alper Yeldan;Abhimanyu Arora;Gim Song Soh",
        "authorids": "/37089447852;/37089447364;/37085341418;/37089447852;/37089447364;/37085341418",
        "aff": "Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161241/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7099657790137879089&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160269",
        "title": "Contact Force Control with Continuously Compliant Robotic Legs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel robotic leg design and an associated control approach, which aims at providing an extension to the classical series elastic actuation concept. We propose to directly integrate the series compliance into the structure of the robotic leg itself, as opposed to co-locating spring and motor as done in traditional series elastic actuators. Our approach will eliminate mechanical design complexity and lead to a reduction of mass in the legs. This will, as a secondary benefit, improve the energy efficiency of locomotion. The primary contribution of this work is a model-based controller that can stably and precisely regulate the ground contact forces during stance. This control approach is demonstrated in a set of test-bench experiments, in which we control the contact forces of a modified version of the robotic leg ScarlETH. Here, the rigid shank is replaced by a continuously compliant element made of spring steel. This work presents the first step towards a new generation of robotic legs with structural compliance.",
        "primary_area": "",
        "author": "Robin Bendfeld;C. David Remy;Robin Bendfeld;C. David Remy",
        "authorids": "/37089895462;/37546418700;/37089895462;/37546418700",
        "aff": "Department of Mechanical Engineering, Institute for Nonlinear Mechanics, University of Stuttgart, Stuttgart, Germany; Department of Mechanical Engineering, Institute for Nonlinear Mechanics, University of Stuttgart, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160269/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5614940322636208233&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Stuttgart",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.uni-stuttgart.de",
        "aff_unique_abbr": "Uni Stuttgart",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160507",
        "title": "Contact Optimization for Non-Prehensile Loco-Manipulation via Hierarchical Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent studies on quadruped robots have focused on either locomotion or mobile manipulation using a robotic arm. However, legged robots can manipulate large objects using non-prehensile manipulation primitives, such as planar pushing, to drive the object to the desired location. This paper presents a novel hierarchical model predictive control (MPC) for contact optimization of the manipulation task. Using two cascading MPCs, we split the loco-manipulation problem into two parts: the first to optimize both contact force and contact location between the robot and the object, and the second to regulate the desired interaction force through the robot locomotion. Our method is successfully validated in both simulation and hardware experiments. While the baseline locomotion MPC fails to follow the desired trajectory of the object, our proposed approach can effectively control both object's position and orientation with minimal tracking error. This capability also allows us to perform obstacle avoidance for both the robot and the object during the loco-manipulation task.",
        "primary_area": "",
        "author": "Alberto Rigo;Yiyu Chen;Satyandra K. Gupta;Quan Nguyen;Alberto Rigo;Yiyu Chen;Satyandra K. Gupta;Quan Nguyen",
        "authorids": "/37088494482;/37089197452;/37878971100;/37085362091;/37088494482;/37089197452;/37878971100;/37085362091",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160507/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13067571987403103692&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161465",
        "title": "Contact-Based Pose Estimation of Workpieces for Robotic Setups",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for contact-based pose estimation of workpieces using a collaborative robot. The proposed pose estimation exploits positions and surface normal vectors along an arbitrary path on an object with known geometry, where surface normal vectors are estimated based on contact forces measured by the robot. When data is only available along a single path, it is difficult to find initial correspondences between source data (recorded points and normal vectors) and target data (CAD of an object); hence, a novel weighted incremental spatial search approach for generating correspondences based on point pair features is proposed. Subsequently, robust pose estimation is employed to reduce the effect of erroneous correspondences. The proposed pose estimation is verified in simulation on three paths on two objects and with different levels of noise on the source data to quantify the robustness of the algorithm. Finally, the method is experimentally validated to provide an average pose rotation and translation accuracy of \\mathbf{0.55}^{\\circ}\\mathbf{0.55}^{\\circ} and 0.51 mm, respectively, when using the robust estimation cost function Geman-McClure.",
        "primary_area": "",
        "author": "Yitaek Kim;Aljaz Kramberger;Anders Glent Buch;Christoffer Sloth;Yitaek Kim;Aljaz Kramberger;Anders Glent Buch;Christoffer Sloth",
        "authorids": "/37089578934;/37085387168;/37534052600;/37547023600;/37089578934;/37085387168;/37534052600;/37547023600",
        "aff": "The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Denmark; The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Denmark; The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Denmark; The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161465/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16213279109723253311&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "The Maersk Mc-Kinney Moller Institute",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "10161308",
        "title": "Context-aware robot control using gesture episodes",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots became a popular tool for increasing productivity in partly automated manufacturing plants. Intuitive robot teaching methods are required to quickly and flexibly adapt the robot programs to new tasks. Gestures have an essential role in human communication. However, in human-robot-interaction scenarios, gesture-based user interfaces are so far used rarely, and if they employ a one-to-one mapping of gestures to robot control variables. In this paper, we propose a method that infers the user's intent based on gesture episodes, the context of the situation, and common sense. The approach is evaluated in a simulated table-top manipulation setting. We conduct deterministic experiments with simulated users and show that the system can even handle the personal preferences of each user.",
        "primary_area": "",
        "author": "Petr Vanc;Jan Kristof Behrens;Karla Stepanova;Petr Vanc;Jan Kristof Behrens;Karla Stepanova",
        "authorids": "/37089893389;/37086828985;/37085758961;/37089893389;/37086828985;/37085758961",
        "aff": "Czech Technical University in Prague, Czech Institute of Informatics, Robotics, and Cybernetics; Czech Technical University in Prague, Czech Institute of Informatics, Robotics, and Cybernetics; Czech Technical University in Prague, Czech Institute of Informatics, Robotics, and Cybernetics",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161308/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12165786314103453836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Czech Institute of Informatics, Robotics, and Cybernetics",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "10160781",
        "title": "Contextual Multi-Objective Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Many critical robot environments, such as healthcare and security, require robots to account for contextdependent criteria when performing their functions (e.g., navigation). Such domains require decisions that balance multiple factors, making it difficult for robots to make contextually appropriate decisions. Multi-Objective Optimization (MOO) methods offer a potential solution by trading off between objectives; however concepts like Pareto fronts are not only expensive to compute but struggle with differentiating among solutions on the Pareto front. This work introduces the Contextual Multi-Objective Path Planning (CMOPP) algorithm, which enables the robot to trade off different complex costs dependent on context. The key insight of this work is to separate the path planning and path cost estimation into two independent steps, thus significantly reducing computation cost without impacting the quality of the resulting path. As a result, CMOPP is able to accurately model path costs, which provide meaningful trade-offs when choosing a path that best fits the context. We show the benefits of CMOPP on case studies that demonstrate its contextual path planning capabilities. CMOPP finds contextually appropriate paths by first reducing the search space up to 99.9% to a near-optimal set of paths. This reduction enables the generation of accurate path cost models, using up to 90% less computation than similar methods.",
        "primary_area": "",
        "author": "Anna Nickelson;Kagan Tumer;William D. Smart;Anna Nickelson;Kagan Tumer;William D. Smart",
        "authorids": "/37089894423;/38534461000;/37274167900;/37089894423;/38534461000;/37274167900",
        "aff": "Collaborative Robotics & Intelligent Systems Institute, Oregon State University, Corvallis, OR; Collaborative Robotics & Intelligent Systems Institute, Oregon State University, Corvallis, OR; Collaborative Robotics & Intelligent Systems Institute, Oregon State University, Corvallis, OR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160781/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15709646284029117219&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics & Intelligent Systems Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160806",
        "title": "Contingency-Aware Task Assignment and Scheduling for Human-Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of task assignment and scheduling for human-robot teams to enable the efficient completion of complex problems, such as satellite assembly. In high-mix, low volume settings, we must enable the human-robot team to handle uncertainty due to changing task requirements, potential failures, and delays to maintain task completion efficiency. We make two contributions: (1) we account for the complex interaction of uncertainty that stems from the tasks and the agents using a multi-agent concurrent MDP framework, and (2) we use Mixed Integer Linear Programs and contingency sampling to approximate action values for task assignment. Our results show that our online algorithm is computationally efficient while making optimal task assignments compared to a value iteration baseline. We evaluate our method on a 24-task representative assembly and a real-world 60-task satellite assembly, and we show that we can find an assignment that results in a near-optimal makespan.",
        "primary_area": "",
        "author": "Neel Dhanaraj;Santosh V. Narayan;Stefanos Nikolaidis;Satyandra K. Gupta;Neel Dhanaraj;Santosh V. Narayan;Stefanos Nikolaidis;Satyandra K. Gupta",
        "authorids": "/37087467558;/37089896068;/37643766400;/37878971100;/37087467558;/37089896068;/37643766400;/37878971100",
        "aff": "Viterbi School of Engineering, University of Southern, California, CA, USA; Viterbi School of Engineering, University of Southern, California, CA, USA; Viterbi School of Engineering, University of Southern, California, CA, USA; Viterbi School of Engineering, University of Southern, California, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160806/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12129535389971321691&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Viterbi School of Engineering",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160673",
        "title": "Continuity-Aware Latent Interframe Information Mining for Reliable UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned aerial vehicle (UAV) tracking is crucial for autonomous navigation and has broad applications in robotic automation fields. However, reliable UAV tracking remains a challenging task due to various difficulties like frequent occlusion and aspect ratio change. Additionally, most of the existing work mainly focuses on explicit information to improve tracking performance, ignoring potential interframe connections. To address the above issues, this work proposes a novel framework with continuity-aware latent interframe information mining for reliable UAV tracking, i.e., ClimRT. Specifically, a new efficient continuity-aware latent interframe information mining network (ClimNet) is proposed for UAV tracking, which can generate highly-effective latent frame between two adjacent frames. Besides, a novel location-continuity Transformer (LCT) is designed to fully explore continuity-aware spatial-temporal information, thereby markedly enhancing UAV tracking. Extensive qualitative and quantitative experiments on three authoritative aerial benchmarks strongly validate the robustness and reliability of ClimRT in UAV tracking performance. Furthermore, real-world tests on the aerial platform validate its practicability and effectiveness. The code and demo materials are released at https://github.com/vision4robotics/ClimRT.",
        "primary_area": "",
        "author": "Changhong Fu;Mutian Cai;Sihang Li;Kunhan Lu;Haobo Zuo;Chongjun Liu;Changhong Fu;Mutian Cai;Sihang Li;Kunhan Lu;Haobo Zuo;Chongjun Liu",
        "authorids": "/37086797986;/37089893712;/37089451036;/37089694530;/37089661486;/37089620358;/37086797986;/37089893712;/37089451036;/37089694530;/37089661486;/37089620358",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; College of Mechanical and Electrical Engineering, Harbin Engineering University, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160673/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12660272788908006328&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Tongji University;Harbin Engineering University",
        "aff_unique_dep": "School of Mechanical Engineering;College of Mechanical and Electrical Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn;http://www.heu.edu.cn",
        "aff_unique_abbr": "Tongji;HEU",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Shanghai;Harbin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160419",
        "title": "Continuous Prediction of Leg Kinematics during Walking using Inertial Sensors, Smart Glasses, and Embedded Computing",
        "track": "main",
        "status": "Poster",
        "abstract": "Unlike traditional hierarchical controllers for robotic leg prostheses and exoskeletons, continuous systems could allow persons with mobility impairments to walk more naturally in real-world environments without requiring high-level switching between locomotion modes. To support these next-generation controllers, we developed a new system called KIFNet (Kinematics and Image Fusing Network) that uses lightweight and efficient deep learning models to continuously predict the leg kinematics during walking. We tested different sensor fusion methods to combine kinematics data from inertial sensors and computer vision data from smart glasses and found that adaptive instance normalization achieved the lowest RMSE predictions for knee and ankle joint kinematics. We also deployed our model on an embedded device. Without inference optimization, our model was 20 times faster than the previous state-of-the-art and achieved 20% higher prediction accuracies, and during some locomotor activities like stair descent, decreased RMSE up to 300%. With inference optimization, our best model achieved 125 FPS on an NVIDIA Jetson Nano. These results demonstrate the potential to build fast and accurate deep learning models for continuous prediction of leg kinematics during walking based on sensor fusion and embedded computing, therein providing a foundation for real-time continuous controllers for robotic leg prostheses and exoskeletons.",
        "primary_area": "",
        "author": "Oleksii Tsepa;Roman Burakov;Brokoslaw Laschowski;Alex Mihailidis;Oleksii Tsepa;Roman Burakov;Brokoslaw Laschowski;Alex Mihailidis",
        "authorids": "/37089894917;/37089894749;/37086917909;/37282695700;/37089894917;/37089894749;/37086917909;/37282695700",
        "aff": "Department of Mathematics, National University of Kyiv-Mohyla Academy, Kyiv, Ukraine; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Toronto Rehabilitation Institute, University Health Network, Toronto, ON, Canada; Toronto Rehabilitation Institute, University Health Network, Toronto, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160419/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4927608081121205210&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "National University of Kyiv-Mohyla Academy;University of Toronto;Toronto Rehabilitation Institute",
        "aff_unique_dep": "Department of Mathematics;Department of Computer Science;University Health Network",
        "aff_unique_url": "https://nuhm.org.ua;https://www.utoronto.ca;https://www.uhn.ca/rehabilitation.html",
        "aff_unique_abbr": "NUKMA;U of T;TRI",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Kyiv;Toronto",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Ukraine;Canada"
    },
    {
        "id": "10160768",
        "title": "Continuous-Time Gaussian Process Motion-Compensation for Event-Vision Pattern Tracking with Distance Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "This work addresses the issue of motion compensation and pattern tracking in event camera data. An event camera generates asynchronous streams of events triggered independently by each of the pixels upon changes in the observed intensity. Providing great advantages in low-light and rapid-motion scenarios, such unconventional data present significant research challenges as traditional vision algorithms are not directly applicable to this sensing modality. The proposed method decomposes the tracking problem into a local SE(2) motion-compensation step followed by a homography registration of small motion-compensated event batches. The first component relies on Gaussian Process (GP) theory to model the continuous occupancy field of the events in the image plane and embed the camera trajectory in the covariance kernel function. In doing so, estimating the trajectory is done similarly to GP hyperparameter learning by maximising the log marginal likelihood of the data. The continuous occupancy fields are turned into distance fields and used as templates for homography-based registration. By benchmarking the proposed method against other state-of-the-art techniques, we show that our open-source implementation performs high-accuracy motion compensation and produces high-quality tracks in real-world scenarios.",
        "primary_area": "",
        "author": "Cedric Le Gentil;Ignacio Alzugaray;Teresa Vidal-Calleja;Cedric Le Gentil;Ignacio Alzugaray;Teresa Vidal-Calleja",
        "authorids": "/37086935323;/37086016139;/37085384801;/37086935323;/37086016139;/37085384801",
        "aff": "Robotics Institute, University of Technology, Sydney, Australia; Department of Computing, Imperial College, London, UK; Robotics Institute, University of Technology, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160768/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14380975966476036138&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Technology, Sydney;Imperial College London",
        "aff_unique_dep": "Robotics Institute;Department of Computing",
        "aff_unique_url": "https://www.uts.edu.au;https://www.imperial.ac.uk",
        "aff_unique_abbr": "UTS;Imperial",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Sydney;London",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Australia;United Kingdom"
    },
    {
        "id": "10161093",
        "title": "Continuous-Time LiDAR-Inertial-Vehicle Odometry Method with Lateral Acceleration Constraint",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a continuous-time-based LiDAR-inertial-vehicle odometry method, which can tightly fuse the data from Light Detection And Ranging (LiDAR), inertial measurement units (IMU), and vehicle measurements. The lateral acceleration constraint is further added to trajectory estimation to make the estimated trajectory follow the motion characteristics of vehicles. In addition, since vehicle model parameters vary with different motion conditions and tyre pressure, we estimate vehicle correction factors that rectify changes in vehicle model parameters online, and also analyze the observability of these vehicle correction factors. In experiments, the proposed method is evaluated and compared with state-of-the-art methods in the public dataset. The experimental results show that the proposed method achieves more accurate results in all sequences since we add additional sensor measurements and utilize the characteristic of vehicle motion to restrict the trajectory estimation. The ablation study also proved the effectiveness of continuous-time representation, online correction factor estimation, and incorporation of lateral acceleration constraint.",
        "primary_area": "",
        "author": "Bin He;Weichen Dai;Zeyu Wan;Hong Zhang;Yu Zhang;Bin He;Weichen Dai;Zeyu Wan;Hong Zhang;Yu Zhang",
        "authorids": "/37089809864;/37086568517;/37088769287;/37089893179;/37086570568;/37089809864;/37086568517;/37088769287;/37089893179;/37086570568",
        "aff": "State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Key Laboratory of Collaborative sensing and autonomous unmanned systems of Zhejiang Province, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161093/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7547116312898900604&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Zhejiang University;Hangzhou Dianzi University;Zhejiang Province Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems",
        "aff_unique_dep": "College of Control Science and Engineering;School of Computer Science;Collaborative Sensing and Autonomous Unmanned Systems",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.hdu.edu.cn;",
        "aff_unique_abbr": "ZJU;HDU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160337",
        "title": "Contour Context: Abstract Structural Distribution for 3D LiDAR Loop Detection and Metric Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes Contour Context, a simple, effective, and efficient topological loop closure detection pipeline with accurate 3-DoF metric pose estimation, targeting the urban autonomous driving scenario. We interpret the Cartesian bird's eye view (BEV) image projected from 3D LiDAR points as layered distribution of structures. To recover elevation information from BEVs, we slice them at different heights, and connected pixels at each level form contours. Each contour is parameterized by abstract information, e.g., pixel count, center position, covariance, and mean height. The similarity of two BEVs is calculated in sequential discrete and continuous steps. The first step considers the geometric consensus of graph-like constellations formed by contours in particular localities. The second step models the majority of contours as a 2.5D Gaussian mixture model, which is used to calculate correlation and optimize relative transform in continuous space. A retrieval key is designed to accelerate the search of a database indexed by layered KD-trees. We validate the efficacy of our method by comparing it with recent works on public datasets.",
        "primary_area": "",
        "author": "Binqian Jiang;Shaojie Shen;Binqian Jiang;Shaojie Shen",
        "authorids": "/37087244909;/37954847200;/37087244909;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160337/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=572229839733913543&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "The Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160710",
        "title": "Control of Shape Memory Alloy Actuator via Electrostatic Capacitive Sensor for Meso-scale Mirror Tilting System",
        "track": "main",
        "status": "Poster",
        "abstract": "Shape memory alloy (SMA) has superior actuation capability over the limit of the scale. However, inherently low controllability is a primary issue that hinders practical usage. To address this challenge, this paper presents an SMA-based artificial muscle actuator capable of the displacement sensing through the capacitive sensor. To realize sensing capability, the theoretical model-based design and fabrication process are proposed. Here, we show that the actuator can be controlled at intervals of 100 \u03bcm as well as maintaining sensing capability while lifting 90 times heavier than its weight. To exhibit the usefulness of the actuator to an optical device, we integrate the actuator into the mirror tilting device, which has 20 degrees tilting angle. We expect that the proposed actuator can overcome the scale limit of meso-scale devices, which require payload capacity and controllability, simultaneously.",
        "primary_area": "",
        "author": "Baekgyeom Kim;Doohoe Lee;Dongjin Kim;Seungyong Han;Daeshik Kang;Uikyum Kim;Je-sung Koh;Baekgyeom Kim;Doohoe Lee;Dongjin Kim;Seungyong Han;Daeshik Kang;Uikyum Kim;Je-sung Koh",
        "authorids": "/37089895273;/37089892695;/37089893656;/37089893709;/37086169524;/38252427700;/37404124500;/37089895273;/37089892695;/37089893656;/37089893709;/37086169524;/38252427700;/37404124500",
        "aff": "Multiscale Bio-inspired Technology Lab, Mechanical Engineering, Ajou University, Suwon, Korea; Multiscale Bio-inspired Technology Lab, Mechanical Engineering, Ajou University, Suwon, Korea; Multiscale Bio-inspired Technology Lab, Mechanical Engineering, Ajou University, Suwon, Korea; Multiscale Bio-inspired Technology Lab, Mechanical Engineering, Ajou University, Suwon, Korea; Multiscale Bio-inspired Technology Lab, Mechanical Engineering, Ajou University, Suwon, Korea; Multiscale Bio-inspired Technology Lab, Mechanical Engineering, Ajou University, Suwon, Korea; Multiscale Bio-inspired Technology Lab, Mechanical Engineering, Ajou University, Suwon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160710/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16820517400936290189&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Ajou University",
        "aff_unique_dep": "Mechanical Engineering",
        "aff_unique_url": "http://www.ajou.ac.kr",
        "aff_unique_abbr": "Ajou",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Suwon",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161146",
        "title": "Controllable Mechanical-domain Energy Accumulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Springs are efficient in storing and returning elastic potential energy but are unable to hold the energy they store in the absence of an external load. Lockable springs use clutches to hold elastic potential energy in the absence of an external load, but have not yet been widely adopted in applications, partly because clutches introduce design complexity, reduce energy efficiency, and typically do not afford high fidelity control over the energy stored by the spring. Here, we present the design of a novel lockable compression spring that uses a small capstan clutch to passively lock a mechanical spring. The capstan clutch can lock over 1000 N force at any arbitrary deflection, unlock the spring in less than 10 ms with a control force less than 1% of the maximal spring force, and provide an 80% energy storage and return efficiency (comparable to a highly efficient electric motor operated at constant nominal speed). By retaining the form factor of a regular spring while providing high-fidelity locking capability even under large spring forces, the proposed design could facilitate the development of energy-efficient spring-based actuators and robots.",
        "primary_area": "",
        "author": "Sung Y. Kim;David J. Braun;Sung Y. Kim;David J. Braun",
        "authorids": "/37088506795;/37609773600;/37088506795;/37609773600",
        "aff": "Department of Mechanical Engineering, Advanced Robotics and Control Laboratory within the Center for Rehabilitation Engineering and Assistive Technology, Vanderbilt University, Nashville, TN; Department of Mechanical Engineering, Advanced Robotics and Control Laboratory within the Center for Rehabilitation Engineering and Assistive Technology, Vanderbilt University, Nashville, TN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161146/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17293895285289103156&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160926",
        "title": "Controlling an Underactuated AUV as an Inverted Pendulum using Nonlinear Model Predictive Control and Behavior Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "Agile and hydrobatic maneuvering capabilities can enhance AUV operations in increasingly challenging scenarios. In this paper, we explore the ability of an underactuated AUV to transition to and hold a pitch angle close to 90 degrees at a particular depth, like an inverted pendulum. Holding such an orientation can be valuable in observing a calving glacier, under-ice launch and recovery, underwater docking, inspecting vertical structures, and observing targets above the water surface. However, such control is challenging because of underactuation, rapid response times and varying stability in different configurations. To address this, a control policy is derived offline using nonlinear MPC in a high-fidelity simulation environment in Simulink. For real-time control, a hybrid controller using a behavior tree (BT) is developed based on the optimal MPC policy and applied on the AUV system. The BT controller considers Safety, Transit and Stabilize behaviors. The control algorithm is validated with simulations in Simulink and Stonefish-ROS as well as field experiments with the hydrobatic SAM AUV, showing repeatable performance in the inverted pendulum maneuver.",
        "primary_area": "",
        "author": "Sriharsha Bhat;Ivan Stenius;Sriharsha Bhat;Ivan Stenius",
        "authorids": "/37086853425;/37086853896;/37086853425;/37086853896",
        "aff": "School of Engineering Sciences, KTH Royal Institute of Technology, Stockholm, Sweden; School of Engineering Sciences, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160926/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14222309930253465742&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "School of Engineering Sciences",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "10161360",
        "title": "Convolutional Bayesian Kernel Inference for 3D Semantic Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic perception is currently at a cross-roads between modern methods, which operate in an efficient latent space, and classical methods, which are mathematically founded and provide interpretable, trustworthy results. In this paper, we introduce a Convolutional Bayesian Kernel Inference (Con-vBKI) layer which learns to perform explicit Bayesian inference within a depthwise separable convolution layer to maximize efficency while maintaining reliability simultaneously. We apply our layer to the task of real-time 3D semantic mapping, where we learn semantic-geometric probability distributions for LiDAR sensor information and incorporate semantic predictions into a global map. We evaluate our network against state-of-the-art semantic mapping algorithms on the KITTI data set, demonstrating improved latency with comparable semantic label inference results.",
        "primary_area": "",
        "author": "Joey Wilson;Yuewei Fu;Arthur Zhang;Jingyu Song;Andrew Capodieci;Paramsothy Jayakumar;Kira Barton;Maani Ghaffari;Joey Wilson;Yuewei Fu;Arthur Zhang;Jingyu Song;Andrew Capodieci;Paramsothy Jayakumar;Kira Barton;Maani Ghaffari",
        "authorids": "/37089447655;/37089446760;/37089449088;/37089447020;/37089448226;/37085570507;/37393918000;/37087056400;/37089447655;/37089446760;/37089449088;/37089447020;/37089448226;/37085570507;/37393918000;/37087056400",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; Neya Systems Division, Applied Research Associates, Warrendale, PA, USA; US Army DEVCOM Ground Vehicle Systems Center, Warren, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161360/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3546120554936992646&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;2;0;0",
        "aff_unique_norm": "University of Michigan;Applied Research Associates;US Army DEVCOM Ground Vehicle Systems Center",
        "aff_unique_dep": ";Neya Systems Division;",
        "aff_unique_url": "https://www.umich.edu;;",
        "aff_unique_abbr": "UM;;",
        "aff_campus_unique_index": "0;0;0;0;2;0;0",
        "aff_campus_unique": "Ann Arbor;;Warren",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160282",
        "title": "Cooperative Driving in Mixed Traffic of Manned and Unmanned Vehicles based on Human Driving Behavior Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "To achieve safe cooperative driving in mixed traffic of manned and unmanned vehicles, it is necessary to understand and model human drivers' driving behaviors. This paper proposed a Hidden Markov Model (HMM)-based method to analyze human driver's control and vehicle's dynamics; and then recognize the human driver's action, such as accelerating, braking, and changing lanes. With the knowledge of the human driver's actions, a probability model is used to predict the human-driven vehicle's acceleration. Such information on the driver behavior and the vehicle behavior can be used to achieve safer cooperative driving, which is realized using vehicle-to-vehicle (V2V) communication and model predictive control (MPC). The proposed method was tested and evaluated in our custom-built cooperative driving testbed. Experimental results show that the above driver action model is effective and accurate. A preliminary case study on a lane merging scenario is provided to further validate its effectiveness and capability.",
        "primary_area": "",
        "author": "Jiaxing Lu;Sanzida Hossain;Weihua Sheng;He Bai;Jiaxing Lu;Sanzida Hossain;Weihua Sheng;He Bai",
        "authorids": "/37088690371;/37089658819;/37276312200;/37085643488;/37088690371;/37089658819;/37276312200;/37085643488",
        "aff": "School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA; School of Mechanical and Aerospace Engineering, Oklahoma State University, Stillwater, OK, USA; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA; School of Mechanical and Aerospace Engineering, Oklahoma State University, Stillwater, OK, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160282/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2624642832823232889&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oklahoma State University",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.okstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stillwater",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161239",
        "title": "Coordinate Calibration of a Dual-Arm Robot System by Visual Tool Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "The calibration of a vision-guided dual-arm robotic system, including the robot-robot and hand-eye calibration, requires the tracked positions of markers in different postures. However, in many cases, using markers to calibrate is impractical. Only some markerless features can be obtained rather than the rigid transform matrix; for example, the shaft of a markerless robotic tool can be tracked. Therefore, we proposed a Kronecker-Product-based method to calibrate the dual-arm system with a tracked robotic tool by decoupling the translation and rotation. The simulation and experiment results on a da Vinci Research Kit show that the proposed method is robust and accurate under different noise levels and various sample robot movements, compared with two state-of-the-art methods for dual-arm calibration with complete homogeneous transformations.",
        "primary_area": "",
        "author": "Junlei Hu;Dominic Jones;Pietro Valdastri;Junlei Hu;Dominic Jones;Pietro Valdastri",
        "authorids": "/37089892000;/37086289005;/37282537500;/37089892000;/37086289005;/37282537500",
        "aff": "STORM Lab UK, School of Electronic and Electrical Engineering, University of Leeds, UK; STORM Lab UK, School of Electronic and Electrical Engineering, University of Leeds, UK; STORM Lab UK, School of Electronic and Electrical Engineering, University of Leeds, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161239/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3069721398296505514&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Leeds",
        "aff_unique_dep": "School of Electronic and Electrical Engineering",
        "aff_unique_url": "https://www.leeds.ac.uk",
        "aff_unique_abbr": "Leeds",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161165",
        "title": "Cost-Aware Evaluation and Model Scaling for LiDAR-Based 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Considerable research effort has been devoted to LiDAR-based 3D object detection and empirical performance has been significantly improved. While progress has been en-couraging, we observe an overlooked issue: it is not yet common practice to compare different 3D detectors under the same cost, e.g., inference latency. This makes it difficult to quantify the true performance gain brought by recently proposed architecture designs. The goal of this work is to conduct a cost-aware evaluation of LiDAR-based 3D object detectors. Specifically, we focus on SECOND, a simple grid-based one-stage detector, and analyze its performance under different costs by scaling its original architecture. Then we compare the family of scaled SECOND with recent 3D detection methods, such as Voxel R-CNN and PV-RCNN++. The results are surprising. We find that, if allowed to use the same latency, SECOND can match the performance of PV-RCNN++, the current state-of-the-art method on the Waymo Open Dataset. Scaled SECOND also easily outperforms many recent 3D detection methods published during the past year. We recommend future research control the inference cost in their empirical comparison and include the family of scaled SECOND as a strong baseline when presenting novel 3D detection methods.",
        "primary_area": "",
        "author": "Xiaofang Wang;Kris M. Kitani;Xiaofang Wang;Kris M. Kitani",
        "authorids": "/37086815246;/37294510900;/37086815246;/37294510900",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161165/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8495392046616587803&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160625",
        "title": "Counter-Hypothetical Particle Filters for Single Object Pose Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Particle filtering is a common technique for six degree of freedom (6D) pose estimation due to its ability to tractably represent belief over object pose. However, the particle filter is prone to particle deprivation due to the high-dimensional nature of 6D pose. When particle deprivation occurs, it can cause mode collapse of the underlying belief distri-bution during importance sampling. If the region surrounding the true state suffers from mode collapse, recovering its belief is challenging since the area is no longer represented in the probability mass formed by the particles. Previous methods mitigate this problem by randomizing and resetting particles in the belief distribution, but determining the frequency of reinvigoration has relied on hand-tuning abstract heuristics. In this paper, we estimate the necessary reinvigoration rate at each time step by introducing a Counter-Hypothetical likelihood function, which is used alongside the standard likelihood. Inspired by the notions of plausibility and implausibility from Evidential Reasoning, the addition of our Counter-Hypothetical likelihood function assigns a level of doubt to each particle. The competing cumulative values of confidence and doubt across the particle set are used to estimate the level of failure within the filter, in order to determine the portion of particles to be reinvigorated. We demonstrate the effectiveness of our method on the rigid body object 6D pose tracking task.",
        "primary_area": "",
        "author": "Elizabeth A. Olson;Jana Pavlasek;Jasmine A. Berry;Odest Chadwicke Jenkins;Elizabeth A. Olson;Jana Pavlasek;Jasmine A. Berry;Odest Chadwicke Jenkins",
        "authorids": "/37086296673;/37088689981;/37089893332;/37297252400;/37086296673;/37088689981;/37089893332;/37297252400",
        "aff": "Robotics Department, University of Michigan, Ann Arbor, MI, USA; Robotics Department, University of Michigan, Ann Arbor, MI, USA; Robotics Department, University of Michigan, Ann Arbor, MI, USA; Robotics Department, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160625/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9068024558552150064&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Robotics Department",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160422",
        "title": "Coupled, closed-system fluidic actuators for use in wearable rehabilitation devices",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel closed-system, coupled soft actuator that aims to increase the applied bending moment that can be powered by a single pneumatic pump. The actuator incorporates both positive pressure and vacuum actuators of established design. The purpose of this development is to enable the design of an effective soft robotic wearable device for the re-habilitation of the revolute joints in post-stroke individuals. The design of a test rig to provide consistent, quantitative data on the output of the soft actuators is presented, allowing a comparison of the positive pressure, vacuum and combined (positive and vacuum) actuators. This combination demonstrates the ability to significantly increase the torque output when compared to a single actuator using the same pump for input, potentially reducing the weight of a wearable device. The closed-system, coupled soft actuator system shows opportunity for use in a wide range of applications due to this reduction in pump weight and isolation from environmental conditions.",
        "primary_area": "",
        "author": "James Greig;Maria Elena Giannaccini;Edward Chadwick;James Greig;Maria Elena Giannaccini;Edward Chadwick",
        "authorids": "/37089896034;/37078539400;/37424427800;/37089896034;/37078539400;/37424427800",
        "aff": "Artificial Intelligence, Robotics and Mechatronic Systems Group (ARMS), School of Engineering, University of Aberdeen, Aberdeen, UK; Artificial Intelligence, Robotics and Mechatronic Systems Group (ARMS), School of Engineering, University of Aberdeen, Aberdeen, UK; Artificial Intelligence, Robotics and Mechatronic Systems Group (ARMS), School of Engineering, University of Aberdeen, Aberdeen, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160422/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:mevpt2YNSUsJ:scholar.google.com/&scioq=Coupled,+closed-system+fluidic+actuators+for+use+in+wearable+rehabilitation+devices&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Aberdeen",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.abdn.ac.uk",
        "aff_unique_abbr": "Aberdeen",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Aberdeen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160249",
        "title": "Covariance Steering for Uncertain Contact-rich Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning and control for uncertain contact systems is challenging as it is not clear how to propagate uncertainty for planning. Contact-rich tasks can be modeled efficiently using complementarity constraints among other techniques. In this paper, we present a stochastic optimization technique with chance constraints for systems with stochastic complementarity constraints. We use a particle filter-based approach to propagate moments for stochastic complementarity system. To circumvent the issues of open-loop chance constrained planning, we propose a contact-aware controller for covariance steering of the complementarity system. Our optimization problem is formulated as Non-Linear Programming (NLP) using bilevel optimization. We present an important-particle algorithm for numerical efficiency for the underlying control problem. We verify that our contact-aware closed-loop controller is able to steer the covariance of the states under stochastic contact-rich tasks.",
        "primary_area": "",
        "author": "Yuki Shirai;Devesh K. Jha;Arvind U. Raghunathan;Yuki Shirai;Devesh K. Jha;Arvind U. Raghunathan",
        "authorids": "/37086344073;/37072717800;/37401365500;/37086344073;/37072717800;/37401365500",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160249/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16872991155587576799&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California, Los Angeles;Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;",
        "aff_unique_url": "https://www.ucla.edu;https://www.merl.com",
        "aff_unique_abbr": "UCLA;MERL",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Los Angeles;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160517",
        "title": "Credible Online Dynamics Learning for Hybrid UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "Hybrid unmanned aerial vehicles (H-UAVs) are highly versatile platforms with the ability to transition between rotary- and fixed-wing flight. However, their (aero)dynamics tend to be highly nonlinear which increases the risk of introducing safety-critical modeling errors in a controller. Designing a safe, yet not too cautious controller, requires a credible model which provides accurate dynamics uncertainty quantification. We present a data-efficient, probabilistic semi-parametric dynamics modeling approach that allows for online, filter-based inference. The proposed model leverages prior knowledge using a nominal parametric model, and combines it with residuals in the form of sparse Gaussian processes to account for possibly unmodeled forces and moments. Uncertain nominal and residual parameters are jointly estimated using Bayesian filtering. The resulting model accuracy and the reliability of its predicted uncertainty are analyzed for both a simulated and a real example, where we learn the 6DoF nonlinear dynamics of a tiltwing H-UAV from a few minutes of flight data. Compared to a residual-free nominal model, the proposed semi-parametric approach provides increased model accuracy in relevant parts of the flight envelope and substantially higher credibility overall.",
        "primary_area": "",
        "author": "David Rohr;Nicholas Lawrance;Olov Andersson;Roland Siegwart;David Rohr;Nicholas Lawrance;Olov Andersson;Roland Siegwart",
        "authorids": "/37086830761;/37571923900;/37085816587;/37281398300;/37086830761;/37571923900;/37085816587;/37281398300",
        "aff": "Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Robotics and Autonomous Systems Group, CSIRO Data61, QLD, Australia; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160517/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10805898097300895291&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "ETH Zurich;CSIRO Data61",
        "aff_unique_dep": "Autonomous Systems Lab;Robotics and Autonomous Systems Group",
        "aff_unique_url": "https://www.ethz.ch;https://www.csiro.au/en/Research/Data61",
        "aff_unique_abbr": "ETHZ;CSIRO Data61",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Zurich;QLD",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Switzerland;Australia"
    },
    {
        "id": "10160345",
        "title": "Croche-Matic: a robot for crocheting 3D cylindrical geometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Crochet is a textile craft that has resisted mech-anization and industrialization except for a select number of one-off crochet machines. These machines are only capable of producing a limited subset of common crochet stitches. Crochet machines are not used in the textile industry, yet mass-produced crochet objects and clothes sold in stores like Target and Zara are almost certainly the products of crochet sweatshops. The popularity of crochet and the existence of crochet products in major chain stores shows that there is both a clear demand for this craft as well as a need for it to be produced in a more ethical way. In this paper, we present Croche-Matic, a radial crochet machine for generating three-dimensional cylindrical geometry. The Croche-Matic is designed based on Magic Ring technique, a method for hand crocheting 3D cylindrical objects. The machine consists of nine mechanical axes that work in sequence to complete different types of crochet stitches, and includes a sensor component for measuring and regulating yarn tension within the mechanical system. Croche-Matic can complete the four main stitches used in Magic Ring technique. It has a success rate of 50.7% with single crochet stitches, and has demonstrated an ability to create three-dimensional objects.",
        "primary_area": "",
        "author": "Gabriella Perry;Jose Luis Garc\u00eda del Castillo y L\u00f3pez;Nathan Melenbrink;Gabriella Perry;Jose Luis Garc\u00eda del Castillo y L\u00f3pez;Nathan Melenbrink",
        "authorids": "/37089895438;/37089893239;/37086291970;/37089895438;/37089893239;/37086291970",
        "aff": "Harvard Graduate School of Design, Cambridge, MA; Harvard Graduate School of Design, Cambridge, MA; Harvard SEAS, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160345/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17967552053438656653&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "Graduate School of Design",
        "aff_unique_url": "https://www.gsd.harvard.edu",
        "aff_unique_abbr": "Harvard GSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160990",
        "title": "CropNav: a Framework for Autonomous Navigation in Real Farms",
        "track": "main",
        "status": "Poster",
        "abstract": "Small robots that can operate under the plant canopy can enable new possibilities in agriculture. However, unlike larger autonomous tractors, autonomous navigation for such under canopy robots remains an open challenge because Global Navigation Satellite System (GNSS) is unreliable under the plant canopy. We present a hybrid navigation system that autonomously switches between different sets of sensing modalities to enable full field navigation, both inside and outside of crop. By choosing the appropriate path reference source, the robot can accommodate for loss of GNSS signal quality and leverage row-crop structure to autonomously navigate. However, such switching can be tricky and difficult to execute over scale. Our system provides a solution by automatically switching between an exteroceptive sensing based system, such as Light Detection And Ranging (LiDAR) row-following navigation and waypoints path tracking. In addition, we show how our system can detect when the navigate fails and recover automatically extending the autonomous time and mitigating the necessity of human intervention. Our system shows an improvement of about 750 m per intervention over GNSS-based navigation and 500 m over row following navigation.",
        "primary_area": "",
        "author": "Mateus V. Gasparino;Vitor A.H. Higuti;Arun N. Sivakumar;Andres E.B. Velasquez;Marcelo Becker;Girish Chowdhary;Mateus V. Gasparino;Vitor A.H. Higuti;Arun N. Sivakumar;Andres E.B. Velasquez;Marcelo Becker;Girish Chowdhary",
        "authorids": "/37089478015;/37089157068;/37089504709;/37089478145;/37398142900;/37402725200;/37089478015;/37089157068;/37089504709;/37089478145;/37398142900;/37402725200",
        "aff": "EarthSense Inc., Champaign, IL, USA; EarthSense Inc., Champaign, IL, USA; EarthSense Inc., Champaign, IL, USA; Field Robotics Engineering and Science Hub (FRESH), Illinois Autonomous Farm, University of Illinois at Urbana-Champaign (UIUC), IL; Dept. of Mechanical Engineering, University of S\u00e3o Paulo (USP), S\u00e3o Carlos, SP, Brazil; Field Robotics Engineering and Science Hub (FRESH), Illinois Autonomous Farm, University of Illinois at Urbana-Champaign (UIUC), IL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160990/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10857790191239363928&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;1",
        "aff_unique_norm": "EarthSense Inc.;University of Illinois at Urbana-Champaign;University of S\u00e3o Paulo",
        "aff_unique_dep": ";Field Robotics Engineering and Science Hub;Dept. of Mechanical Engineering",
        "aff_unique_url": ";https://www illinois.edu;https://www.usp.br",
        "aff_unique_abbr": ";UIUC;USP",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Urbana-Champaign;S\u00e3o Carlos",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "United States;Brazil"
    },
    {
        "id": "10160941",
        "title": "Cross-Agent Relocalization for Decentralized Collaborative SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art decentralized collaborative Simultaneous Localization And Mapping (SLAM) systems crucially lack the ability to effectively use well-mapped areas generated by other agents in the team for relocalization. This often leads to map redundancy between agents, inefficient communication, and the need for costly re-mapping of areas previously mapped by other agents. In this work, we propose a strategy to efficiently share the areas mapped by different agents in a collaborative, decentralized SLAM system. This approach directly addresses map redundancy while maintaining the consistency of the estimates across the agents and keeping the overall system scalable in terms of cross-agent communication and individual computational effort. Our method leverages covisibility information between keyframes instantiated by different agents to transfer local sub-maps on-the-fly in a completely decentralized, peer-to-peer fashion. A globally consistent estimate is achieved by solving a distributed bundle adjustment problem using the Alternating Direction Method of Multipliers (ADMM), where we enforce constraints on shared map points and keyframes across agents.",
        "primary_area": "",
        "author": "Philipp B\u00e4nninger;Ignacio Alzugaray;Marco Karrer;Margarita Chli;Philipp B\u00e4nninger;Ignacio Alzugaray;Marco Karrer;Margarita Chli",
        "authorids": "/37089381818;/37086016139;/37086206672;/37546501900;/37089381818;/37086016139;/37086206672;/37546501900",
        "aff": "ETH Z\u00fcrich, Vision for Robotics Lab, Switzerland; Department of Computing, Imperial College, London, UK; ETH Z\u00fcrich, Vision for Robotics Lab, Switzerland; ETH Z\u00fcrich, Vision for Robotics Lab, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160941/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13390093721905119140&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich;Imperial College London",
        "aff_unique_dep": "Vision for Robotics Lab;Department of Computing",
        "aff_unique_url": "https://www.ethz.ch;https://www.imperial.ac.uk",
        "aff_unique_abbr": "ETHZ;Imperial",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Switzerland;United Kingdom"
    },
    {
        "id": "10160810",
        "title": "Cross-Modal Monocular Localization in Prior LiDAR Maps Utilizing Semantic Consistency",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual localization for mobile robots and intelligent vehicles in prior LiDAR maps can achieve high accuracy and low cost. However, algorithms for finding the cross-modal correspondences between images and LiDAR map points are not yet stable. In this paper, we propose a monocular visual localization system in prior LiDAR maps, which is based on the cross-modal registration to optimize the camera pose. To align the point clouds from vision and LiDAR map, a point-to-plane Iterative Closest Point algorithm utilizing semantic consistency is designed, and a decoupling optimization strategy is proposed to compute the affine transformation for the monocular scale ambiguity. Experiments on KITTI dataset show that utilizing the semantic consistency and geometric information of the map makes our system competitive with other methods. On the self-collected dataset, experiments on different light intensities demonstrate the robustness of the system in long-term localization tasks, and the ablation study demonstrates the effectiveness of the proposed algorithms.",
        "primary_area": "",
        "author": "Chi Zhang;Hengwang Zhao;Chunxiang Wang;Xuanlai Tang;Ming Yang;Chi Zhang;Hengwang Zhao;Chunxiang Wang;Xuanlai Tang;Ming Yang",
        "authorids": "/37089544012;/37088633379;/37578423000;/37089892531;/37576820400;/37089544012;/37088633379;/37578423000;/37089892531;/37576820400",
        "aff": "Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai Jiao Tong University, Shanghai, China; KEENON Robotics Co., Ltd., China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160810/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=146119245587671629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;KEENON Robotics",
        "aff_unique_dep": "Department of Automation;",
        "aff_unique_url": "https://www.sjtu.edu.cn;",
        "aff_unique_abbr": "SJTU;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161478",
        "title": "Cross-Modality Time-Variant Relation Learning for Generating Dynamic Scene Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic scene graphs generated from video clips could help enhance the semantic visual understanding in a wide range of challenging tasks such as environmental perception, autonomous navigation, and task planning of self-driving vehicles and mobile robots. In the process of temporal and spatial modeling during dynamic scene graph generation, it is particularly intractable to learn time-variant relations in dynamic scene graphs among frames. In this paper, we propose a Time-variant Relation-aware TRansformer (TR2), which aims to model the temporal change of relations in dynamic scene graphs. Explicitly, we leverage the difference of text embeddings of prompted sentences about relation labels as the supervision signal for relations. In this way, cross-modality feature guidance is realized for the learning of time-variant relations. Implicitly, we design a relation feature fusion module with a transformer and an additional message token that describes the difference between adjacent frames. Extensive experiments on the Action Genome dataset prove that our TR2 can effectively model the time-variant relations. TR2 significantly outperforms previous state-of-the-art methods under two different settings by 2.1 % and 2.6% respectively.",
        "primary_area": "",
        "author": "Jingyi Wang;Jinfa Huang;Can Zhang;Zhidong Deng;Jingyi Wang;Jinfa Huang;Can Zhang;Zhidong Deng",
        "authorids": "/37089938794;/37089878840;/37088853687;/37330240100;/37089938794;/37089878840;/37088853687;/37330240100",
        "aff": "Department of Computer Science, Tsinghua University, Beijing, China; School of Electronic and Computer Engineering, Peking University, China; School of Electronic and Computer Engineering, Peking University, China; Department of Computer Science, Beijing National Research Center for Information Science and Technology (BNRist), THUAI, State Key Laboratory of Intelligent Technology and Systems, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161478/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7089102663869985333&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Tsinghua University;Peking University",
        "aff_unique_dep": "Department of Computer Science;School of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://www.pku.edu.cn",
        "aff_unique_abbr": "THU;Peking U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160662",
        "title": "Cross-domain Transfer Learning and State Inference for Soft Robots via a Semi-supervised Sequential Variational Bayes Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, data-driven models such as deep neural networks have shown to be promising tools for modelling and state inference in soft robots. However, voluminous amounts of data are necessary for deep models to perform effectively, which requires exhaustive and quality data collection, particularly of state labels. Consequently, obtaining labelled state data for soft robotic systems is challenged for various reasons, including difficulty in the sensorization of soft robots and the inconvenience of collecting data in unstructured environments. To address this challenge, in this paper, we propose a semi-supervised sequential variational Bayes (DSVB) framework for transfer learning and state inference in soft robots with missing state labels on certain robot configurations. Considering that soft robots may exhibit distinct dynamics under different robot configurations, a feature space transfer strategy is also incorporated to promote the adaptation of latent features across multiple configurations. Unlike existing transfer learning approaches, our proposed DSVB employs a recurrent neural network to model the nonlinear dynamics and temporal coherence in soft robot data. The proposed framework is validated on multiple setup configurations of a pneumatic-based soft robot finger. Experimental results on four transfer scenarios demonstrate that DSVB performs effective transfer learning and accurate state inference amidst missing state labels.",
        "primary_area": "",
        "author": "Shageenderan Sapai;Junn Yong Loo;Ze Yang Ding;Chee Pin Tan;Rapha\u00ebl C.-W. Phan;Vishnu Monn Baskaran;Surya Girinatha Nurzaman;Shageenderan Sapai;Junn Yong Loo;Ze Yang Ding;Chee Pin Tan;Rapha\u00ebl C.-W. Phan;Vishnu Monn Baskaran;Surya Girinatha Nurzaman",
        "authorids": "/37088748413;/37086958270;/37088319545;/37291019600;/37392880200;/37084844300;/37586367200;/37088748413;/37086958270;/37088319545;/37291019600;/37392880200;/37084844300;/37586367200",
        "aff": "School of Information Technology, Monash University Malaysia; School of Information Technology, Monash University Malaysia; School of Engineering, Monash University Malaysia; School of Engineering, Monash University Malaysia; School of Information Technology, Monash University Malaysia; School of Information Technology, Monash University Malaysia; School of Engineering, Monash University Malaysia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160662/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10745384787997177489&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Monash University Malaysia",
        "aff_unique_dep": "School of Information Technology",
        "aff_unique_url": "https://www.monash.edu.my",
        "aff_unique_abbr": "MUM",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Malaysia",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Malaysia"
    },
    {
        "id": "10161451",
        "title": "CrossDTR: Cross-view and Depth-guided Transformers for 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "To achieve accurate 3D object detection at a low cost for autonomous driving, many multi-camera methods have been proposed and solved the occlusion problem of monocular approaches. However, due to the lack of accurate estimated depth, existing multi-camera methods often generate multiple bounding boxes along a ray of depth direction for difficult small objects such as pedestrians, resulting in an extremely low recall. Furthermore, directly applying depth prediction modules to existing multi-camera methods, generally composed of large network architectures, cannot meet the real-time requirements of self-driving applications. To address these issues, we propose Cross-view and Depth-guided Transformers for 3D Object Detection, CrossDTR. First, our lightweight depth predictor is designed to produce precise object-wise sparse depth maps and low-dimensional depth embeddings without extra depth datasets during supervision. Second, a cross-view depth-guided transformer is developed to fuse the depth embeddings as well as image features from cameras of different views and generate 3D bounding boxes. Extensive experiments demonstrated that our method hugely surpassed existing multi-camera methods by 10 percent in pedestrian detection and about 3 percent in overall mAP and NDS metrics. Also, computational analyses showed that our method is 5 times faster than prior approaches. Our codes will be made publicly available at https://github.com/sty61010/CrossDTR.",
        "primary_area": "",
        "author": "Ching-Yu Tseng;Yi-Rong Chen;Hsin-Ying Lee;Tsung-Han Wu;Wen-Chin Chen;Winston H. Hsu;Ching-Yu Tseng;Yi-Rong Chen;Hsin-Ying Lee;Tsung-Han Wu;Wen-Chin Chen;Winston H. Hsu",
        "authorids": "/37089895397;/37089895731;/37089613229;/37088232411;/37088230745;/37272584600;/37089895397;/37089895731;/37089613229;/37088232411;/37088230745;/37272584600",
        "aff": "National Taiwan University; National Taiwan University; National Taiwan University; National Taiwan University; National Taiwan University; Mobile Drive Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161451/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12967633605250313957&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "National Taiwan University;Mobile Drive Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ntu.edu.tw;",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "10160765",
        "title": "CuRobo: Parallelized Collision-Free Robot Motion Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores the problem of collision-free motion generation for manipulators by formulating it as a global motion optimization problem. We develop a parallel optimization technique to solve this problem and demonstrate its effectiveness on massively parallel GPUs. We show that combining simple optimization techniques with many parallel seeds leads to solving difficult motion generation problems within 53ms on average, 62x faster than SOTA trajectory optimization methods. We achieve SOTA performance by combining L-BFGS step direction estimation with a novel parallel noisy line search scheme and a particle-based optimization solver. To further aid trajectory optimization, we develop a parallel geometric planner that is atleast 28x faster than SOTA RRTConnect implementations. We also introduce a collision-free IK solver that can solve over 9000 queries/s. We are releasing our GPU accelerated library CuRobo that contains core components for robot motion generation. Additional details are available at sites.google.com/nvidia.com/curobo.",
        "primary_area": "",
        "author": "Balakumar Sundaralingam;Siva Kumar Sastry Hari;Adam Fishman;Caelan Garrett;Karl Van Wyk;Valts Blukis;Alexander Millane;Helen Oleynikova;Ankur Handa;Fabio Ramos;Nathan Ratliff;Dieter Fox;Balakumar Sundaralingam;Siva Kumar Sastry Hari;Adam Fishman;Caelan Garrett;Karl Van Wyk;Valts Blukis;Alexander Millane;Helen Oleynikova;Ankur Handa;Fabio Ramos;Nathan Ratliff;Dieter Fox",
        "authorids": "/37086455625;/38192250000;/37088690696;/37085688184;/37085779307;/37086279571;/37085729647;/37085472384;/37546502600;/37285364500;/37579950900;/37284329000;/37086455625;/38192250000;/37088690696;/37085688184;/37085779307;/37086279571;/37085729647;/37085472384;/37546502600;/37285364500;/37579950900;/37284329000",
        "aff": "NVIDIA; NVIDIA; University of Washington; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; University of Sydney; NVIDIA; University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160765/",
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8933114625526871739&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;1;0;0;0;0;0;0;2;0;1",
        "aff_unique_norm": "NVIDIA Corporation;University of Washington;University of Sydney",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nvidia.com;https://www.washington.edu;https://www.sydney.edu.au",
        "aff_unique_abbr": "NVIDIA;UW;USYD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;1;0;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "10161576",
        "title": "CueCAn: Cue-driven Contextual Attention for Identifying Missing Traffic Signs on Unconstrained Roads",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Varun Gupta;Anbumani Subramanian;C.V. Jawahar;Rohit Saluja;Varun Gupta;Anbumani Subramanian;C.V. Jawahar;Rohit Saluja",
        "authorids": "/37089894048;/37086702670;/37270075200;/37086288748;/37089894048;/37086702670;/37270075200;/37086288748",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161576/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2344826495022509885&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "10160543",
        "title": "Curriculum-Based Imitation of Versatile Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning skills by imitation is a promising concept for the intuitive teaching of robots. A common way to learn such skills is to learn a parametric model by maximizing the likelihood given the demonstrations. Yet, human demonstrations are often multi-modal, i.e., the same task is solved in multiple ways which is a major challenge for most imitation learning methods that are based on such a maximum likelihood (ML) objective. The ML objective forces the model to cover all data, it prevents specialization in the context space and can cause mode-averaging in the behavior space, leading to suboptimal or potentially catastrophic behavior. Here, we alleviate those issues by introducing a curriculum using a weight for each data point, allowing the model to specialize on data it can represent while incentivizing it to cover as much data as possible by an entropy bonus. We extend our algorithm to a Mixture of (linear) Experts (MoE) such that the single components can specialize on local context regions, while the MoE covers all data points. We evaluate our approach in complex simulated and real robot control tasks and show it learns from versatile human demonstrations and significantly outperforms current SOTA methods. 11A reference implementation can be found at https://github.com/intuitive-robots/ML-Cur",
        "primary_area": "",
        "author": "Maximilian Xiling Li;Onur Celik;Philipp Becker;Denis Blessing;Rudolf Lioutikov;Gerhard Neumann;Maximilian Xiling Li;Onur Celik;Philipp Becker;Denis Blessing;Rudolf Lioutikov;Gerhard Neumann",
        "authorids": "/37089743647;/37089893814;/37089895398;/37089895390;/37085362450;/38542033100;/37089743647;/37089893814;/37089895398;/37089895390;/37085362450;/38542033100",
        "aff": "Intuitive Robots Lab, Karlsruhe Institute of Technology, Karlsruhe, Germany; Autonomous Learning Robots, Karlsruhe Institute of Technology, Karlsruhe, Germany; Autonomous Learning Robots, Karlsruhe Institute of Technology, Karlsruhe, Germany; Autonomous Learning Robots, Karlsruhe Institute of Technology, Karlsruhe, Germany; Intuitive Robots Lab, Karlsruhe Institute of Technology, Karlsruhe, Germany; Autonomous Learning Robots, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160543/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1680451375688815289&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Intuitive Robots Lab",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161177",
        "title": "Curvature-Aware Model Predictive Contouring Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel Curvature-Aware Model Pre-dictive Contouring Control (CA-MPCC) formulation for mobile robotics motion planning. Our method aims at generalizing the traditional contouring control formulation derived from machining to autonomous driving applications. The proposed controller is able of handling sharp curvatures in the reference path while subject to non-linear constraints, such as lane boundaries and dynamic obstacle collision avoidance. Com-pared to a standard MPCC formulation, our method improves the reliability of the path-following algorithm and simplifies the tuning, while preserving real-time capabilities. We validate our findings in both simulations and experiments on a scaled-down car-like robot.",
        "primary_area": "",
        "author": "Lorenzo Lyons;Laura Ferranti;Lorenzo Lyons;Laura Ferranti",
        "authorids": "/37089616686;/37085778570;/37089616686;/37085778570",
        "aff": "Department of Cognitive Robotics, Reliable Robot Control Lab, Delft University of Technology, Delft, CD, The Netherlands; Department of Cognitive Robotics, Reliable Robot Control Lab, Delft University of Technology, Delft, CD, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161177/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11462927627150045682&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Department of Cognitive Robotics",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10161160",
        "title": "CurveFormer: 3D Lane Detection by Curve Propagation with Curve Queries and Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "3D lane detection is an integral part of au-tonomous driving systems. Previous CNN and Transformer-based methods usually first generate a bird's-eye-view (BEV) feature map from the front view image, and then use a sub-network with BEV feature map as input to predict 3D lanes. Such approaches require an explicit view transformation between BEV and front view, which itself is still a challenging problem. In this paper, we propose CurveFormer, a single-stage Transformer-based method that directly calculates 3D lane pa-rameters and can circumvent the difficult view transformation step. Specifically, we formulate 3D lane detection as a curve propagation problem by using curve queries. A 3D lane query is represented by a dynamic and ordered anchor point set. In this way, queries with curve representation in Transformer decoder iteratively refine the 3D lane detection results. Moreover, a curve cross-attention module is introduced to compute the similarities between curve queries and image features. Additionally, a context sampling module that can capture more relative image features of a curve query is provided to further boost the 3D lane detection performance. We evaluate our method for 3D lane detection on both synthetic and real-world datasets, and the experimental results show that our method achieves promising performance compared with the state-of-the-art approaches. The effectiveness of each component is validated via ablation studies as well.",
        "primary_area": "",
        "author": "Yifeng Bai;Zhirong Chen;Zhangjie Fu;Lang Peng;Pengpeng Liang;Erkang Cheng;Yifeng Bai;Zhirong Chen;Zhangjie Fu;Lang Peng;Pengpeng Liang;Erkang Cheng",
        "authorids": "/37089893341;/37089713627;/37089714577;/37089709534;/37076966700;/37088874018;/37089893341;/37089713627;/37089714577;/37089709534;/37076966700;/37088874018",
        "aff": "University of Science and Technology of China, Hefei, China; NullMax, Shanghai, China; NullMax, Shanghai, China; NullMax, Shanghai, China; School of Computer and Artificial Intelligence, Zhengzhou University, China; NullMax, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161160/",
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17683237931097818818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;2;1",
        "aff_unique_norm": "University of Science and Technology of China;NullMax;Zhengzhou University",
        "aff_unique_dep": ";;School of Computer and Artificial Intelligence",
        "aff_unique_url": "http://www.ustc.edu.cn;;http://www.zzu.edu.cn",
        "aff_unique_abbr": "USTC;;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Hefei;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160484",
        "title": "D-Align: Dual Query Co-attention Network for 3D Object Detection Based on Multi-frame Point Cloud Sequence",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR sensors are widely used for 3D object detection in various mobile robotics applications. LiDAR sensors continuously generate point cloud data in real-time. Conventional 3D object detectors detect objects using a set of points acquired over a fixed duration. However, recent studies have shown that the performance of object detection can be further enhanced by utilizing spatio-temporal information obtained from point cloud sequences. In this paper, we propose a new 3D object detector, named D-Align, which can effectively produce strong bird's-eye-view (BEV) features by aligning and aggregating the features obtained from a sequence of point sets. The proposed method includes a novel dual-query co-attention network that uses two types of queries, including target query set (T-QS) and support query set (S-QS), to update the features of target and support frames, respectively. D-Align aligns S-QS to T-QS based on the temporal context features extracted from the adjacent feature maps and then aggregates S-QS with T-QS using a gated fusion mechanism. The dual queries are updated through multiple attention layers to progressively enhance the target frame features used to produce the detection results. Our experiments on the nuScenes dataset show that the proposed D-Align method greatly improved the performance of a single frame-based baseline method and significantly outperformed the latest 3D object detectors. Code is available at https://github.com/junhyung-SPALab/D-Align.",
        "primary_area": "",
        "author": "Junhyung Lee;Junho Koh;Youngwoo Lee;Jun Won Choi;Junhyung Lee;Junho Koh;Youngwoo Lee;Jun Won Choi",
        "authorids": "/37089896039;/37086487628;/37089891875;/37405961800;/37089896039;/37086487628;/37089891875;/37405961800",
        "aff": "Department of Future Mobility, Hanyang University, Seoul, Korea; Department of Electrical Engineering, Hanyang University, Seoul, Korea; Department of Electrical Engineering, Hanyang University, Seoul, Korea; Department of Electrical Engineering, Hanyang University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160484/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2682818353459077204&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hanyang University",
        "aff_unique_dep": "Department of Future Mobility",
        "aff_unique_url": "http://www.hanyang.ac.kr",
        "aff_unique_abbr": "HYU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160341",
        "title": "D2CoPlan: A Differentiable Decentralized Planner for Multi-Robot Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "Centralized approaches for multi-robot coverage planning problems suffer from the lack of scalability. Learning-based distributed algorithms provide a scalable avenue in addition to bringing data-oriented feature generation capabilities to the table, allowing integration with other learning-based approaches. To this end, we present a learning-based, differentiable distributed coverage planner (D2CoPLAN) which scales efficiently in runtime and number of agents compared to the expert algorithm, and performs on par with the classical distributed algorithm. In addition, we show that D2CoPLANcan be seamlessly combined with other learning methods to learn end-to-end, resulting in a better solution than the individually trained modules, opening doors to further research for tasks that remain elusive with classical methods.",
        "primary_area": "",
        "author": "Vishnu Dutt Sharma;Lifeng Zhou;Pratap Tokekar;Vishnu Dutt Sharma;Lifeng Zhou;Pratap Tokekar",
        "authorids": "/37088689166;/37086092920;/37546532700;/37088689166;/37086092920;/37546532700",
        "aff": "Dept. of Computer Science, University of Maryland, College Park, MD, USA; Dept. of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, USA; Dept. of Computer Science, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160341/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10579471713573252663&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Maryland;Drexel University",
        "aff_unique_dep": "Department of Computer Science;Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www/umd.edu;https://drexel.edu",
        "aff_unique_abbr": "UMD;Drexel",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "College Park;Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161000",
        "title": "D2NT: A High-Performing Depth-to-Normal Translator",
        "track": "main",
        "status": "Poster",
        "abstract": "Surface normal holds significant importance in visual environmental perception, serving as a source of rich geometric information. However, the state-of-the-art (SoTA) surface normal estimators (SNEs) generally suffer from an unsatisfactory trade-off between efficiency and accuracy. To resolve this dilemma, this paper first presents a superfast depth-to-normal translator (D2NT), which can directly translate depth images into surface normal maps without calculating 3D coordinates. We then propose a discontinuity-aware gradient (DAG) filter, which adaptively generates gradient convolution kernels to improve depth gradient estimation. Finally, we propose a surface normal refinement module that can easily be integrated into any depth-to-normal SNEs, substantially improving the surface normal estimation accuracy. Our proposed algorithm demonstrates the best accuracy among all other existing real-time SNEs and achieves the SoTA trade-off between efficiency and accuracy.",
        "primary_area": "",
        "author": "Yi Feng;Bohuan Xue;Ming Liu;Qijun Chen;Rui Fan;Yi Feng;Bohuan Xue;Ming Liu;Qijun Chen;Rui Fan",
        "authorids": "/37089703437;/37087244661;/37085398677;/37276133600;/37085892666;/37089703437;/37087244661;/37085398677;/37276133600;/37085892666",
        "aff": "Robotics & Artificial Intelligence Laboratory (RAIL), the State Key Laboratory of Intelligent Autonomous Systems, and Frontiers Science Center for Intelligent Autonomous Systems, the College of Electronic & Information Engineering, Tongji University, Shanghai, P. R. China; Department of Computer Science & Engineering, the Hong Kong University of Science and Technology (Guangzhou), Hong Kong SAR, P. R. China; Robotics & Autonomous Systems Thrust of the Systems Hub, the Hong Kong University of Science and Technol-ogy (Guangzhou), Nansha, Guangzhou, P. R. China; Robotics & Artificial Intelligence Laboratory (RAIL), the State Key Laboratory of Intelligent Autonomous Systems, and Frontiers Science Center for Intelligent Autonomous Systems, the College of Electronic & Information Engineering, Tongji University, Shanghai, P. R. China; Robotics & Artificial Intelligence Laboratory (RAIL), the State Key Laboratory of Intelligent Autonomous Systems, and Frontiers Science Center for Intelligent Autonomous Systems, the College of Electronic & Information Engineering, Tongji University, Shanghai, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161000/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11490914310756170867&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Tongji University;Hong Kong University of Science and Technology",
        "aff_unique_dep": "College of Electronic & Information Engineering;Department of Computer Science & Engineering",
        "aff_unique_url": "http://www.tongji.edu.cn;https://www.ust.hk",
        "aff_unique_abbr": "Tongji;HKUST",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Shanghai;Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160971",
        "title": "DAMS-LIO: A Degeneration-Aware and Modular Sensor-Fusion LiDAR-inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "With robots being deployed in increasingly complex environments like underground mines and planetary surfaces, the multi-sensor fusion method has gained more and more attention which is a promising solution to state estimation in the such scene. The fusion scheme is a central component of these methods. In this paper, a light-weight iEKF-based LiDAR-inertial odometry system is presented, which utilizes a degeneration-aware and modular sensor-fusion pipeline that takes both LiDAR points and relative pose from another odometry as the measurement in the update process only when degeneration is detected. Both the Cramer-Rao Lower Bound (CRLB) theory and simulation test are used to demonstrate the higher accuracy of our method compared to methods using a single observation. Furthermore, the proposed system is evaluated in perceptually challenging datasets against various state-of-the-art sensor-fusion methods. The results show that the proposed system achieves real-time and high estimation accuracy performance despite the challenging environment and poor observations.",
        "primary_area": "",
        "author": "Fuzhang Han;Han Zheng;Wenjun Huang;Rong Xiong;Yue Wang;Yanmei Jiao;Fuzhang Han;Han Zheng;Wenjun Huang;Rong Xiong;Yue Wang;Yanmei Jiao",
        "authorids": "/37088657317;/37089892001;/37087882607;/37271511300;/37072299700;/37086475262;/37088657317;/37089892001;/37087882607;/37271511300;/37072299700;/37086475262",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; College of Electrical Engineering, Zhejiang University, China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160971/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10405961482092601473&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Zhejiang University;Hangzhou Normal University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology;School of Information Science and Engineering",
        "aff_unique_url": "http://www.zju.edu.cn;http://www.hgh.edu.cn",
        "aff_unique_abbr": "ZJU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160931",
        "title": "DC-MOT: Motion Deblurring and Compensation for Multi-Object Tracking in UAV Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a multi-object tracking framework for videos captured by UAVs, considering motion imperfection in the following two aspects: 1) motion blurring of objects due to high-speed motion of the UAV and the objects, deteriorating the performance of the detector; 2) motion coupling of the global movement of the UAV camera with the object motion, resulting in the nonlinearity of objects trajectories in adjacent frames and further more difficult to predict. For motion blurring, this paper proposes a hybrid deblurring module that deals with the blurred frames while retaining the clear frames, trading off between video tracking performance and spatio-temporal consistency. For motion coupling, we proposed a motion compensation module to align adjacent frames by feature matching, and the corrected target position is obtained in the next frame to alleviate the interference of camera movement with tracking. We evaluate the proposed methods on VisDrone dataset and validate that our framework achieves new state-of-the-art performance on UAV-based MOT systems.",
        "primary_area": "",
        "author": "Song Cheng;Meibao Yao;Xueming Xiao;Song Cheng;Meibao Yao;Xueming Xiao",
        "authorids": "/37088907126;/37086470879;/37085625137;/37088907126;/37086470879;/37085625137",
        "aff": "Engineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China; Engineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China; Key Lab of Optoelectronic Measurement and Optical Information Transmission Technology, Ministry of Education, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160931/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9808080866732952064&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Engineering Research Center of Knowledge-Driven Human-Machine Intelligence;Ministry of Education",
        "aff_unique_dep": "Ministry of Education;Key Lab of Optoelectronic Measurement and Optical Information Transmission Technology",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161104",
        "title": "DDK: A Deep Koopman Approach for Longitudinal and Lateral Control of Autonomous Ground Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous driving has attracted lots of attention in recent years. For some tasks, e.g., trajectory prediction, motion planning, and trajectory tracking, an accurate vehicle model can reduce the difficulty of these tasks and improve task completion performance. Prior works focused on parameter estimation of physical models or modeling nonlinear dynamics using neural networks. Still, these methods rely on internal parameters of vehicles or are not friendly for control due to the strong nonlinearity of models. This paper proposes a data-driven method to approximate vehicle dynamics based on the Koopman operator. The resulting model is an interpretable linear time-invariant model, facilitating controller design and solving related optimization problems. In the proposed approach, the state transition matrix is constructed based on the learned Koopman eigenvalues, while the input matrix is trained as a tensor. Based on the resulting model, a linear model predictive controller is designed to implement coupled longitudinal and lateral trajectory tracking. Simulations and experiments, including vehicle dynamics modeling and coupled longitudinal and lateral trajectory tracking, are performed in a high-fidelity CarSim environment and a real vehicle platform. An oil-driven D-Class SUV is selected in the simulation, while a real electric SUV is utilized in the experiment. Simulation and experiment results illustrate that the model of the nonlinear vehicle dynamics can be identified effectively via the proposed method, and high-quality trajectory tracking performance can be obtained with the resulting model.",
        "primary_area": "",
        "author": "Yongqian Xiao;Xinglong Zhang;Xin Xu;Yang Lu;Junxiang Lil;Yongqian Xiao;Xinglong Zhang;Xin Xu;Yang Lu;Junxiang Lil",
        "authorids": "/37089699290;/37088567941;/37334606400;/37088569359;/37089895716;/37089699290;/37088567941;/37334606400;/37088569359;/37089895716",
        "aff": "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, P. R. China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, P. R. China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, P. R. China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, P. R. China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161104/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15870427616528511223&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "College of Intelligence Science and Technology",
        "aff_unique_url": "http://www.nudt.edu.cn",
        "aff_unique_abbr": "NUDT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160489",
        "title": "DDS3D: Dense Pseudo-Labels with Dynamic Threshold for Semi-Supervised 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a simple yet effective semi-supervised 3D object detector named DDS3D. Our main contributions have two-fold. On the one hand, different from previous works using Non-Maximal Suppression (NMS) or its variants for obtaining the sparse pseudo labels, we propose a dense pseudo-label generation strategy to get dense pseudo-labels, which can retain more potential supervision information for the student network. On the other hand, instead of traditional fixed thresholds, we propose a dynamic threshold manner to generate pseudo-labels, which can guarantee the quality and quantity of pseudo-labels during the whole training process. Benefiting from these two components, our DDS3D outperforms the state-of-the-art semi-supervised 3d object detection with mAP of 3.1% on the pedestrian and 2.1% on the cyclist under the same configuration of 1% samples. Extensive ablation studies on the KITTI dataset demonstrate the effectiveness of our DDS3D. The code and models will be made publicly available at https://github.com/hust-jy/DDS3D",
        "primary_area": "",
        "author": "Jingyu Li;Zhe Liu;Jinghua Hou;Dingkang Liang;Jingyu Li;Zhe Liu;Jinghua Hou;Dingkang Liang",
        "authorids": "/37089894937;/37086347435;/37089895252;/37089021716;/37089894937;/37086347435;/37089895252;/37089021716",
        "aff": "School of Electronic Information and Communication, Huazhong University of Science and Technology; School of Electronic Information and Communication, Huazhong University of Science and Technology; School of Electronic Information and Communication, Huazhong University of Science and Technology; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160489/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7219197224232294496&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huazhong University of Science and Technology",
        "aff_unique_dep": "School of Electronic Information and Communication",
        "aff_unique_url": "http://www.hust.edu.cn",
        "aff_unique_abbr": "HUST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160910",
        "title": "DEdgeNet: Extrinsic Calibration of Camera and LiDAR with Depth-discontinuous Edges",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of calibrating extrinsic parameter matrix between an RGB camera and a LiDAR. Multimodal sensing systems are essential for fully autonomous navigation platforms. A key pre-requisite for such a system is calibration between different sensors. As the two most widely equipped sensors, calibration between RGB cameras and LiDARs remains challenging. Existing methods address this problem without using explicit geometric priors. In this paper, we propose a novel real-time network that utilizes depth-discontinuous edges extracted from a single image to calibrate cameras and LiDARs. Our network consists of two key components: (1) a self-supervised edge extraction network named DEdgeNet, which detects depth-discontinuous edges from a single image and extracts corresponding features; (2) prediction of the extrinsic parameter matrix between the camera and the LiDAR by matching fixed features in RGB images and updating depth features in a coarse-to-fine frame. Specifically, considering that edges are rich and common in natural scenes, DEdgeNet simplifies RGB image encoding and extracts fixed edges for feature matching. We conducted extensive experiments on the KITTI-odometry dataset. The results show that our method achieves an average rotation error of 0.028\u00b0 and an average translation error of 0.247 cm, which demonstrates the superiority of our method.",
        "primary_area": "",
        "author": "Yiyang Hu;Hui Ma;Leiping Jie;Hui Zhang;Yiyang Hu;Hui Ma;Leiping Jie;Hui Zhang",
        "authorids": "/37089894237;/37089895767;/37089468102;/37559772500;/37089894237;/37089895767;/37089468102;/37559772500",
        "aff": "Faculty of Science and Technology, United International College, BNU-HKBU, Zhuhai, China; Faculty of Science and Technology, United International College, BNU-HKBU, Zhuhai, China; Faculty of Science and Technology, United International College, BNU-HKBU, Zhuhai, China; Faculty of Science and Technology, United International College, BNU-HKBU, Zhuhai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160910/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11604936317178749049&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "United International College",
        "aff_unique_dep": "Faculty of Science and Technology",
        "aff_unique_url": "https://www.uic.edu.hk",
        "aff_unique_abbr": "UIC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zhuhai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160328",
        "title": "DFR-FastMOT: Detection Failure Resistant Tracker for Fast Multi-Object Tracking Based on Sensor Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Persistent multi-object tracking (MOT) allows autonomous vehicles to navigate safely in highly dynamic environments. One of the well-known challenges in MOT is object occlusion when an object becomes unobservant for subsequent frames. The current MOT methods store objects information, such as trajectories, in internal memory to recover the objects after occlusions. However, they retain short-term memory to save computational time and avoid slowing down the MOT method. As a result, they lose track of objects in some occlusion scenarios, particularly long ones. In this paper, we propose DFR-FastMOT, a light MOT method that uses data from a camera and LiDAR sensors and relies on an algebraic formulation for object association and fusion. The formulation boosts the computational time and permits long-term memory that tackles more occlusion scenarios. Our method shows outstanding tracking performance over recent learning and non-learning benchmarks with about 3% and 4% margin in MOTA, respectively. Also, we conduct extensive experiments that simulate occlusion phenomena by employing detectors with various distortion levels. The proposed solution enables superior performance under various distortion levels in detection over current state-of-art methods. Our framework processes about 7,763 frames in 1.48 seconds, which is seven times faster than recent benchmarks. The framework will be available at https://github.com/MohamedNagyMostafa/DFR-FastMOT.",
        "primary_area": "",
        "author": "Mohamed Nagy;Majid Khonji;Jorge Dias;Sajid Javed;Mohamed Nagy;Majid Khonji;Jorge Dias;Sajid Javed",
        "authorids": "/37089895663;/37085584255;/37274037500;/37085461619;/37089895663;/37085584255;/37274037500;/37085461619",
        "aff": "Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, United Arab Emirates; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, United Arab Emirates; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, United Arab Emirates; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, United Arab Emirates",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160328/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14340143687040280041&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Khalifa University",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.khalifa.edu",
        "aff_unique_abbr": "KU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Abu Dhabi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Arab Emirates"
    },
    {
        "id": "10160437",
        "title": "DLOFTBs \u2013 Fast Tracking of Deformable Linear Objects with B-splines",
        "track": "main",
        "status": "Poster",
        "abstract": "While manipulating rigid objects is an extensively explored research topic, deformable linear object (DLO) manipulation seems significantly underdeveloped. A potential reason for this is the inherent difficulty in describing and observing the state of the DLO as its geometry changes during manipulation. This paper proposes an algorithm for fast-tracking the shape of a DLO based on the masked image. Having no prior knowledge about the tracked object, the proposed method finds a reliable representation of the shape of the tracked object within tens of milliseconds. This algorithm's main idea is to first skeletonize the DLO mask image, walk through the parts of the DLO skeleton, arrange the segments into an ordered path, and finally fit a B-spline into it. Experiments show that our solution outperforms the State-of-the-Art approaches in DLO's shape reconstruction accuracy and algorithm running time and can handle challenging scenarios such as severe occlusions, self-intersections, and multiple DLOs in a single image.",
        "primary_area": "",
        "author": "Piotr Kicki;Amadeusz Szymko;Krzysztof Walas;Piotr Kicki;Amadeusz Szymko;Krzysztof Walas",
        "authorids": "/37086604933;/37089894119;/37688621800;/37086604933;/37089894119;/37688621800",
        "aff": "Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160437/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4675651112901541414&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Poznan University of Technology",
        "aff_unique_dep": "Institute of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.put.poznan.pl/",
        "aff_unique_abbr": "PUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Poznan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Poland"
    },
    {
        "id": "10160401",
        "title": "DMMGAN: Diverse Multi Motion Prediction of 3D Human Joints using Attention-Based Generative Adversarial Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Human body motion prediction is a fundamental part of many human-robot applications. Despite the recent progress in the area, most studies predict human body motion relative to a fixed joint and only limit their model to predict one possible future motion, or both. However, due to the complex nature of human motion, a single prediction cannot adequately reflect the many possible movements one can make. Also, for any robotics application, prediction of the full human body motion including the absolute 3D trajectory - not just a 3D body pose relative to the hip joint - is needed. In this paper, we try to address these two shortcomings by proposing a transformer-based generative model for forecasting multiple diverse human motions. Our model generates NN future possible body motions given the human motion history. This is achieved by first predicting the pose of the body relative to the hip joint as was done in prior work. Then, our proposed Hip Prediction Module predicts the trajectory of the hip position relative to a global reference frame for each predicted pose frame, an aspect of human body motion neglected by previous work. To obtain a set of diverse predicted motions, we introduce a similarity loss that penalizes the pairwise sample distance. Our system not only outperforms the state-of-the-art in human motion prediction, but also is able to predict a diverse set of future human body motions, including the hip trajectory.",
        "primary_area": "",
        "author": "Payam Nikdel;Mohammad Mahdavian;Mo Chen;Payam Nikdel;Mohammad Mahdavian;Mo Chen",
        "authorids": "/37086454305;/37085364544;/37085494765;/37086454305;/37085364544;/37085494765",
        "aff": "School of Computing Science, Simon Fraser University (SFU), Canada; School of Computing Science, Simon Fraser University (SFU), Canada; School of Computing Science, Simon Fraser University (SFU), Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160401/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3336528316812199415&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "School of Computing Science",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "SFU",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161164",
        "title": "DOTIE - Detecting Objects through Temporal Isolation of Events using a Spiking Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based autonomous navigation systems rely on fast and accurate object detection algorithms to avoid obstacles. Algorithms and sensors designed for such systems need to be computationally efficient, due to the limited energy of the hardware used for deployment. Biologically inspired event cameras are a good candidate as a vision sensor for such systems due to their speed, energy efficiency, and robustness to varying lighting conditions. However, traditional computer vision algorithms fail to work on event-based outputs, as they lack photometric features such as light intensity and texture. In this work, we propose a novel technique that utilizes the temporal information inherently present in the events to efficiently detect moving objects. Our technique consists of a lightweight spiking neural architecture that is able to separate events based on the speed of the corresponding objects. These separated events are then further grouped spatially to determine object boundaries. This method of object detection is both asynchronous and robust to camera noise. In addition, it shows good performance in scenarios with events generated by static objects in the background, where existing event-based algorithms fail. We show that by utilizing our architecture, autonomous navigation systems can have minimal latency and energy overheads for performing object detection.",
        "primary_area": "",
        "author": "Manish Nagaraj;Chamika Mihiranga Liyanagedera;Kaushik Roy;Manish Nagaraj;Chamika Mihiranga Liyanagedera;Kaushik Roy",
        "authorids": "/37086830632;/37891661900;/37274519700;/37086830632;/37891661900;/37274519700",
        "aff": "Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161164/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8372818001605489037&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161023",
        "title": "DQN-based on-line Path Planning Method for Automatic Navigation of Miniature Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Untethered magnetic microrobots with control-lable locomotion property and multiple functions have attracted lots of attention in recent years. Owing to the small scale, micro-robots with automatic navigation possess a promising perspec-tive for biomedical applications including precise delivery and targeted therapy in confined and narrow space, especially for in-vivo scenario. However, the practical working environment for microrobots can be various, dynamic, and complicated, and path planning algorithm applicable for both dynamic obstacle avoidance and planning in maze-like environments still remains a challenge. Furthermore, considering the sizes, different types of microrobots may occupy different proportions of the field of vision. The safe distance between the waypoints and the obstacles needs to be taken into thoughts. In this work, we proposed a reinforcement learning-based strategy capable of real-time path planning for microrobots in different scales. The reference moving direction at each control period is provided by a deep Q network (DQN) according to the local surrounding environment, and the corresponding control magnetic field is generated via a 3-axis Helmholtz coil system. A distur-bance observer (DOB) is responsible for the locomotion state observation and direction error compensation. Experiments demonstrate the effectiveness of our proposed strategy using microrobots with different locomotion mechanisms and scales, in both virtual dynamic obstacle environments and channel-like environments.",
        "primary_area": "",
        "author": "Jialin Jiang;Lidong Yang;Li Zhang;Jialin Jiang;Lidong Yang;Li Zhang",
        "authorids": "/37086351869;/37086079463;/37085379138;/37086351869;/37086079463;/37085379138",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Shatin NT, Hong Kong, China; Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University (PolyU), Kowloon, Hong Kong, China; Multi-Scale Medical Robotics Center, Shatin NT, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161023/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10061919219172587561&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "The Chinese University of Hong Kong;The Hong Kong Polytechnic University;Multi-Scale Medical Robotics Center",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Department of Industrial and Systems Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.polyu.edu.hk;",
        "aff_unique_abbr": "CUHK;PolyU;",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Shatin NT;Kowloon;Shatin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160364",
        "title": "DS-K3DOM: 3-D Dynamic Occupancy Mapping with Kernel Inference and Dempster-Shafer Evidential Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "Occupancy mapping has been widely utilized to represent the surroundings for autonomous robots to perform tasks such as navigation and manipulation. While occupancy mapping in 2-D environments has been well-studied, there have been few approaches suitable for 3-D dynamic occupancy mapping which is essential for aerial robots. This paper presents a novel 3-D dynamic occupancy mapping algorithm called DS-K3DOM. We first establish a Bayesian method to sequentially update occupancy maps for a stream of measurements based on the random finite set theory. Then, we approximate it with particles in the Dempster-Shafer domain to enable real-time computation. Moreover, the algorithm applies kernel-based inference with Dirichlet basic belief assignment to enable dense mapping from sparse measurements. The efficacy of the proposed algorithm is demonstrated through simulations and real experimentsiiThe code is available at: https://github.com/JuyeopHan/dsk3dom_public.",
        "primary_area": "",
        "author": "Juyeop Han;Youngjae Min;Hyeok-Joo Chae;Byeong-Min Jeong;Han-Lim Choi;Juyeop Han;Youngjae Min;Hyeok-Joo Chae;Byeong-Min Jeong;Han-Lim Choi",
        "authorids": "/37089894734;/37087015731;/37085589352;/37085555745;/37308867500;/37089894734;/37087015731;/37085589352;/37085555745;/37308867500",
        "aff": "Department of Aerospace Engineering, KAIST Institutes for Robotics, Korea Advanced Institide of Science and Technology (KAIST), Daejeon, South Korea; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Aerospace Engineering, KAIST Institutes for Robotics, Korea Advanced Institide of Science and Technology (KAIST), Daejeon, South Korea; Department of Aerospace Engineering, KAIST Institutes for Robotics, Korea Advanced Institide of Science and Technology (KAIST), Daejeon, South Korea; Department of Aerospace Engineering, KAIST Institutes for Robotics, Korea Advanced Institide of Science and Technology (KAIST), Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160364/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6370225851012045991&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology (KAIST);Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aerospace Engineering;Laboratory for Information and Decision Systems (LIDS)",
        "aff_unique_url": "https://www.kaist.ac.kr;https://web.mit.edu",
        "aff_unique_abbr": "KAIST;MIT",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Daejeon;Cambridge",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "10160796",
        "title": "DTact: A Vision-Based Tactile Sensor that Measures High-Resolution 3D Geometry Directly from Darkness",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based tactile sensors that can measure 3D geometry of the contacting objects are crucial for robots to perform dexterous manipulation tasks. However, the existing sensors are usually complicated to fabricate and delicate to extend. In this work, we novelly take advantage of the reflection property of semitransparent elastomer to design a robust, low-cost, and easy-to-fabricate tactile sensor named DTact. DTact measures high-resolution 3D geometry accurately from the darkness shown in the captured tactile images with only a single image for calibration. In contrast to previous sensors, DTact is robust under various illumination conditions. Then, we build prototypes of DTact that have non-planar contact surfaces with minimal extra efforts and costs. Finally, we perform two intelligent robotic tasks including pose estimation and object recognition using DTact, in which DTact shows large potential in applications.",
        "primary_area": "",
        "author": "Changyi Lin;Ziqi Lin;Shaoxiong Wang;Huazhe Xu;Changyi Lin;Ziqi Lin;Shaoxiong Wang;Huazhe Xu",
        "authorids": "/37089894603;/37089895406;/37086252778;/37086242886;/37089894603;/37089895406;/37086252778;/37086242886",
        "aff": "Shanghai Qi Zhi Institute, China; Tsinghua University, China; Massachusetts Institute of Technology, United States; Shanghai Qi Zhi Institute, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160796/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7817914438860114106&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Shanghai Qi Zhi Institute;Tsinghua University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.tsinghua.edu.cn;https://web.mit.edu",
        "aff_unique_abbr": ";THU;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160719",
        "title": "Data-Association-Free Landmark-based SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We study landmark-based SLAM with unknown data association: our robot navigates in a completely unknown environment and has to simultaneously reason over its own trajectory, the positions of an unknown number of landmarks in the environment, and potential data associations between measurements and landmarks. This setup is interesting since: (i) it arises when recovering from data association failures or from SLAM with information-poor sensors, (ii) it sheds light on fundamental limits (and hardness) of landmark-based SLAM problems irrespective of the front-end data association method, and (iii) it generalizes existing approaches where data association is assumed to be known or partially known. We approach the problem by splitting it into an inner problem of estimating the trajectory, landmark positions and data associations and an outer problem of estimating the number of landmarks. Our approach creates useful and novel connections with existing techniques from discrete-continuous optimization (e.g., k-means clustering), which has the potential to trigger novel research. We demonstrate the proposed approaches in extensive simulations and on real datasets and show that the proposed techniques outperform typical data association baselines and are even competitive against an \u201coracle\u201d baseline which has access to the number of landmarks and an initial guess for each landmark.",
        "primary_area": "",
        "author": "Yihao Zhang;Odin A. Severinsen;John J. Leonard;Luca Carlone;Kasra Khosoussi;Yihao Zhang;Odin A. Severinsen;John J. Leonard;Luca Carlone;Kasra Khosoussi",
        "authorids": "/37088999548;/37089660564;/37329387400;/37545784100;/37085362096;/37088999548;/37089660564;/37329387400;/37545784100;/37085362096",
        "aff": "Massachusetts Institute of Technology, United States; Massachusetts Institute of Technology, United States; Massachusetts Institute of Technology, United States; Massachusetts Institute of Technology, United States; Commonwealth Scientific and Industrial Research Organisation (CSIRO), Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160719/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12857749207691756411&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Commonwealth Scientific and Industrial Research Organisation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.csiro.au",
        "aff_unique_abbr": "MIT;CSIRO",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "10161391",
        "title": "Data-Driven Estimation of Forces Along the Backbone of Concentric Tube Continuum Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Concentric tube continuum robots (CTCRs) belong to the family of continuum robots with applications in minimally invasive surgeries. Because of this application domain, measuring the external forces along the body of the robot is paramount. CTCRs are made up of thin elastic rods and are intended to be applied inside the human body, where conventional sensor-based measurements are not feasible. Consequently, research is resorting to estimate the forces through geometric, numeric, or optimization methods. However, these methods often suffer from slow convergence. In this paper, we introduce a novel data-driven approach for estimating contact forces along the body of a CTCR that offers an estimation precision comparable to the current state-of-the-art optimization-based approaches, but exhibits nearly two orders of magnitude faster convergence. The proposed method is scalable and exhibits a significant performance in response to a wide range of external forces. The approach was evaluated in simulations and on a real 2-tube CTCR.",
        "primary_area": "",
        "author": "Heiko Donat;Pouya Mohammadi;Jochen Steil;Heiko Donat;Pouya Mohammadi;Jochen Steil",
        "authorids": "/37088504042;/37085482974;/37328304300;/37088504042;/37085482974;/37328304300",
        "aff": "The Institute of Robotics and Process Control - IRP, Technische Universit\u00e4t Braunschweig, Germany; The Institute of Robotics and Process Control - IRP, Technische Universit\u00e4t Braunschweig, Germany; The Institute of Robotics and Process Control - IRP, Technische Universit\u00e4t Braunschweig, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161391/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:fB0JfSIN114J:scholar.google.com/&scioq=Data-Driven+Estimation+of+Forces+Along+the+Backbone+of+Concentric+Tube+Continuum+Robots&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Braunschweig",
        "aff_unique_dep": "Institute of Robotics and Process Control - IRP",
        "aff_unique_url": "https://www.tu-braunschweig.de",
        "aff_unique_abbr": "TU Braunschweig",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161002",
        "title": "Data-Driven Risk-sensitive Model Predictive Control for Safe Navigation in Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe navigation is a fundamental challenge in multi-robot systems due to the uncertainty surrounding the future trajectory of the robots that act as obstacles for each other. In this work, we propose a principled data-driven approach where each robot repeatedly solves a finite horizon optimization problem subject to collision avoidance constraints with latter being formulated as distributionally robust conditional value-at-risk (CVaR) of the distance between the agent and a polyhedral obstacle geometry. Specifically, the CVaR constraints are required to hold for all distributions that are close to the empirical distribution constructed from observed samples of prediction error collected during execution. The generality of the approach allows us to robustify against prediction errors that arise under commonly imposed assumptions in both distributed and decentralized settings. We derive tractable finite-dimensional approximations of this class of constraints by leveraging convex and minmax duality results for Wasserstein distributionally robust optimization problems. The effectiveness of the proposed approach is illustrated in a multi-drone navigation setting implemented in Gazebo platform.",
        "primary_area": "",
        "author": "Atharva Navsalkar;Ashish R. Hota;Atharva Navsalkar;Ashish R. Hota",
        "authorids": "/37089302282;/37857659300;/37089302282;/37857659300",
        "aff": "Department of Mechanical Engineering, Indian Istitute of Technology (IIT), Kharagpur, India; Department of Electrical Engineering, Indian Institute of Technology (IIT), Kharagpur, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161002/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12068482933417836716&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Indian Institute of Technology Kharagpur;Indian Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical Engineering",
        "aff_unique_url": "https://www.iitkgp.ac.in;https://iitkgp.ac.in",
        "aff_unique_abbr": "IIT Kharagpur;IIT Kharagpur",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kharagpur",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "10160418",
        "title": "Data-Driven Spectral Submanifold Reduction for Nonlinear Optimal Control of High-Dimensional Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling and control of high-dimensional, nonlinear robotic systems remains a challenging task. While various model- and learning-based approaches have been proposed to address these challenges, they broadly lack generalizability to different control tasks and rarely preserve the structure of the dynamics. In this work, we propose a new, data-driven approach for extracting control-oriented, low-dimensional models from data using Spectral Submanifold Reduction (SSMR). In contrast to other data-driven methods which fit dynamical models to training trajectories, we identify the dynamics on generic, low-dimensional attractors embedded in the full phase space of the robotic system. This allows us to obtain computationally-tractable models for control which preserve the system's dominant dynamics and better track trajectories radically different from the training data. We demonstrate the superior performance and generalizability of SSMR in dynamic trajectory tracking tasks vis-\u00e1-vis the state of the art, including Koopman operator-based approaches.",
        "primary_area": "",
        "author": "John Irvin Alora;Mattia Cenedese;Edward Schmerling;George Haller;Marco Pavone;John Irvin Alora;Mattia Cenedese;Edward Schmerling;George Haller;Marco Pavone",
        "authorids": "/37086181243;/37089895030;/37085548931;/37089681531;/37307912900;/37086181243;/37089895030;/37085548931;/37089681531;/37307912900",
        "aff": "Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Institute for Mechanical Systems, ETH Zurich, Z\u00fcrich, Switzerland; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Institute for Mechanical Systems, ETH Zurich, Z\u00fcrich, Switzerland; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160418/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15567741214724790844&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Stanford University;ETH Zurich",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;Institute for Mechanical Systems",
        "aff_unique_url": "https://www.stanford.edu;https://www.ethz.ch",
        "aff_unique_abbr": "Stanford;ETHZ",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Stanford;Z\u00fcrich",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "10161262",
        "title": "Data-Driven Stochastic Motion Evaluation and Optimization with Image by Spatially-Aligned Temporal Encoding",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a probabilistic motion prediction method for long motions. The motion is predicted so that it accomplishes a task from the initial state observed in the given image. While our method evaluates the task achievability by the Energy-Based Model (EBM), previous EBMs are not designed for evaluating the consistency between different domains (i.e., image and motion in our method). Our method seamlessly integrates the image and motion data into the image feature domain by spatially-aligned temporal encoding so that features are extracted along the motion trajectory projected onto the image. Furthermore, this paper also proposes a data-driven motion optimization method, Deep Motion Optimizer (DMO), that works with EBM for motion prediction. Different from previous gradient-based optimizers, our self-supervised DMO alleviates the difficulty of hyper-parameter tuning to avoid local minima. The effectiveness of the proposed method is demonstrated with a variety of experiments with similar SOTA methods.",
        "primary_area": "",
        "author": "Takeru Oba;Norimichi Ukita;Takeru Oba;Norimichi Ukita",
        "authorids": "/37088955442;/37266271300;/37088955442;/37266271300",
        "aff": "Graduate School of Engineering, Toyota Technological Institute, Nagoya, Japan; Graduate School of Engineering, Toyota Technological Institute, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161262/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5626378849242552147&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyota Technological Institute",
        "aff_unique_dep": "Graduate School of Engineering",
        "aff_unique_url": "https://www.tti.ac.jp",
        "aff_unique_abbr": "TTI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nagoya",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160428",
        "title": "Data-Efficient Characterization of the Global Dynamics of Robot Controllers with Confidence Guarantees",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an integration of surrogate modeling and topology to significantly reduce the amount of data required to describe the underlying global dynamics of robot controllers, including closed-box ones. A Gaussian Process (GP), trained with randomized short trajectories over the state-space, acts as a surrogate model for the underlying dynamical system. Then, a combinatorial representation is built and used to describe the dynamics in the form of a directed acyclic graph, known as Morse graph. The Morse graph is able to describe the system's attractors and their corresponding regions of attraction (RoA). Furthermore, a pointwise confidence level of the global dynamics estimation over the entire state space is provided. In contrast to alternatives, the framework does not require estimation of Lyapunov functions, alleviating the need for high prediction accuracy of the GP. The framework is suit-able for data-driven controllers that do not expose an analytical model as long as Lipschitz-continuity is satisfied. The method is compared against established analytical and recent machine learning alternatives for estimating Roas, outperforming them in data efficiency without sacrificing accuracy. Link to code: https://go.rutgers.edu/49hy35en",
        "primary_area": "",
        "author": "Ewerton R. Vieira;Aravind Sivaramakrishnan;Yao Song;Edgar Granados;Marcio Gameiro;Konstantin Mischaikow;Ying Hung;Kostas E. Bekris;Ewerton R. Vieira;Aravind Sivaramakrishnan;Yao Song;Edgar Granados;Marcio Gameiro;Konstantin Mischaikow;Ying Hung;Kostas E. Bekris",
        "authorids": "/37089447525;/37089195641;/37089892598;/37088505477;/37088731774;/37332004000;/37086576100;/37282424700;/37089447525;/37089195641;/37089892598;/37088505477;/37088731774;/37332004000;/37086576100;/37282424700",
        "aff": "IME, Universidade Federal de Goi\u00e1s, Goi\u00e2nia, GO, Brazil; ICMC, Universidade de S\u00e3o Paulo, S\u00e3o Carlos, S\u00e3o Paulo, Brazil; Dept. of Statistics, Rutgers University, NJ, USA; Dept. of Computer Science, Rutgers, NJ, USA; Dept. of Mathematics, Rutgers, NJ, USA; Dept. of Mathematics, Rutgers, NJ, USA; Dept. of Statistics, Rutgers University, NJ, USA; Dept. of Computer Science, Rutgers, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160428/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7105942903730259796&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;2;2;2;2;2",
        "aff_unique_norm": "Universidade Federal de Goi\u00e1s;Universidade de S\u00e3o Paulo;Rutgers University",
        "aff_unique_dep": "IME;ICMC;Department of Statistics",
        "aff_unique_url": "http://www.ufg.br;https://www.icmc.usp.br;https://www.rutgers.edu",
        "aff_unique_abbr": ";USP;Rutgers",
        "aff_campus_unique_index": "0;1;2;3;3;3;2;3",
        "aff_campus_unique": "Goi\u00e2nia;S\u00e3o Carlos;New Brunswick;Newark",
        "aff_country_unique_index": "0;0;1;1;1;1;1;1",
        "aff_country_unique": "Brazil;United States"
    },
    {
        "id": "10161125",
        "title": "Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification",
        "track": "main",
        "status": "Poster",
        "abstract": "To make robots accessible to a broad audience, it is critical to endow them with the ability to take universal modes of communication, like commands given in natural language, and extract a concrete desired task specification, defined using a formal language like linear temporal logic (LTL). In this paper, we present a learning-based approach for translating from natural language commands to LTL specifications with very limited human-labeled training data. This is in stark contrast to existing natural-language to LTL translators, which require large human-labeled datasets, often in the form of labeled pairs of LTL formulas and natural language commands, to train the translator. To reduce reliance on human data, our approach generates a large synthetic training dataset through algorithmic generation of LTL formulas, conversion to structured English, and then exploiting the paraphrasing capabilities of modern large language models (LLMs) to synthesize a diverse corpus of natural language commands corresponding to the LTL formu-las. We use this generated data to finetune an LLM and apply a constrained decoding procedure at inference time to ensure the returned LTL formula is syntactically correct. We evaluate our approach on three existing LTL/natural language datasets and show that we can translate natural language commands at 75% accuracy with far less human data (\u226412 annotations). Moreover, when training on large human-annotated datasets, our method achieves higher test accuracy (95% on average) than prior work. Finally, we show the translated formulas can be used to plan long-horizon, multi-stage tasks on a 12D quadrotor.",
        "primary_area": "",
        "author": "Jiayi Pan;Glen Chou;Dmitry Berenson;Jiayi Pan;Glen Chou;Dmitry Berenson",
        "authorids": "/37089894365;/37086482625;/37542925700;/37089894365;/37086482625;/37542925700",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161125/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4557552849173598144&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160783",
        "title": "Data-driven Loop Closure Detection in Bathymetric Point Clouds for Underwater SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous localization and mapping (SLAM) frameworks for autonomous navigation rely on robust data association to identify loop closures for back-end trajectory optimization. In the case of autonomous underwater vehicles (AUVs) equipped with multibeam echosounders (MBES), data association is particularly challenging due to the scarcity of identifiable landmarks in the seabed, the large drift in deadreckoning navigation estimates to which AUVs are prone and the low resolution characteristic of MBES data. Deep learning solutions to loop closure detection have shown excellent performance on data from more structured environments. However, their transfer to the seabed domain is not immediate and efforts to port them are hindered by the lack of bathymetric datasets. Thus, in this paper we propose a neural network architecture aimed to showcase the potential of adapting such techniques to correspondence matching in bathymetric data. We train our framework on real bathymetry from an AUV mission and evaluate its performance on the tasks of loop closure detection and coarse point cloud alignment. Finally, we show its potential against a more traditional method and release both its implementation and the dataset used.",
        "primary_area": "",
        "author": "Jiarui Tan;Ignacio Torroba;Yiping Xie;John Folkesson;Jiarui Tan;Ignacio Torroba;Yiping Xie;John Folkesson",
        "authorids": "/37089895320;/37086852366;/37088566456;/37282372400;/37089895320;/37086852366;/37088566456;/37282372400",
        "aff": "Division of Robotics, Perception and Learning at KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning at KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning at KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning at KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160783/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17280644866514758577&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "Division of Robotics, Perception and Learning",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "10160641",
        "title": "Data-driven optimal control under safety constraints using sparse Koopman approximation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we approach the dual optimal reach-safe control problem using sparse approximations of Koopman operator. Matrix approximation of Koopman operator needs to solve a least-squares (LS) problem in the lifted function space, which is computationally intractable for fine discretizations and high dimensions. The state transitional physical meaning of the Koopman operator leads to a sparse LS problem in this space. Leveraging this sparsity, we propose an efficient method to solve the sparse LS problem where we reduce the problem dimension dramatically by formulating the problem using only the non-zero elements in the approximation matrix with known sparsity pattern. The obtained matrix approximation of the operators is then used in a dual optimal reach-safe problem formulation where a linear program with sparse linear constraints naturally appears. We validate our proposed method on various dynamical systems and show that the computation time for operator approximation is greatly reduced with high precision in the solutions.",
        "primary_area": "",
        "author": "Hongzhe Yu;Joseph Moyalan;Umesh Vaidya;Yongxin Chen;Hongzhe Yu;Joseph Moyalan;Umesh Vaidya;Yongxin Chen",
        "authorids": "/37089246371;/37086939234;/37301338000;/37085498513;/37089246371;/37086939234;/37301338000;/37085498513",
        "aff": "School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA; Department of Mechanical Engineering, Clemson University, Clemson, SC; Department of Mechanical Engineering, Clemson University, Clemson, SC; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160641/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13312320604465420035&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Clemson University",
        "aff_unique_dep": "School of Aerospace Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.clemson.edu",
        "aff_unique_abbr": "Georgia Tech;Clemson",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Atlanta;Clemson",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161275",
        "title": "Data-efficient Non-parametric Modelling and Control of an Extensible Soft Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Data-driven approaches have shown promising results in modeling and controlling robots, specifically soft and flexible robots where developing physics-based models are more challenging. However, these methods often require a large number of real data, and gathering such data is time-consuming and can damage the robot as well. This paper proposed a novel data-efficient and non-parametric approach to develop a continuous model using a small dataset of real robot demonstrations (only 25 points). To the best of our knowledge, the proposed approach is the most sample-efficient method for soft continuum robot. Furthermore, we employed this model to develop a controller to track arbitrary trajectories in the feasible kinematic space. To show the performance of the proposed approach, a set of trajectory-tracking experiments has been conducted. The results showed that the robot was able to track the references precisely even in presence of external loads (up to 25 grams). Moreover, fine object manipulation experiments were performed to demonstrate the effectiveness of the proposed method in real-world tasks. Finally, we compared its performance with common data-driven approaches in seen/useen-before trajectory tracking scenarios. The results validated that the proposed approach significantly outperformed the existing approaches in unseen-before scenarios and offered similar performance in seen-before scenarios.",
        "primary_area": "",
        "author": "Mohammadreza Kasaei;Keyhan Kouhkiloui Babarahmati;Zhibin Li;Mohsen Khadem;Mohammadreza Kasaei;Keyhan Kouhkiloui Babarahmati;Zhibin Li;Mohsen Khadem",
        "authorids": "/37089894512;/37086453340;/37857029500;/37085447737;/37089894512;/37086453340;/37857029500;/37085447737",
        "aff": "School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; Department of Computer Science, University College London, UK; School of Informatics, University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161275/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3100543912812531829&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Edinburgh;University College London",
        "aff_unique_dep": "School of Informatics;Department of Computer Science",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Edinburgh;UCL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160216",
        "title": "DeXtreme: Transfer of Agile In-hand Manipulation from Simulation to Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work has demonstrated the ability of deep reinforcement learning (RL) algorithms to learn complex robotic behaviours in simulation, including in the domain of multi-fingered manipulation. However, such models can be challenging to transfer to the real world due to the gap between simulation and reality. In this paper, we present our techniques to train a) a policy that can perform robust dexterous manipulation on an anthropomorphic robot hand and b) a robust pose estimator suitable for providing reliable real-time information on the state of the object being manipulated. Our policies are trained to adapt to a wide range of conditions in simulation. Consequently, our vision-based policies significantly outperform the best vision policies in the literature on the same reorientation task and are competitive with policies that are given privileged state information via motion capture systems. Our work reaffirms the possibilities of sim-to-real transfer for dexterous manipulation in diverse kinds of hardware and simulator setups, and in our case, with the Allegro Hand and Isaac Gym GPU-based simulation. Furthermore, it opens up possibilities for researchers to achieve such results with commonly-available, affordable robot hands and cameras. Videos of the resulting policy and supplementary information, including experiments and demos, can be found on the website.",
        "primary_area": "",
        "author": "Ankur Handa;Arthur Allshire;Viktor Makoviychuk;Aleksei Petrenko;Ritvik Singh;Jingzhou Liu;Denys Makoviichuk;Karl Van Wyk;Alexander Zhurkevich;Balakumar Sundaralingam;Yashraj Narang;Ankur Handa;Arthur Allshire;Viktor Makoviychuk;Aleksei Petrenko;Ritvik Singh;Jingzhou Liu;Denys Makoviichuk;Karl Van Wyk;Alexander Zhurkevich;Balakumar Sundaralingam;Yashraj Narang",
        "authorids": "/37546502600;/37089002143;/37086938547;/37089183236;/793166137201905;/37089830927;/37089659184;/37085779307;/37086587371;/37086455625;/37085801324;/37546502600;/37089002143;/37086938547;/37089183236;/793166137201905;/37089830927;/37089659184;/37085779307;/37086587371;/37086455625;/37085801324",
        "aff": "Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State; Jean-Francois Lafleche, Dieter Fox, Gavriel State",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160216/",
        "gs_citation": 146,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12654495202520287708&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10161186",
        "title": "Dealing with Sparse Rewards in Continuous Control Robotics via Heavy-Tailed Policy Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel Heavy-Tailed Stochastic Policy Gradient (HT-PSG) algorithm to deal with the challenges of sparse rewards in continuous control problems. Sparse rewards are common in continuous control robotics tasks such as manipulation and navigation and make the learning problem hard due to the non-trivial estimation of value functions over the state space. This demands either reward shaping or expert demonstrations for the sparse reward environment. However, obtaining high-quality demonstrations is quite expensive and sometimes even impossible. We propose a heavy-tailed policy parametrization along with a modified momentum-based policy gradient tracking scheme (HT-SPG) to induce a stable exploratory behavior in the algorithm. The proposed algorithm does not require access to expert demonstrations. We test the performance of HT-SPG on various benchmark tasks of continuous control with sparse rewards such as 1D Mario, Pathological Mountain Car, Sparse Pendulum in OpenAI Gym, and Sparse MuJoCo environments (Hopper-v2, Half-Cheetah, Walker-2D). We show consistent performance improvement across all tasks in terms of high average cumulative reward without requiring access to expert demonstrations. We further demonstrate that a navigation policy trained using HT-SPG can be easily transferred into a Clearpath Husky robot to perform real-world navigation tasks.",
        "primary_area": "",
        "author": "Souradip Chakraborty;Amrit Singh Bedi;Kasun Weerakoon;Prithvi Poddar;Alec Koppel;Pratap Tokekar;Dinesh Manocha;Souradip Chakraborty;Amrit Singh Bedi;Kasun Weerakoon;Prithvi Poddar;Alec Koppel;Pratap Tokekar;Dinesh Manocha",
        "authorids": "/37089892277;/37085892109;/37089653638;/37089894935;/37085457697;/37546532700;/37267825600;/37089892277;/37085892109;/37089653638;/37089894935;/37085457697;/37546532700;/37267825600",
        "aff": "University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; Indian Institutes of Science Education and Research; JP Morgan AI Research, NewYork, NY, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161186/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4459267477943008499&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;2;0;0",
        "aff_unique_norm": "University of Maryland;Indian Institutes of Science Education and Research;JP Morgan AI Research",
        "aff_unique_dep": ";;AI Research",
        "aff_unique_url": "https://www/umd.edu;https://www.iiser.ac.in;https://www.jpmorgan.com/global/research",
        "aff_unique_abbr": "UMD;IISER;JPM AI",
        "aff_campus_unique_index": "0;0;0;2;0;0",
        "aff_campus_unique": "College Park;;New York",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "10161026",
        "title": "Decentralised Active Perception in Continuous Action Spaces for the Coordinated Escort Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the coordinated escort problem, where a decentralised team of supporting robots implicitly assist the mission of higher-value principal robots. The defining challenge is how to evaluate the effect of supporting robots' actions on the principal robots' mission. To capture this effect, we define two novel auxiliary reward functions for supporting robots called satisfaction improvement and satisfaction entropy, which computes the improvement in probability of mission success, or the uncertainty thereof. Given these reward functions, we coordinate the entire team of principal and supporting robots using decentralised cross entropy method (Dec-CEM), a new extension of CEM to multi-agent systems based on the product distribution approximation. In a simulated object avoidance scenario, our planning framework demonstrates up to two-fold improvement in task satisfaction against conventional decoupled information gathering. The significance of our results is to introduce a new family of algorithmic problems that will enable important new practical applications of heterogeneous multi-robot systems.",
        "primary_area": "",
        "author": "Rhett Hull;Ki Myung Brian Lee;Jennifer Wakulicz;Chanyeol Yoo;James McMahon;Bryan Clarke;Stuart Anstee;Jijoong Kim;Robert Fitch;Rhett Hull;Ki Myung Brian Lee;Jennifer Wakulicz;Chanyeol Yoo;James McMahon;Bryan Clarke;Stuart Anstee;Jijoong Kim;Robert Fitch",
        "authorids": "/37089895864;/37088506983;/37088996209;/37086933786;/37085353635;/37089895319;/37601910400;/37086936936;/38466367800;/37089895864;/37088506983;/37088996209;/37086933786;/37085353635;/37089895319;/37601910400;/37086936936;/38466367800",
        "aff": "Department of Defence, Defence Science and Technology Group, Australia; the University of Technology Sydney, Ultimo, NSW, Australia; the University of Technology Sydney, Ultimo, NSW, Australia; the University of Technology Sydney, Ultimo, NSW, Australia; the US Naval Research Laboratory, USA; Department of Defence, Defence Science and Technology Group, Australia; Department of Defence, Defence Science and Technology Group, Australia; Department of Defence, Defence Science and Technology Group, Australia; the University of Technology Sydney, Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161026/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15871963102663004848&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;2;0;0;0;1",
        "aff_unique_norm": "Defence Science and Technology Group;University of Technology Sydney;US Naval Research Laboratory",
        "aff_unique_dep": "Department of Defence;;",
        "aff_unique_url": "https://www.dstgroup.com.au;https://www.uts.edu.au;https://www.nrl.navy.mil",
        "aff_unique_abbr": "DST Group;UTS;NRL",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Ultimo",
        "aff_country_unique_index": "0;0;0;0;1;0;0;0;0",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "10160847",
        "title": "Decentralized Deadlock-free Trajectory Planning for Quadrotor Swarm in Obstacle-rich Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a decentralized multi-agent trajectory planning (MATP) algorithm that guarantees to generate a safe, deadlock-free trajectory in an obstacle-rich environment under a limited communication range. The proposed algorithm utilizes a grid-based multi-agent path planning (MAPP) algorithm for deadlock resolution, and we introduce the subgoal optimization method to make the agent converge to the waypoint generated from the MAPP without deadlock. In addition, the proposed algorithm ensures the feasibility of the optimization problem and collision avoidance by adopting a linear safe corridor (LSC). We verify that the proposed algorithm does not cause a deadlock in both random forests and dense mazes regardless of communication range, and it outperforms our previous work in flight time and distance. We validate the proposed algorithm through a hardware demonstration with ten quadrotors.",
        "primary_area": "",
        "author": "Jungwon Park;Inkyu Jang;H. Jin Kim;Jungwon Park;Inkyu Jang;H. Jin Kim",
        "authorids": "/37087323909;/37087499137;/37599626400;/37087323909;/37087499137;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University (SNU), and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University (SNU), and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University (SNU), and Automation and Systems Research Institute (ASRI), Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160847/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12632634901252546988&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160599",
        "title": "Decentralized Multi-agent Exploration with Limited Inter-agent Communications",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of decentralized multiagent environmental learning through maximizing the joint information gain among a team of agents. Inspired by subsea applications where bandwidth is severely limited, we explicitly consider the challenge of restricted communication between agents. The environment is modeled as a Gaussian process (GP), and the global information gain maximization problem in a GP is a set-valued optimization problem involving all agents' locally acquired data. We develop a decentralized method to solve it based on decomposition of information gain and exchange of limited subsets of data between agents. A key technical novelty of our approach is that we formulate the incentives for information exchange among agents as a submodular set optimization problem in terms of the log-determinant of their local covariance matrices. Numerical experiments on real-world data demonstrate the ability of our algorithm to explore trade-off between objectives. In particular, we demonstrate favorable performance on mapping problems where both decentralized information gathering and limited information exchange are essential.",
        "primary_area": "",
        "author": "Hans J. He;Alec Koppel;Amrit Singh Bedi;Daniel J. Stilwell;Mazen Farhood;Benjamin Biggs;Hans J. He;Alec Koppel;Amrit Singh Bedi;Daniel J. Stilwell;Mazen Farhood;Benjamin Biggs",
        "authorids": "/37089385711;/37085457697;/37085892109;/37283170000;/37297013300;/37087324207;/37089385711;/37085457697;/37085892109;/37283170000;/37297013300;/37087324207",
        "aff": "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; JP Morgan AI Research, New York, NY; Institute of Systems Research at the University of Maryland, College Park, MD, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Kevin T. Crofton Department of Aerospace and Ocean Engineering, Virginia Tech, Blacksburg, VA, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160599/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10436433087845498745&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;0",
        "aff_unique_norm": "Virginia Tech;JP Morgan;University of Maryland",
        "aff_unique_dep": "Bradley Department of Electrical and Computer Engineering;AI Research;Institute of Systems Research",
        "aff_unique_url": "https://www.vt.edu;https://www.jpmorgan.com;https://www.umd.edu",
        "aff_unique_abbr": "VT;JPM;UMD",
        "aff_campus_unique_index": "0;1;2;0;0;0",
        "aff_campus_unique": "Blacksburg;New York;College Park",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161530",
        "title": "Decision diagrams as plans: Answering observation-grounded queries",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider a robot that answers questions about its environment by traveling to appropriate places and then sensing. Questions are posed as structured queries and may involve conditional or contingent relationships between observable properties. After formulating this problem, and empha-sizing the advantages of exploiting deducible information, we describe how non-trivial knowledge of the world and queries can be given a convenient, concise, unified representation via reduced ordered binary decision diagrams (BDDs). To use these data structures directly for inference and planning, we introduce a new product operation, and generalize the classic dynamic variable reordering techniques to solve planning problems. Also, finally, we evaluate optimizations that exploit locality.",
        "primary_area": "",
        "author": "Dylan A. Shell;Jason M. O'Kane;Dylan A. Shell;Jason M. O'Kane",
        "authorids": "/37269198900;/37279835400;/37269198900;/37279835400",
        "aff": "Department of Computer Science and Engineering\u2019, Texas A&M University, College Station, TX, USA; Department of Computer Science and Engineering\u2019, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161530/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7294002572764793877&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160332",
        "title": "Decoupling Skill Learning from Robotic Control for Generalizable Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent works in robotic manipulation through reinforcement learning (RL) or imitation learning (IL) have shown potential for tackling a range of tasks e.g., opening a drawer or a cupboard. However, these techniques generalize poorly to unseen objects. We conjecture that this is due to the high-dimensional action space for joint control. In this paper, we take an alternative approach and separate the task of learning \u2018what to do\u2019 from \u2018how to do it\u2019 i.e., whole-body control. We pose the RL problem as one of determining the skill dynamics for a disembodied virtual manipulator interacting with articulated objects. The whole-body robotic kinematic control is optimized to execute the high-dimensional joint motion to reach the goals in the workspace. It does so by solving a quadratic programming (QP) model with robotic singularity and kinematic constraints. Our experiments on manipulating complex articulated objects show that the proposed approach is more generalizable to unseen objects with large intra-class variations, outperforming previous approaches. The evaluation results indicate that our approach generates more compliant robotic motion and outperforms the pure RL and IL baselines in task success rates. Additional information and videos are available at https://kl-research.github.io/decoupskill.",
        "primary_area": "",
        "author": "Kai Lu;Bo Yang;Bing Wang;Andrew Markham;Kai Lu;Bo Yang;Bing Wang;Andrew Markham",
        "authorids": "/37089894995;/37086306785;/37088504237;/37410667900;/37089894995;/37086306785;/37088504237;/37410667900",
        "aff": "Department of Computer Science, University of Oxford, Oxford, UK; Department of Computing, vLAR Group, Hong Kong Polytechnic University, HKSAR; Department of Computer Science, University of Oxford, Oxford, UK; Department of Computer Science, University of Oxford, Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160332/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5581006313455360129&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Oxford;Hong Kong Polytechnic University",
        "aff_unique_dep": "Department of Computer Science;Department of Computing",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.polyu.edu.hk",
        "aff_unique_abbr": "Oxford;PolyU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Oxford;Hong Kong SAR",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "10160863",
        "title": "Deep Interactive Full Transformer Framework for Point Cloud Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "Point cloud registration is a crucial technology in the fields of robotics and computer vision. Despite the significant advances in point cloud registration enabled by Transformer-based methods, limitations persist due to indistinct feature extraction, noise sensitivity, and outlier handling. These limitations stem from three factors: (1) the inefficiency of convolutional neural networks (CNNs) to capture global relationships due to their local receptive fields, resulting in extracted features susceptible to noise; (2) the shallow-wide architecture of Transformers, coupled with a lack of positional information, leading to inefficient information interaction and indistinct feature extraction; and (3) the omission of geometrical compatibility leads to ambiguous identification of incorrect correspondences. To overcome these limitations, we propose the Deep Interactive Full Transformer (DIFT) network for point cloud registration, which consists of three key components: (1) a Point Cloud Structure Extractor (PSE) for modeling global relationships and retrieving structural information; (2) a Point Feature Transformer (PFT) for establishing comprehensive associations and directly learning the relative positions between points; and (3) a Geometric Matching-based Correspondence Confidence Evaluation (GMCCE) method for measuring spatial consistency and estimating correspondence confidence. Experimental results on ModelNet40 and 3DMatch datasets demonstrate the superior performance of our proposed method compared to existing state-of-the-art methods. The code for our method is publicly available at https://github.com/CGuangyan-BIT/DIFT.",
        "primary_area": "",
        "author": "Guangyan Chen;Meiling Wang;Qingxiang Zhang;Li Yuan;Tong Liu;Yufeng Yue;Guangyan Chen;Meiling Wang;Qingxiang Zhang;Li Yuan;Tong Liu;Yufeng Yue",
        "authorids": "/37089894774;/37406965500;/37089002259;/37089892837;/37085425408;/37086172414;/37089894774;/37406965500;/37089002259;/37089892837;/37085425408;/37086172414",
        "aff": "School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; Pecheng Lab, School of Electrical and Computer Engineering at Peking University, Shenzhen, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160863/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17048290173777589244&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Beijing Institute of Technology;Peking University",
        "aff_unique_dep": "School of Automation;School of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.bit.edu.cn;http://www.pku.edu.cn",
        "aff_unique_abbr": "BIT;PKU",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Beijing;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160827",
        "title": "Deep Learning on Home Drone: Searching for the Optimal Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "We suggest the first system that runs real-time semantic segmentation via deep learning on the weak microcomputer Raspberry Pi Zero v2 (whose price was 15) attached to a toy drone. In particular, since the Raspberry Pi weighs less than 16 grams, and its size is half of a credit card, we could easily attach it to the common commercial DJI Tello toy-drone (<15) attached to a toy drone. In particular, since the Raspberry Pi weighs less than 16 grams, and its size is half of a credit card, we could easily attach it to the common commercial DJI Tello toy-drone (<100, <90 grams, 98 \\times 92.5\\times 41\\times 92.5\\times 41 mm). The result is an autonomous drone (no laptop nor human in the loop) that can detect and classify objects in real-time from a video stream of an onboard monocular RGB camera (no GPS or LIDAR sensors). The companion videos demonstrate how this Tello drone scans the lab for people (e.g. for the use of firefighters or security forces) and for an empty parking slot outside the lab. Existing deep learning solutions are either much too slow for real-time computation on such IoT devices, or provide results of impractical quality. Our main challenge was to design a system that takes the best of all worlds among numerous combinations of networks, deep learning platforms/frameworks, compression techniques, and compression ratios. To this end, we provide an efficient searching algorithm that aims to find the optimal combination which results in the best tradeoff between the network running time and its accuracy/performance.",
        "primary_area": "",
        "author": "Alaa Maalouf;Yotam Gurfinkel;Barak Diker;Oren Gal;Daniela Rus;Dan Feldman;Alaa Maalouf;Yotam Gurfinkel;Barak Diker;Oren Gal;Daniela Rus;Dan Feldman",
        "authorids": "/37089318922;/37089892564;/37089894908;/37577144200;/37279652300;/38540643000;/37089318922;/37089892564;/37089894908;/37577144200;/37279652300;/38540643000",
        "aff": "CSAIL, MIT, USA; Department of Computer Science, Robotics and Big Data Labs, University of Haifa, Israel; Department of Computer Science, Robotics and Big Data Labs, University of Haifa, Israel; Department of Computer Science, Robotics and Big Data Labs, University of Haifa, Israel; CSAIL, MIT, USA; Department of Computer Science, Robotics and Big Data Labs, University of Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160827/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16449387428499421028&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Haifa",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Department of Computer Science",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.haifa.ac.il",
        "aff_unique_abbr": "MIT;Haifa U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;1;1;1;0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "10161231",
        "title": "Deep Masked Graph Matching for Correspondence Identification in Collaborative Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Correspondence identification (CoID) is an essential component for collaborative perception in multi-robot systems, such as connected autonomous vehicles. The goal of CoID is to identify the correspondence of objects observed by multiple robots in their own field of view in order for robots to consistently refer to the same objects. CoID is challenging due to perceptual aliasing, object non-covisibility, and noisy sensing. In this paper, we introduce a novel deep masked graph matching approach to enable CoID and address the challenges. Our approach formulates CoID as a graph matching problem and we design a masked neural network to integrate the multimodal visual, spatial, and GPS information to perform CoID. In addition, we design a new technique to explicitly address object non-covisibility caused by occlusion and the vehicle's limited field of view. We evaluate our approach in a variety of street environments using a high-fidelity simulation that integrates the CARLA and SUMO simulators. The experimental results show that our approach outperforms the previous approaches and achieves state-of-the- art CoID performance in connected autonomous driving applications. Our work is available at: https://github.com/gaopeng5/DMGM.git.",
        "primary_area": "",
        "author": "Peng Gao;Qingzhao Zhu;Hongsheng Lu;Chuang Gan;Hao Zhang;Peng Gao;Qingzhao Zhu;Hongsheng Lu;Chuang Gan;Hao Zhang",
        "authorids": "/37089501844;/37088503796;/37085839592;/37085611353;/37085545929;/37089501844;/37088503796;/37085839592;/37085611353;/37085545929",
        "aff": "Department of Computer Science, University of Maryland, College Park, MD, USA; Department of Computer Science, Colorado School of Mines, Golden, CO, USA; Toyota Motor North America, Mountain View, CA, USA; MIT-IBM Watson AI Lab, Cambridge, MA, USA; Manning College of Information and Computer Sciences (CICS), University of Massachusetts Amherst, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161231/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7440236650447179466&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "University of Maryland;Colorado School of Mines;Toyota Motor North America;MIT-IBM Watson AI Lab;University of Massachusetts Amherst",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;;AI Lab;Manning College of Information and Computer Sciences (CICS)",
        "aff_unique_url": "https://www/umd.edu;https://www.mines.edu;https://www.toyota.com;https://www.ibmwatson.com/;https://www.umass.edu",
        "aff_unique_abbr": "UMD;CSM;TMNA;MIT-IBM AI Lab;UMass Amherst",
        "aff_campus_unique_index": "0;1;2;3;4",
        "aff_campus_unique": "College Park;Golden;Mountain View;Cambridge;Amherst",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160369",
        "title": "Deep Neural Network Architecture Search for Accurate Visual Pose Estimation aboard Nano-UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "Miniaturized autonomous unmanned aerial vehicles (UAVs) are an emerging and trending topic. With their form factor as big as the palm of one hand, they can reach spots otherwise inaccessible to bigger robots and safely operate in human surroundings. The simple electronics aboard such robots (sub-100 mW) make them particularly cheap and attractive but pose significant challenges in enabling onboard sophisticated intelligence. In this work, we leverage a novel neural architecture search (NAS) technique to automatically identify several Pareto-optimal convolutional neural networks (CNNs) for a visual pose estimation task. Our work demonstrates how reallife and field-tested robotics applications can concretely leverage NAS technologies to automatically and efficiently optimize CNNs for the specific hardware constraints of small UAVs. We deploy several NAS-optimized CNNs and run them in closed-loop aboard a 27-g Crazyflie nano-UAV equipped with a parallel ultra-low power System-on-Chip. Our results improve the State-of-the-Art by reducing the in-field control error of 32% while achieving a real-time onboard inference-rate of ~10Hz@10mW and ~50Hz@90mW.",
        "primary_area": "",
        "author": "E. Cereda;L. Crupi;M. Risso;A. Burrello;L. Benini;A. Giusti;D. Jahier Pagliari;D. Palossi;E. Cereda;L. Crupi;M. Risso;A. Burrello;L. Benini;A. Giusti;D. Jahier Pagliari;D. Palossi",
        "authorids": "/37086553441;/37089895354;/37088900743;/37086554422;/37274443600;/38498058400;/37085644559;/37073862400;/37086553441;/37089895354;/37088900743;/37086554422;/37274443600;/38498058400;/37085644559;/37073862400",
        "aff": "Dalle Molle Institute for Artificial Intelligence, USI and SUPSI, Lugano, Switzerland; Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Department of Electrical, Electronic, and Information Engineering, University of Bologna, Bologna, Italy; Integrated Systems Laboratory, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Dalle Molle Institute for Artificial Intelligence, USI and SUPSI, Lugano, Switzerland; Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Integrated Systems Laboratory, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160369/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7950306553323430471&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;2;3;0;1;3",
        "aff_unique_norm": "Dalle Molle Institute for Artificial Intelligence;Politecnico di Torino;University of Bologna;ETH Z\u00fcrich",
        "aff_unique_dep": ";Department of Control and Computer Engineering;Department of Electrical, Electronic, and Information Engineering;Integrated Systems Laboratory",
        "aff_unique_url": ";https://www.polito.it;https://www.unibo.it;https://www.ethz.ch",
        "aff_unique_abbr": ";Politecnico di Torino;UNIBO;ETHZ",
        "aff_campus_unique_index": "0;1;1;2;3;0;1;3",
        "aff_campus_unique": "Lugano;Turin;Bologna;Z\u00fcrich",
        "aff_country_unique_index": "0;1;1;1;0;0;1;0",
        "aff_country_unique": "Switzerland;Italy"
    },
    {
        "id": "10160559",
        "title": "Deep Occupancy-Predictive Representations for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Manually specifying features that capture the diversity in traffic environments is impractical. Consequently, learning-based agents cannot realize their full potential as neural motion planners for autonomous vehicles. Instead, this work proposes to learn which features are task-relevant. Given its immediate relevance to motion planning, our proposed architecture encodes the probabilistic occupancy map as a proxy for obtaining pre-trained state representations of the environment. By leveraging a map-aware traffic graph formulation, our agent-centric encoder generalizes to arbitrary road networks and traffic situations. We show that our approach significantly improves the downstream performance of a reinforcement learning agent operating in urban traffic environments.",
        "primary_area": "",
        "author": "Eivind Meyer;Lars Frederik Peiss;Matthias Althoff;Eivind Meyer;Lars Frederik Peiss;Matthias Althoff",
        "authorids": "/37088234243;/37089895886;/37541135900;/37088234243;/37089895886;/37541135900",
        "aff": "Department of Informatics, Technical University of Munich, Garching, Germany; Department of Informatics, Technical University of Munich, Garching, Germany; Department of Informatics, Technical University of Munich, Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160559/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13149436437420642421&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Garching",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160858",
        "title": "Deep Reinforcement Learning Based Tracking Control of an Autonomous Surface Vessel in Natural Waters",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate control of autonomous marine robots still poses challenges due to the complex dynamics of the environment. In this paper, we propose a Deep Reinforcement Learning (DRL) approach to train a controller for autonomous surface vessel (ASV) trajectory tracking and compare its performance with an advanced nonlinear model predictive controller (NMPC) in real environments. Taking into account environmental disturbances (e.g., wind, waves, and currents), noisy measurements, and non-ideal actuators presented in the physical ASV, several effective reward functions for DRL tracking control policies are carefully designed. The control policies were trained in a simulation environment with diverse tracking trajectories and disturbances. The performance of the DRL controller has been verified and compared with the NMPC in both simulations with model-based environmental disturbances and in natural waters. Simulations show that the DRL controller has 53.33% lower tracking error than that of NMPC. Experimental results further show that, compared to NMPC, the DRL controller has 35.51% lower tracking error, indicating that DRL controllers offer better disturbance rejection in river environments than NMPC.",
        "primary_area": "",
        "author": "Wei Wang;Xiaojing Cao;Alejandro Gonzalez-Garcia;Lianhao Yin;Niklas Hagemann;Yuanyuan Qiao;Carlo Ratti;Daniela Rus;Wei Wang;Xiaojing Cao;Alejandro Gonzalez-Garcia;Lianhao Yin;Niklas Hagemann;Yuanyuan Qiao;Carlo Ratti;Daniela Rus",
        "authorids": "/37073346500;/37089894244;/37088836024;/37089892801;/37089000190;/37593728200;/37590016800;/37279652300;/37073346500;/37089894244;/37088836024;/37089892801;/37089000190;/37593728200;/37590016800;/37279652300",
        "aff": "SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Intelligent Perception and Computing Research Center, School of Artificial Intelligence, Beijing University of Posts and Telecommunications (BUPT), Beijing, China; Department of Mechanical Engineering, MECO Research Team, KU Leuven, Belgium and Flanders Make@KU, Leuven, Belgium; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Intelligent Perception and Computing Research Center, School of Artificial Intelligence, Beijing University of Posts and Telecommunications (BUPT), Beijing, China; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160858/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6270718194919559904&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;0;1;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Beijing University of Posts and Telecommunications;KU Leuven",
        "aff_unique_dep": "SENSEable City Laboratory;School of Artificial Intelligence;Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu;http://www.bupt.edu.cn/;https://www.kuleuven.be",
        "aff_unique_abbr": "MIT;BUPT;KU Leuven",
        "aff_campus_unique_index": "0;1;2;0;0;1;0;0",
        "aff_campus_unique": "Cambridge;Beijing;Leuven",
        "aff_country_unique_index": "0;1;2;0;0;1;0;0",
        "aff_country_unique": "United States;China;Belgium"
    },
    {
        "id": "10161559",
        "title": "Deep Reinforcement Learning based Personalized Locomotion Planning for Lower-Limb Exoskeletons",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces intelligent central pattern generators (iCPGs) that can plan personalized walking trajectories for lower-limb exoskeletons. This can make walking more comfortable for the users by resolving one of the significant shortcomings of most commercially available exoskeletons, which is the use of pre-defined fixed trajectories for all users. The proposed method combines reinforcement learning (RL) with previously introduced adaptable central pattern generators (ACPGs) to learn a user's physical interaction behaviour and refine the exoskeleton's walking trajectories. The ACPG method embeds physical human-robot interaction (pHRI) in CPGs to make changing gait trajectories in real-time, possible. However, to effectively refine gait trajectories based on pHRIs, the parameters must be precisely identified and updated as a user interacts with the exoskeleton. Our proposed method uses RL to modify (amplify/attenuate) the pHRI energy based on a user's interaction behaviour, and form an effective energy value which can facilitate reaching desired gait pattern for users via iCPG dynamics. The proposed method can resolve the aforementioned challenges with ACPGs and personalized trajectory generation. The simulation and experimental results provide evidence that the proposed method can effectively adapt to the user's behaviour in different walking scenarios with the Indego lower-limb exoskeleton.",
        "primary_area": "",
        "author": "Javad K. Mehr;Eddie Guo;Mojtaba Akbari;Vivian K. Mushahwar;Mahdi Tavakoli;Javad K. Mehr;Eddie Guo;Mojtaba Akbari;Vivian K. Mushahwar;Mahdi Tavakoli",
        "authorids": "/37088955559;/37089896006;/37089195415;/37281914300;/37282400400;/37088955559;/37089896006;/37089195415;/37281914300;/37282400400",
        "aff": "Sensory Motor Adaptive Rehabilitation Technology (SMART) Network, University of Alberta, Edmonton, Alberta, Canada; Sensory Motor Adaptive Rehabilitation Technology (SMART) Network, University of Alberta, Edmonton, Alberta, Canada; Sensory Motor Adaptive Rehabilitation Technology (SMART) Network, University of Alberta, Edmonton, Alberta, Canada; Sensory Motor Adaptive Rehabilitation Technology (SMART) Network, University of Alberta, Edmonton, Alberta, Canada; Sensory Motor Adaptive Rehabilitation Technology (SMART) Network, University of Alberta, Edmonton, Alberta, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161559/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5372202275126225333&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Sensory Motor Adaptive Rehabilitation Technology (SMART) Network",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160762",
        "title": "Deep Reinforcement Learning for Autonomous Driving using High-Level Heterogeneous Graph Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph networks have recently been used for decision making in automated driving tasks for their ability to capture a variable number of traffic participants. Current high-level graph-based approaches, however, do not model the entire road network and thus must rely on handcrafted features for vehicle-to-vehicle edges encompassing the road topology indirectly. We propose an entity-relation framework that intuitively models the road network and the traffic participants in a heterogeneous graph, representing all relevant information. Our novel architecture transforms the heterogeneous road-vehicle graph into a simpler graph of homogeneous node and edge types to allow effective training for deep reinforcement learning while introducing minimal prior knowledge. Unlike previous approaches, the vehicle-to-vehicle edges of this reduced graph are fully learnable and can therefore encode traffic rules without explicit feature design, an important step towards a holistic reinforcement learning model for automated driving. We show that our proposed method outperforms precomputed handcrafted features on intersection scenarios while also learning the semantics of right-of-way rules.",
        "primary_area": "",
        "author": "Maximilian Schier;Christoph Reinders;Bodo Rosenhahn;Maximilian Schier;Christoph Reinders;Bodo Rosenhahn",
        "authorids": "/37089894277;/37086488712;/37294525800;/37089894277;/37086488712;/37294525800",
        "aff": "Leibniz University Hannover, L3S / Institute for Information Processing; Leibniz University Hannover, L3S / Institute for Information Processing; Leibniz University Hannover, L3S / Institute for Information Processing",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160762/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3606029993651405638&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Leibniz University Hannover",
        "aff_unique_dep": "Institute for Information Processing",
        "aff_unique_url": "https://www.uni-hannover.de",
        "aff_unique_abbr": "LUH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161439",
        "title": "Deep Underwater Monocular Depth Estimation with Single-Beam Echosounder",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater depth estimation is essential for safe Autonomous Underwater Vehicles (AUV) navigation. While there has been recent advances in out-of-water monocular depth estimation, it is difficult to apply these methods to the underwater domain due to the lack of well-established datasets with labelled ground truths. In this paper, we propose a novel method for self-supervised underwater monocular depth estimation by leveraging a low-cost single-beam echosounder (SBES). We also present a synthetic dataset for underwater depth estimation to facilitate visual learning research in the underwater domain, available at https://github.com/hdacnw/sbes-depth. We evaluated our method on the proposed dataset with results outperforming previous methods and tested our method in a dataset we collected with an inexpensive AUV. We further investigated the use of SBES as an additional component in our self-supervised method for up-to-scale depth estimation providing insights on next research directions.",
        "primary_area": "",
        "author": "Haowen Liu;Monika Roznere;Alberto Quattrini Li;Haowen Liu;Monika Roznere;Alberto Quattrini Li",
        "authorids": "/37089893349;/37087322448;/37085808885;/37089893349;/37087322448;/37085808885",
        "aff": "Department of Computer Science, Dartmouth College, USA; Department of Computer Science, Dartmouth College, USA; Department of Computer Science, Dartmouth College, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161439/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12415806005020789871&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Dartmouth College",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://dartmouth.edu",
        "aff_unique_abbr": "Dartmouth",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160703",
        "title": "Deep Unsupervised Visual Odometry Via Bundle Adjusted Pose Graph Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised visual odometry as an active topic has attracted extensive attention, benefiting from its label-free practical value and robustness in real-world scenarios. However, the performance of camera pose estimation and tracking through deep neural network is still not as ideal as most other tasks, such as detection, segmentation and depth estimation, due to the lack of drift correction in the estimated trajectory and map optimization in the recovered 3D scenes. In this work, we introduce pose graph and bundle adjustment optimization to our network training process, which iteratively updates both the motion and depth estimations from the deep learning network, and enforces the refined outputs to further meet the unsupervised photometric and geometric constraints. The integration of pose graph and bundle adjustment is easy to implement and significantly enhances the training effectiveness. Experiments on KITTI dataset demonstrate that the introduced method achieves a significant improvement in motion estimation compared with other recent unsupervised monocular visual odometry algorithms.",
        "primary_area": "",
        "author": "Guoyu Lu;Guoyu Lu",
        "authorids": "/37086529299;/37086529299",
        "aff": "Intelligent Vision and Sensing Lab, University of Georgia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160703/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4209500243880029381&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Georgia",
        "aff_unique_dep": "Intelligent Vision and Sensing Lab",
        "aff_unique_url": "https://www.uga.edu",
        "aff_unique_abbr": "UGA",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160963",
        "title": "Deep metric learning for visual servoing: when pose and image meet in latent space",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new visual servoing method that controls a robot's motion in a latent space. We aim to extract the best properties of two previously proposed servoing methods: we seek to obtain the accuracy of photometric methods such as Direct Visual Servoing (DVS), as well as the behavior and convergence of pose-based visual servoing (PBVS). Photometric methods suffer from limited convergence area due to a highly non-linear cost function, while PBVS requires estimating the pose of the camera which may introduce some noise and incurs a loss of accuracy. Our approach relies on shaping (with metric learning) a latent space, in which the representations of camera poses and the embeddings of their respective images are tied together. By leveraging the multimodal aspect of this shared space, our control law minimizes the difference between latent image representations thanks to information obtained from a set of pose embeddings. Experiments in simulation and on a robot validate the strength of our approach, showing that the sought out benefits are effectively found.",
        "primary_area": "",
        "author": "Samuel Felton;Elisa Fromont;Eric Marchand;Samuel Felton;Elisa Fromont;Eric Marchand",
        "authorids": "/37089308455;/38234506600;/37269970500;/37089308455;/38234506600;/37269970500",
        "aff": "CNRS, Irisa, Univ Rennes, Inria, Rennes, France; CNRS, Irisa, Univ Rennes, Inria, Rennes, France; CNRS, Irisa, Univ Rennes, Inria, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160963/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17317699614987821803&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10161435",
        "title": "DeepRING: Learning Roto-translation Invariant Representation for LiDAR based Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR based place recognition is popular for loop closure detection and re-localization. In recent years, deep learning brings improvements to place recognition by learnable feature extraction. However, these methods degenerate when the robot re-visits previous places with a large perspective difference. To address the challenge, we propose DeepRING to learn the roto-translation invariant representation from LiDAR scan, so that robot visiting the same place with a different perspective can have similar representations. There are two keys in DeepRING: the feature is extracted from sinogram, and the feature is aggregated by magnitude spectrum. The two steps keep the final representation with both discrimination and roto-translation invariance. Moreover, we state place recognition as a one-shot learning problem with each place being a class, leveraging relation learning to build representation similarity. Substantial experiments are carried out on public datasets, validating the effectiveness of each proposed component, and showing that DeepRING outperforms the comparative methods, especially in dataset level generalization.",
        "primary_area": "",
        "author": "Sha Lu;Xuecheng Xu;Li Tang;Rong Xiong;Yue Wang;Sha Lu;Xuecheng Xu;Li Tang;Rong Xiong;Yue Wang",
        "authorids": "/37089449878;/37087245452;/37086334310;/37271511300;/37072299700;/37089449878;/37087245452;/37086334310;/37271511300;/37072299700",
        "aff": "State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161435/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8205274807861434479&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Zhejiang University;Alibaba Group",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control;",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.alibaba.com",
        "aff_unique_abbr": "ZJU;Alibaba",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160477",
        "title": "DeepSeeColor: Realtime Adaptive Color Correction for Autonomous Underwater Vehicles via Deep Learning Methods",
        "track": "main",
        "status": "Poster",
        "abstract": "Successful applications of complex vision-based behaviours underwater have lagged behind progress in terrestrial and aerial domains. This is largely due to the degraded image quality resulting from the physical phenomena involved in underwater image formation. Spectrally-selective light attenuation drains some colors from underwater images while backscattering adds others, making it challenging to perform vision-based tasks underwater. State-of-the-art methods for underwater color correction optimize the parameters of image formation models to restore the full spectrum of color to underwater imagery. However, these methods have high computational complexity that is unfavourable for realtime use by autonomous underwater vehicles (AUVs), as a result of having been primarily designed for offline color correction. Here, we present DeepSeeColor, a novel algorithm that combines a state-of-the-art underwater image formation model with the computational efficiency of deep learning frameworks. In our experiments, we show that DeepSeeColor offers comparable performance to the popular \u201cSea-Thru\u201d algorithm [1] while being able to rapidly process images at up to 60Hz, thus making it suitable for use onboard AUVs as a preprocessing step to enable more robust vision-based behaviours.",
        "primary_area": "",
        "author": "Stewart Jamieson;Jonathan P. How;Yogesh Girdhar;Stewart Jamieson;Jonathan P. How;Yogesh Girdhar",
        "authorids": "/37086936061;/37276347700;/37546414900;/37086936061;/37276347700;/37546414900",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT); Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT); Applied Ocean Physics and Engineering Department, Woods Hole Oceanographic Institution (WHOI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160477/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3705850023450329506&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Woods Hole Oceanographic Institution",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;Applied Ocean Physics and Engineering Department",
        "aff_unique_url": "https://web.mit.edu;https://www.whoi.edu",
        "aff_unique_abbr": "MIT;WHOI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160986",
        "title": "DefGraspNets: Grasp Planning on 3D Fields with Graph Neural Nets",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic grasping of 3D deformable objects is critical for real-world applications such as food handling and robotic surgery. Unlike rigid and articulated objects, 3D deformable objects have infinite degrees of freedom. Fully defining their state requires 3D deformation and stress fields, which are exceptionally difficult to analytically compute or experimentally measure. Thus, evaluating grasp candidates for grasp planning typically requires accurate, but slow 3D finite element method (FEM) simulation. Sampling-based grasp planning is often impractical, as it requires evaluation of a large number of grasp candidates. Gradient-based grasp planning can be more efficient, but requires a differentiable model to synthesize optimal grasps from initial candidates. Differentiable FEM simulators may fill this role, but are typically no faster than standard FEM. In this work, we propose learning a predictive graph neural network (GNN), DefGraspNets, to act as our differentiable model. We train DefGraspNets to predict 3D stress and deformation fields based on FEM-based grasp simulations. DefGraspNets not only runs up to 1500x faster than the FEM simulator, but also enables fast gradient-based grasp optimization over 3D stress and deformation metrics. We design DefGraspNets to align with real-world grasp planning practices and demonstrate generalization across multiple test sets, including real-world experiments.",
        "primary_area": "",
        "author": "Isabella Huang;Yashraj Narang;Ruzena Bajcsy;Fabio Ramos;Tucker Hermans;Dieter Fox;Isabella Huang;Yashraj Narang;Ruzena Bajcsy;Fabio Ramos;Tucker Hermans;Dieter Fox",
        "authorids": "/37086538069;/37085801324;/37298488400;/37285364500;/38230909600;/37284329000;/37086538069;/37085801324;/37298488400;/37285364500;/38230909600;/37284329000",
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, USA; NVIDIA Corporation, Seattle, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, USA; School of Computer Science, University of Sydney, Sydney, Australia; School of Computing, University of Utah, Salt Lake City, USA; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160986/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5696409803127623524&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;3;4",
        "aff_unique_norm": "University of California, Berkeley;NVIDIA Corporation;University of Sydney;University of Utah;University of Washington",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences;;School of Computer Science;School of Computing;Paul G. Allen School of Computer Science & Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://www.nvidia.com;https://www.sydney.edu.au;https://www.utah.edu;https://www.washington.edu",
        "aff_unique_abbr": "UC Berkeley;NVIDIA;USYD;U of U;UW",
        "aff_campus_unique_index": "0;1;0;2;3;1",
        "aff_campus_unique": "Berkeley;Seattle;Sydney;Salt Lake City",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "10161447",
        "title": "Demonstration-Bootstrapped Autonomous Practicing via Multi-Task Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning systems have the potential to enable continuous improvement in unstructured environments, leveraging data collected autonomously. However, in practice these systems require significant amounts of instrumentation or human intervention to learn in the real world. In this work, we propose a system for reinforcement learning that leverages multi-task reinforcement learning bootstrapped with prior data to enable continuous autonomous practicing, minimizing the number of resets needed while being able to learn temporally extended behaviors. We show how appropriately provided prior data can help bootstrap both low-level multi-task policies and strategies for sequencing these tasks one after another to enable learning with minimal resets. This mechanism enables our robotic system to practice with minimal human intervention at training time, while being able to solve long horizon tasks at test time. We show the efficacy of the proposed system on a challenging kitchen manipulation task both in simulation and the real world, demonstrating the ability to practice autonomously in order to solve temporally extended problems.",
        "primary_area": "",
        "author": "Abhishek Gupta;Corey Lynch;Brandon Kinman;Garrett Peake;Sergey Levine;Karol Hausman;Abhishek Gupta;Corey Lynch;Brandon Kinman;Garrett Peake;Sergey Levine;Karol Hausman",
        "authorids": "/37085516247;/37086099911;/37089446770;/37089893801;/37085481973;/37077039600;/37085516247;/37086099911;/37089446770;/37089893801;/37085481973;/37077039600",
        "aff": "UC Berkeley; Robotics at Google; Robotics at Google; Robotics at Google; UC Berkeley; Robotics at Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161447/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3974697372709345148&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "University of California, Berkeley;Google",
        "aff_unique_dep": ";Robotics",
        "aff_unique_url": "https://www.berkeley.edu;https://www.google.com",
        "aff_unique_abbr": "UC Berkeley;Google Robotics",
        "aff_campus_unique_index": "0;1;1;1;0;1",
        "aff_campus_unique": "Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160327",
        "title": "Demonstration-Guided Reinforcement Learning with Efficient Exploration for Task Automation of Surgical Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Task automation of surgical robot has the potentials to improve surgical efficiency. Recent reinforcement learning (RL) based approaches provide scalable solutions to surgical automation, but typically require extensive data collection to solve a task if no prior knowledge is given. This issue is known as the exploration challenge, which can be alleviated by providing expert demonstrations to an RL agent. Yet, how to make effective use of demonstration data to improve exploration efficiency still remains an open challenge. In this work, we introduce Demonstration-guided EXploration (DEX), an efficient reinforcement learning algorithm that aims to overcome the exploration problem with expert demonstrations for surgical automation. To effectively exploit demonstrations, our method estimates expert-like behaviors with higher values to facilitate productive interactions, and adopts non-parametric regression to enable such guidance at states unobserved in demonstration data. Extensive experiments on 10 surgical manipulation tasks from SurRoL, a comprehensive surgical simulation platform, demonstrate significant improvements in the exploration efficiency and task success rates of our method. Moreover, we also deploy the learned policies to the da Vinci Research Kit (dVRK) platform to show the effectiveness on the real robot. Code is available at https://github.com/med-air/DEX.",
        "primary_area": "",
        "author": "Tao Huang;Kai Chen;Bin Li;Yun-Hui Liu;Qi Dou;Tao Huang;Kai Chen;Bin Li;Yun-Hui Liu;Qi Dou",
        "authorids": "/37089876860;/37404002500;/37089266122;/37279412600;/37085465414;/37089876860;/37404002500;/37089266122;/37279412600;/37085465414",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160327/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1736019616139187862&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161496",
        "title": "Demonstration-guided Optimal Control for Long-term Non-prehensile Planar Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Long-term non-prehensile planar manipulation is a challenging task for robot planning and feedback control. It is characterized by underactuation, hybrid control, and contact uncertainty. One main difficulty is to determine both the continuous and discrete contact configurations, e.g., contact points and modes, which requires joint logical and geometrical reasoning. To tackle this issue, we propose a demonstration-guided hierarchical optimization framework to achieve offline task and motion planning (TAMP). Our work extends the formulation of the dynamics model of the pusher-slider system to include separation mode with face switching mechanism, and solves a warm-started TAMP problem by exploiting human demonstrations. We show that our approach can cope well with the local minima problems currently present in the state-of-the-art solvers and determine a valid solution to the task. We validate our results in simulation and demonstrate its applicability on a pusher-slider system with a real Franka Emika robot in the presence of external disturbances. Project webpage: https://sites.google.com/view/dg-oc/.",
        "primary_area": "",
        "author": "Teng Xue;Hakan Girgin;Teguh Santoso Lembono;Sylvain Calinon;Teng Xue;Hakan Girgin;Teguh Santoso Lembono;Sylvain Calinon",
        "authorids": "/37089893955;/37086578243;/37085616225;/37295947200;/37089893955;/37086578243;/37085616225;/37295947200",
        "aff": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161496/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9043284363675979614&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161549",
        "title": "Dense Depth Completion Based on Multi-Scale Confidence and Self-Attention Mechanism for Intestinal Endoscopy",
        "track": "main",
        "status": "Poster",
        "abstract": "Doctors perform limited one-way intestine endoscopy, in which advanced surgical robots with depth sensors, such as stereo and ToF endoscopes, can only provide sparse and incomplete depth information. However, dense, accurate and instant depth estimation during endoscopy is vital for doctors to judge the 3D location and shape of intestinal tissues, which affects the human-robot interaction between doctors and surgical robots, such as the operation on the subsequent moving of the probe. In this paper, we present a deep learning-based dense depth completion method for intestine endoscopy. We utilize the scattered depth information from depth sensors to make up for the deficiency of features in the intestine and design a multi-scale confidence prediction network to extract dense geometric depth features. Then, we introduce the structure awareness module based on the self-attention mechanism in the depth completion network to enhance the geometry and texture features of the intestine. We also present a virtual multi-modal RGBD intestine dataset and conduct comprehensive experiments on a total of three intestine datasets. The experimental results clearly demonstrate that our method achieves better results in all metrics in all intestinal environments compared to state-of-the-art methods.",
        "primary_area": "",
        "author": "Ruyu Liu;Zhengzhe Liu;Haoyu Zhang;Guodao Zhang;Zhigui Zuo;Weiguo Sheng;Ruyu Liu;Zhengzhe Liu;Haoyu Zhang;Guodao Zhang;Zhigui Zuo;Weiguo Sheng",
        "authorids": "/37086354166;/37085644612;/37089892989;/37088986552;/37089895292;/37276312100;/37086354166;/37085644612;/37089892989;/37088986552;/37089895292;/37276312100",
        "aff": "Haixi Institutes, Chinese Academy of Sciences Quanzhou Institute of Equipment Manufacturing, Quanzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; Department of Digital Media Technology, Hangzhou Dianzi University, Hangzhou, China; Department of Colorectal Surgery, The First Affiliated Hospital of Wenzhou Medical University, Wenzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161549/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13162714938800875387&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;3;1",
        "aff_unique_norm": "Chinese Academy of Sciences;Hangzhou Normal University;Hangzhou Dianzi University;The First Affiliated Hospital of Wenzhou Medical University",
        "aff_unique_dep": "Haixi Institutes;School of Information Science and Technology;Department of Digital Media Technology;Department of Colorectal Surgery",
        "aff_unique_url": "http://www.cas.cn;http://www.hgh.edu.cn;http://www.hdu.edu.cn;",
        "aff_unique_abbr": "CAS;;HDU;",
        "aff_campus_unique_index": "0;1;1;1;2;1",
        "aff_campus_unique": "Quanzhou;Hangzhou;Wenzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161150",
        "title": "DenseTact 2.0: Optical Tactile Sensor for Shape and Force Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots stand to have an immense impact on both human welfare in domestic service applications and industrial superiority in advanced manufacturing with dexterous assembly. The outstanding challenge is providing robotic fingertips with a physical design that makes them adept at performing dexterous tasks that require high-resolution, calibrated shape reconstruction and force sensing. In this work, we present DenseTact 2.0, an optical-tactile sensor capable of visualizing the deformed surface of a soft fingertip and using that image in a neural network to perform both calibrated shape reconstruction and 6-axis wrench estimation. We demon-strate the sensor accuracy of 0.3633mm per pixel for shape reconstruction, 0.410N for forces, 0.387N. mm for torques, and the ability to calibrate new fingers through transfer learning, which achieves comparable performance with only 12% of the non-transfer learning dataset size.",
        "primary_area": "",
        "author": "Won Kyung Do;Bianca Jurewicz;Monroe Kennedy;Won Kyung Do;Bianca Jurewicz;Monroe Kennedy",
        "authorids": "/37086922065;/37089895586;/37089500447;/37086922065;/37089895586;/37089500447",
        "aff": "Mechanical Engineering Department, ARMLab, Stanford University, Stanford, CA, USA; Mechanical Engineering Department, ARMLab, Stanford University, Stanford, CA, USA; Mechanical Engineering Department, ARMLab, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161150/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8132186316901213043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161378",
        "title": "Density Planner: Minimizing Collision Risk in Motion Planning with Dynamic Obstacles using Density-based Reachability",
        "track": "main",
        "status": "Poster",
        "abstract": "Uncertainty is prevalent in robotics. Due to measurement noise and complex dynamics, we cannot estimate the exact system and environment state. Since conservative motion planners are not guaranteed to find a safe control strategy in a crowded, uncertain environment, we propose a density-based method. Our approach uses a neural network and the Liouville equation to learn the density evolution for a system with an uncertain initial state. We can plan for feasible and probably safe trajectories by applying a gradient-based optimization procedure to minimize the collision risk. We conduct motion planning experiments on simulated environments and environments generated from real-world data and outperform baseline methods such as model predictive control and nonlinear programming. While our method requires offline planning, the online run time is 100 times smaller compared to model predictive control. The code and supplementary material can be found at https://mit-realm.github.io/density_planner/.",
        "primary_area": "",
        "author": "Laura L\u00fctzow;Yue Meng;Andres Chavez Armijos;Chuchu Fan;Laura L\u00fctzow;Yue Meng;Andres Chavez Armijos;Chuchu Fan",
        "authorids": "/37089892919;/37089197843;/37089892656;/38564621900;/37089892919;/37089197843;/37089892656;/38564621900",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, USA; Division of Systems Engineering, Boston University, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161378/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11689875643037068940&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Boston University",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;Division of Systems Engineering",
        "aff_unique_url": "https://web.mit.edu;https://www.bu.edu",
        "aff_unique_abbr": "MIT;BU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161012",
        "title": "Density-aware NeRF Ensembles: Quantifying Predictive Uncertainty in Neural Radiance Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "We show that ensembling effectively quantifies model uncertainty in Neural Radiance Fields (NeRFs) if a density-aware epistemic uncertainty term is considered. The naive ensembles investigated in prior work simply average rendered RGB images to quantify the model uncertainty caused by conflicting explanations of the observed scene. In contrast, we additionally consider the termination probabilities along individual rays to identify epistemic model uncertainty due to a lack of knowledge about the parts of a scene unobserved during training. We achieve new state-of-the-art performance across established uncertainty quantification benchmarks for NeRFs, outperforming methods that require complex changes to the NeRF architecture and training regime. We furthermore demonstrate that NeRF uncertainty can be utilised for next-best view selection and model refinement.",
        "primary_area": "",
        "author": "Niko S\u00fcnderhauf;Jad Abou-Chakra;Dimity Miller;Niko S\u00fcnderhauf;Jad Abou-Chakra;Dimity Miller",
        "authorids": "/37563890800;/37089893388;/37086453967;/37563890800;/37089893388;/37086453967",
        "aff": "Queensland University of Technology (QUT) in Brisbane, Australia; Queensland University of Technology (QUT) in Brisbane, Australia; Queensland University of Technology (QUT) in Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161012/",
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15142195911472814582&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160925",
        "title": "Depth Estimation for Oral Cavity by Shape from Shading with Endoscope",
        "track": "main",
        "status": "Poster",
        "abstract": "Tracheal intubation for patients with respiratory infectious diseases requires doctors to wear a full set of protective clothing, which takes a certain time. How to protect doctors from infection when facing an emergency operation has become an important issue. The intubation robot may solve this contradiction. To provide visual information for real-time path planning for robotic intubation, this study recovers depth information about the oral environment using the low-cost and widely used endoscopic. Since the oral cavity is small and has less texture, the Shape from Shading (SFS) method may be a good choice for oral depth estimation. This paper proposes the \u201coral elbow\u201d hypothesis, filters outliers caused by saliva, calculates the 3-D contour map, and highlights the contour map features from different views. Oral images are obtained from a healthy person and a silicon dummy. This work expands the application scenarios of depth estimation to the oral environment; provides depth information for the visual navigation of the intubation surgical robot.",
        "primary_area": "",
        "author": "Xi Wu;Gangtie Zheng;Xi Wu;Gangtie Zheng",
        "authorids": "/37089894233;/37089227869;/37089894233;/37089227869",
        "aff": "School of Aerospace Engineering, Tsinghua University, Beijing, China; School of Aerospace Engineering, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160925/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15364128633330846288&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "School of Aerospace Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160483",
        "title": "Depth Is All You Need for Monocular 3D Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "A key contributor to recent progress in 3D detection from single images is monocular depth estimation. Existing methods focus on how to leverage depth explicitly, by generating pseudo-pointclouds or providing attention cues for image features. More recent works leverage depth prediction as a pretraining task and fine-tune the depth representation while training it for 3D detection. However, the adaptation is limited in scale by manual labels. In this work, we propose further aligning the depth representation with the target domain in an unsupervised fashion. Our methods leverage commonly available LiDAR or RGB videos during training time to fine-tune the depth representation, which leads to improved 3D detectors. Especially when using RGB videos, we show that our two-stage training by first generating depth pseudo-labels is critical, because of the inconsistency in loss distribution between the two tasks. With either type of reference data, our multi-task learning approach improves over the state of the art on both KITTI and NuScenes, while matching the test-time complexity of its single-task sub-network. Source code and pretrained models are available on https://github.com/TRI-ML/DD3D.",
        "primary_area": "",
        "author": "Dennis Park;Jie Li;Dian Chen;Vitor Guizilini;Adrien Gaidon;Dennis Park;Jie Li;Dian Chen;Vitor Guizilini;Adrien Gaidon",
        "authorids": "/37089319989;/37085348265;/37089536880;/37946098900;/37945420900;/37089319989;/37085348265;/37089536880;/37946098900;/37945420900",
        "aff": "Toyota Research Institute; Toyota Research Institute; Dian Chen; Vitor Guizilini; Adrien Gaidon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160483/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7370193840251115014&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyota Research Institute;",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tri.global;",
        "aff_unique_abbr": "TRI;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "10160541",
        "title": "Descriptor Distillation for Efficient Multi-Robot SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Performing accurate localization while maintaining the low-level communication bandwidth is an essential challenge of multi-robot simultaneous localization and mapping (MR-SLAM). In this paper, we tackle this problem by generating a compact yet discriminative feature descriptor with minimum inference time. We propose descriptor distillation that formulates the descriptor generation into a learning problem under the teacher-student framework. To achieve real-time descriptor generation, we design a compact student network and learn it by transferring the knowledge from a pre-trained large teacher model. To reduce the descriptor dimensions from the teacher to the student, we propose a novel loss function that enables the knowledge transfer between two different dimensional descriptors. The experimental results demonstrate that our model is 30% lighter than the state-of-the-art model and produces better descriptors in patch matching. Moreover, we build a MR-SLAM system based on the proposed method and show that our descriptor distillation can achieve higher localization performance for MR-SLAM with lower bandwidth.",
        "primary_area": "",
        "author": "Xiyue Guo;Junjie Hu;Hujun Bao;Guofeng Zhang;Xiyue Guo;Junjie Hu;Hujun Bao;Guofeng Zhang",
        "authorids": "/37088961551;/37088469703;/37271755400;/37405938800;/37088961551;/37088469703;/37271755400;/37405938800",
        "aff": "State Key Lab of CAD&CG, Zhejiang University; Chinese University of Hong Kong, Shenzhen; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160541/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17338008439898444714&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Zhejiang University;Chinese University of Hong Kong",
        "aff_unique_dep": "State Key Lab of CAD&CG;",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.cuhk.edu.cn",
        "aff_unique_abbr": "ZJU;CUHK",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161225",
        "title": "Design Optimization and Data-driven Shallow Learning for Dynamic Modeling of a Smart Segmented Electroadhesive Clutch",
        "track": "main",
        "status": "Poster",
        "abstract": "Electroadhesive clutches have attracted a great deal of interest in the last decade as semi-active actuators for human-robot interaction due to their lightweight, low power consumption, and tunable high-torque output capability. However, because of the complexity of their dynamics, in most cases, they are utilized in an ON/OFF -control strategy. In this regard, the non-autonomous (time-dependent) degradation of electroadhesive behavior is an inherent challenge that injects unpredictability and uncertainty into the behavior of this family of semi-active clutches. We propose a novel approach to preventing degradation of electroadhesion using a segmented electrode design that modulates the electrical field on the dielectric surface while using a direct current signal and securing low power consumption. This paper, for the first time, presents an optimization process based on a novel analytic model of the proposed actuator. It also develops a data-driven model augmentation using a hybrid shallow learning approach composed of a long short-term memory (LSTM) architecture which is combined with the analytical model. The performance of the proposed semi-active clutch and the data-driven hybrid model is experimentally validated in this paper.",
        "primary_area": "",
        "author": "Navid Feizi;Zahra Bahrami;S. Farokh Atashzar;Mehrdad R. Kermani;Rajni V. Patel;Navid Feizi;Zahra Bahrami;S. Farokh Atashzar;Mehrdad R. Kermani;Rajni V. Patel",
        "authorids": "/37086131797;/37086925060;/37592440100;/37266294100;/37271878600;/37086131797;/37086925060;/37592440100;/37266294100;/37271878600",
        "aff": "School of Biomedical Engineering, Western University, London, ON, Canada; Institute of Geography, University of Erlangen-Nuremberg, Erlangen, Germany; NYU WIRELESS and NYU CUSP; Department of Electrical and Computer Engineering, Western University, London, ON, Canada; Department of Electrical and Computer Engineering, the Department of Surgery, and the Department of Clinical Neurological Sciences, School of Biomedical Engineering, Western University, London, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161225/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:zzfs7Xs4Ze0J:scholar.google.com/&scioq=Design+Optimization+and+Data-driven+Shallow+Learning+for+Dynamic+Modeling+of+a+Smart+Segmented+Electroadhesive+Clutch&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Western University;University of Erlangen-Nuremberg;New York University",
        "aff_unique_dep": "School of Biomedical Engineering;Institute of Geography;NYU WIRELESS",
        "aff_unique_url": "https://www.uwo.ca;https://www.uni-erlangen.de;https://www.nyu.edu",
        "aff_unique_abbr": "Western;;NYU",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "London;Erlangen;New York",
        "aff_country_unique_index": "0;1;2;0;0",
        "aff_country_unique": "Canada;Germany;United States"
    },
    {
        "id": "10161060",
        "title": "Design and Control of a Micro Overactuated Aerial Robot with an Origami Delta Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents the mechanical design and control of a novel small-size and lightweight Micro Aerial Vehicle (MAV) for aerial manipulation. To our knowledge, with a total take-off mass of only 2.0 kg, the proposed system is the most lightweight Aerial Manipulator (AM) that has 8-DOF independently controllable: 5 for the aerial platform and 3 for the articulated arm. We designed the robot to be fully-actuated in the body forward direction. This allows independent pitching and instantaneous force generation, improving the platform's performance during physical interaction. The robotic arm is an origami delta manipulator driven by three servomotors, enabling active motion compensation at the end-effector. Its composite multimaterial links help reduce the weight, while their flexibility allow for compliant aerial interaction with the environment. In particular, the arm's stiffness can be changed according to its configuration. We provide an in depth discussion of the system design and characterize the stiffness of the delta arm. A control architecture to deal with the platform's overactuation while exploiting the delta arm is presented. Its capabilities are experimentally illustrated both in free flight and physical interaction, highlighting advantages and disadvantages of the origami's folding mechanism.",
        "primary_area": "",
        "author": "Eugenio Cuniato;Christian Geckeler;Maximilian Brunner;Dario Str\u00fcbin;Elia B\u00e4hler;Fabian Ospelt;Marco Tognon;Stefano Mintchev;Roland Siegwart;Eugenio Cuniato;Christian Geckeler;Maximilian Brunner;Dario Str\u00fcbin;Elia B\u00e4hler;Fabian Ospelt;Marco Tognon;Stefano Mintchev;Roland Siegwart",
        "authorids": "/37089225670;/37086453068;/37086325079;/37089892433;/37089893279;/37089895455;/37085377048;/37085587624;/37281398300;/37089225670;/37086453068;/37086325079;/37089892433;/37089893279;/37089895455;/37085377048;/37085587624;/37281398300",
        "aff": "ETH Zurich, Autonomous Systems Laboratory, Switzerland; ETH Zurich, Environmental Robotics Laboratory, Switzerland; ETH Zurich, Autonomous Systems Laboratory, Switzerland; ETH Zurich, Autonomous Systems Laboratory, Switzerland; ETH Zurich, Autonomous Systems Laboratory, Switzerland; ETH Zurich, Autonomous Systems Laboratory, Switzerland; ETH Zurich, Autonomous Systems Laboratory, Switzerland; ETH Zurich, Environmental Robotics Laboratory, Switzerland; ETH Zurich, Autonomous Systems Laboratory, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161060/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12516254771061966989&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Laboratory",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161218",
        "title": "Design and Control of a Tunable-Stiffness Coiled-Spring Actuator",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel design for a lightweight and compact tunable stiffness actuator capable of stiffness changes up to 20x. The design is based on the concept of a coiled spring, where changes in the number of layers in the spring change the bulk stiffness in a near linear fashion. We present an elastica nested rings model for the deformation of the proposed actuator and empirically verify that the designed stiffness-changing spring abides by this model. Using the resulting model, we design a physical prototype of the tunable-stiffness coiled-spring actuator and discuss the effect of design choices on the resulting achievable stiffness range and resolution. In the future, this actuator design could be useful in a wide variety of soft robotics applications, where fast, controllable, and local stiffness change is required over a large range of stiffnesses.",
        "primary_area": "",
        "author": "Shivangi Misra;Mason Mitchell;Rongqian Chen;Cynthia Sung;Shivangi Misra;Mason Mitchell;Rongqian Chen;Cynthia Sung",
        "authorids": "/37088073413;/37088982932;/37089507269;/37086639646;/37088073413;/37088982932;/37089507269;/37086639646",
        "aff": "General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA; Soft Robotics Lab, Worcester Polytechnic Institute, Worcester, MA, USA; General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA; General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161218/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1069952589037343190&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Pennsylvania;Worcester Polytechnic Institute",
        "aff_unique_dep": "General Robotics, Automation, Sensing & Perception (GRASP) Lab;Soft Robotics Lab",
        "aff_unique_url": "https://www.upenn.edu;https://www.wpi.edu",
        "aff_unique_abbr": "UPenn;WPI",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Philadelphia;Worcester",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160807",
        "title": "Design and Development of a Hydrogel-based Soft Sensor for Multi-Axis Force Control",
        "track": "main",
        "status": "Poster",
        "abstract": "As soft robotic systems become increasingly complex, there is a need to develop sensory systems which can provide rich state information to the robot for feedback control. Multi-axis force sensing and control is one of the less explored problems in this domain. There are numerous challenges in the development of a multi-axis soft sensor: from the design and fabrication to the data processing and modelling. This work presents the design and development of a novel multi-axis soft sensor using a gelatin-based ionic hydrogel and 3D printing technology. A learning-based modelling approach coupled with sensor redundancy is developed to model the environmentally dependent soft sensors. Numerous real-time experiments are conducted to test the performance of the sensor and its applicability in closed-loop control tasks at 20 Hz. Our results indicate that the soft sensor can predict force values and orientation angle within 4% and 7% of their total range, respectively.",
        "primary_area": "",
        "author": "Yichen Cai;David Hardman;Fumiya Iida;Thomas George Thuruthel;Yichen Cai;David Hardman;Fumiya Iida;Thomas George Thuruthel",
        "authorids": "/37089893501;/37088852636;/37552719700;/37086306163;/37089893501;/37088852636;/37552719700;/37086306163",
        "aff": "Bio-Inspired Robotics Lab, University of Cambridge, UK; Bio-Inspired Robotics Lab, University of Cambridge, UK; Bio-Inspired Robotics Lab, University of Cambridge, UK; Bio-Inspired Robotics Lab, University of Cambridge, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160807/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9007668633056687271&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Bio-Inspired Robotics Lab",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160254",
        "title": "Design and Development of a Novel Force-Sensing Robotic System for the Transseptal Puncture in Left Atrial Catheter Ablation",
        "track": "main",
        "status": "Poster",
        "abstract": "Transseptal puncture (TSP) is a prerequisite for left atrial catheter ablation for atrial fibrillation, requiring access from the right side of the heart. It is a demanding procedural step associated with complications, including inadvertent puncturing and application of large forces on the tissue wall. Robotic systems have shown great potential to overcome such challenges by introducing force-sensing capabilities and increased precision and localization accuracy. Therefore, this work introduces the design and development of a novel robotic system developed to perform TSP. We integrated optoelectronic sensors into the tools' fixtures, measuring tissue contact and puncture forces along one axis. The novelty of this design is in the system's ability to manipulate a Brockenbrough (BRK) needle and dilator-sheath simultaneously and measure tissue contact and puncture forces. In performing puncture experiments on anthropomorphic tissue models, an average puncture force of 3.97 \u00b1 0.45 N (1SD) was established - similar to the force reported in literature on the manual procedure. This research highlights the potential for improving patient safety by enforcing force constraints, paving the way to more automated and safer TSP.",
        "primary_area": "",
        "author": "Aya Mutaz Zeidan;Zhouyang Xu;Christopher E. Mower;Honglei Wu;Quentin Walker;Oyinkansola Ayoade;Natalia Cotic;Jonathan Behar;Steven Williams;Aruna Arujuna;Yohan Noh;Richard Housden;Kawal Rhode;Aya Mutaz Zeidan;Zhouyang Xu;Christopher E. Mower;Honglei Wu;Quentin Walker;Oyinkansola Ayoade;Natalia Cotic;Jonathan Behar;Steven Williams;Aruna Arujuna;Yohan Noh;Richard Housden;Kawal Rhode",
        "authorids": "/37089892569;/37089892457;/37086311529;/37089895877;/37089895351;/37089892706;/37089893858;/37085898120;/37086092694;/37972789800;/37085437433;/38559299300;/37294454000;/37089892569;/37089892457;/37086311529;/37089895877;/37089895351;/37089892706;/37089893858;/37085898120;/37086092694;/37972789800;/37085437433;/38559299300;/37294454000",
        "aff": "Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Mechanical and Aerospace Engineering, Brunel University, London, Uxbridge, U.K; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.; Department of Surgical & Interventional Engineering, School of Biomedical Engineering & Imaging Sciences, King's College London, London, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160254/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18231766545354565092&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "King's College London;Brunel University",
        "aff_unique_dep": "Department of Surgical & Interventional Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.kcl.ac.uk;https://www.brunel.ac.uk",
        "aff_unique_abbr": "KCL;Brunel",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;1;0;0",
        "aff_campus_unique": "London;Uxbridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161278",
        "title": "Design and Evaluation of an Augmented Reality Head-Mounted Display User Interface for Controlling Legged Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing an intuitive User Interface (UI) for controlling assistive robots remains challenging. Most existing UIs leverage traditional control interfaces such as joysticks, hand-held controllers, and 2D UIs. Thus, users have limited availability to use their hands for other tasks. Furthermore, although there is extensive research regarding legged manipulators, comparatively little is on their UIs. Towards extending the state-of-art in this domain, we provide a user study comparing an Augmented Reality (AR) Head-Mounted Display (HMD) UI we developed for controlling a legged manipulator against off-the-shelf control methods for such robots. We made this comparison baseline across multiple factors relevant to a successful interaction. The results from our user study (N=17N=17N=17) show that although the AR UI increases immersion, off-the-shelf control methods outperformed the AR UI in terms of time performance and cognitive workload. Nonetheless, a follow-up pilot study incorporating the lessons learned shows that AR UIs can outpace hand-held-based control methods and reduce the cognitive requirements when designers include hands-free interactions and cognitive offloading principles into the UI.",
        "primary_area": "",
        "author": "Rodrigo Chac\u00f3n Quesada;Yiannis Demiris;Rodrigo Chac\u00f3n Quesada;Yiannis Demiris",
        "authorids": "/37089340834;/37296338900;/37089340834;/37296338900",
        "aff": "Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College London, London, United Kingdom; Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161278/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6674566069880809906&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160832",
        "title": "Design and Mechanics of Cable-Driven Rolling Diaphragm Transmission for High-Transparency Robotic Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Applications of rolling diaphragm transmissions for medical and teleoperated robotics are of great interest, due to the low friction of rolling diaphragms combined with the power density and stiffness of hydraulic transmissions. However, the stiffness-enabling pressure preloads can form a tradeoff against bearing loading in some rolling diaphragm layouts, and transmission setup can be difficult. Utilization of cable drives compliment the rolling diaphragm transmission's advantages, but maintaining cable tension is crucial for optimal and consistent performance. In this paper, a coaxial opposed rolling diaphragm layout with cable drive and an electronic transmission control system are investigated, with a focus on system reliability and scalability. Mechanical features are proposed which enable force balancing, decoupling of transmission pressure from bearing loads, and maintenance of cable tension. Key considerations and procedures for automation of transmission setup, phasing, and operation are also presented. We also present an analysis of system stiffness to identify key compliance contributors, and conduct experiments to validate prototype design performance.",
        "primary_area": "",
        "author": "Hoi Man Lam;W. Jared Walker;Lucas Jonasch;Dimitri Schreiber;Michael C. Yip;Hoi Man Lam;W. Jared Walker;Lucas Jonasch;Dimitri Schreiber;Michael C. Yip",
        "authorids": "/37089353225;/37089893177;/37089892547;/37087322737;/37085382768;/37089353225;/37089893177;/37089892547;/37087322737;/37085382768",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering, University of California San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering, University of California San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160832/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:wGYXQrFrjBkJ:scholar.google.com/&scioq=Design+and+Mechanics+of+Cable-Driven+Rolling+Diaphragm+Transmission+for+High-Transparency+Robotic+Motion&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California San Diego",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160389",
        "title": "Design and Validation of a Multi-Arm Relocatable Manipulator for Space Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents the computational design and validation of the Multi-Arm Relocatable Manipulator (MARM), a three-limb robot for space applications, with particular reference to the MIRROR (i.e., the Multi-arm Installation Robot for Readying ORUs and Reflectors) use-case scenario as proposed by the European Space Agency. A holistic computational design and validation pipeline is proposed, with the aim of comparing different limb designs, as well as ensuring that valid limb candidates enable MARM to perform the complex loco-manipulation tasks required. Moti-vated by the task complexity in terms of kinematic reachability, (self)-collision avoidance, contact wrench limits, and motor torque limits affecting Earth experiments, this work leverages on multiple state-of-art planning and control approaches to aid the robot design and validation. These include sampling-based planning on manifolds, non-linear trajectory optimization, and quadratic programs for inverse dynamics computations with constraints. Finally, we present the attained MARM design and conduct preliminary tests for hardware validation through a set of lab experiments.",
        "primary_area": "",
        "author": "Enrico Mingo Hoffman;Arturo Laurenzi;Francesco Ruscelli;Luca Rossini;Lorenzo Baccelliere;Davide Antonucci;Alessio Margan;Paolo Guria;Marco Migliorini;Stefano Cordasco;Gennaro Raiola;Luca Muratore;Joaqu\u00edn Estremera Rodrigo;Andrea Rusconi;Guido Sangiovanni;Nikos G. Tsagarakis;Enrico Mingo Hoffman;Arturo Laurenzi;Francesco Ruscelli;Luca Rossini;Lorenzo Baccelliere;Davide Antonucci;Alessio Margan;Paolo Guria;Marco Migliorini;Stefano Cordasco;Gennaro Raiola;Luca Muratore;Joaqu\u00edn Estremera Rodrigo;Andrea Rusconi;Guido Sangiovanni;Nikos G. Tsagarakis",
        "authorids": "/37085377101;/37086141170;/37086034535;/37394440300;/37086298221;/37089893554;/37085533071;/37086692970;/37089893474;/37086298765;/37085402464;/37086139432;/37089896007;/37550154200;/37089895631;/37295830800;/37085377101;/37086141170;/37086034535;/37394440300;/37086298221;/37089893554;/37085533071;/37086692970;/37089893474;/37086298765;/37085402464;/37086139432;/37089896007;/37550154200;/37089895631;/37295830800",
        "aff": "Leonardo S.p.A., Viale Europa, Nerviano, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Leonardo S.p.A., Viale Europa, Nerviano, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; GMV, Madrid, Spain; Leonardo S.p.A., Viale Europa, Nerviano, Italy; Leonardo S.p.A., Viale Europa, Nerviano, Italy; Humanoids & Human Centred Mechatronics Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160389/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5547877717121254692&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 32,
        "aff_unique_index": "0;1;1;1;1;1;1;1;1;1;0;1;2;0;0;1",
        "aff_unique_norm": "Leonardo S.p.A.;Istituto Italiano di Tecnologia;GMV",
        "aff_unique_dep": ";Humanoids & Human Centred Mechatronics Lab.;",
        "aff_unique_url": "https://www.leonardo.com;https://www.iit.it;https://www.gmv.com/",
        "aff_unique_abbr": ";IIT;",
        "aff_campus_unique_index": "1;1;1;1;1;1;1;1;1;1;2;1",
        "aff_campus_unique": ";Genova;Madrid",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0",
        "aff_country_unique": "Italy;Spain"
    },
    {
        "id": "10161524",
        "title": "Design and characterization of a low mechanical loss, high-resolution wearable strain gauge",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft, wearable systems hold promise for a wide variety of new or enhanced applications in the realm of human-computer interaction, physiological monitoring, wear-able robotics, and a host of other human-centric devices. Soft sensor systems have been developed concurrently in order to allow these wearable systems to respond intelligently with their surroundings. A recently reported sensing mechanism based on the strain-mediated contact in anisotropically resistive structures (SCARS) is an attractive solution due to its high sensing resolution, low-profile nature, and high mechanical resilience. Furthermore, the resistance-based output provides a simple electronic readout, facilitating its use in a wide variety of applications. However, previous iterations of the sensing mech-anism have exhibited stress relaxation and hysteretic behaviors that limit the scope of its use. Here, we report an iteration of the SCARS mechanism that uses silicone-based materials with low mechanical loss in order to improve the sensor signal stability and bandwidth. A new fabrication approach is developed which permits the incorporation of a liquid elastomer adhesive layer while also preserving the SCARS sensing functionality. The silicone-based SCARS sensors exhibited fast stress relaxation response (< 1 s) and reduced cyclic drift properties by more than half that of previously reported designs. A physiological monitoring demonstration is presented, validating that the new sensor design is mechanically resilient to such applications and has potential for use in real-world wearable use cases.",
        "primary_area": "",
        "author": "Addison Liu;Seun Araromi;Conor J. Walsh;Robert J. Wood;Addison Liu;Seun Araromi;Conor J. Walsh;Robert J. Wood",
        "authorids": "/37089895828;/37089894040;/37951364100;/37326227400;/37089895828;/37089894040;/37951364100;/37326227400",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161524/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8369025383163377487&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160256",
        "title": "Design of a Multimodal Fingertip Sensor for Dynamic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a spherical fingertip sensor for dynamic manipulation. It is based on barometric pressure and time-of-flight proximity sensors and is low-latency, compact, and physically robust. The sensor uses a trained neural network to estimate the contact location and three-axis contact forces based on data from the pressure sensors, which are embedded within the sensor's sphere of polyurethane rubber. The time-of-flight sensors face in three different outward directions, and an integrated microcontroller samples each of the individual sensors at up to 200 Hz. To quantify the effect of system latency on dynamic manipulation performance, we develop and analyze a metric called the collision impulse ratio and characterize the end-to-end latency of our new sensor. We also present experimental demonstrations with the sensor, including measuring contact transitions, performing coarse mapping, maintaining a contact force with a moving object, and reacting to avoid collisions.",
        "primary_area": "",
        "author": "Andrew SaLoutos;Elijah Stanger-Jones;Menglong Guo;Hongmin Kim;Sangbae Kim;Andrew SaLoutos;Elijah Stanger-Jones;Menglong Guo;Hongmin Kim;Sangbae Kim",
        "authorids": "/37088688960;/37088991680;/37085891920;/37089893288;/37537397200;/37088688960;/37088991680;/37085891920;/37089893288;/37537397200",
        "aff": "Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160256/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3788247481296001667&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161305",
        "title": "Design of a Variable Stiffness Spring with Human-Selectable Stiffness",
        "track": "main",
        "status": "Poster",
        "abstract": "Springs are commonly used in wearable robotic devices to provide assistive joint torque without the need for motors and batteries. However, different tasks (such as walking or running) and different users (such as athletes with strong legs or the elderly with weak legs) necessitate different assistive joint torques, and therefore, springs with different stiffness. Variable stiffness springs are a special class of springs which can exert more or less torque upon the same deflection, provided that the user is able to change the stiffness of the spring. In this paper, we present a novel variable stiffness spring design in which the user can select a preferred spring stiffness similar to switching gears on a bicycle. Using a leg-swing experiment, we demonstrate that the user can increment and decrement spring stiffness in a large range to effectively assist the hip joint during leg oscillations. Variable stiffness springs with human-selectable stiffness could be key components of wearable devices which augment locomotion tasks, such as walking, running, and swimming.",
        "primary_area": "",
        "author": "Chase W. Mathews;David J. Braun;Chase W. Mathews;David J. Braun",
        "authorids": "/37089195363;/37609773600;/37089195363;/37609773600",
        "aff": "Department of Mechanical Engineering, Advanced Robotics and Control Laboratory within the Center for Rehabilitation Engineering and Assistive Technology, Vanderbilt University, Nashville, Tennessee, USA; Department of Mechanical Engineering, Advanced Robotics and Control Laboratory within the Center for Rehabilitation Engineering and Assistive Technology, Vanderbilt University, Nashville, Tennessee, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161305/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14368992269928187137&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160993",
        "title": "Design of an Energy-Aware Cartesian Impedance Controller for Collaborative Disassembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot collaborative disassembly is an emerging trend in the sustainable recycling process of electronic and mechanical products. It requires the use of advanced technologies to assist workers in repetitive physical tasks and deal with creaky and potentially damaged components. Nevertheless, when disassembling worn-out or damaged components, unexpected robot behaviors may emerge, so harmless and symbiotic physical interaction with humans and the environment becomes paramount. This work addresses this challenge at the control level by ensuring safe and passive behaviors in unplanned interactions and contact losses. The proposed algorithm capitalizes on an energy-aware Cartesian impedance controller, which features energy scaling and damping injection, and an augmented energy tank, which limits the power flow from the controller to the robot. The controller is evaluated in a real-world flawed unscrewing task with a Franka Emika Panda and is compared to a standard impedance controller and a hybrid force-impedance controller. The results demonstrate the high potential of the algorithm in human-robot collaborative disassembly tasks.",
        "primary_area": "",
        "author": "Sebastian Hjorth;Edoardo Lamon;Dimitrios Chrysostomou;Arash Ajoudani;Sebastian Hjorth;Edoardo Lamon;Dimitrios Chrysostomou;Arash Ajoudani",
        "authorids": "/37088690340;/37086599073;/37541236100;/37945239900;/37088690340;/37086599073;/37541236100;/37945239900",
        "aff": "Dept. of Materials and Production, Aalborg University, Aalborg, Denmark; Human-Robot Interfaces and Interaction, Istituto Italiano di Tecnologia, Genoa, Italy; Dept. of Materials and Production, Aalborg University, Aalborg, Denmark; Human-Robot Interfaces and Interaction, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160993/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=707526628371542543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Aalborg University;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dept. of Materials and Production;Human-Robot Interfaces and Interaction",
        "aff_unique_url": "https://www.aau.dk;https://www.iit.it",
        "aff_unique_abbr": "AAU;IIT",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Aalborg;Genoa",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Denmark;Italy"
    },
    {
        "id": "10160656",
        "title": "Detecting spatio-temporal Relations by Combining a Semantic Map with a Stream Processing Engine",
        "track": "main",
        "status": "Poster",
        "abstract": "Changes in topological spatial relations of objects are often strong indicators for state transitions in the underlying processes they are involved in. While various aspects of semantic mapping have been extensively researched, the reasoning about the temporal development of spatial relations of instances is often neglected. This paper presents a concept to combine a semantic map with a stream processing framework for live analysis of the spatio-temporal relation of objects, based on the map and information inferred from sensors streams. To demonstrate the functionality of our concept, we implemented a proof-of-concept system to track everyday events in an office environment. The presented application scenario clearly demonstrates the benefits of the proposed architecture for detecting and handling complex spatio-temporal events.",
        "primary_area": "",
        "author": "Lennart Niecksch;Henning Deeken;Thomas Wiemann;Lennart Niecksch;Henning Deeken;Thomas Wiemann",
        "authorids": "/37089893085;/37085638616;/37945726600;/37089893085;/37085638616;/37945726600",
        "aff": "German Research Center for Artificial Intelligence (DFKI), DFKI Niedersachsen, Plan-based Robot Control Group, Osnabr\u00fcck, Germany; Knowledge Based Systems and Autonomous Robotics groups, Institute of Computer Science, Osnabr\u00fcck University, Osnabr\u00fcck, Germany; Knowledge Based Systems and Autonomous Robotics groups, Institute of Computer Science, Osnabr\u00fcck University, Osnabr\u00fcck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160656/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14264029928577682291&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "German Research Center for Artificial Intelligence;Osnabr\u00fcck University",
        "aff_unique_dep": "Plan-based Robot Control Group;Institute of Computer Science",
        "aff_unique_url": "https://www.dFKI.de;https://www.uni-osnabrueck.de",
        "aff_unique_abbr": "DFKI;",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Niedersachsen;Osnabr\u00fcck",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161296",
        "title": "Development and Evaluation of a Robotic Vessel Positioning System for Semi-Automatic Microvascular Anastomosis",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a novel tissue positioning system with an integrated suturing robot and demonstrates its ability to perform semi-automatic anastomoses of synthetic blood vessels. We began with a finite element analysis-based design consideration for achieving adequate grasping of blood vessels to demonstrate robust performance under expected clinical forces. We then conducted standardized positioning tests to measure the repeatability of the system and incorporated a high-resolution optical coherence tomography (OCT) fiber imaging sensor within the tip of the suturing tool to provide position feedback of the robot during a suturing task. Using the microvascular positioner and OCT sensor, the system performed semi-automatic suturing of synthetic 5 mm diameter blood vessels (\\mathrm{N}=4\\mathrm{N}=4), and the suture quality was evaluated for consistency in spacing, bite depth, percent lumen reduction, and maximum suture strength. The system completed the task in an average time of 31.75 minutes. The samples had zero missed stitches, average spacing of 1.64 mm, an average bite depth of 2.14 mm, an average lumen reduction of 57.98%, and an average suture strength of 3.13 N.",
        "primary_area": "",
        "author": "Jesse Haworth;Justin Opfermann;Michael Kam;Yaning Wang;Robin Yang;Jin U. Kang;Axel Krieger;Jesse Haworth;Justin Opfermann;Michael Kam;Yaning Wang;Robin Yang;Jin U. Kang;Axel Krieger",
        "authorids": "/37089895369;/37085778776;/37086456157;/37089894591;/37088912565;/37273713000;/38484449800;/37089895369;/37085778776;/37086456157;/37089894591;/37088912565;/37273713000;/38484449800",
        "aff": "Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, United States; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, United States; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, United States; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, United States; Department of Plastic and Reconstructive Surgery, Johns Hopkins Medicine, Baltimore, MD, United States; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, United States; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161296/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17709549616114909254&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Johns Hopkins University;Johns Hopkins Medicine",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics;Department of Plastic and Reconstructive Surgery",
        "aff_unique_url": "https://www.jhu.edu;https://www.hopkinsmedicine.org",
        "aff_unique_abbr": "JHU;JHM",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161254",
        "title": "Development and Experimental Verification of a 3D Dynamic Absolute Nodal Coordinate Formulation Model of Flexible Prostate Biopsy/Brachytherapy Needles",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-assisted percutaneous needle insertion is expected to significantly increase targeting accuracy in minimally invasive operations. For this, it is necessary to provide mathematical models that can accurately capture the underlying dynamics of medical needles. Here, we present a novel nonlinear mathematical model of flexible medical needles based on the Absolute Nodal Coordinate Formulation. The model allows the description of large needle deflections and arbitrarily large rigid body motions. Tailored to the requirements of transperineal prostate biopsy and brachytherapy, it can correlate both the translational and rotational coordinates of the needle's base with its deflection, provide force feedback and accept arbitrary loading conditions. The model is optimised in terms of computational efficiency in order to allow real-time simulation and control. Experiments show that the proposed model allows for submillimeter precision in both static and dynamic needle deflection settings. Due to its accuracy and computational efficiency, it is expected to constitute a valuable tool for both real-time visual/haptic simulation and control of percutaneous needle insertion.",
        "primary_area": "",
        "author": "Athanasios Martsopoulos;Thomas L. Hill;Rajendra Persad;Stefanos Bolomytis;Antonia Tzemanaki;Athanasios Martsopoulos;Thomas L. Hill;Rajendra Persad;Stefanos Bolomytis;Antonia Tzemanaki",
        "authorids": "/37089892881;/37086559185;/37088560637;/37089893783;/37085386549;/37089892881;/37086559185;/37088560637;/37089893783;/37085386549",
        "aff": "University of the West of England, Bristol, UK; School of Civil, Aerospace and Mechanical Engineering, University of Bristol, UK; Southmead Hospital, Bristol Urological Institute, Bristol, UK; Southmead Hospital, Bristol Urological Institute, Bristol, UK; Bristol Robotics Laboratory, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161254/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5581844023583356313&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;3",
        "aff_unique_norm": "University of the West of England;University of Bristol;Southmead Hospital;Bristol Robotics Laboratory",
        "aff_unique_dep": ";School of Civil, Aerospace and Mechanical Engineering;Bristol Urological Institute;",
        "aff_unique_url": "https://www.uwe.ac.uk;https://www.bristol.ac.uk;https://www.southmeadhospital.nhs.uk;",
        "aff_unique_abbr": "UWE;UoB;;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bristol;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160629",
        "title": "Development of Hydraulically-driven Soft Hand for Handling Heavy Vegetables and its Experimental Evaluation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we develop a hydraulically-driven soft robotic hand for handling heavy vegetables in a vegetable factory and report its experimental validations. The working population in agriculture is decreasing worldwide, creating a lot of demands for the robotic automation in harvest and trans-portation of agricultural produces. In particular, a vegetable factory deals with large and heavy vegetables, e.g., cabbages, with 2\u20133 kg weight and 20\u201330 cm diameter. A soft robot hand is suitable for handling a food or vegetable; however, most of existing soft robot hands cannot generate necessary output because they are usually actuated by the air-pressure. Therefore, we employ the hydraulic actuation for our soft hand to generate 1 or 2 MPa pressure. Using the developed soft hand, we report experimental validations including basic control performance evaluation and grasping experiments assuming a vegetable factory environment.",
        "primary_area": "",
        "author": "Osamu Azami;Kyosuke Ishibashi;Mitsuo Komagata;Ko Yamamoto;Osamu Azami;Kyosuke Ishibashi;Mitsuo Komagata;Ko Yamamoto",
        "authorids": "/37086063897;/37089895313;/37089103698;/37536641800;/37086063897;/37089895313;/37089103698;/37536641800",
        "aff": "Department of Mechano-informatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-informatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-informatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Mechano-informatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160629/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7464574667552411118&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "Department of Mechano-informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160982",
        "title": "DexGraspNet: A Large-Scale Robotic Dexterous Grasp Dataset for General Objects Based on Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic dexterous grasping is the first step to enable human-like dexterous object manipulation and thus a crucial robotic technology. However, dexterous grasping is much more under-explored than object grasping with parallel grippers, partially due to the lack of a large-scale dataset. In this work, we present a large-scale robotic dexterous grasp dataset, DexGraspNet, generated by our proposed highly efficient synthesis method that can be generally applied to any dexterous hand. Our method leverages a deeply accelerated differentiable force closure estimator and thus can efficiently and robustly synthesize stable and diverse grasps on a large scale. We choose ShadowHand and generate 1.32 million grasps for 5355 objects, covering more than 133 object categories and containing more than 200 diverse grasps for each object instance, with all grasps having been validated by the Isaac Gym simulator. Compared to the previous dataset from Liu et al. generated by GraspIt!, our dataset has not only more objects and grasps, but also higher diversity and quality. Via performing cross-dataset experiments, we show that training several algorithms of dexterous grasp synthesis on our dataset significantly outperforms training on the previous one. To access our data and code, including code for human and Allegro grasp synthesis, please visit our project page: https://pku-epic.github.io/DexGraspNet/.",
        "primary_area": "",
        "author": "Ruicheng Wang;Jialiang Zhang;Jiayi Chen;Yinzhen Xu;Puhao Li;Tengyu Liu;He Wang;Ruicheng Wang;Jialiang Zhang;Jiayi Chen;Yinzhen Xu;Puhao Li;Tengyu Liu;He Wang",
        "authorids": "/37089892284;/37089938947;/37089538329;/37089892505;/37089893346;/37089165200;/37087234128;/37089892284;/37089938947;/37089538329;/37089892505;/37089893346;/37089165200;/37087234128",
        "aff": "Peking University; Peking University; Beijing Institute for General Artificial Intelligence; Beijing Institute for General Artificial Intelligence; Tsinghua University; Beijing Institute for General Artificial Intelligence; Peking University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160982/",
        "gs_citation": 122,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17374432468210982460&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;2;1;0",
        "aff_unique_norm": "Peking University;Beijing Institute for General Artificial Intelligence;Tsinghua University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.bigaiai.org/;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Peking U;BIGAI;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160275",
        "title": "Dexterous Imitation Made Easy: A Learning-Based Framework for Efficient Dexterous Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimizing behaviors for dexterous manipulation has been a longstanding challenge in robotics, with a variety of methods from model-based control to model-free reinforcement learning having been previously explored in literature. Such prior work often require extensive trial-and-error training along with task-specific tuning of reward functions, which makes applying dexterous manipulation for general purpose problems quite impractical. A sample-efficient and practical alternate to trial-and-error learning is imitation learning. However, collecting and learning from demonstrations in dexterous manipulation is quite challenging due to the high-dimensional action-space involved with multi-finger control. In this work, we propose \u2018Dexterous Imitation Made Easy\u2019 (DIME) a new imitation learning framework for dexterous manipulation. DIME only requires a single RGB camera that observes a human operator to teleoperate a robotic hand. Once demonstrations are collected, DIME employs state-of-the-art imitation learning methods to train dexterous manipulation policies. On real robot benchmarks we demonstrate that DIME can be used to solve complex, in-hand manipulation tasks such as \u2018flipping\u2019, \u2018spinning\u2019, and \u2018rotating\u2019 objects with just 30 demonstrations and no additional robot training. Our code, pre-collected demonstrations, and robot videos are publicly available at: https://nyu-robot-learning.github.io/dime.",
        "primary_area": "",
        "author": "Sridhar Pandian Arunachalam;Sneha Silwal;Ben Evans;Lerrel Pinto;Sridhar Pandian Arunachalam;Sneha Silwal;Ben Evans;Lerrel Pinto",
        "authorids": "/37089892054;/37089894598;/37089448121;/37085796211;/37089892054;/37089894598;/37089448121;/37085796211",
        "aff": "New York University; New York University; New York University; New York University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160275/",
        "gs_citation": 124,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8659904206232868226&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161493",
        "title": "Dexterous Manipulation from Images: Autonomous Real-World RL via Substep Guidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Complex and contact-rich robotic manipulation tasks, particularly those that involve multi-fingered hands and underactuated object manipulation, present a significant challenge to any control method. Methods based on reinforcement learning offer an appealing choice for such settings, as they can enable robots to learn to delicately balance contact forces and dexterously reposition objects without strong modeling assumptions. However, running reinforcement learning on real-world dexterous manipulation systems often requires significant manual engineering. This negates the benefits of autonomous data collection and ease of use that reinforcement learning should in principle provide. In this paper, we describe a system for vision-based dexterous manipulation that provides a \u201cprogramming-free\u201d approach for users to define new tasks and enable robots with complex multi-fingered hands to learn to perform them through interaction. The core principle under-lying our system is that, in a vision-based setting, users should be able to provide high-level intermediate supervision that circumvents challenges in teleoperation or kinesthetic teaching which allows a robot to not only learn a task efficiently but also to autonomously practice. Our system includes a framework for users to define a final task and intermediate sub-tasks with image examples, a reinforcement learning procedure that learns the task autonomously without interventions, and experimental results with a four-finger robotic hand learning multi-stage object manipulation tasks directly in the real world, without simulation, manual modeling, or reward engineering.",
        "primary_area": "",
        "author": "Kelvin Xu;Zheyuan Hu;Ria Doshi;Aaron Rovinsky;Vikash Kumar;Abhishek Gupta;Sergey Levine;Kelvin Xu;Zheyuan Hu;Ria Doshi;Aaron Rovinsky;Vikash Kumar;Abhishek Gupta;Sergey Levine",
        "authorids": "/37089000064;/37088469918;/37089895288;/37088997834;/37077886400;/37085516247;/37085481973;/37089000064;/37088469918;/37089895288;/37088997834;/37077886400;/37085516247;/37085481973",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley; Meta AI Research; University of Washington; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161493/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12877195912014599129&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;0",
        "aff_unique_norm": "University of California, Berkeley;Meta Platforms, Inc.;University of Washington",
        "aff_unique_dep": ";Meta AI Research;",
        "aff_unique_url": "https://www.berkeley.edu;https://meta.com;https://www.washington.edu",
        "aff_unique_abbr": "UC Berkeley;Meta AI;UW",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160756",
        "title": "Dextrous Tactile In-Hand Manipulation Using a Modular Reinforcement Learning Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "Dextrous in-hand manipulation with a multi-fingered robotic hand is a challenging task, esp. when performed with the hand oriented upside down, demanding permanent force-closure, and when no external sensors are used. For the task of reorienting an object to a given goal orientation (vs. infinitely spinning it around an axis), the lack of external sensors is an additional fundamental challenge as the state of the object has to be estimated all the time, e.g., to detect when the goal is reached. In this paper, we show that the task of reorienting a cube to any of the 24 possible goal orientations in a \u03c0/2-raster using the torque-controlled DLR-Hand II is possible. The task is learned in simulation using a modular deep reinforcement learning architecture: the actual policy has only a small observation time window of 0.5 s but gets the cube state as an explicit input which is estimated via a deep differentiable particle filter trained on data generated by running the policy. In simulation, we reach a success rate of 92% while applying significant domain randomization. Via zero-shot Sim2Real-transfer on the real robotic system, all 24 goal orientations can be reached with a high success rate. (Web: dlr-alr.github.io/dlr-tactile-manipulation)",
        "primary_area": "",
        "author": "Johannes Pitz;Lennart R\u00f6stel;Leon Sievers;Berthold B\u00e4uml;Johannes Pitz;Lennart R\u00f6stel;Leon Sievers;Berthold B\u00e4uml",
        "authorids": "/37089449984;/37089662539;/37089450909;/37295469600;/37089449984;/37089662539;/37089450909;/37295469600",
        "aff": "Deggendorf Institute of Technology; Deggendorf Institute of Technology; Deggendorf Institute of Technology; Deggendorf Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160756/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7988875477417263742&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Deggendorf Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.dit.de/",
        "aff_unique_abbr": "DIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160271",
        "title": "DifFAR: Differentiable Frequency-based Disentanglement for Aerial Video Action Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a learning algorithm, DifFAR, for human activity recognition in videos. Our approach is designed for UAV videos, which are mainly acquired from obliquely placed dynamic cameras that contain a human actor along with background motion. Typically, the human actors occupy less than one-tenth of the spatial resolution. DifFAR simultaneously harnesses the benefits of frequency domain representations, a classical analysis tool in signal processing, and data driven neural networks. We build a differentiable static-dynamic frequency mask prior to model the salient static and dynamic pixels in the video, crucial for the underlying task of action recognition. We use this differentiable mask prior to enable the neural network to intrinsically learn disentangled feature representations via an identity loss function. Our formulation empowers the network to inherently compute disentangled salient features within its layers. Further, we propose a cost-function encapsulating temporal relevance and spatial content to sample the most important frame within uniformly spaced video segments. We conduct extensive experiments on the UAV Human dataset and the NEC Drone dataset and demonstrate relative improvements of 5.72% - 13.00% over the state-of-the-art and 14.28% - 38.05% over the corresponding baseline model.",
        "primary_area": "",
        "author": "Divya Kothandaraman;Ming Lin;Dinesh Manocha;Divya Kothandaraman;Ming Lin;Dinesh Manocha",
        "authorids": "/37088844152;/37089891926;/37267825600;/37088844152;/37089891926;/37267825600",
        "aff": "University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160271/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12592511623852646832&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160716",
        "title": "Differentiable Collision Detection for a Set of Convex Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision detection between objects is critical for simulation, control, and learning for robotic systems. How-ever, existing collision detection routines are inherently non-differentiable, limiting their applications in gradient-based opti-mization tools. In this work, we propose DCOL: a fast and fully differentiable collision-detection framework that reasons about collisions between a set of composable and highly expressive convex primitive shapes. This is achieved by formulating the collision detection problem as a convex optimization problem that solves for the minimum uniform scaling applied to each primitive before they intersect. The optimization problem is fully differentiable with respect to the configurations of each primitive and is able to return a collision detection metric and contact points on each object, agnostic of interpenetration. We demonstrate the capabilities of DCOL on a range of robotics problems from trajectory optimization and contact physics, and have made an open-source implementation available.",
        "primary_area": "",
        "author": "Kevin Tracy;Taylor A. Howell;Zachary Manchester;Kevin Tracy;Taylor A. Howell;Zachary Manchester",
        "authorids": "/37086545632;/37087324047;/37086011525;/37086545632;/37087324047;/37086011525",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160716/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7910685222113949154&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Stanford University",
        "aff_unique_dep": "The Robotics Institute;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.stanford.edu",
        "aff_unique_abbr": "CMU;Stanford",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160251",
        "title": "Differentiable Collision Detection: a Randomized Smoothing Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision detection is an important component of many robotics applications, from robot control to simulation, including motion planning and estimation. While the seminal works on the topic date back to the 80s, it is only recently that the question of properly differentiating collision detection has emerged as a central issue, thanks notably to the ongoing and various efforts made by the scientific community around the topic of differentiable physics. Yet, very few solutions have been suggested so far, and only with a strong assumption on the nature of the shapes involved. In this work, we introduce a generic and efficient approach to compute the derivatives of collision detection for any pair of convex shapes, by notably leveraging randomized smoothing techniques which have shown to be particularly adapted to capture the derivatives of non-smooth problems. This approach is implemented in the HPP-FCL and Pinocchio ecosystems, and evaluated on classic datasets and problems of the robotics literature, demonstrating few micro-second timings to compute informative derivatives directly exploitable by many real robotic applications, including differentiable simulation.",
        "primary_area": "",
        "author": "Louis Montaut;Quentin Le Lidec;Antoine Bambade;Vladimir Petrik;Josef Sivic;Justin Carpentier;Louis Montaut;Quentin Le Lidec;Antoine Bambade;Vladimir Petrik;Josef Sivic;Justin Carpentier",
        "authorids": "/37089894556;/37089893754;/37089658667;/37085341098;/37282919700;/37085506841;/37089894556;/37089893754;/37089658667;/37085341098;/37282919700;/37085506841",
        "aff": "Czech Institute - of Informatics, Robotics and Cybernetics, Czech Technical University; Inria - D\u00e9partement d\u2018Informatique de l\u2019\u00c9cole normale sup\u00e9rieure, PSL Research University; Inria - D\u00e9partement d\u2018Informatique de l\u2019\u00c9cole normale sup\u00e9rieure, PSL Research University; Czech Institute - of Informatics, Robotics and Cybernetics, Czech Technical University; Czech Institute - of Informatics, Robotics and Cybernetics, Czech Technical University; Inria - D\u00e9partement d\u2018Informatique de l\u2019\u00c9cole normale sup\u00e9rieure, PSL Research University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160251/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14532580608032778094&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;1",
        "aff_unique_norm": "Czech Technical University;Inria",
        "aff_unique_dep": "Czech Institute of Informatics, Robotics and Cybernetics;D\u00e9partement d\u2018Informatique de l\u2018\u00c9cole normale sup\u00e9rieure",
        "aff_unique_url": "https://www.cvut.cz;https://www.inria.fr",
        "aff_unique_abbr": "CTU;Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0;0;1",
        "aff_country_unique": "Czech Republic;France"
    },
    {
        "id": "10161519",
        "title": "Differentiable Dynamics Simulation Using Invariant Contact Mapping and Damped Contact Force",
        "track": "main",
        "status": "Poster",
        "abstract": "The gradient of typical differentiable simulation is uninformative for two reasons: 1) non-smoothness in contact dynamics not considered properly, and 2) excessive local minima generated from the smoothing procedure. To tackle this issue, we first propose differentiable contact dynamics with an invariant contact set and coordinate differentiation using a signed distance function (SDF). Also, to eliminate the undesirable jittering caused by the smoothing procedure, which induces extra local minima, and to achieve a smooth and informative gradient, we further endow our framework with a novel damped contact model. Various optimization problems are implemented to demonstrate the usefulness and efficacy of our differentiable framework.",
        "primary_area": "",
        "author": "Minji Lee;Jeongmin Lee;Dongjun Lee;Minji Lee;Jeongmin Lee;Dongjun Lee",
        "authorids": "/37086549787;/37088998350;/37077171500;/37086549787;/37088998350;/37077171500",
        "aff": "Department of Mechanical Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea; Department of Mechanical Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea; Department of Mechanical Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161519/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16562705450791904975&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160640",
        "title": "Differentiable Parsing and Visual Grounding of Natural Language Instructions for Object Placement",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new method, PARsing And visual GrOuNding (PARAGON), for grounding natural language in object placement tasks. Natural language generally describes objects and spatial relations with compositionality and ambiguity, two major obstacles to effective language grounding. For compositionality, Paragon parses a language instruction into an object-centric graph representation to ground objects individually. For ambiguity, Paragon uses a novel particle-based graph neural network to reason about object placements with uncertainty. Essentially, Paragon integrates a parsing algorithm into a probabilistic, data-driven learning framework. It is fully differentiable and trained end-to-end from data for robustness against complex, ambiguous language input.",
        "primary_area": "",
        "author": "Zirui Zhao;Wee Sun Lee;David Hsu;Zirui Zhao;Wee Sun Lee;David Hsu",
        "authorids": "/37089894965;/37366213700;/37421581500;/37089894965;/37366213700;/37421581500",
        "aff": "National University of Singapore; National University of Singapore; National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160640/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8417477478789888279&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160817",
        "title": "Differential Dynamic Programming based Hybrid Manipulation Strategy for Dynamic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "To fully explore the potential of robots for dexterous manipulation, this paper presents a whole dynamic grasping process to achieve fluent grasping of a target object by the robot end-effector. The process starts from the phase of approaching the object over the phases of colliding with the object and letting it roll about the colliding point to the final phase of catching it by the palm or grasping it by the fingers of the end-effector. We derive a unified model for this hybrid dynamic manipulation process embodied as approaching-colliding-rolling-catching/grasping from the spatial vector based articulated body dynamics. Then, the whole process is formulated as a free-terminal constrained multi-phase optimal control problem (OCP). We extend the traditional differential dynamic programming (DDP) to solving this free-terminal OCP, where the backward pass of DDP involves constrained quadratic programming (QP) problems and we solve them by the primal-dual Augmented Lagrangian (PDAL) method. Simulations and real experiments are conducted to show the effectiveness of the proposed method for robotic dynamic grasping.",
        "primary_area": "",
        "author": "Cheng Zhou;Yanbo Long;Lei Shi;Longfei Zhao;Yu Zheng;Cheng Zhou;Yanbo Long;Lei Shi;Longfei Zhao;Yu Zheng",
        "authorids": "/37088946786;/37089662991;/37089894821;/37088945859;/37086993722;/37088946786;/37089662991;/37089894821;/37088945859;/37086993722",
        "aff": "Tencent Robotics X, Shenzhen, Guangdong, China; University of Bristol, Bristol, UK; Johns Hopkins University, Baltimore, MD, US; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160817/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7868302624259628959&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Tencent Robotics X;University of Bristol;Johns Hopkins University",
        "aff_unique_dep": "Robotics X;;",
        "aff_unique_url": "https://robotics.tencent.com;https://www.bristol.ac.uk;https://www.jhu.edu",
        "aff_unique_abbr": "Tencent Robotics X;UoB;JHU",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "Shenzhen;Bristol;Baltimore",
        "aff_country_unique_index": "0;1;2;0;0",
        "aff_country_unique": "China;United Kingdom;United States"
    },
    {
        "id": "10160750",
        "title": "Dimensional Optimization and Anti-Disturbance Analysis of an Upgraded Feed Mechanism in FAST",
        "track": "main",
        "status": "Poster",
        "abstract": "Five-hundred-meter aperture spherical radio telescope (FAST) is a very famous large-scale scientific facility with excellent performance for astronomical observation in the world, but it currently fails to observe the center of the Milky Way Galaxy due to the limited observation angle that is affected by the heavy weight of the feed cabin. To improve this problem, an upgraded feed mechanism (UFM) with a lighter cable structure is designed and employed to replace the existing heavy rigid A-B rotator and Stewart platform in the feed cabin of FAST. The structural dimension of the UFM is analyzed and optimized under cable tension constraints to meet the requirements of the observation angle. Then, a novel disturbance increment method is proposed to analyze the anti-disturbance ability of the UFM, where a gradually increased disturbance wrench is applied to the UFM with the stiffness matrix iteratively updated. Through the dimensional optimization and further anti-disturbance analysis, the newly-designed UFM can indeed meet the higher demand for astronomical observation with the larger observation angle, which benefits from the lightweight cable structure. Besides, the UFM also has the appreciable anti-disturbance ability for long-term stable operation of FAST.",
        "primary_area": "",
        "author": "Xiaoyan Wang;Bin Zhang;Zhaoyang Li;Xinyu Gao;Fei Zhang;Yifan Ma;Rui Yao;Jia-Ning Yin;Hui Li;Qingge Yang;Qingwei Li;Weiwei Shang;Xiaoyan Wang;Bin Zhang;Zhaoyang Li;Xinyu Gao;Fei Zhang;Yifan Ma;Rui Yao;Jia-Ning Yin;Hui Li;Qingge Yang;Qingwei Li;Weiwei Shang",
        "authorids": "/37089893797;/37086584596;/37089893762;/37088963265;/37086585490;/37089893207;/37952278000;/37089893862;/37089894586;/37089895253;/37089892182;/37409386300;/37089893797;/37086584596;/37089893762;/37088963265;/37086585490;/37089893207;/37952278000;/37089893862;/37089894586;/37089895253;/37089892182;/37409386300",
        "aff": "Department of Automation, University of Science and Technology of China, Hefei, P. R. China; Department of Automation, University of Science and Technology of China, Hefei, P. R. China; Department of Automation, University of Science and Technology of China, Hefei, P. R. China; Department of Automation, University of Science and Technology of China, Hefei, P. R. China; Department of Automation, University of Science and Technology of China, Hefei, P. R. China; Department of Automation, University of Science and Technology of China, Hefei, P. R. China; CAS Key Laboratory of FAST, National Astronomical Observatories, Chinese Academy of Sciences, Beijing, P. R. China; CAS Key Laboratory of FAST, National Astronomical Observatories, Chinese Academy of Sciences, Beijing, P. R. China; CAS Key Laboratory of FAST, National Astronomical Observatories, Chinese Academy of Sciences, Beijing, P. R. China; CAS Key Laboratory of FAST, National Astronomical Observatories, Chinese Academy of Sciences, Beijing, P. R. China; CAS Key Laboratory of FAST, National Astronomical Observatories, Chinese Academy of Sciences, Beijing, P. R. China; Department of Automation, University of Science and Technology of China, Hefei, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160750/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5297928793297038959&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;0;0;0;1;1;1;1;1;0",
        "aff_unique_norm": "University of Science and Technology of China;Chinese Academy of Sciences",
        "aff_unique_dep": "Department of Automation;National Astronomical Observatories",
        "aff_unique_url": "http://www.ustc.edu.cn;http://www.cas.ac.cn",
        "aff_unique_abbr": "USTC;CAS",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;1;1;1;1;0",
        "aff_campus_unique": "Hefei;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160967",
        "title": "Direct Angular Rate Estimation Without Event Motion-Compensation At High Angular Rates",
        "track": "main",
        "status": "Poster",
        "abstract": "Feature-based methods are a popular method for camera state estimation using event cameras. Due to the spatiotemporal nature of events, all event images exhibit smearing of events analogous to motion blur for a camera under motion. As such, events must be motion compensated to derive a sharp event image. However, this presents a causality dilemma where motion prior is required to unsmear the events, but a sharp event image is required to estimate motion. While it is possible to use the IMU to develop motion prior, it has been shown that the limited dynamic range of \\pm \\mathbf{2000}^{\\circ}/\\mathrm{s}\\pm \\mathbf{2000}^{\\circ}/\\mathrm{s} is insufficient for high angular rate rotorcrafts. Furthermore, smoothing of motion-compensated images due to actual event detection time latency in event cameras severely limits the performance of feature-based methods at high angular rates. This paper proposes a Fourier-based angular rate estimator capable of estimating angular rates directly on non-motion compensated event images. This method circumvents the need for external motion priors in camera state estimation and sidesteps problematic smoothing of features in the spatial domain due to motion blur. Lastly, using an NVIDIA Jetson Xavier NX, the algorithm is demonstrated to be real-time performant up to 3960\u00b0/s.",
        "primary_area": "",
        "author": "Matthew Ng;Xinyu Cai;Shaohui Foong;Matthew Ng;Xinyu Cai;Shaohui Foong",
        "authorids": "/37086449487;/37088689871;/37542925800;/37086449487;/37088689871;/37542925800",
        "aff": "Faculty of Engineering Product Development, Singapore University of Technology and Design, Singapore; Faculty of Engineering Product Development, Singapore University of Technology and Design, Singapore; Faculty of Engineering Product Development, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160967/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9049789439450860064&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Faculty of Engineering Product Development",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160508",
        "title": "Direct LiDAR-Inertial Odometry: Lightweight LIO with Continuous-Time Motion Correction",
        "track": "main",
        "status": "Poster",
        "abstract": "Aggressive motions from agile flights or traversing irregular terrain induce motion distortion in LiDAR scans that can degrade state estimation and mapping. Some methods exist to mitigate this effect, but they are still too simplistic or computationally costly for resource-constrained mobile robots. To this end, this paper presents Direct LiDAR-Inertial Odometry (DLIO), a lightweight LiDAR-inertial odometry algorithm with a new coarse-to-fine approach in constructing continuous-time trajectories for precise motion correction. The key to our method lies in the construction of a set of analytical equations which are parameterized solely by time, enabling fast and parallelizable point-wise deskewing. This method is feasible only because of the strong convergence properties in our nonlinear geometric observer, which provides provably correct state estimates for initializing the sensitive IMU integration step. Moreover, by simultaneously performing motion correction and prior generation, and by directly registering each scan to the map and bypassing scan-to-scan, DLIO's condensed architecture is nearly 20% more computationally efficient than the current state-of-the-art with a 12% increase in accuracy. We demonstrate DLIO's superior localization accuracy, map quality, and lower computational overhead as compared to four state-of-the-art algorithms through extensive tests using multiple public benchmark and self-collected datasets.",
        "primary_area": "",
        "author": "Kenny Chen;Ryan Nemiroff;Brett T. Lopez;Kenny Chen;Ryan Nemiroff;Brett T. Lopez",
        "authorids": "/37088689284;/37089893738;/37085654767;/37088689284;/37089893738;/37085654767",
        "aff": "Verifiable and Control-Theoretic Robotics Laboratory, University of California Los Angeles, Los Angeles, CA, USA; Verifiable and Control-Theoretic Robotics Laboratory, University of California Los Angeles, Los Angeles, CA, USA; Verifiable and Control-Theoretic Robotics Laboratory, University of California Los Angeles, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160508/",
        "gs_citation": 111,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2638410067672777737&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Verifiable and Control-Theoretic Robotics Laboratory",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161537",
        "title": "Direct and inverse modeling of soft robots by learning a condensed FEM model",
        "track": "main",
        "status": "Poster",
        "abstract": "The Finite Element Method (FEM) is a powerful modeling tool for predicting the behavior of soft robots. However, its use for control can be difficult for non-specialists of numerical computation: it requires an optimization of the computation to make it real-time. In this paper, we propose a learning-based approach to obtain a compact but sufficiently rich mechanical representation. Our choice is based on non-linear compliance data in the actuator/effector space provided by a condensation of the FEM model. We demonstrate that this compact model can be learned with a reasonable amount of data and, at the same time, be very efficient in terms of modeling, since we can deduce the direct and inverse kinematics of the robot. We also show how to couple some models learned individually in particular on an example of a gripper composed of two soft fingers. Other results are shown by comparing the inverse model derived from the full FEM model and the one from the compact learned version. This work opens new perspectives, namely for the embedded control of soft robots, but also for their design. These perspectives are also discussed in the paper.",
        "primary_area": "",
        "author": "Etienne M\u00e9nager;Tanguy Navez;Olivier Goury;Christian Duriez;Etienne M\u00e9nager;Tanguy Navez;Olivier Goury;Christian Duriez",
        "authorids": "/37089836748;/37089894984;/37086187223;/37428704500;/37089836748;/37089894984;/37086187223;/37428704500",
        "aff": "Inria, CNRS, Centrale Lille, UMR 9189 CRIStAL, Univ. Lille, Lille, France; Inria, CNRS, Centrale Lille, UMR 9189 CRIStAL, Univ. Lille, Lille, France; Inria, CNRS, Centrale Lille, UMR 9189 CRIStAL, Univ. Lille, Lille, France; Inria, CNRS, Centrale Lille, UMR 9189 CRIStAL, Univ. Lille, Lille, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161537/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7662436091067817782&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Inria",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160878",
        "title": "DisCo: A Multiagent 3D Coordinate System for Lattice Based Modular Self-Reconfigurable Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Localizing each module in a modular self-reconfigurable robot (MSR) is of paramount importance. In MSR, the communication graph is directly mapped to the real topology which makes the localization problem easy to solve. However, some types of connectors can lose the orientation of the modules, making the problem intractable. In this work, we propose to build a coordinate system for 3D lattice-based modular robots using a multiagent system. We present DisCo algorithm, that uses one agent per module which can only communicate with its connected neighbors and that does not need a central coordination system. We show that the agents can tackle any kinds of 3D lattice and we illustrate it with a Face Centered Cubic lattice (12 neighbors) and a cubic lattice (6 neighbors). Using communications and only four states, DisCo can also deduce the orientation of modules if the connectors do not provide this information.",
        "primary_area": "",
        "author": "Beno\u00eet Piranda;Fr\u00e9d\u00e9ric Lassabe;Julien Bourgeois;Beno\u00eet Piranda;Fr\u00e9d\u00e9ric Lassabe;Julien Bourgeois",
        "authorids": "/38340189300;/37423013100;/37545876400;/38340189300;/37423013100;/37545876400",
        "aff": "CNRS, University of Franche-Comt\u00e9, FEMTO-ST institute, Montb\u00e9liard, France; CNRS, University of Franche-Comt\u00e9, FEMTO-ST institute, Montb\u00e9liard, France; CNRS, University of Franche-Comt\u00e9, FEMTO-ST institute, Montb\u00e9liard, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160878/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8031230589460223646&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160363",
        "title": "Discovering Multiple Algorithm Configurations",
        "track": "main",
        "status": "Poster",
        "abstract": "Many practitioners in robotics regularly depend on classic, hand-designed algorithms. Often the performance of these algorithms is tuned across a dataset of annotated examples which represent typical deployment conditions. Automatic tuning of these settings is traditionally known as algorithm configuration. In this work, we extend algorithm configuration to automatically discover multiple modes in the tuning dataset. Unlike prior work, these configuration modes represent multiple dataset instances and are detected automatically during the course of optimization. We propose three methods for mode discovery: a post hoc method, a multistage method, and an online algorithm using a multi-armed bandit. Our results characterize these methods on synthetic test functions and in multiple robotics application domains: stereoscopic depth estimation, differentiable rendering, motion planning, and visual odometry. We show the clear benefits of detecting multiple modes in algorithm configuration space.",
        "primary_area": "",
        "author": "Leonid Keselman;Martial Hebert;Leonid Keselman;Martial Hebert",
        "authorids": "/37086054709;/37271437400;/37086054709;/37271437400",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160363/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13277048959184942938&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160743",
        "title": "Discrete-time model based control of soft manipulator with FBG sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article we investigate the discrete-time model based control of a planar soft continuum manipulator with proprioceptive sensing provided by fiber Bragg gratings. A control algorithm is designed with a discrete-time energy shaping approach which is extended to account for control-related lag of digital nature. A discrete-time nonlinear observer is employed to estimate the uncertain bending stiffness of the manipulator and to compensate constant matched disturbances. Simulations and experiments demonstrate the effectiveness of the controller compared to a continuous time implementation.",
        "primary_area": "",
        "author": "Enrico Franco;Ayhan Aktas;Shen Treratanakulchai;Arnau Garriga-Casanovas;Abdulhamit Donder;Ferdinando Rodriguez y Baena;Enrico Franco;Ayhan Aktas;Shen Treratanakulchai;Arnau Garriga-Casanovas;Abdulhamit Donder;Ferdinando Rodriguez y Baena",
        "authorids": "/37085386901;/37089893343;/37085534256;/37085716200;/37086271217;/37085615495;/37085386901;/37089893343;/37085534256;/37085716200;/37086271217;/37085615495",
        "aff": "Mechanical Engineering Department, Mechatronics in Medicine Laboratory, Imperial College London, London, UK; Mechanical Engineering Department, Mechatronics in Medicine Laboratory, Imperial College London, London, UK; Biomedical and Robotics Technology Laboratory, Mahidol University, Nakon Pathom, Thailand; Mechanical Engineering Department, Mechatronics in Medicine Laboratory, Imperial College London, London, UK; Boston Children's Hospital, Harvard Medical School, USA; Mechanical Engineering Department, Mechatronics in Medicine Laboratory, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160743/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16219879244921876318&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;2;0",
        "aff_unique_norm": "Imperial College London;Mahidol University;Harvard Medical School",
        "aff_unique_dep": "Mechanical Engineering Department;Biomedical and Robotics Technology Laboratory;Boston Children's Hospital",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.mahidol.ac.th;https://hms.harvard.edu",
        "aff_unique_abbr": "Imperial;;HMS",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "London;Nakon Pathom;",
        "aff_country_unique_index": "0;0;1;0;2;0",
        "aff_country_unique": "United Kingdom;Thailand;United States"
    },
    {
        "id": "10160644",
        "title": "Discriminative 3D Shape Modeling for Few-Shot Instance Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a simple and efficient scheme for segmenting approximately convex 3D object instances in depth images in a few-shot setting via discriminatively modeling the 3D shape of the object using a neural network. Our key idea is to select pairs of 3D points on the depth image between which we compute surface geodesics. As the number of such geodesics is quadratic in the number of image pixels, we can create a large training set of geodesics using only very limited ground truth instance annotations. These annotations are used to create a binary label for each geodesic, which indicates whether or not that geodesic belongs entirely to one instance segment. A neural network is then trained to classify the geodesics using these labels. During inference, we create geodesics from selected seed points in the test depth image, then produce a convex hull of the points that are classified by the neural network as belonging to the same instance, thereby achieving instance segmentation. We present experiments applying our method to segmenting instances of food items in real-world depth images. Our results demonstrate promising performances compared to prior methods in accuracy and computational efficiency.",
        "primary_area": "",
        "author": "Anoop Cherian;Siddarth Jain;Tim K. Marks;Alan Sullivan;Anoop Cherian;Siddarth Jain;Tim K. Marks;Alan Sullivan",
        "authorids": "/37546001600;/37088688017;/37542341500;/37086700005;/37546001600;/37088688017;/37542341500;/37086700005",
        "aff": "Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160644/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4653942059432593249&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.merl.com",
        "aff_unique_abbr": "MERL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160914",
        "title": "Distributed Data-Driven Predictive Control for Multi-Agent Collaborative Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "The aim of this work is to define a planner that enables robust legged locomotion for complex multi-agent systems consisting of several holonomically constrained quadrupeds. To this end, we employ a methodology based on behavioral systems theory to model the sophisticated and high-dimensional structure induced by the holonomic constraints. The resulting model is then used in tandem with distributed control techniques such that the computational burden is shared across agents while the coupling between agents is preserved. Finally, this distributed model is framed in the context of a predictive controller, resulting in a robustly stable method for trajectory planning. This methodology is tested in simulation with up to five agents and is further experimentally validated on three A1 quadrupedal robots subject to various uncertainties, including payloads, rough terrain, and push disturbances.",
        "primary_area": "",
        "author": "Randall T. Fawcett;Leila Amanzadeh;Jeeseop Kim;Aaron D. Ames;Kaveh Akbari Hamed;Randall T. Fawcett;Leila Amanzadeh;Jeeseop Kim;Aaron D. Ames;Kaveh Akbari Hamed",
        "authorids": "/37088687180;/37089894466;/37088425327;/37300877900;/37592529600;/37088687180;/37089894466;/37088425327;/37300877900;/37592529600",
        "aff": "Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160914/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7937769493341889550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Virginia Tech;California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.vt.edu;https://www.caltech.edu",
        "aff_unique_abbr": "VT;Caltech",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Blacksburg;Pasadena",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161382",
        "title": "Distributed Initialization for Visual-Inertial-Ranging Odometry with Position-Unknown UWB Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, the visual-inertial-ranging (VIR) state estimator with a position-unknown UWB network has become popular. However, most existing VIR methods leverage centralized algorithms to initialize the UWB anchors, which are challenging to be applied to massive UWB networks. In this paper, we propose a distributed initialization method for consistent visual-inertial-ranging odometry with a position-unknown UWB network (DC-VIRO). For the position-unknown UWB anchors, we solve a Robot-aided Distributed Localization (RaDL) to initialize their positions. For robot state estimation, we fuse the ranging measurements of initialized anchors and visual-inertial measurements in a consistent filter. The RaDL is formulated as a consensus-based optimization problem and solved by the Distributed Alternating Direction Method of Multipliers (D-ADMM) algorithm. To identify the unobservable conditions, we propose a self-contained Fisher Information Matrix (FIM) based criterion which can be evaluated by each anchor directly with locally-preserved ranging measurements. We use Covariance Intersection (CI) to estimate the covariance of initialized anchors' positions for consistent data fusion. The proposed DC-VIRO is validated in both simulation and real-world experiments.",
        "primary_area": "",
        "author": "Shenhan Jia;Rong Xiong;Yue Wang;Shenhan Jia;Rong Xiong;Yue Wang",
        "authorids": "/37088073358;/37271511300;/37072299700;/37088073358;/37271511300;/37072299700",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161382/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15495565251087876669&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161260",
        "title": "Distributed Model Predictive Formation Control with Gait Synchronization for Multiple Quadruped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a fully distributed framework for multiple quadruped robots in environments with obstacles. Our approach utilizes Model Predictive Control (MPC) and multi-robot consensus protocol to obtain the distributed control law. It ensures that all the robots are able to avoid obstacles, navigate to the desired positions, and meanwhile synchronize the gaits. In particular, via MPC and consensus, the robots compute the optimal trajectory and the contact profile of the legs. Then an MPC-based locomotion controller is implemented to achieve the gait, stabilize the locomotion and track the desired trajectory. We present experiments in simulation and with three real quadruped robots in an environment with a static obstacle.",
        "primary_area": "",
        "author": "Shaohang Xu;Wentao Zhang;Lijun Zhu;Chin Pang Ho;Shaohang Xu;Wentao Zhang;Lijun Zhu;Chin Pang Ho",
        "authorids": "/37089450582;/37089892960;/37535028800;/37089448658;/37089450582;/37089892960;/37535028800;/37089448658",
        "aff": "School of Data Science, City University of Hong Kong, HKSAR; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China; School of Data Science, City University of Hong Kong, HKSAR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161260/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16191061836175116202&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "City University of Hong Kong;Huazhong University of Science and Technology",
        "aff_unique_dep": "School of Data Science;School of Artificial Intelligence and Automation",
        "aff_unique_url": "https://www.cityu.edu.hk;http://www.hust.edu.cn",
        "aff_unique_abbr": "CityU;HUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161176",
        "title": "Distributed Potential iLQR: Scalable Game-Theoretic Trajectory Planning for Multi-Agent Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we develop a scalable, local tra-jectory optimization algorithm that enables robots to interact with other robots. It has been shown that agents' interactions can be successfully captured in game-theoretic formulations, where the interaction outcome can be best modeled via the equilibria of the underlying dynamic game. However, it is typically challenging to compute equilibria of dynamic games as it involves simultaneously solving a set of coupled optimal control problems. Existing solvers operate in a centralized fashion and do not scale up tractably to multiple interacting agents. We enable scalable distributed game-theoretic planning by leveraging the structure inherent in multi-agent interactions, namely, interactions belonging to the class of dynamic potential games. Since equilibria of dynamic potential games can be found by minimizing a single potential function, we can apply distributed and decentralized control techniques to seek equi-libria of multi-agent interactions in a scalable and distributed manner. We compare the performance of our algorithm with a centralized interactive planner in a number of simulation studies and demonstrate that our algorithm results in better efficiency and scalability. We further evaluate our method in hardware experiments involving multiple quadcopters.11Code Repository - https://github.com/labicon/dp-ilqr",
        "primary_area": "",
        "author": "Zach Williams;Jushan Chen;Negar Mehr;Zach Williams;Jushan Chen;Negar Mehr",
        "authorids": "/37089893009;/37089892712;/37085844571;/37089893009;/37089892712;/37085844571",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Urbana, IL, USA; Department of Aerospace Engineering, University of Illinois Urbana-Champaign, Urbana, IL, USA; Department of Aerospace Engineering, University of Illinois Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161176/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2465985105543600495&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160974",
        "title": "Distributed barrier function-enabled human-in-the-loop control for multi-robot systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a distributed control scheme for multi-robot systems in the presence of multiple constraints using control barrier functions. The proposed scheme expands previous work where only one single constraint can be handled. Here we show how to transform multiple constraints to a collective one using a smoothly approximated minimum function. Additionally, human-in-the-loop control is also incorporated seamlessly to our control design, both through the nominal control in the optimization objective as well as a safety condition in the constraints. Possible failure regions are identified and a suitable fix is proposed. Two types of human-in- the-loop scenarios are tested on real multi-robot systems with multiple constraints, including collision avoidance, connectivity maintenance, and arena range limits.",
        "primary_area": "",
        "author": "Victor Nan Fernandez-Ayala;Xiao Tan;Dimos V. Dimarogonas;Victor Nan Fernandez-Ayala;Xiao Tan;Dimos V. Dimarogonas",
        "authorids": "/37089896056;/37088479610;/37282084700;/37089896056;/37088479610;/37282084700",
        "aff": "Victor Nan Fernandez-Ayala Xiao Tan and Dimos V. Dimarogonas are with the Division of Decision and Control Systems, School of EECS, Royal Institute of Technology (KTH),, Stockholm, Sweden; Victor Nan Fernandez-Ayala Xiao Tan and Dimos V. Dimarogonas are with the Division of Decision and Control Systems, School of EECS, Royal Institute of Technology (KTH),, Stockholm, Sweden; Victor Nan Fernandez-Ayala Xiao Tan and Dimos V. Dimarogonas are with the Division of Decision and Control Systems, School of EECS, Royal Institute of Technology (KTH),, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160974/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8397527656651572356&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Royal Institute of Technology (KTH)",
        "aff_unique_dep": "Division of Decision and Control Systems, School of EECS",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "10160812",
        "title": "Distributional Instance Segmentation: Modeling Uncertainty and High Confidence Predictions with Latent-MaskRCNN",
        "track": "main",
        "status": "Poster",
        "abstract": "Object recognition and instance segmentation are fundamental skills in any robotic or autonomous system. Existing state-of-the-art methods are often unable to capture meaningful uncertainty in challenging or ambiguous scenes, and as such can cause critical errors in high-performance applications. In this paper, we explore a class of distributional instance segmentation models using latent codes that can model uncertainty over plausible hypotheses of object masks. For robotic picking applications, we propose a confidence mask method to achieve the high precision necessary in industrial use cases. We show that our method can significantly reduce critical errors in robotic systems, including our newly released dataset of ambiguous scenes in a robotic application. On a real-world apparel-picking robot, our method significantly reduces double pick errors while maintaining high performance.",
        "primary_area": "",
        "author": "YuXuan Liu;Nikhil Mishra;Pieter Abbeel;Xi Chen;YuXuan Liu;Nikhil Mishra;Pieter Abbeel;Xi Chen",
        "authorids": "/37086454558;/37085770625;/37542877900;/37089917767;/37086454558;/37085770625;/37542877900;/37089917767",
        "aff": "University of California, Berkeley, United States; University of California, Berkeley, United States; University of California, Berkeley, United States; Covariant.ai, Berkeley, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160812/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3139002060714212416&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of California, Berkeley;Covariant.ai",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;",
        "aff_unique_abbr": "UC Berkeley;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161246",
        "title": "Distributionally Robust Optimization with Unscented Transform for Learning-Based Motion Control in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is one of the main challenges when applying learning-based motion controllers to practical robotic systems, especially when the dynamics of the robots and their surrounding dynamic environments are unknown. This issue is further exacerbated when the learned information is unreliable and inaccurate. In this paper, we aim to enhance the safety of learning-enabled mobile robots in dynamic environments from the perspective of distributionally robust optimization (DRO) and the unscented transform (UT). Our method infers the unknown dynamics of both the robot and the environment by adopting Gaussian process regression with an uncertainty propagation scheme based on UT to improve prediction accuracy. This leads to a novel learning-based model predictive control (MPC) method in which state information about both the robot and the environment is propagated via UT. The proposed method uses DRO to proactively limit the risk of collisions or other unsafe events in the presence of learning errors. However, the distributionally robust risk constraint is intractable because it involves a separate infinite-dimensional optimization problem. To overcome this challenge, we exploit UT with modern DRO techniques to replace the risk constraint with its simple upper bound. The performance and the utility of our method are demonstrated through simulations in autonomous driving scenarios, showing its capability to enhance safety and computational efficiency.",
        "primary_area": "",
        "author": "Astghik Hakobyan;Insoon Yang;Astghik Hakobyan;Insoon Yang",
        "authorids": "/37086926675;/37085833849;/37086926675;/37085833849",
        "aff": "Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161246/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5084773597546956250&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161303",
        "title": "Distributionally Robust RRT with Risk Allocation",
        "track": "main",
        "status": "Poster",
        "abstract": "An integration of distributionally robust risk allocation into sampling-based motion planning algorithms for robots operating in uncertain environments is proposed. We perform non-uniform risk allocation by decomposing the distributionally robust joint risk constraints defined over the entire planning horizon into individual risk constraints given the total risk budget. Specifically, the deterministic tightening defined using the individual risk constraints is leveraged to define our proposed exact risk allocation procedure. Embedding the risk allocation technique into sampling-based motion planning algorithms realises guaranteed conservative, yet increasingly more risk-feasible trajectories for efficient state-space exploration.",
        "primary_area": "",
        "author": "Kajsa Ekenberg;Venkatraman Renganathan;Bj\u00f6rn Olofsson;Kajsa Ekenberg;Venkatraman Renganathan;Bj\u00f6rn Olofsson",
        "authorids": "/37089895950;/37086291196;/38230591200;/37089895950;/37086291196;/38230591200",
        "aff": "Department of Automatic Control LTH, Lund University, Sweden; Department of Automatic Control LTH, Lund University, Lund, Sweden; Department of Automatic Control LTH, Lund University, Lund, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161303/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5872699458182955534&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Lund University",
        "aff_unique_dep": "Department of Automatic Control",
        "aff_unique_url": "https://www.lth.se",
        "aff_unique_abbr": "LU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lund",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "10161250",
        "title": "Disturbance Observer Based Contact Detection for Motorized Hydraulic Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Contact detection without endpoint tactile sensing is challenging; friction and inertia obscure the sensing of low amplitude and high frequency forces. In this work we explore fluidic transmissions as series-elastic actuators, coupled to remotely-located direct-drive brushless motors, in a bid to maximize low-impedance sensitivity to contact while maintaining high bandwidth. We employ a disturbance observer to remove motor friction and further reduce minimum impedance. Using a 2-DOF remotely-actuated hydraulically-coupled robotic gripper, we demonstrate a maximum endpoint Z-width of 40dB and a robust contact detection threshold of 0.2N, without endpoint tactile sensing or joint position sensing. These results enable wiring-free and joint sensor-free arm and end-effector design, which are of particular interest for human-robot interaction, harsh-environment, magnetically-sensitive, and low-cost robotic manipulators that must maintain high bandwidth and high contact sensitivity.",
        "primary_area": "",
        "author": "Chunpeng Wang;John P. Whitney;Chunpeng Wang;John P. Whitney",
        "authorids": "/37089663306;/37409281700;/37089663306;/37409281700",
        "aff": "Department of Mechanical and Industrial Engineering, Northeastern University, Boston, MA, USA; Department of Mechanical and Industrial Engineering, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161250/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=816396836992805665&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Department of Mechanical and Industrial Engineering",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161431",
        "title": "Ditto in the House: Building Articulation Models of Indoor Scenes through Interactive Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Virtualizing the physical world into virtual models has been a critical technique for robot navigation and planning in the real world. To foster manipulation with articulated objects in everyday life, this work explores building articulation models of indoor scenes through a robot's purposeful inter-actions in these scenes. Prior work on articulation reasoning primarily focuses on siloed objects of limited categories. To extend to room-scale environments, the robot has to efficiently and effectively explore a large-scale 3D space, locate articulated objects, and infer their articulations. We introduce an interactive perception approach to this task. Our approach, named Ditto in the House, discovers possible articulated objects through affordance prediction, interacts with these objects to produce articulated motions, and infers the articulation properties from the visual observations before and after each interaction. It tightly couples affordance prediction and articulation inference to improve both tasks. We demonstrate the effectiveness of our approach in both simulation and real-world scenes. Code and additional results are available at https://ut-austin-rpl.github.io/HouseDitto/",
        "primary_area": "",
        "author": "Cheng-Chun Hsu;Zhenyu Jiang;Yuke Zhu;Cheng-Chun Hsu;Zhenyu Jiang;Yuke Zhu",
        "authorids": "/37089540236;/37089537824;/37086080772;/37089540236;/37089537824;/37086080772",
        "aff": "Department of Computer Science, University of Texas at Austin; Department of Computer Science, University of Texas at Austin; Department of Computer Science, University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161431/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6066954636050853551&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160292",
        "title": "Diver Interest via Pointing: Human-Directed Object Inspection for AUVs",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the Diver Interest via Pointing (DIP) algorithm, a highly modular method for conveying a diver's area of interest to an autonomous underwater vehicle (AUV) using pointing gestures for underwater humanrobot collaborative tasks. DIP uses a single monocular camera and exploits human body pose, even with complete dive gear, to extract underwater human pointing gesture poses and their directions. By extracting 2D scene geometry based on the human body pose and density of salient feature points along the direction of pointing, using a low-level feature detector, the DIP algorithm is able to locate objects of interest as indicated by the diver. DIP makes it possible for scuba divers and swimmers to use directional cues, through pointing, to an AUV for inspection, surveillance, manipulation, and navigation. We examine the elements that make up our method, provide quantitative and qualitative evaluation, and demonstrate AUV actuation based on diver pointing gestures in closed-water human-robot collaborative experiments. Our evaluations demonstrate the high efficacy of the DIP algorithm in correctly identifying the direction of a pointing gesture and locating an object within that region of interest. We also show that the findings of the algorithm qualitatively conform with human assessment of pointing gestures, directions, and targets.",
        "primary_area": "",
        "author": "Chelsey Edge;Junaed Sattar;Chelsey Edge;Junaed Sattar",
        "authorids": "/37086933249;/37546394500;/37086933249;/37546394500",
        "aff": "Department of Computer Science and Engineering (CSE), Minnesota Robotics Institute (MnRI), University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering (CSE), Minnesota Robotics Institute (MnRI), University of Minnesota Twin Cities, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160292/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17924117994369189944&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota Twin Cities",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160937",
        "title": "Domain Generalised Fully Convolutional One Stage Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time vision in robotics plays an important role in localising and recognising objects. Recently, deep learning approaches have been widely used in robotic vision. However, most of these approaches have assumed that training and test sets come from similar data distributions, which is not valid in many real world applications. This study proposes an approach to address domain generalisation (i.e. out-of-distribution generalisation, OODG) where the goal is to train a model via one or more source domains, that will generalise well to unknown target domains using single stage detectors. All existing approaches which deal with OODG either use slow two stage detectors or operate under the covariate shift assumption which may not be useful for real-time robotics. This is the first paper to address domain generalisation in the context of single stage anchor free object detector FCOS without the covariate shift assumption. We focus on improving the generalisation ability of object detection by proposing new regularisation terms to address the domain shift that arises due to both classification and bounding box regression. Also, we include an additional consistency regularisation term to align the local and global level predictions. The proposed approach is implemented as a Domain Generalised Fully Convolutional One Stage (DGFCOS) detection and evaluated using four object detection datasets which provide domain metadata (GWHD, Cityscapes, BDD100K, Sim10K) where it exhibits a consistent performance improvement over the baselines and is able to run in real-time for robotics.",
        "primary_area": "",
        "author": "Karthik Seemakurthy;Petra Bosilj;Erchan Aptoula;Charles Fox;Karthik Seemakurthy;Petra Bosilj;Erchan Aptoula;Charles Fox",
        "authorids": "/37085571553;/38228212100;/37572058800;/37089937901;/37085571553;/38228212100;/37572058800;/37089937901",
        "aff": "Lincoln Institute of Agri-Food Technology, University of Lincoln, UK; School of Computer Science, University of Lincoln; Faculty of Engineering and Natural Sciences (VPALab), Sabanci University, T\u00fcrkiye; School of Computer Science, University of Lincoln",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160937/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10114597253120783357&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Lincoln;Sabanci University",
        "aff_unique_dep": "Lincoln Institute of Agri-Food Technology;Faculty of Engineering and Natural Sciences",
        "aff_unique_url": "https://www.lincoln.ac.uk;https://www.sabanciuniv.edu/",
        "aff_unique_abbr": ";Sabanci",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;Turkey"
    },
    {
        "id": "10160474",
        "title": "Domain-specific languages for kinematic chains and their solver algorithms: lessons learned for composable models",
        "track": "main",
        "status": "Poster",
        "abstract": "The Unified Robot Description Format (URDF) and, to a lesser extent, the COLLAborative Design Activity (COLLADA) format are two of the most popular domain-specific languages (DSLs) to represent kinematic chains in robotics with support in many tools including Gazebo, MoveIt!, KDL or IKFast. In this paper we analyse both DSLs with respect to their structure and semantics as seen by tools that produce or consume such representations. For the former, we notice a tight coupling of various unrelated domains like kinematics and dynamics with visualisation, control or even specific simulators. For the latter, a key insight is that both DSLs target human developers and leave important design decisions like the choice of joint attachment frames implicit or hidden in the documentation. The lessons learned from this analysis guide us to an improved interchange format by designing composable, loosely coupled models with complete metamodels that unambiguously define the model semantics. We substantiate our findings with concrete examples. Furthermore, we compose solver algorithms on top of the kinematic chain representation. As a consequence of the above analysis and decomposition we can systematically apply structure- and semantics-conserving model-to-code transformations to those algorithms.",
        "primary_area": "",
        "author": "Sven Schneider;Nico Hochgeschwender;Herman Bruyninckx;Sven Schneider;Nico Hochgeschwender;Herman Bruyninckx",
        "authorids": "/37085594507;/38228828900;/37278642900;/37085594507;/38228828900;/37278642900",
        "aff": "Dept. of Mechanical Engineering, KU Leuven, Belgium; Dept. of Computer Science, Bonn-Rhein-Sieg UoAS, Germany; Flanders Make, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160474/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2058329127865157676&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "KU Leuven;Bonn-Rhein-Sieg University of Applied Sciences;Flanders Make",
        "aff_unique_dep": "Dept. of Mechanical Engineering;Department of Computer Science;",
        "aff_unique_url": "https://www.kuleuven.be;https://www.bonn-rhein-sieg.de;https://www.flandersmake.be",
        "aff_unique_abbr": "KU Leuven;UoAS;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Belgium;Germany"
    },
    {
        "id": "10161144",
        "title": "DreamWaQ: Learning Robust Quadrupedal Locomotion With Implicit Terrain Imagination via Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrupedal robots resemble the physical ability of legged animals to walk through unstructured terrains. However, designing a controller for quadrupedal robots poses a significant challenge due to their functional complexity and requires adaptation to various terrains. Recently, deep reinforcement learning, inspired by how legged animals learn to walk from their experiences, has been utilized to synthesize natural quadrupedal locomotion. However, state-of-the-art methods strongly depend on a complex and reliable sensing framework. Furthermore, prior works that rely only on proprioception have shown a limited demonstration for overcoming challenging terrains, especially for a long distance. This work proposes a novel quadrupedal locomotion learning framework that allows quadrupedal robots to walk through challenging terrains, even with limited sensing modalities. The proposed framework was validated in real-world outdoor environments with varying conditions within a single run for a long distance.",
        "primary_area": "",
        "author": "I Made Aswin Nahrendra;Byeongho Yu;Hyun Myung;I Made Aswin Nahrendra;Byeongho Yu;Hyun Myung",
        "authorids": "/37089892098;/37088969841;/37424926900;/37089892098;/37088969841;/37424926900",
        "aff": "School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161144/",
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16973068217237097374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160325",
        "title": "DribbleBot: Dynamic Legged Manipulation in the Wild",
        "track": "main",
        "status": "Poster",
        "abstract": "DribbleBot (Dexterous Ball Manipulation with a Legged Robot) is a legged robotic system that can dribble a soccer ball under the same real-world conditions as humans. We identify key challenges of in-the-wild soccer ball manipulation, including variable ball motion dynamics and perception using body-mounted cameras. To overcome these challenges, we propose a domain and task specification for learning viable soccer dribbling behaviors in simulation that transfer to real fields. Our system provides promising evidence that current legged robots are physically capable and adequately sensorized for varied and dynamic real-world soccer play. Video is available at https://gmargoll.github.io/dribblebot.",
        "primary_area": "",
        "author": "Yandong Ji;Gabriel B. Margolis;Pulkit Agrawal;Yandong Ji;Gabriel B. Margolis;Pulkit Agrawal",
        "authorids": "/37087473472;/37089894719;/37085611190;/37087473472;/37089894719;/37085611190",
        "aff": "Improbable AI Lab, Massachusetts Institute of Technology, USA; Improbable AI Lab, Massachusetts Institute of Technology, USA; Improbable AI Lab, Massachusetts Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160325/",
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6597537580026498412&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Improbable AI Lab",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160449",
        "title": "DriveIRL: Drive in Real Life with Inverse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce the first published planner to drive a car in dense, urban traffic using Inverse Reinforcement Learning (IRL). Our planner, DriveIRL, generates a diverse set of trajectory proposals and scores them with a learned model. The best trajectory is tracked by our self-driving vehicle's low-level controller. We train our trajectory scoring model on a 500+ hour real-world dataset of expert driving demonstrations in Las Vegas within the maximum entropy IRL framework. DriveIRL's benefits include: a simple design due to only learning the trajectory scoring function, a flexible and relatively interpretable feature engineering approach, and strong real-world performance. We validated DriveIRL on the Las Vegas Strip and demonstrated fully autonomous driving in heavy traffic, including scenarios involving cut-ins, abrupt braking by the lead vehicle, and hotel pickup/dropoff zones. Our dataset, a part of nuPlan, has been released to the public to help further research in this area.",
        "primary_area": "",
        "author": "Tung Phan-Minh;Forbes Howington;Ting-Sheng Chu;Momchil S. Tomov;Robert E. Beaudoin;Sang Uk Lee;Nanxiang Li;Caglayan Dicle;Samuel Findler;Francisco Suarez-Ruiz;Bo Yang;Sammy Omari;Eric M. Wolff;Tung Phan-Minh;Forbes Howington;Ting-Sheng Chu;Momchil S. Tomov;Robert E. Beaudoin;Sang Uk Lee;Nanxiang Li;Caglayan Dicle;Samuel Findler;Francisco Suarez-Ruiz;Bo Yang;Sammy Omari;Eric M. Wolff",
        "authorids": "/37086955501;/37089893742;/37089894060;/37089892619;/37089894472;/37089894750;/37089939866;/38235167200;/37089894108;/37076324700;/37089895117;/37089577117;/38548726400;/37086955501;/37089893742;/37089894060;/37089892619;/37089894472;/37089894750;/37089939866;/38235167200;/37089894108;/37076324700;/37089895117;/37089577117;/38548726400",
        "aff": "Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.; Motional AD Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160449/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5141956519436697563&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Motional AD Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.motional.com",
        "aff_unique_abbr": "Motional",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161353",
        "title": "DuEqNet: Dual-Equivariance Network in Outdoor 3D Object Detection for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Outdoor 3D object detection has played an essential role in the environment perception of autonomous driving. In complicated traffic situations, precise object recognition provides indispensable information for prediction and planning in the dynamic system, improving self-driving safety and reliability. However, with the vehicle's veering, the constant rotation of the surrounding scenario makes a challenge for the perception systems. Yet most existing methods have not focused on alleviating the detection accuracy impairment brought by the vehicle's rotation, especially in outdoor 3D detection. In this paper, we propose DuEqNet, which first introduces the concept of equivariance into 3D object detection network by leveraging a hierarchical embedded framework. The dual-equivariance of our model can extract the equivariant features at both local and global levels, respectively. For the local feature, we utilize the graph-based strategy to guarantee the equivariance of the feature in point cloud pillars. In terms of the global feature, the group equivariant convolution layers are adopted to aggregate the local feature to achieve the global equivariance. In the experiment part, we evaluate our approach with different baselines in 3D object detection tasks and obtain State-Of-The-Art performance. According to the results, our model presents higher accuracy on orientation and better prediction efficiency. Moreover, our dual-equivariance strategy exhibits the satisfied plug-and-play ability on various popular object detection frameworks to improve their performance.",
        "primary_area": "",
        "author": "Xihao Wang;Jiaming Lei;Hai Lan;Arafat Al-Jawari;Xian Wei;Xihao Wang;Jiaming Lei;Hai Lan;Arafat Al-Jawari;Xian Wei",
        "authorids": "/37089713019;/37088876723;/37089708919;/37089896054;/37086035222;/37089713019;/37088876723;/37089708919;/37089896054;/37086035222",
        "aff": "Technical University of Munich, Germany; Fujian Institute of Research on the Structure of Matter, Chinese Academy of Sciences, China; Fujian Institute of Research on the Structure of Matter, Chinese Academy of Sciences, China; Fujian Institute of Research on the Structure of Matter, Chinese Academy of Sciences, China; East China Normal University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161353/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2445995923885769935&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Technical University of Munich;Fujian Institute of Research on the Structure of Matter;East China Normal University",
        "aff_unique_dep": ";Chinese Academy of Sciences;",
        "aff_unique_url": "https://www.tum.de;;http://www.ecnu.edu.cn",
        "aff_unique_abbr": "TUM;;ECNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "10160848",
        "title": "Dual Robot Collaborative System for Autonomous Venous Access Based on Ultrasound and Bioimpedance Sensing Technology",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate needle insertion is an important task in many medical procedures. This paper studies the case of an autonomous needle insertion system for central venous access, which is a risky and challenging procedure involving the simultaneous manipulation of an ultrasound probe and of a catheterization needle. The goal of this medical operation is to provide access to a deep central vein, which is a key step in cardiovascular treatments or for the administration of drugs and treatments for cancer or infections. Accordingly, in this work we propose an autonomous dual-arm system for central venous access. The system is composed of two Franka robotic arms that are precisely co-registered and collaborate to achieve accurate needle insertion by combining ultrasound and bioimpedance sensing to ensure robust deep vessels visualization and venipuncture detection. The proposed system performance is evaluated on a phantom trainer through experiments simulating the jugular vein access for cardiac catheterization purposes. Quantitative results show the system is able to autonomously scan the area of interest, localize the vein and perform autonomous needle insertion with high accuracy and placement error below 1.7mm, proving the potential of the technology for real clinical use.",
        "primary_area": "",
        "author": "Maria Koskinopoulou;Alperen Acemoglu;Veronica Penza;Leonardo S. Mattos;Maria Koskinopoulou;Alperen Acemoglu;Veronica Penza;Leonardo S. Mattos",
        "authorids": "/37085817036;/37086117935;/37085895473;/37283193500;/37085817036;/37086117935;/37085895473;/37283193500",
        "aff": "Department of Advanced Robotics (ADVR), Istituto Italiano di Tecnologia, Genova, Italy; Department of Advanced Robotics (ADVR), Istituto Italiano di Tecnologia, Genova, Italy; Department of Advanced Robotics (ADVR), Istituto Italiano di Tecnologia, Genova, Italy; Department of Advanced Robotics (ADVR), Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160848/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6155013516539549630&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Advanced Robotics (ADVR)",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10160970",
        "title": "Dual quaternion based dynamic movement primitives to learn industrial tasks using teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic movement primitives (DMPs) provide an effective method of learning manipulation skills from human demonstration. DMPs can be especially useful for imitating industrial manipulation tasks which are performed by humans and are difficult to model, for instance, deformable object manipulation. In this work the effectiveness of a conventional Cartesian space DMP is enhanced using a compact and efficient representation of dual quaternions (DQ). We demonstrate that our DQ based DMP learning approach that utilizes the geometrical meaning of screw-based kinematics, outperforms traditional decoupled task-space DMPs in terms of accuracy during learning in certain situations. Our DMP formulation affords two additional applications: (1) Filter the noisy and irregular sensing of human demonstration; (2) Limit the robotic manipulator's task-space velocity during teleoperation, thus improving the safety of the robot and the environment. The learning and filtering strategies are validated on a bimanual robotic system and a motion capture system. We demonstrate the effectiveness of DMP based manipulation of deformable object by learning a bimanual deformation trajectory and then using it to perform the same task in new scenarios.",
        "primary_area": "",
        "author": "Rohit Chandra;Victor H. Giraud;Mohammad Alkhatib;Youcef Mezouar;Rohit Chandra;Victor H. Giraud;Mohammad Alkhatib;Youcef Mezouar",
        "authorids": "/37086174078;/37089662159;/37086949597;/37299713100;/37086174078;/37089662159;/37086949597;/37299713100",
        "aff": "SIGMA, CNRS, Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, Institut Pascal, Clermont-Ferrand, France; SIGMA, CNRS, Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, Institut Pascal, Clermont-Ferrand, France; SIGMA, CNRS, Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, Institut Pascal, Clermont-Ferrand, France; SIGMA, CNRS, Universit\u00e9 Clermont Auvergne, Clermont Auvergne INP, Institut Pascal, Clermont-Ferrand, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160970/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8809380758243931250&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Clermont Auvergne",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uca.fr",
        "aff_unique_abbr": "UCA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Clermont-Ferrand",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160857",
        "title": "Dynamic Control Barrier Function-based Model Predictive Control to Safety-Critical Obstacle-Avoidance of Mobile Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an efficient and safe method to avoid static and dynamic obstacles based on LiDAR. First, point cloud is used to generate a real-time local grid map for obstacle detection. Then, obstacles are clustered by DBSCAN algorithm and enclosed with minimum bounding ellipses (MBEs). In addition, data association is conducted to match each MBE with the obstacle in the current frame. Considering MBE as an observation, Kalman filter (KF) is used to estimate and predict the motion state of the obstacle. In this way, the trajectory of each obstacle in the forward time domain can be parameterized as a set of ellipses. Due to the uncertainty of the MBE, the semi-major and semi-minor axes of the parameterized ellipse are extended to ensure safety. We extend the traditional Control Barrier Function (CBF) and propose Dynamic Control Barrier Function (D-CBF). We combine D-CBF with Model Predictive Control (MPC) to implement safety-critical dynamic obstacle avoidance. Experiments in simulated and real scenarios are conducted to verify the effectiveness of our algorithm. The source code is released for the reference of the community11Code: https://github.com/jianzhuozhuTHU/MPC-D-CBF..",
        "primary_area": "",
        "author": "Zhuozhu Jian;Zihong Yan;Xuanang Lei;Zihong Lu;Bin Lan;Xueqian Wang;Bin Liang;Zhuozhu Jian;Zihong Yan;Xuanang Lei;Zihong Lu;Bin Lan;Xueqian Wang;Bin Liang",
        "authorids": "/37089661474;/37088895544;/37089892608;/37089663701;/37088984476;/37085383477;/37270783900;/37089661474;/37088895544;/37089892608;/37089663701;/37088984476;/37085383477;/37270783900",
        "aff": "Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of D-MAVT, ETH Zurich, Zurich, Switzerland; School of Mechanical Engineering and Automation at Harbin Institute of Technology, Shenzhen, China; Jianghuai Advance Technology Center, China; Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160857/",
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18355416818679065622&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;3;0;0",
        "aff_unique_norm": "Tsinghua University;ETH Zurich;Harbin Institute of Technology;Jianghuai Advance Technology Center",
        "aff_unique_dep": "Center for Artificial Intelligence and Robotics;Department of D-MAVT;School of Mechanical Engineering and Automation;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.ethz.ch;http://www.hit.edu.cn/;",
        "aff_unique_abbr": "Tsinghua;ETHZ;HIT;",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Shenzhen;Zurich;",
        "aff_country_unique_index": "0;0;1;0;0;0;0",
        "aff_country_unique": "China;Switzerland"
    },
    {
        "id": "10160647",
        "title": "Dynamic Interactive Relation Capturing via Scene Graph Learning for Robotic Surgical Report Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "For robot-assisted surgery, an accurate surgical report reflects clinical operations during surgery and helps document entry tasks, post-operative analysis and follow-up treatment. It is a challenging task due to many complex and diverse interactions between instruments and tissues in the surgical scene. Although existing surgical report generation methods based on deep learning have achieved large success, they often ignore the interactive relation between tissues and instrumental tools, thereby degrading the report generation performance. This paper presents a neural network to boost surgical report generation by explicitly exploring the interactive relation between tissues and surgical instruments. To do so, we first devise a relational exploration (RE) module to model the interactive relation via graph learning, and an interaction perception (IP) module to assist the graph learning in RE module. In our IP module, we first devise a node tracking system to identify and append missing graph nodes of the current video frame for constructing graphs at RE module. Moreover, the IP module generates a global attention model to indicate the existence of the interactive relation on the whole scene of the current video frame to eliminate the graph learning at the current video frame. Furthermore, our IP module predicts a local attention model to more accurately identify the interaction relation of each graph node for assisting the graph updating at the RE module. After that, we concatenate features of all graph nodes of RE module and pass concatenated features into a transformer for generating the output surgical report. We validate the effectiveness of our method on a widely-used robotic surgery benchmark dataset, and experimental results show that our network can significantly outperform existing state-of-the-art surgical report generation methods (e.g., 7.48% and 5.43% higher for BLEU-1 and ROUGE).",
        "primary_area": "",
        "author": "Hongqiu Wang;Yueming Jin;Lei Zhu;Hongqiu Wang;Yueming Jin;Lei Zhu",
        "authorids": "/37089895102;/37086369638;/37085479102;/37089895102;/37086369638;/37085479102",
        "aff": "The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, Guangdong, China; Department of Computer Science, Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London; The Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160647/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=510125740077681907&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "The Hong Kong University of Science and Technology;University College London;Hong Kong University of Science and Technology",
        "aff_unique_dep": ";Department of Computer Science;",
        "aff_unique_url": "https://www.ust.hk;https://www.ucl.ac.uk;https://www.ust.hk",
        "aff_unique_abbr": "HKUST;UCL;HKUST",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Guangzhou;London;Hong Kong",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10160896",
        "title": "Dynamic Locomotion of a Quadruped Robot with Active Spine via Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "As an active spine introduces more degree of freedoms (DOFs) as well as time-varying inertia, locomotion control of spined quadruped robots is challenging. Direct optimization on the full dynamics model causes prohibitive calculation time and is difficult to apply to embedded platforms. Model predictive control (MPC)-based on SRB dynamics is a prevalent approach for ordinary quadruped robots, regarding the whole robot as a single rigid body (SRB). However, the approach ignores the changes of the center of mass (CoM) and inertia, which seriously affects the robot's stability and could not be used in spined quadruped robots directly. To resolve the above issue, this paper presents an MPC approach that considers the movements of the spine in the SRB model. Since the mass of the robot is concentrated on its body, the whole robot is modelled as an unactuated SRB with fully-actuated internal spine joints. MPC finds the optimal ground reaction forces (GRFs) based on the SRB dynamics, in which the missing spine part is complemented by the pre-defined spine joints' states and corresponding inertia sequence. According to the GRFs, the full dynamic model calculates the precise joint torques. In addition, a quadruped robot with a 3-DOF active spine, Yat-sen Lion, is developed. With the presented approach, experimental results illustrate that Yat-sen Lion freely achieves bending, arching, and turning behaviors while trotting at speeds of 3.8 m/s in simulations and 0.5 m/s in real-world experiments.",
        "primary_area": "",
        "author": "Wanyue Li;Zida Zhou;Hui Cheng;Wanyue Li;Zida Zhou;Hui Cheng",
        "authorids": "/37089894291;/37088999699;/38008557800;/37089894291;/37088999699;/38008557800",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160896/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15662469797985066081&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160319",
        "title": "Dynamic Modeling and Identification of a Robotic Intracardiac Echo Catheter",
        "track": "main",
        "status": "Poster",
        "abstract": "Catheter-based cardiac ablation is the preferred method of treating atrial fibrillation. Conventionally, the catheter is navigated in the heart using X-ray fluoroscopy imaging and an electroanatomical map. Although successful, these imaging modalities do not provide real-time feedback on the quality of lesions created, which in turn could lead to recurrence of arrhythmia. Intracardiac echo (ICE) catheter provides real-time imaging within the heart to visualize both the ablation catheter and lesions created. However, manipulating the ablation and ICE catheters simultaneously is tedious and time consuming. As a first step towards developing a robotic ICE catheter that can autonomously follow the ablation catheter and monitor the lesions, we have developed a dynamic model for the ICE catheter. The model is based on the Cosserat theory for flexible rods that relies on strain parametrization. The model also accounts for frictional forces between the catheter sheath and tendons, external loads and fluid forces acting on the catheter. A good nominal model for describing the catheter dynamics is essential to develop a robust control scheme for the robotic ICE catheter. The parameters of the ICE catheter are estimated using weight release, tendon-driven actuation and fluid flow experiments. To the best of our knowledge, this is the first dynamic model for the ICE catheter that accurately reflects the dynamics of the catheter under pulsatile fluid flow within a heart phantom.",
        "primary_area": "",
        "author": "Mohammad Salehizadeh;Filipe Pedrosa;Harmanpreet Bassan;Rajni Patel;Jayender Jagadeesan;Mohammad Salehizadeh;Filipe Pedrosa;Harmanpreet Bassan;Rajni Patel;Jayender Jagadeesan",
        "authorids": "/37089921962;/37086289072;/37089894651;/37271878600;/37087079187;/37089921962;/37086289072;/37089894651;/37271878600;/37087079187",
        "aff": "Department of Radiology at Brigham and Women's Hospital, Harvard Medical School, Boston, MA, USA; Department of Electrical and Computer Engineering, Canadian Surgical Technologies & Advanced Robotics (CSTAR), Western University, London, ON, Canada; Electronics Engineering Division - Accelerator Directorate, SLAC National Accelerator Lab, CA; Department of Electrical and Computer Engineering, Canadian Surgical Technologies & Advanced Robotics (CSTAR), Western University, London, ON, Canada; Department of Radiology at Brigham and Women's Hospital, Harvard Medical School, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160319/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2455189512401310981&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Harvard Medical School;Western University;SLAC National Accelerator Laboratory",
        "aff_unique_dep": "Department of Radiology;Department of Electrical and Computer Engineering;Electronics Engineering Division - Accelerator Directorate",
        "aff_unique_url": "https://hms.harvard.edu;https://www.westernu.ca;https://www.slac.stanford.edu",
        "aff_unique_abbr": "HMS;Western;SLAC",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Boston;London;",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "10160935",
        "title": "Dynamical System-based Imitation Learning for Visual Servoing using the Large Projection Formulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Nowadays ubiquitous robots must be adaptive and easy to use. To this end, dynamical system-based imitation learning plays an important role. In fact, it allows to realize stable and complex robotic tasks without explicitly coding them, thus facilitating the robot use. However, the adaptation capabilities of dynamical systems have not been fully exploited due to the lack of closed-loop implementations making use of visual feedback. In this regard, the integration of visual information allows higher flexibility to cope with environmental changes. This work presents a dynamical system-based imitation learning for visual servoing, based on the large projection task priority formulation. The proposed scheme enables complex and stable visual tasks, as demonstrated by a simulation analysis and experiments with a robotic manipulator.",
        "primary_area": "",
        "author": "Antonio Paolillo;Paolo Robuffo Giordano;Matteo Saveriano;Antonio Paolillo;Paolo Robuffo Giordano;Matteo Saveriano",
        "authorids": "/37077525100;/37544316400;/38542234400;/37077525100;/37544316400;/38542234400",
        "aff": "USI-SUPSI, Dalle Molle Institute for Artificial Intelligence (IDSIA), Lugano, Switzerland; CNRS, Univ Rennes, Inria, IRISA, Rennes, France; Department of Industrial Engineering (DII), University of Trento, Trento, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160935/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3981417214489378515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Applied Sciences and Arts of Southern Switzerland (USI-SUPSI);CNRS;University of Trento",
        "aff_unique_dep": "Dalle Molle Institute for Artificial Intelligence (IDSIA);;Department of Industrial Engineering",
        "aff_unique_url": "https://www.supsi.ch;https://www.cnrs.fr;https://www.unitn.it",
        "aff_unique_abbr": "USI-SUPSI;CNRS;UniTN",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Lugano;;Trento",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "Switzerland;France;Italy"
    },
    {
        "id": "10161306",
        "title": "DytanVO: Joint Refinement of Visual Odometry and Motion Segmentation in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based visual odometry (VO) algorithms achieve remarkable performance on common static scenes, benefiting from high-capacity models and massive annotated data, but tend to fail in dynamic, populated environments. Semantic segmentation is largely used to discard dynamic associations before estimating camera motions but at the cost of discarding static features and is hard to scale up to unseen categories. In this paper, we leverage the mutual dependence between camera ego-motion and motion segmentation and show that both can be jointly refined in a single learning-based framework. In particular, we present DytanVO, the first supervised learning-based VO method that deals with dynamic environments. It takes two consecutive monocular frames in real-time and predicts camera ego-motion in an iterative fashion. Our method achieves an average improvement of 27.7% in ATE over state-of-the-art VO solutions in real-world dynamic environments, and even performs competitively among dynamic visual SLAM systems which optimize the trajectory on the backend. Experiments on plentiful unseen environments also demonstrate our method's generalizability.",
        "primary_area": "",
        "author": "Shihao Shen;Yilin Cai;Wenshan Wang;Sebastian Scherer;Shihao Shen;Yilin Cai;Wenshan Wang;Sebastian Scherer",
        "authorids": "/37089895823;/37089366342;/37087322184;/37584159000;/37089895823;/37089366342;/37087322184;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161306/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4400080796011076849&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160276",
        "title": "E-VFIA: Event-Based Video Frame Interpolation with Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Video frame interpolation (VFI) is a fundamental vision task that aims to synthesize several frames between two consecutive original video images. Most algorithms aim to accomplish VFI by using only keyframes, which is an ill-posed problem since the keyframes usually do not yield any accurate precision about the trajectories of the objects in the scene. On the other hand, event-based cameras provide more precise information between the keyframes of a video. Some recent state-of-the-art event-based methods approach this problem by utilizing event data for better optical flow estimation to interpolate for video frame by warping. Nonetheless, those methods heavily suffer from the ghosting effect. On the other hand, some of kernel-based VFI methods that only use frames as input, have shown that deformable convolutions, when backed up with transformers, can be a reliable way of dealing with long-range dependencies. We propose event-based video frame interpolation with attention (E-VFIA), as a lightweight kernelbased method. E-VFIA fuses event information with standard video frames by deformable convolutions to generate high quality interpolated frames. The proposed method represents events with high temporal resolution and uses a multi-head selfattention mechanism to better encode event-based information, while being less vulnerable to blurring and ghosting artifacts; thus, generating crispier frames. The simulation results show that the proposed technique outperforms current state-of-the-art methods (both frame and event-based) with a significantly smaller model size. Multimedia material: The code is available at https://github.com/ahmetakman/E-VFIA",
        "primary_area": "",
        "author": "Onur Selim K\u0131l\u0131\u00e7;Ahmet Akman;A. Ayd\u0131n Alatan;Onur Selim K\u0131l\u0131\u00e7;Ahmet Akman;A. Ayd\u0131n Alatan",
        "authorids": "/37586569800;/37089893173;/37298479700;/37586569800;/37089893173;/37298479700",
        "aff": "Department and Center for Image Analysis (OGAM), Electrical and Electronics Engineering, Middle East Technical University (METU), Ankara, Turkey; Department and Center for Image Analysis (OGAM), Electrical and Electronics Engineering, Middle East Technical University (METU), Ankara, Turkey; Department and Center for Image Analysis (OGAM), Electrical and Electronics Engineering, Middle East Technical University (METU), Ankara, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160276/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10868093110593432478&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Middle East Technical University",
        "aff_unique_dep": "Electrical and Electronics Engineering",
        "aff_unique_url": "https://www.metu.edu.tr",
        "aff_unique_abbr": "METU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ankara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Turkey"
    },
    {
        "id": "10161234",
        "title": "EDO-Net: Learning Elastic Properties of Deformable Objects from Graph Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of learning graph dynamics of deformable objects that generalizes to unknown physical properties. Our key insight is to leverage a latent representation of elastic physical properties of cloth-like deformable objects that can be extracted, for example, from a pulling interaction. In this paper we propose EDO-Net (Elastic Deformable Object - Net), a model of graph dynamics trained on a large variety of samples with different elastic properties that does not rely on ground-truth labels of the properties. EDO-Net jointly learns an adaptation module, and a forward-dynamics module. The former is responsible for extracting a latent representation of the physical properties of the object, while the latter leverages the latent representation to predict future states of cloth-like objects represented as graphs. We evaluate EDO-Net both in simulation and real world, assessing its capabilities of: 1) generalizing to unknown physical properties, 2) transferring the learned representation to new downstream tasks.",
        "primary_area": "",
        "author": "Alberta Longhini;Marco Moletta;Alfredo Reichlin;Michael C. Welle;David Held;Zackory Erickson;Danica Kragic;Alberta Longhini;Marco Moletta;Alfredo Reichlin;Michael C. Welle;David Held;Zackory Erickson;Danica Kragic",
        "authorids": "/37088920995;/37088511151;/37089663394;/38202265300;/37408101800;/37085785366;/37281296000;/37088920995;/37088511151;/37089663394;/38202265300;/37408101800;/37085785366;/37281296000",
        "aff": "Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Carnegie Mellon University, Pittsburgh, USA; Carnegie Mellon University, Pittsburgh, USA; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161234/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2184880658505124224&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "EECS;",
        "aff_unique_url": "https://www.kth.se;https://www.cmu.edu",
        "aff_unique_abbr": "KTH;CMU",
        "aff_campus_unique_index": "0;0;0;0;1;1;0",
        "aff_campus_unique": "Stockholm;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;1;1;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "10160685",
        "title": "EFTrack: A Lightweight Siamese Network for Aerial Object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual object tracking is a very important task for unmanned aerial vehicle (UAV). Limited resources of UAV lead to strong demand for efficient and robust trackers. In recent years, deep learning-based trackers, especially, siamese trackers achieve very impressive results. Though siamese trackers can run a relatively fast speed on the high-end GPU, they are becoming heavier and heavier which restricts them to be deployed on UAV platform. In this work, we propose a lightweight aerial tracker based on the siamese network. We use EfficientNet as the backbone, which has less parameters and stronger feature extract ability compared with ResNet-50. After a pixel-wise correlation, a classification branch and a regression branch are applied to predict the front/back score and offset of the target without the predefined anchor. The results show that our tracker works efficiently and achieves impressive performance on UAV tracking datasets. In addition, the real-world test shows that it runs effectively on the Nvidia Jetson NX deployed on DJI UAV.",
        "primary_area": "",
        "author": "Wenqi Zhang;Yuan Yao;Xincheng Liu;Kai Kou;Gang Yang;Wenqi Zhang;Yuan Yao;Xincheng Liu;Kai Kou;Gang Yang",
        "authorids": "/37089738257;/37672202700;/37089892549;/37089740140;/37594682400;/37089738257;/37672202700;/37089892549;/37089740140;/37594682400",
        "aff": "School of Computer Science, Northwestern Polytechnical University, Xi'an, China; School of Computer Science, Northwestern Polytechnical University, Xi'an, China; School of Computer Science, Northwestern Polytechnical University, Xi'an, China; School of Computer Science, Northwestern Polytechnical University, Xi'an, China; School of Computer Science, Northwestern Polytechnical University, Xi'an, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160685/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15936554741859205295&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northwestern Polytechnical University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "http://www.nwpu.edu.cn",
        "aff_unique_abbr": "NPU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160948",
        "title": "EMS\u00ae: A Massive Computational Experiment Management System towards Data-driven Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose EMS\u00ae, a cloud-enabled massive computational experiment management system supporting high-throughput computational robotics research. Compared to existing systems, EMS\u00ae features a sky-based pipeline orchestrator which allows us to exploit heterogeneous computing environments painlessly (e.g., on-premise clusters, public clouds, edge devices) to optimally deploy large-scale computational jobs (e.g., with more than millions of computational hours) in an integrated fashion. Cornerstoned on this sky-based pipeline orchestrator, this paper introduces three abstraction layers of the EMS\u00ae software architecture: (i) Configuration management layer focusing on automatically enumerating experimental configurations; (ii) Dependency management layer focusing on managing the complex task dependencies within each experimental configuration; (iii) Computation management layer focusing on optimally executing the computational tasks using the given computing resource. Such an architectural design greatly increases the scalability and reproducibility of data-driven robotics research leading to much-improved productivity. To demonstrate this point, we compare EMS\u00ae with more traditional approaches on an offline reinforcement learning problem for training mobile robots. Our results show that EMS\u00ae outperforms more traditional approaches in two magnitudes of orders (in terms of experimental high throughput and cost) with only several lines of code change. We also exploit EMS\u00ae to develop mobile robot, robot arm, and bipedal applications, demonstrating its applicability to numerous robot applications.",
        "primary_area": "",
        "author": "Qinjie Lin;Guo Ye;Han Liu;Qinjie Lin;Guo Ye;Han Liu",
        "authorids": "/37086347031;/37088505860;/37086489597;/37086347031;/37088505860;/37086489597",
        "aff": "Department of Computer Science, Northwestern University, Evanston, IL, USA; Department of Computer Science, Northwestern University, Evanston, IL, USA; Department of Computer Science, Northwestern University, Evanston, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160948/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1897727471718904574&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Evanston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160343",
        "title": "ERASE-Net: Efficient Segmentation Networks for Automotive Radar Signals",
        "track": "main",
        "status": "Poster",
        "abstract": "Among various sensors for assisted and autonomous driving systems, automotive radar has been considered as a robust and low-cost solution even in adverse weather or lighting conditions. With the recent development of radar technologies and open-sourced annotated data sets, semantic segmentation with radar signals has become very promising. However, existing methods are either computationally expensive or discard significant amounts of valuable information from raw 3D radar signals by reducing them to 2D planes via averaging. In this work, we introduce ERASE-Net, an Efficient RAdar SEgmentation Network to segment the raw radar signals semantically. The core of our approach is the novel detect-then-segment method for raw radar signals. It first detects the center point of each object, then extracts a compact radar signal representation, and finally performs semantic segmentation. We show that our method can achieve superior performance on radar semantic segmentation task compared to the state-of-the-art (SOTA) technique. Furthermore, our approach requires up to 20\u00d7less computational resources. Finally, we show that the proposed ERASE-Net can be compressed by 40% without significant loss in performance, significantly more than the SOTA network, which makes it a more promising candidate for practical automotive applications.",
        "primary_area": "",
        "author": "Shihong Fang;Haoran Zhu;Devansh Bisla;Anna Choromanska;Satish Ravindran;Dongyin Ren;Ryan Wu;Shihong Fang;Haoran Zhu;Devansh Bisla;Anna Choromanska;Satish Ravindran;Dongyin Ren;Ryan Wu",
        "authorids": "/37086936147;/37089893228;/37088366223;/37086309990;/37089575593;/37085848614;/37088657587;/37086936147;/37089893228;/37088366223;/37086309990;/37089575593;/37085848614;/37088657587",
        "aff": "Department of Electrical and Computer Engineering, Learning Systems Laboratory, New York University, NY, USA; Department of Electrical and Computer Engineering, Learning Systems Laboratory, New York University, NY, USA; Department of Electrical and Computer Engineering, Learning Systems Laboratory, New York University, NY, USA; Department of Electrical and Computer Engineering, Learning Systems Laboratory, New York University, NY, USA; NXP Semiconductors, San Jose, CA, USA; NXP Semiconductors, San Jose, CA, USA; NXP Semiconductors, San Jose, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160343/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5414782883094999974&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;1",
        "aff_unique_norm": "New York University;NXP Semiconductors",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.nyu.edu;https://www.nxp.com",
        "aff_unique_abbr": "NYU;NXP",
        "aff_campus_unique_index": "0;0;0;0;1;1;1",
        "aff_campus_unique": "New York;San Jose",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161504",
        "title": "EWareNet: Emotion-Aware Pedestrian Intent Prediction and Adaptive Spatial Profile Fusion for Social Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present EWareNet, a novel intent and affect-aware social robot navigation algorithm among pedestrians. Our approach predicts the trajectory-based pedestrian intent from gait sequence, which is then used for intent-guided navigation taking into account social and proxemic constraints. We propose a transformer-based model that works on commodity RGB-D cameras mounted onto a moving robot. Our intent prediction routine is integrated into a mapless navigation scheme and makes no assumptions about the environment of pedestrian motion. Our navigation scheme consists of a novel obstacle profile representation methodology that is dynamically adjusted based on the pedestrian pose, intent, and affect. The navigation scheme is based on a reinforcement learning algorithm that takes pedestrian intent and robot's impact on pedestrian intent into consideration, in addition to the environmental configuration. We outperform current state-of-art algorithms for intent prediction from 3D gaits.",
        "primary_area": "",
        "author": "Venkatraman Narayanan;Bala Murali Manoghar;Rama Prashanth RV;Aniket Bera;Venkatraman Narayanan;Bala Murali Manoghar;Rama Prashanth RV;Aniket Bera",
        "authorids": "/37089405415;/37088686456;/37089895238;/37085393882;/37089405415;/37088686456;/37089895238;/37085393882",
        "aff": "Department of Computer Science, Purdue University, USA; Department of Computer Science, Purdue University, USA; Department of Computer Science, Purdue University, USA; Department of Computer Science, Purdue University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161504/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8913225554731847883&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160481",
        "title": "EXOT: Exit-aware Object Tracker for Safe Robotic Manipulation of Moving Object",
        "track": "main",
        "status": "Poster",
        "abstract": "Current robotic hand manipulation narrowly operates with objects in predictable positions in limited environments. Thus, when the location of the target object deviates severely from the expected location, a robot sometimes responds in an unexpected way, especially when it operates with a human. For safe robot operation, we propose the EXit-aware Object Tracker (EXOT) on a robot hand camera that recognizes an object's absence during manipulation. The robot decides whether to proceed by examining the tracker's bounding box output containing the target object. We adopt an out-of-distribution classifier for more accurate object recognition since trackers can mistrack a background as a target object. To the best of our knowledge, our method is the first approach of applying an out-of-distribution classification technique to a tracker output. We evaluate our method on the first-person video benchmark dataset, TREK-150, and on the custom dataset, RMOT-223, that we collect from the UR5e robot. Then we test our tracker on the UR5e robot in real-time with a conveyor-belt sushi task, to examine the tracker's ability to track target dishes and to determine the exit status. Our tracker shows 38% higher exit-aware performance than a baseline method. The dataset and the code will be released at https://github.com/hskAlena/EXOT.",
        "primary_area": "",
        "author": "Hyunseo Kim;Hye Jung Yoon;Minji Kim;Dong-Sig Han;Byoung-Tak Zhang;Hyunseo Kim;Hye Jung Yoon;Minji Kim;Dong-Sig Han;Byoung-Tak Zhang",
        "authorids": "/37088485902;/37089893007;/37089450354;/37089894943;/37336068500;/37088485902;/37089893007;/37089450354;/37089894943;/37336068500",
        "aff": "Interdisciplinary Program in Neuroscience, Seoul National University, Seoul, Korea; Interdisciplinary Program in Artificial Intelligence, Seoul National University; Dept. of Computer Science and Engineering, Seoul National University; Dept. of Computer Science and Engineering, Seoul National University; AIIS, Seoul National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160481/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:q7dXDxcfNKIJ:scholar.google.com/&scioq=EXOT:+Exit-aware+Object+Tracker+for+Safe+Robotic+Manipulation+of+Moving+Object&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Interdisciplinary Program in Neuroscience",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160728",
        "title": "Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Given point cloud input, the problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. This important problem has many practical applications. Here we propose a novel method and neural network model that enables better grasp success rates relative to what is available in the literature. The method takes standard point cloud data as input and works well with single-view point clouds observed from arbitrary viewing directions. Videos and code are available at https://haojhuang.github.io/edge_grasp_page/.",
        "primary_area": "",
        "author": "Haojie Huang;Dian Wang;Xupeng Zhu;Robin Walters;Robert Platt;Haojie Huang;Dian Wang;Xupeng Zhu;Robin Walters;Robert Platt",
        "authorids": "/37089230165;/37089895590;/37089893313;/37089893733;/37273991200;/37089230165;/37089895590;/37089893313;/37089893733;/37273991200",
        "aff": "Khoury College of Computer Science, Northeastern University; Khoury College of Computer Science, Northeastern University; Khoury College of Computer Science, Northeastern University; Khoury College of Computer Science, Northeastern University; Khoury College of Computer Science, Northeastern University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160728/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6423563185807945208&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Khoury College of Computer Science",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161210",
        "title": "Edge-guided Multi-domain RGB-to-TIR image Translation for Training Vision Tasks with Challenging Labels",
        "track": "main",
        "status": "Poster",
        "abstract": "The insufficient number of annotated thermal infrared (TIR) image datasets not only hinders TIR image-based deep learning networks to have comparable performances to that of RGB but it also limits the supervised learning of TIR image-based tasks with challenging labels. As a remedy, we propose a modified multidomain RGB to TIR image translation model focused on edge preservation to employ annotated RGB images with challenging labels. Our proposed method not only preserves key details in the original image but also leverages the optimal TIR style code to portray accurate TIR characteristics in the translated image, when applied on both synthetic and real world RGB images. Using our translation model, we have enabled the supervised learning of deep TIR image-based optical flow estimation and object detection that ameliorated in deep TIR optical flow estimation by reduction in end point error by 56.5% on average and the best object detection mAP of 23.9% respectively. Our code and supplementary materials are available at https://github.com/rpmsnu/sRGB-TIR.",
        "primary_area": "",
        "author": "Dong\u2013Guw Lee;Myung\u2013Hwan Jeon;Younggun Cho;Ayoung Kim;Dong\u2013Guw Lee;Myung\u2013Hwan Jeon;Younggun Cho;Ayoung Kim",
        "authorids": "/37089256320;/37088439542;/37085469522;/37403315600;/37089256320;/37088439542;/37085469522;/37403315600",
        "aff": "Dept. of Mechanical Engineering, SNU, Seoul, S. Korea; Institute of Advanced Machines and Design, SNU, Seoul, S.Korea; Dept. Electrical Engineering, Inha University, Incheon, S. Korea; Dept. of Mechanical Engineering, SNU, Seoul, S. Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161210/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9056331604129962827&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Seoul National University;Inha University",
        "aff_unique_dep": "Department of Mechanical Engineering;Dept. Electrical Engineering",
        "aff_unique_url": "https://www.snu.ac.kr;http://www.inha.ac.kr",
        "aff_unique_abbr": "SNU;Inha U",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Seoul;Incheon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160754",
        "title": "EdgeVO: An Efficient and Accurate Edge-based Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual odometry is important for plenty of applications such as autonomous vehicles, and robot navigation. It is challenging to conduct visual odometry in textureless scenes or environments with sudden illumination changes where popular feature-based methods or direct methods cannot work well. To address this challenge, some edge-based methods have been proposed, but they usually struggle between the efficiency and accuracy. In this work, we propose a novel visual odometry approach called EdgeVO, which is accurate, efficient, and robust. By efficiently selecting a small set of edges with certain strategies, we significantly improve the computational efficiency without sacrificing the accuracy. Compared to existing edge-based method, our method can significantly reduce the computational complexity while maintaining similar accuracy or even achieving better accuracy. This is attributed to that our method removes useless or noisy edges. Experimental results on the TUM datasets indicate that EdgeVO significantly outperforms other methods in terms of efficiency, accuracy and robustness.",
        "primary_area": "",
        "author": "Hui Zhao;Jianga Shang;Kai Liu;Chao Chen;Fuqiang Gu;Hui Zhao;Jianga Shang;Kai Liu;Chao Chen;Fuqiang Gu",
        "authorids": "/37089895477;/37665714800;/38269608600;/38067271700;/37086096747;/37089895477;/37665714800;/38269608600;/38067271700;/37086096747",
        "aff": "College of Computer Science, Chongqing University, Chongqing, China; School of Geography and Information Engineering, China University of Geoscience, Wuhan, China; College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160754/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13539165053292306341&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Chongqing University;China University of Geoscience",
        "aff_unique_dep": "College of Computer Science;School of Geography and Information Engineering",
        "aff_unique_url": "http://en.cqu.edu.cn/;http://www.cug.edu.cn",
        "aff_unique_abbr": "CQU;CUG",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Chongqing;Wuhan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160772",
        "title": "Effect of the Dynamics of a Horizontally Wobbling Mass on Biped Walking Performance",
        "track": "main",
        "status": "Poster",
        "abstract": "We have developed biped robots with a passive dynamic walking mechanism. This study proposes a compass model with a wobbling mass connected to the upper body and oscillating in the horizontal direction to clarify the influence of the horizontal dynamics of the upper body on bipedal walking. The limit cycles of the model were numerically searched, and their stability and energy efficiency was investigated. Several qualitatively different limit cycles were obtained depending mainly on the spring constant that supports the wobbling mass. Specific types of solutions decreased the stability while reducing the risk of accidental falling and improving the energy efficiency. The obtained results were attributed to the wobbling mass moving in the opposite direction to the upper body, thereby preventing large changes in acceleration and deceleration while walking. The relationship between the locomotion of the proposed model and the actual biped robot and human gaits was investigated.",
        "primary_area": "",
        "author": "Tomoya Kamimura;Akihito Sano;Tomoya Kamimura;Akihito Sano",
        "authorids": "/37086120932;/37276868500;/37086120932;/37276868500",
        "aff": "Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Nagoya, Japan; Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160772/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15095126595351968128&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Nagoya Institute of Technology",
        "aff_unique_dep": "Department of Electrical and Mechanical Engineering",
        "aff_unique_url": "https://www.nitech.ac.jp",
        "aff_unique_abbr": "NIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nagoya",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160550",
        "title": "Effective Combination of Vertical, Longitudinal and Lateral Data for Vehicle Mass Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time knowledge of the vehicle mass is valuable for several applications, mainly: active safety systems design and energy consumption optimization. This work describes a novel strategy for mass estimation in static and dynamic conditions. First, when the vehicle is powered-up, an initial estimation is given by observing the variations of one suspension deflection sensor mounted on the rear. Then, the estimation is refined based on conditioned and filtered longitudinal and lateral motions. In this study, we suggest using these extracted events on two different algorithms, namely: the recursive least squares and the prior-recursive Bayesian inference. That is to express the results in a deterministic and statistical sense. Both simulations and experimental tests show that our approach encompasses the benefits of various works in the literature, preeminently, robustness to resistive loads, fast convergence, and minimal instrumentation.",
        "primary_area": "",
        "author": "Younesse El Mrhasli;Bruno Monsuez;Xavier Mouton;Younesse El Mrhasli;Bruno Monsuez;Xavier Mouton",
        "authorids": "/37089892592;/37072108200;/37086487206;/37089892592;/37072108200;/37086487206",
        "aff": "Department of Computer and System Engineering, ENSTA Paris, Institut Polytechnique de Paris, PALAISEAU, FRANCE; Department of Computer and System Engineering, ENSTA Paris, Institut Polytechnique de Paris, PALAISEAU, FRANCE; Chassis Systems Department, Groupe RENAULT, 1, avenue du Golf, GUAYANCOURT, FRANCE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160550/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10145012248151850511&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "ENSTA Paris;Groupe RENAULT",
        "aff_unique_dep": "Department of Computer and System Engineering;Chassis Systems Department",
        "aff_unique_url": "https://www.ensta-paris.fr;https://www.groupe-renault.com",
        "aff_unique_abbr": "ENSTA;Groupe RENAULT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "PALAISEAU;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160739",
        "title": "Efficient Bimanual Handover and Rearrangement via Symmetry-Aware Actor-Critic Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Bimanual manipulation is important for building intelligent robots that unlock richer skills than single arms. We consider a multi-object bimanual rearrangement task, where a reinforcement learning (RL) agent aims to jointly control two arms to rearrange these objects as fast as possible. Solving this task efficiently is challenging for an RL agent due to the requirement of discovering precise intra-arm coordination in an exponentially large control space. We develop a symmetry-aware actor-critic framework that leverages the interchangeable roles of the two manipulators in the bimanual control setting to reduce the policy search space. To handle the compositionality over multiple objects, we augment training data with an object-centric relabeling technique. The overall approach produces an RL policy that can rearrange up to 8 objects with a success rate of over 70% in simulation. We deploy the policy to two Franka Panda arms and further show a successful demo on human-robot collaboration. Videos can be found at https://sites.google.com/view/bimanual.",
        "primary_area": "",
        "author": "Yunfei Li;Chaoyi Pan;Huazhe Xu;Xiaolong Wang;Yi Wu;Yunfei Li;Chaoyi Pan;Huazhe Xu;Xiaolong Wang;Yi Wu",
        "authorids": "/37089195348;/37089568742;/37086242886;/37085652454;/37089194863;/37089195348;/37089568742;/37086242886;/37085652454;/37089194863",
        "aff": "Institute of Inter-disciplinary Information Sciences, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Shanghai Qi Zhi Institute, Shanghai, China; Department of Electrical and Computer Engineering, UC, San Diego, CA, USA; Shanghai Qi Zhi Institute, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160739/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10584259270089417441&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;1",
        "aff_unique_norm": "Tsinghua University;Shanghai Qi Zhi Institute;University of California, San Diego",
        "aff_unique_dep": "Institute of Inter-disciplinary Information Sciences;;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;;https://www.ucsd.edu",
        "aff_unique_abbr": "THU;;UCSD",
        "aff_campus_unique_index": "0;0;1;2;1",
        "aff_campus_unique": "Beijing;Shanghai;San Diego",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160834",
        "title": "Efficient Bundle Adjustment for Coplanar Points and Lines",
        "track": "main",
        "status": "Poster",
        "abstract": "Bundle adjustment (BA) is a well-studied fundamental problem in the robotics and vision community. In man-made environments, coplanar points and lines are ubiquitous. However, the number of works on bundle adjustment with coplanar points and lines is relatively small. This paper focuses on this special BA problem, referred to as \\pi-\\mathbf{BA}\\pi-\\mathbf{BA}. For a point or a line on a plane, we derive a new constraint to describe the relationship among two poses and the plane, called \\pi\\pi-constraint. We distribute \\pi\\pi-constraints into different groups. Each group is called a \\pi\\pi-factor. We prove that, with some simple preprocessing, the computational complexity associated with a \\pi\\pi-factor in the Levenberg-Marquardt (LM) algorithm is O(1)O(1), independent of the number of \\pi\\pi-constraints packed into the \\pi\\pi-factor. In \\pi-\\mathbf{BA}, \\pi\\pi-\\mathbf{BA}, \\pi-factors replace original reprojection errors. One problem is how to divide \\pi\\pi-constraints into \\pi\\pi-factors. Different strategies may result in different numbers of \\pi\\pi-factors, which in turn affects the efficiency. It is difficult to get the optimal division. We present a greedy algorithm to overcome this problem. Experimental results verify that our algorithm can significantly accelerate the computation.",
        "primary_area": "",
        "author": "Lipu Zhou;Jiacheng Liu;Fengguang Zhai;Pan Ai;Kefei Ren;Yinian Mao;Guoquan Huang;Ziyang Meng;Michael Kaess;Lipu Zhou;Jiacheng Liu;Fengguang Zhai;Pan Ai;Kefei Ren;Yinian Mao;Guoquan Huang;Ziyang Meng;Michael Kaess",
        "authorids": "/37088198282;/37088469930;/37089892291;/37089891872;/37089892460;/37089321433;/37077670600;/37392103100;/37324200400;/37088198282;/37088469930;/37089892291;/37089891872;/37089892460;/37089321433;/37077670600;/37392103100;/37324200400",
        "aff": "UAV Lab, Meituan, Beijing, China; Department of Precision Instrument, Tsinghua University, Beijing, China; UAV Lab, Meituan, Beijing, China; UAV Lab, Meituan, Beijing, China; UAV Lab, Meituan, Beijing, China; UAV Lab, Meituan, Beijing, China; UAV Lab, Meituan, Beijing, China; Department of Precision Instrument, Tsinghua University, Beijing, China; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160834/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=589900394717276127&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;0;0;0;0;1;2",
        "aff_unique_norm": "Meituan;Tsinghua University;Carnegie Mellon University",
        "aff_unique_dep": "UAV Lab;Department of Precision Instrument;Robotics Institute",
        "aff_unique_url": "https://www.meituan.com;https://www.tsinghua.edu.cn;https://www.cmu.edu",
        "aff_unique_abbr": ";THU;CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160322",
        "title": "Efficient Implicit Neural Reconstruction Using LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling scene geometry using implicit neural representation has revealed its advantages in accuracy, flexibility, and low memory usage. Previous approaches have demonstrated impressive results using color or depth images but still have difficulty handling poor light conditions and large-scale scenes. Methods taking global point cloud as input require accurate registration and ground truth coordinate labels, which limits their application scenarios. In this paper, we propose a new method that uses sparse LiDAR point clouds and rough odometry to reconstruct fine-grained implicit occupancy field efficiently within a few minutes. We introduce a new loss function that supervises directly in 3D space without 2D rendering, avoiding information loss. We also manage to refine poses of input frames in an end-to-end manner, creating consistent geometry without global point cloud registration. As far as we know, our method is the first to reconstruct implicit scene representation from LiDAR-only input. Experiments on synthetic and real-world datasets, including indoor and outdoor scenes, prove that our method is effective, efficient, and accurate, obtaining comparable results with existing methods using dense input.",
        "primary_area": "",
        "author": "Dongyu Yan;Xiaoyang Lyu;Jieqi Shi;Yi Lin;Dongyu Yan;Xiaoyang Lyu;Jieqi Shi;Yi Lin",
        "authorids": "/37089895747;/37089682429;/37088457112;/37086281245;/37089895747;/37089682429;/37088457112;/37086281245",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen).; Department of Electrical and Electronic Engineering, The University of Hong Kong.; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology.; Dji Co.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160322/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2578914675733138203&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Harbin Institute of Technology;The University of Hong Kong;Hong Kong University of Science and Technology;DJI",
        "aff_unique_dep": "School of Mechanical Engineering and Automation;Department of Electrical and Electronic Engineering;Department of Electronic and Computer Engineering;",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.hku.hk;https://www.ust.hk;https://www.dji.com",
        "aff_unique_abbr": "HIT;HKU;HKUST;DJI",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160692",
        "title": "Efficient Inference of Temporal Task Specifications from Human Demonstrations using Experiment Design",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic deployments in human environments have motivated the need for autonomous systems to be able to interact with humans and solve tasks effectively. Human demonstrations of tasks can be used to infer underlying task specifications, commonly modeled with temporal logic. State-of-the-art methods have developed Bayesian inference tools to estimate a temporal logic formula from a sequence of demon-strations. The current work proposes the use of experiment design to choose environments for humans to perform these demonstrations. This reduces the number of demonstrations needed to estimate the unknown ground truth formula with low error. A novel computationally efficient strategy is proposed to generate informative environments by using an optimal planner as the model for the demonstrator. Instead of evaluating all possible environments, the search space reduces to the placement of informative orderings of likely eventual goals along an optimal planner's solution. A human study with 600 demonstrations from 20 participants for 4 tasks on a 2D interface validates the proposed hypothesis and empirical performance benefit in terms of convergence and error over baselines. The human study dataset is also publicly shared.",
        "primary_area": "",
        "author": "Shlok Sobti;Rahul Shome;Lydia E. Kavraki;Shlok Sobti;Rahul Shome;Lydia E. Kavraki",
        "authorids": "/37087412631;/37085557993;/37279015600;/37087412631;/37085557993;/37279015600",
        "aff": "Department of Computer Science, Rice University; School of Computing, Australian National University, Canberra; Department of Computer Science, Rice University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160692/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4059232275363328223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Rice University;Australian National University",
        "aff_unique_dep": "Department of Computer Science;School of Computing",
        "aff_unique_url": "https://www.rice.edu;https://www.anu.edu.au",
        "aff_unique_abbr": "Rice;ANU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Canberra",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "10161415",
        "title": "Efficient Learning of High Level Plans from Play",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-world robotic manipulation tasks remain an elusive challenge, since they involve both fine-grained environment interaction, as well as the ability to plan for long-horizon goals. Although deep reinforcement learning (RL) methods have shown encouraging results when planning end-to-end in high-dimensional environments, they remain fundamentally limited by poor sample efficiency due to inefficient exploration, and by the complexity of credit assignment over long horizons. In this work, we present Efficient Learning of High-Level Plans from Play (ELF-P), a framework for robotic learning that bridges motion planning and deep RL to achieve long-horizon complex manipulation tasks. We leverage task-agnostic play data to learn a discrete behavioral prior over object-centric primitives, modeling their feasibility given the current context. We then design a high-level goal-conditioned policy which (1) uses primitives as building blocks to scaffold complex long-horizon tasks and (2) leverages the behavioral prior to accelerate learning. We demonstrate that ELF-P has significantly better sample efficiency than relevant baselines over multiple realistic manipulation tasks and learns policies that can be easily transferred to physical hardware.",
        "primary_area": "",
        "author": "N\u00faria Armengol Urp\u00ed;Marco Bagatella;Otmar Hilliges;Georg Martius;Stelian Coros;N\u00faria Armengol Urp\u00ed;Marco Bagatella;Otmar Hilliges;Georg Martius;Stelian Coros",
        "authorids": "/37089891881;/37089894360;/37299646200;/37870313400;/37077396200;/37089891881;/37089894360;/37299646200;/37870313400;/37077396200",
        "aff": "Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Department of Computer Science, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161415/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5230006142604661247&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "ETH Zurich;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.ethz.ch;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "ETHZ;MPI-IS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "10161267",
        "title": "Efficient Learning of Locomotion Skills through the Discovery of Diverse Environmental Trajectory Generator Priors",
        "track": "main",
        "status": "Poster",
        "abstract": "Data-driven learning based methods have recently been particularly successful at learning robust locomotion controllers for a variety of unstructured terrains. Prior work has shown that incorporating good locomotion priors in the form of trajectory generators (TGs) is effective at efficiently learning complex locomotion skills. However, defining a good, single TG as tasks/environments become increasingly more complex remains a challenging problem as it requires extensive tuning and risks reducing the effectiveness of the prior. In this paper, we present Evolved Environmental Trajectory Generators (EETG), a method that learns a diverse set of specialised locomotion priors using Quality-Diversity algorithms while maintaining a single policy within the Policies Modulating TG (PMTG) architecture. The results demonstrate that EETG enables a quadruped robot to successfully traverse a wide range of environments, such as slopes, stairs, rough terrain, and balance beams. Our experiments show that learning a diverse set of specialized TG priors is significantly (5 times) more efficient than using a single, fixed prior when dealing with a wide range of environments.",
        "primary_area": "",
        "author": "Shikha Surana;Bryan Lim;Antoine Cully;Shikha Surana;Bryan Lim;Antoine Cully",
        "authorids": "/37089895291;/37088504437;/37085649925;/37089895291;/37088504437;/37085649925",
        "aff": "Imperial College London, United Kingdom; Imperial College London, United Kingdom; Imperial College London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161267/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5557418283266489491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161424",
        "title": "Efficient Optimal Planning in non-FIFO Time-Dependent Flow Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an algorithm for solving the time-dependent shortest path problem in flow fields where the FIFO (first-in-first-out) assumption is violated. This problem variant is important for autonomous vehicles in the ocean, for example, that cannot arbitrarily hover in a fixed position and that are strongly influenced by time-varying ocean currents. Although polynomial-time solutions are available for discrete-time problems, the continuous-time non-FIFO case is NP-hard with no known relevant special cases. Our main result is to show that this problem can be solved in polynomial time if the edge travel time functions are piecewise-constant, agreeing with existing worst-case bounds for FIFO problems with restricted slopes. We present a minimum-time algorithm for graphs that allows for paths with finite-length cycles, and then embed this algorithm within an asymptotically optimal sampling-based framework to find time-optimal paths in flows. The algorithm relies on an efficient data structure to represent and manipulate piecewise-constant functions and is straightforward to implement. We illustrate the behaviour of the algorithm in an example based on a common ocean vortex model.",
        "primary_area": "",
        "author": "James Ju Heon Lee;Chanyeol Yoo;Stuart Anstee;Robert Fitch;James Ju Heon Lee;Chanyeol Yoo;Stuart Anstee;Robert Fitch",
        "authorids": "/37089896128;/37086933786;/37601910400;/38466367800;/37089896128;/37086933786;/37601910400;/38466367800",
        "aff": "University of Technology Sydney, Ultimo, Australia; University of Technology Sydney, Ultimo, Australia; Department of Defence, Defence Science and Technology Group, Australia; University of Technology Sydney, Ultimo, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161424/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=201787875913018249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Technology Sydney;Defence Science and Technology Group",
        "aff_unique_dep": ";Department of Defence",
        "aff_unique_url": "https://www.uts.edu.au;https://www.dstgroup.com.au",
        "aff_unique_abbr": "UTS;DST Group",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ultimo;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10161456",
        "title": "Efficient Planar Pose Estimation via UWB Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "State estimation is an essential part of autonomous systems. Integrating the Ultra-Wideband (UWB) technique has been shown to correct the long-term estimation drift and bypass the complexity of loop closure detection. However, few works on robotics treat UWB as a stand-alone state estimation solution. The primary purpose of this work is to investigate planar pose estimation using only UWB range measurements. We prove the excellent property of a two-step scheme, which says we can refine a consistent estimator to be asymptotically efficient by one step of Gauss-Newton iteration. Grounded on this result, we design the GN-ULS estimator, which reduces the computation time significantly compared to previous methods and presents the possibility of using only UWB for real-time state estimation.",
        "primary_area": "",
        "author": "Haodong Jiang;Wentao Wang;Yuan Shen;Xinghan Li;Xiaoqiang Ren;Biqiang Mu;Junfeng Wu;Haodong Jiang;Wentao Wang;Yuan Shen;Xinghan Li;Xiaoqiang Ren;Biqiang Mu;Junfeng Wu",
        "authorids": "/37089478764;/37089895632;/37089783203;/37089480326;/37085369550;/38540863300;/37085446840;/37089478764;/37089895632;/37089783203;/37089480326;/37085369550;/38540863300;/37085446840",
        "aff": "School of Data Science, the Chinese University of HongKong, Shenzhen, P. R. China; College of Control Science and Engineering and the State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, P. R. China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, P. R. China; College of Control Science and Engineering and the State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, P. R. China; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, P. R. China; Key Laboratory of Systems and Control, Institute of Systems Science, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, P. R. China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161456/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4444737339832009103&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;1;3;4;5",
        "aff_unique_norm": "the Chinese University of Hong Kong;Zhejiang University;Nanjing University of Science and Technology;Shanghai University;Chinese Academy of Sciences;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "School of Data Science;College of Control Science and Engineering;School of Electronic and Optical Engineering;School of Mechatronic Engineering and Automation;Institute of Systems Science;Artificial Intelligence and Robotics",
        "aff_unique_url": "https://www.cuhk.edu.cn;http://www.zju.edu.cn;http://www.nust.edu.cn;https://www.shu.edu.cn;http://www.cas.cn;http://www.airs.shenzhen.gov.cn/",
        "aff_unique_abbr": "CUHK;ZJU;NUST;SHU;CAS;AIRS",
        "aff_campus_unique_index": "0;1;2;1;3;4;0",
        "aff_campus_unique": "Shenzhen;Hangzhou;Nanjing;Shanghai;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161517",
        "title": "Efficient Planning of Multi-Robot Collective Transport using Graph Reinforcement Learning with Higher Order Topological Abstraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient multi-robot task allocation (MRTA) is fundamental to various time-sensitive applications such as disaster response, warehouse operations, and construction. This paper tackles a particular class of these problems that we call MRTA-collective transport or MRTA-CT - here tasks present varying workloads and deadlines, and robots are subject to flight range, communication range, and payload constraints. For large instances of these problems involving 100s-1000's of tasks and 10s-100s of robots, traditional non-learning solvers are often time-inefficient, and emerging learning-based policies do not scale well to larger-sized problems without costly retraining. To address this gap, we use a recently proposed encoder-decoder graph neural network involving Capsule networks and multi-head attention mechanism, and innovatively add topological descriptors (TD) as new features to improve transferability to unseen problems of similar and larger size. Persistent homology is used to derive the TD, and proximal policy optimization is used to train our TD-augmented graph neural network. The resulting policy model compares favorably to state-of-the-art non-learning baselines while being much faster. The benefit of using TD is readily evident when scaling to test problems of size larger than those used in training.",
        "primary_area": "",
        "author": "Steve Paul;Wenyuan Li;Brian Smyth;Yuzhou Chen;Yulia Gel;Souma Chowdhury;Steve Paul;Wenyuan Li;Brian Smyth;Yuzhou Chen;Yulia Gel;Souma Chowdhury",
        "authorids": "/37086118266;/37089360674;/37089895874;/37087237104;/37085883537;/37086117851;/37086118266;/37089360674;/37089895874;/37087237104;/37085883537;/37086117851",
        "aff": "Department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; Department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; Department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA; Department of Mathematical Sciences, University of Texas at Dallas, Dallas, TX, USA; Department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161517/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15786975824115496665&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "University at Buffalo;Temple University;University of Texas at Dallas",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;Department of Computer and Information Sciences;Department of Mathematical Sciences",
        "aff_unique_url": "https://www.buffalo.edu;https://www.temple.edu;https://www.utdallas.edu",
        "aff_unique_abbr": "UB;Temple;UT Dallas",
        "aff_campus_unique_index": "0;0;0;1;2;0",
        "aff_campus_unique": "Buffalo;Philadelphia;Dallas",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161081",
        "title": "Efficient Preference-Based Reinforcement Learning Using Learned Dynamics Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Preference-based reinforcement learning (PbRL) can enable robots to learn to perform tasks based on an individual's preferences without requiring a hand-crafted re-ward function. However, existing approaches either assume access to a high-fidelity simulator or analytic model or take a model-free approach that requires extensive, possibly unsafe online environment interactions. In this paper, we study the benefits and challenges of using a learned dynamics model when performing PbRL. In particular, we provide evidence that a learned dynamics model offers the following benefits when performing PbRL: (1) preference elicitation and policy optimization require significantly fewer environment interactions than model-free PbRL, (2) diverse preference queries can be synthesized safely and efficiently as a byproduct of standard model-based RL, and (3) reward pre-training based on suboptimal demonstrations can be performed without any environmental interaction. Our paper provides empirical ev-idence that learned dynamics models enable robots to learn customized policies based on user preferences in ways that are safer and more sample efficient than prior preference learning approaches. Supplementary materials and code are available at https://sites.google.com/berkeley.edu/mop-rl.",
        "primary_area": "",
        "author": "Yi Liu;Gaurav Datta;Ellen Novoseller;Daniel S. Brown;Yi Liu;Gaurav Datta;Ellen Novoseller;Daniel S. Brown",
        "authorids": "/37089893117;/37089893707;/37088507027;/38478370100;/37089893117;/37089893707;/37088507027;/38478370100",
        "aff": "UC Berkeley; UC Berkeley; Army Research Lab; University of Utah",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161081/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11694898154355625842&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "University of California, Berkeley;Army Research Laboratory;University of Utah",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.arl.army.mil;https://www.utah.edu",
        "aff_unique_abbr": "UC Berkeley;ARL;Utah",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160382",
        "title": "Efficient Recovery Learning using Model Predictive Meta-Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Operating under real world conditions is challenging due to the possibility of a wide range of failures induced by execution errors and state uncertainty. In relatively benign settings, such failures can be overcome by retrying or executing one of a small number of hand-engineered recovery strategies. By contrast, contact-rich sequential manipulation tasks, like opening doors and assembling furniture, are not amenable to exhaustive hand-engineering. To address this issue, we present a general approach for robustifying manipulation strategies in a sample-efficient manner. Our approach incrementally improves robustness by first discovering the failure modes of the current strategy via exploration in simulation and then learning additional recovery skills to handle these failures. To ensure efficient learning, we propose an online algorithm called Meta-Reasoning for Skill Learning (MetaReSkill) that monitors the progress of all recovery policies during training and allocates training resources to recoveries that are likely to improve the task performance the most. We use our approach to learn recovery skills for door-opening and evaluate them both in simulation and on a real robot with little fine-tuning. Compared to open-loop execution, our experiments show that even a limited amount of recovery learning improves task success substantially from 71% to 92.4% in simulation and from 75% to 90% on a real robot.",
        "primary_area": "",
        "author": "Shivam Vats;Maxim Likhachev;Oliver Kroemer;Shivam Vats;Maxim Likhachev;Oliver Kroemer",
        "authorids": "/37088690871;/37309318800;/37593222300;/37088690871;/37309318800;/37593222300",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160382/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7771577744636211268&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160793",
        "title": "Efficient View Path Planning for Autonomous Implicit Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Implicit neural representations have shown promising potential for 3D scene reconstruction. Recent work applies it to autonomous 3D reconstruction by learning information gain for view path planning. Effective as it is, the computation of the information gain is expensive, and compared with that using volumetric representations, collision checking using the implicit representation for a 3D point is much slower. In the paper, we propose to 1) leverage a neural network as an implicit function approximator for the information gain field and 2) combine the implicit fine-grained representation with coarse volumetric representations to improve efficiency. Further with the improved efficiency, we propose a novel informative path planning based on a graph-based planner. Our method demonstrates significant improvements in the reconstruction quality and planning efficiency compared with autonomous reconstructions with implicit and explicit representations. We deploy the method on a real UAV and the results show that our method can plan informative views and reconstruct a scene with high quality.",
        "primary_area": "",
        "author": "Jing Zeng;Yanxu Li;Yunlong Ran;Shuo Li;Fei Gao;Lincheng Li;Shibo He;Jiming Chen;Qi Ye;Jing Zeng;Yanxu Li;Yunlong Ran;Shuo Li;Fei Gao;Lincheng Li;Shibo He;Jiming Chen;Qi Ye",
        "authorids": "/37088479527;/37089892816;/37089694650;/37089895714;/37086045143;/37088489974;/37405849000;/37280686900;/37086235936;/37088479527;/37089892816;/37089694650;/37089895714;/37086045143;/37088489974;/37405849000;/37280686900;/37086235936",
        "aff": "Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Fuxi AI Lab, NetEase, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology and also the Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems of Zhejiang Province, College of Control Science and Engineering, Zhejiang University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160793/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15516795259813281165&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;0;0;0",
        "aff_unique_norm": "Zhejiang University;NetEase",
        "aff_unique_dep": ";Fuxi AI Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.163.com",
        "aff_unique_abbr": "ZJU;NetEase",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160393",
        "title": "Efficient Visual-Inertial Navigation with Point-Plane Map",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and real-time global pose estimation relative to a global prior map is indispensable in many applications, such as logistics with micro aerial vehicles and Augmented Reality. Supposed that a pure sparse 3D point map can provide a structureless representation of the environment, then generating a point-plane prior map can further model the environment topology and offer global constraints for an accurate localization. To implement this, we propose a filter-based, large-scale visual-inertial odometry system, termed PPM-VIO, which utilizes a point-plane map to correct the cumulative drift. Our system, detecting coplanar information from sparse point clouds with semantic information, achieves accurate online plane matching via geometric constraints, semantic constraints, and descriptor constraints. To improve the localization performance, we effectively integrate and formulate the global planar measurements and points measurements in a filter-based estimator. The effectiveness of the proposed method is extensively validated on real-world datasets collected in different scenarios. Experimental results demonstrate that, rather than using the point map alone, leveraging the plane information in the prior map can yield better trajectory estimates and broaden the effective scope of the prior map in different scenes.",
        "primary_area": "",
        "author": "Jiaxin Hu;Kefei Ren;Xiaoyu Xu;Lipu Zhou;Xiaoming Lang;Yinian Mao;Guoquan Huang;Jiaxin Hu;Kefei Ren;Xiaoyu Xu;Lipu Zhou;Xiaoming Lang;Yinian Mao;Guoquan Huang",
        "authorids": "/37089379711;/37089892460;/37089893926;/37088198282;/37089450635;/37089321433;/37077670600;/37089379711;/37089892460;/37089893926;/37088198282;/37089450635;/37089321433;/37077670600",
        "aff": "Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160393/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2389427054828595687&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Meituan",
        "aff_unique_dep": "UAV",
        "aff_unique_url": "https://www.meituan.com",
        "aff_unique_abbr": "Meituan",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161331",
        "title": "Efficient and Hybrid Decoder for Local Map Construction in Bird'-Eye-View",
        "track": "main",
        "status": "Poster",
        "abstract": "High-definition maps are crucial perception elements for autonomous robot navigation systems, which can provide accurate scene layout and environment information for downstream motion prediction and planning control tasks. Traditional methods based on manual annotation or SLAM algorithms require massive labor efforts and time costs, which hinders the deployment of practical applications. Online construction of local maps from on-board cameras offers an alternative solution. Aiming at the problems of unsatisfying precision and redundant computation of HDMapNet, we propose an efficient and hybrid decoder (EHD) that consists of a CNN-based segmentation (Seg) head and a query-based lane detection head (QLD). Specifically, the Seg head outputs pixel-level semantic maps, and QLD predicts instance mask for each lane object through learnable query embeddings. The designed decoding method eliminates the cumulative error caused by inaccurate semantic maps and does not require additional clustering algorithm for post-processing. Through combining with a variety of bird's-eye-view (BEV) encoders, the effectiveness and efficiency of our EHD is demonstrated by extensive experiments. For segmentation task, the mIoU scores of semantic map can be improved by 1.3%\u223c2.9%. Additionally, the accuracy of lane detection is also significantly increased (more than 10.2% mAP) under all evaluation criteria. Since our method discards redundant post-processing, the inference speed is up to 22.71 FPS, which is 32 times faster than HDMapNet.",
        "primary_area": "",
        "author": "Kun Tian;Yun Ye;Zheng Zhu;Peng Li;Guan Huang;Kun Tian;Yun Ye;Zheng Zhu;Peng Li;Guan Huang",
        "authorids": "/37089893421;/37089013027;/37085640794;/37090018282;/37087235182;/37089893421;/37089013027;/37085640794;/37090018282;/37087235182",
        "aff": "PhiGent Robotics, Beijing, China; PhiGent Robotics, Beijing, China; PhiGent Robotics, Beijing, China; PhiGent Robotics, Beijing, China; PhiGent Robotics, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161331/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1797409897458018515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "PhiGent Robotics",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160378",
        "title": "Efficiently Approaching Groups of People in a Socially Acceptable Manner in Environments with Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "Advancements in mobile robotics have allowed humans and robots to interact in different environments and ways. A problem of great interest in Human-Robot Interaction is how to approach individuals, e.g., to gather information, in a socially acceptable manner. We present a new method for planning sequential visits to various groups of people in cluttered environments. The problem is formulated as a Set Orienteering Problem, where each group denotes a cluster with a set of possible approaching points considering different F-formations. We use the concept of a social probabilistic roadmap to determine safe paths between groups. Simulations considering different cases show that methodology produces efficient tours that maximize the number of approached individuals while respecting social norms of distance and a limited budget.",
        "primary_area": "",
        "author": "Aline F. F. Silva;Luciano E. Almeida;Douglas G. Macharet;Aline F. F. Silva;Luciano E. Almeida;Douglas G. Macharet",
        "authorids": "/37088225365;/37089893459;/37590114800;/37088225365;/37089893459;/37590114800",
        "aff": "Laborat\u00f3rio de Intelig\u00eancia Computacional e Rob\u00f3tica (LICRo), Instituto Federal do Tri\u00e2ngulo Mineiro (IFTM), Brazil; Department of Computer Science, Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas, Gerais, Brazil; Department of Computer Science, Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas, Gerais, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160378/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6632896308875744339&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Instituto Federal do Tri\u00e2ngulo Mineiro;Universidade Federal de Minas Gerais",
        "aff_unique_dep": "Laborat\u00f3rio de Intelig\u00eancia Computacional e Rob\u00f3tica;Department of Computer Science",
        "aff_unique_url": ";http://www.ufmg.br",
        "aff_unique_abbr": "IFTM;UFMG",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "10160791",
        "title": "Efficiently Learning Small Policies for Locomotion and Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural control of memory-constrained, agile robots requires small, yet highly performant models. We leverage graph hyper networks to learn graph hyper policies trained with off-policy reinforcement learning resulting in networks that are two orders of magnitude smaller than commonly used networks yet encode policies comparable to those encoded by much larger networks trained on the same task. We show that our method can be appended to any off-policy reinforcement learning algorithm, without any change in hyperparameters, by showing results across locomotion and manipulation tasks. Further, we obtain an array of working policies, with differing numbers of parameters, allowing us to pick an optimal network for the memory constraints of a system. Training multiple policies with our method is as sample efficient as training a single policy. Finally, we provide a method to select the best architecture, given a constraint on the number of parameters. Project website: https://sites.google.com/usc.edu/graphhyperpolicy",
        "primary_area": "",
        "author": "Shashank Hegde;Gaurav S. Sukhatme;Shashank Hegde;Gaurav S. Sukhatme",
        "authorids": "/37089182123;/37278934100;/37089182123;/37278934100",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160791/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9495648414410220386&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "10161247",
        "title": "EgoHMR: Egocentric Human Mesh Recovery via Hierarchical Latent Diffusion Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Egocentric vision has gained increasing popularity in social robotics, demonstrating great potentials for personal assistance and human-centric behavior analysis. Holistic per-ception of human body itself is a prerequisite for downstream applications, including action recognition and anticipation. Extensive research has been performed for human mesh recovery from the exocentric images captured from a third-person view, but limited studies are conducted for heavily distorted yet occluded egocentric images. In this paper, we propose Egocentric Human Mesh Recovery (EgoHMR), a novel hierarchical network based on latent diffusion models. Our method takes a single egocentric frame as the input and it can be trained in an end-to-end manner without supervision of 2D pose. The network is built upon the latent diffusion model by incorporating both global and local features in a hierarchical structure. To train the proposed network, we generate weak labels from synchronized exocentric images. The proposed method can perform human mesh recovery directly from egocentric images and detailed quantitative and qualitative experiments have been conducted to demonstrate the effectiveness of the proposed EgoHMR method.",
        "primary_area": "",
        "author": "Yuxuan Liu;Jianxin Yang;Xiao Gu;Yao Guo;Guang-Zhong Yang;Yuxuan Liu;Jianxin Yang;Xiao Gu;Yao Guo;Guang-Zhong Yang",
        "authorids": "/37089612525;/37089447797;/37086360965;/37086919325;/37276270800;/37089612525;/37089447797;/37086360965;/37086919325;/37276270800",
        "aff": "Institute of Medical Robotics, School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Institute of Medical Robotics, School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; Institute of Medical Robotics, School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Institute of Medical Robotics, School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161247/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2042582827531207145&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Imperial College London",
        "aff_unique_dep": "School of Biomedical Engineering;Hamlyn Centre for Robotic Surgery",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.imperial.ac.uk",
        "aff_unique_abbr": "SJTU;ICL",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Shanghai;London",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10160740",
        "title": "Elastic Context: Encoding Elasticity for Data-driven Models of Textiles Elastic Context: Encoding Elasticity for Data-driven Models of Textiles",
        "track": "main",
        "status": "Poster",
        "abstract": "Physical interaction with textiles, such as assistive dressing or household tasks, requires advanced dexterous skills. The complexity of textile behavior during stretching and pulling is influenced by the material properties of the yarn and by the textile's construction technique, which are often unknown in real-world settings. Moreover, identification of physical properties of textiles through sensing commonly available on robotic platforms remains an open problem. To address this, we introduce Elastic Context (EC), a method to encode the elasticity of textiles using stress-strain curves adapted from textile engineering for robotic applications. We employ EC to learn generalized elastic behaviors of textiles and examine the effect of EC dimension on accurate force modeling of real-world non-linear elastic behaviors.",
        "primary_area": "",
        "author": "Alberta Longhini;Marco Moletta;Alfredo Reichlin;Michael C. Welle;Alexander Kravberg;Yufei Wang;David Held;Zackory Erickson;Danica Kragic;Alberta Longhini;Marco Moletta;Alfredo Reichlin;Michael C. Welle;Alexander Kravberg;Yufei Wang;David Held;Zackory Erickson;Danica Kragic",
        "authorids": "/37088920995;/37088511151;/37089663394;/38202265300;/37089895121;/37089513951;/37408101800;/37085785366;/37281296000;/37088920995;/37088511151;/37089663394;/38202265300;/37089895121;/37089513951;/37408101800;/37085785366;/37281296000",
        "aff": "Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Carnegie Mellon University, Pittsburgh, USA; Carnegie Mellon University, Pittsburgh, USA; Carnegie Mellon University, Pittsburgh, USA; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160740/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13274769431291396816&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;1;1;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "EECS;",
        "aff_unique_url": "https://www.kth.se;https://www.cmu.edu",
        "aff_unique_abbr": "KTH;CMU",
        "aff_campus_unique_index": "0;0;0;0;0;1;1;1;0",
        "aff_campus_unique": "Stockholm;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;1;1;1;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "10161500",
        "title": "Electroadhesive Auxetics as Programmable Layer Jamming Skins for Formable Crust Shape Displays",
        "track": "main",
        "status": "Poster",
        "abstract": "Shape displays are a class of haptic devices that enable whole-hand haptic exploration of 3D surfaces. However, their scalability is limited by the mechanical complexity and high cost of traditional actuator arrays. In this paper, we propose using electroadhesive auxetic skins as a strain-limiting layer to create programmable shape change in a continuous (\u201cformable crust\u201d) shape display. Auxetic skins are manufactured as flexible printed circuit boards with dielectric-laminated electrodes on each auxetic unit cell (AUC), using monolithic fabrication to lower cost and assembly time. By layering multiple sheets and applying a voltage between electrodes on subsequent layers, electroadhesion locks individual AUCs, achieving a maximum in-plane stiffness variation of 7.6x with a power consumption of 50 \\boldsymbol{\\mu \\mathrm{W}/\\text{AUC}.}\\boldsymbol{\\mu \\mathrm{W}/\\text{AUC}.} We first characterize an individual AUC and compare results to a kinematic model. We then validate the ability of a 5x5 AUC array to actively modify its own axial and transverse stiffness. Finally, we demonstrate this array in a continuous shape display as a strain-limiting skin to programmatically modulate the shape output of an inflatable LDPE pouch. Integrating electroadhesion with auxetics enables new capabilities for scalable, low-profile, and low-power control of flexible robotic systems.",
        "primary_area": "",
        "author": "Ahad M. Rauf;Jack S. Bernardo;Sean Follmer;Ahad M. Rauf;Jack S. Bernardo;Sean Follmer",
        "authorids": "/37088358720;/37089895608;/37085667725;/37088358720;/37089895608;/37085667725",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161500/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9809952922429933957&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160882",
        "title": "Embedded Active Stiffening Mechanisms to Modulate Kresling Tower Kinetostatic Properties",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-rigidly foldable origamis are of great interest to build robotic components, as they are light, offer large deployability and can also be multistable. In this paper, we consider the Kresling tower, and propose an original way to actively modulate its kinetostatic properties. Actuated stiffening mechanisms are embedded on some folds of the origami. By adjusting the axial stiffness of the folds, modulation of the axial stiffness and the force required to switch between stable configurations are demonstrated. This adjustment can in addition be performed independently from the height of the stable configurations, which makes it simple to use. The interest of fold stiffening is outlined experimentally. Three actuation strategies are considered and implemented. Impact on Kresling tower properties are shown, with complementary performances of pneumatic, SMA-based and DC motor actuation.",
        "primary_area": "",
        "author": "John Berre;Lennart Rubbert;Fran\u00e7ois Geiskopf;Pierre Renaud;John Berre;Lennart Rubbert;Fran\u00e7ois Geiskopf;Pierre Renaud",
        "authorids": "/37089894056;/37086476458;/38228753000;/37277292000;/37089894056;/37086476458;/38228753000;/37277292000",
        "aff": "ICube - University of Strasbourg - CNRS - INSA, Strasbourg; ICube - University of Strasbourg - CNRS - INSA, Strasbourg; ICube - University of Strasbourg - CNRS - INSA, Strasbourg; ICube - University of Strasbourg - CNRS - INSA, Strasbourg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160882/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5662782281390186139&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Strasbourg",
        "aff_unique_dep": "ICube",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "Unistra",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Strasbourg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160668",
        "title": "Embodied Agents for Efficient Exploration and Smart Scene Description",
        "track": "main",
        "status": "Poster",
        "abstract": "The development of embodied agents that can communicate with humans in natural language has gained increasing interest over the last years, as it facilitates the diffusion of robotic platforms in human-populated environments. As a step towards this objective, in this work, we tackle a setting for visual navigation in which an autonomous agent needs to explore and map an unseen indoor environment while portraying interesting scenes with natural language descriptions. To this end, we propose and evaluate an approach that combines recent advances in visual robotic exploration and image captioning on images generated through agent-environment interaction. Our approach can generate smart scene descriptions that maximize semantic knowledge of the environment and avoid repetitions. Further, such descriptions offer user-understandable insights into the robot's representation of the environment by high-lighting the prominent objects and the correlation between them as encountered during the exploration. To quantitatively assess the performance of the proposed approach, we also devise a specific score that takes into account both exploration and description skills. The experiments carried out on both photorealistic simulated environments and real-world ones demonstrate that our approach can effectively describe the robot's point of view during exploration, improving the human-friendly interpretability of its observations.",
        "primary_area": "",
        "author": "Roberto Bigazzi;Marcella Cornia;Silvia Cascianelli;Lorenzo Baraldi;Rita Cucchiara;Roberto Bigazzi;Marcella Cornia;Silvia Cascianelli;Lorenzo Baraldi;Rita Cucchiara",
        "authorids": "/37088855073;/37086032067;/37085823191;/37085380498;/37271902200;/37088855073;/37086032067;/37085823191;/37085380498;/37271902200",
        "aff": "University of Modena and Reggio Emilia, Italy; University of Modena and Reggio Emilia, Italy; University of Modena and Reggio Emilia, Italy; University of Modena and Reggio Emilia, Italy; University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160668/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13774018997885041136&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.unimore.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10160748",
        "title": "Embodied Referring Expression for Manipulation Question Answering in Interactive Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Embodied agents are expected to perform more complicated tasks in an interactive environment, with the progress of Embodied AI in recent years. Existing embodied tasks including Embodied Referring Expression (ERE) and other QA-form tasks mainly focuses on interaction in term of linguistic instruction. Therefore, enabling the agent to manipulate objects in the environment for exploration actively has become a challenging problem for the community. To solve this problem, We introduce a new embodied task: Remote Embodied Manipulation Question Answering (REMQA) to combine ERE with manipulation tasks. In REMQA task, the agent needs to navigate to a remote position and perform manipulation with the target object to answer the question. We build a benchmark dataset for the REMQA task in AI2-THOR simulator. To this end, a framework with 3D semantic reconstruction and modular network paradigms is proposed. The evaluation of the proposed framework on REMQA dataset is presented to validate its effectiveness.",
        "primary_area": "",
        "author": "Qie Sima;Sinan Tan;Huaping Liu;Fuchun Sun;Weifeng Xu;Ling Fu;Qie Sima;Sinan Tan;Huaping Liu;Fuchun Sun;Weifeng Xu;Ling Fu",
        "authorids": "/37088690631;/37089447513;/37310126400;/37279269000;/37089629785;/37089629001;/37088690631;/37089447513;/37310126400;/37279269000;/37089629785;/37089629001",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Siemens Ltd., China; Siemens Ltd., China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160748/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14824373741779399231&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;1",
        "aff_unique_norm": "Tsinghua University;Siemens Ltd.",
        "aff_unique_dep": "Department of Computer Science and Technology;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.siemens.com.cn",
        "aff_unique_abbr": "THU;Siemens",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160981",
        "title": "Emulating Human Kinematic Behavior on Lower-Limb Prostheses via Multi-Contact Models and Force-Based Nonlinear Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Active lower-limb prostheses could enable more natural assisted locomotion by contributing net positive work through important gait events, such as ankle push-off. This paper uses multi-contact models of locomotion together with force-based nonlinear optimization-based controllers to achieve human-like kinematic behavior, including ankle push-off, on a powered transfemoral prosthesis. In particular, we leverage model-based control approaches for dynamic bipedal robotic walking to develop a systematic method to realize human-like walking on a powered prosthesis that does not require subject- specific tuning. The proposed controller is implemented on a prosthesis for 2 subjects without tuning between subjects, emulating subject-specific human kinematic trends on the prosthesis joints. These experimental results demonstrate that our force- based nonlinear control approach achieves better tracking of human-like kinematic trajectories, with an average RMSE of 0.0223 during weight-bearing, compared to 2 non-force-sensing methods with an average RMSE of 0.0411 and 0.0430.",
        "primary_area": "",
        "author": "Rachel Gehlhar;Aaron D. Ames;Rachel Gehlhar;Aaron D. Ames",
        "authorids": "/37088435299;/37300877900;/37088435299;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160981/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10526592117604119291&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161049",
        "title": "Enable Natural Tactile Interaction for Robot Dog based on Large-format Distributed Flexible Pressure Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Touch is an important channel for human-robot interaction, while it is challenging for robots to recognize human touch accurately and make appropriate responses. In this paper, we design and implement a set of large-format distributed flexible pressure sensors on a robot dog to enable natural human-robot tactile interaction. Through a heuristic study, we sorted out 81 tactile gestures commonly used when humans interact with real dogs and 44 dog reactions. A gesture classification algorithm based on ResNet is proposed to recognize these 81 human gestures, and the classification accuracy reaches 98.7%. In addition, an action prediction algorithm based on Transformer is proposed to predict dog actions from human gestures, reaching a 1-gram BLEU score of 0.87. Finally, we compare the tactile interaction with the voice interaction during a freedom human-robot-dog interactive playing study. The results show that tactile interaction plays a more significant role in alleviating user anxiety, stimulating user excitement and improving the acceptability of robot dogs.",
        "primary_area": "",
        "author": "Lishuang Zhan;Yancheng Cao;Qitai Chen;Haole Guo;Jiasi Gao;Yiyue Luo;Shihui Guo;Guyue Zhou;Jiangtao Gong;Lishuang Zhan;Yancheng Cao;Qitai Chen;Haole Guo;Jiasi Gao;Yiyue Luo;Shihui Guo;Guyue Zhou;Jiangtao Gong",
        "authorids": "/37089893920;/37089893301;/37089895750;/37089449179;/37088532058;/37089013363;/37086383636;/37085489402;/37089661527;/37089893920;/37089893301;/37089895750;/37089449179;/37088532058;/37089013363;/37086383636;/37085489402;/37089661527",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, Haidian District, Beijing, P.R.China; Institute for AI Industry Research (AIR), Tsinghua University, Haidian District, Beijing, P.R.China; Institute for AI Industry Research (AIR), Tsinghua University, Haidian District, Beijing, P.R.China; Institute for AI Industry Research (AIR), Tsinghua University, Haidian District, Beijing, P.R.China; Institute for AI Industry Research (AIR), Tsinghua University, Haidian District, Beijing, P.R.China; Computer Science and Artificial Intelligence Laboratory (CSAIL), Mas-sachusetts Institute of Technology., UK; School of Informatics, Xiamen University., China; Institute for AI Industry Research (AIR), Tsinghua University, Haidian District, Beijing, P.R.China; Institute for AI Industry Research (AIR), Tsinghua University, Haidian District, Beijing, P.R.China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161049/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16890166140039368021&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;2;0;0",
        "aff_unique_norm": "Tsinghua University;Massachusetts Institute of Technology;Xiamen University",
        "aff_unique_dep": "Institute for AI Industry Research (AIR);Computer Science and Artificial Intelligence Laboratory;School of Informatics",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.csail.mit.edu;https://www.xmu.edu.cn",
        "aff_unique_abbr": "Tsinghua;MIT CSAIL;XMU",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Haidian District, Beijing;Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10161235",
        "title": "Enabling safe walking rehabilitation on the exoskeleton Atalante: experimental results",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper exposes a control architecture enabling rehabilitation of walking impaired patients with the lower-limb exoskeleton Atalante. Atalante's control system is modified to allow the patient to contribute to the walking motion through their efforts. Only the swing leg degree of freedom along the nominal path is relaxed. An online trajectory optimization checks that the muscle forces do not jeopardize stability. The optimization generates reference trajectories that satisfy several key constraints from the current point to the end of the step. One of the constraints requires that the center or pressure remains inside the support polygon, which ensures that the support leg subsystem successfully tracks the reference trajectory. As a result of the presented works, the robot provides a non-zero force in the direction of motion only when required, helping the patient go fast enough to maintain balance (or preventing him from going too fast). Experimental results are reported. They illustrate that variations of \u00b150% of the duration of the step can be achieved in response to the patient's efforts and that many steps are achieved without falling.",
        "primary_area": "",
        "author": "Maxime Brunet;Marine P\u00e9triaux;Florent Di Meglio;Nicolas Petit;Maxime Brunet;Marine P\u00e9triaux;Florent Di Meglio;Nicolas Petit",
        "authorids": "/37089680824;/37089307773;/37546922100;/37299796200;/37089680824;/37089307773;/37546922100;/37299796200",
        "aff": "Wandercraft, Paris, France; Wandercraft, Paris, France; MINES Paris, Centre Automatique et Syst\u00e8mes, PSL University, Paris Cedex, France; MINES Paris, Centre Automatique et Syst\u00e8mes, PSL University, Paris Cedex, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161235/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13301775227365924219&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Wandercraft;MINES Paris",
        "aff_unique_dep": ";Centre Automatique et Syst\u00e8mes",
        "aff_unique_url": ";https://www.minesparis.psl.eu",
        "aff_unique_abbr": ";MINES Paris",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160267",
        "title": "Energy-Based Models for Cross-Modal Localization using Convolutional Transformers",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel framework using Energy-Based Models (EBMs) for localizing a ground vehicle mounted with a range sensor against satellite imagery in the absence of GPS. Lidar sensors have become ubiquitous on autonomous vehicles for describing its surrounding environment. Map priors are typically built using the same sensor modality for localization purposes. However, these map building endeavors using range sensors are often expensive and time-consuming. Alternatively, we leverage the use of satellite images as map priors, which are widely available, easily accessible, and pro-vide comprehensive coverage. We propose a method using convolutional transformers that performs accurate metric-level localization in a cross-modal manner, which is challenging due to the drastic difference in appearance between the sparse range sensor readings and the rich satellite imagery. We train our model end-to-end and demonstrate our approach achieving higher accuracy than the state-of-the-art on KITTI, Pandaset, and a custom dataset.",
        "primary_area": "",
        "author": "Alan Wu;Michael S. Ryoo;Alan Wu;Michael S. Ryoo",
        "authorids": "/37089892490;/37397559800;/37089892490;/37397559800",
        "aff": "MIT Lincoln Laboratory, Lexington, MA, USA; Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160267/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15530519894488810615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology Lincoln Laboratory;Stony Brook University",
        "aff_unique_dep": "Lincoln Laboratory;Department of Computer Science",
        "aff_unique_url": "https://www.ll.mit.edu;https://www.stonybrook.edu",
        "aff_unique_abbr": "MIT LL;SBU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Lexington;Stony Brook",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160360",
        "title": "Enforcing Constraints for Dynamic Obstacle Avoidance by Compliant Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work a control scheme is proposed to enforce dynamic obstacle avoidance constraints to the full body of actively compliant robots. We argue that both compliance and accuracy are necessary to build safe collaborative robotic systems; obstacle avoidance is usually not enough, due to the reliance on perception systems which exhibit delays and errors. Our scheme is able to successfully avoid obstacles, while remaining compliant in the entirety of the executed task. Therefore, in case of unexpected collisions due to perception system errors, the robot remains safe for humans and its environment. Our approach is validated through experiments with simulated and real obstacles utilizing a 7-dof KUKA LBR iiwa robotic manipulator.",
        "primary_area": "",
        "author": "Leonidas Koutras;Konstantinos Vlachos;George S. Kanakis;Fotios Dimeas;Zoe Doulgeri;George A. Rovithakis;Leonidas Koutras;Konstantinos Vlachos;George S. Kanakis;Fotios Dimeas;Zoe Doulgeri;George A. Rovithakis",
        "authorids": "/37088507216;/37273088900;/37086939020;/37085442111;/37274011500;/37284600700;/37088507216;/37273088900;/37086939020;/37085442111;/37274011500;/37284600700",
        "aff": "Dept. of Electrical & Computer Engineering, Automation & Robotics Lab, Aristotle University of Thessaloniki, Greece; Dept. of Electrical & Computer Engineering, Automation & Robotics Lab, Aristotle University of Thessaloniki, Greece; Dept. of Electrical & Computer Engineering, Automation & Robotics Lab, Aristotle University of Thessaloniki, Greece; Dept. of Electrical & Computer Engineering, Automation & Robotics Lab, Aristotle University of Thessaloniki, Greece; Dept. of Electrical & Computer Engineering, Automation & Robotics Lab, Aristotle University of Thessaloniki, Greece; Dept. of Electrical & Computer Engineering, Automation & Robotics Lab, Aristotle University of Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160360/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14178931371855038347&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Dept. of Electrical & Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "10161482",
        "title": "Enforcing safety for vision-based controllers via Control Barrier Functions and Neural Radiance Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "To navigate complex environments, robots must increasingly use high-dimensional visual feedback (e.g. images) for control. However, relying on high-dimensional image data to make control decisions raises important questions; particularly, how might we prove the safety of a visual-feedback controller? Control barrier functions (CBFs) are powerful tools for certifying the safety of feedback controllers in the state-feedback setting, but CBFs have traditionally been poorly-suited to visual feedback control due to the need to predict future observations in order to evaluate the barrier function. In this work, we solve this issue by leveraging recent advances in neural radiance fields (NeRFs), which learn implicit representations of \\boldsymbol{3\\mathrm{D}}\\boldsymbol{3\\mathrm{D}} scenes and can render images from previously-unseen camera perspectives, to provide single-step visual foresight for a CBF-based controller, where the CBFs possess a discrete-time nature. This novel combination is able to filter out unsafe actions and intervene to preserve safety. We demonstrate the effect of our controller in real-time simulation experiments where it successfully prevents the robot from taking dangerous actions.",
        "primary_area": "",
        "author": "Mukun Tong;Charles Dawson;Chuchu Fan;Mukun Tong;Charles Dawson;Chuchu Fan",
        "authorids": "/37089895948;/37088688620;/38564621900;/37089895948;/37088688620;/38564621900",
        "aff": "Dept. of Automation, Tsinghua University, Beijing, China; Dept. of Aeronautics and Astronautics, MIT, Cambridge, USA; Dept. of Aeronautics and Astronautics, MIT, Cambridge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161482/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15029113255768191821&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Tsinghua University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Dept. of Automation;Dept. of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://web.mit.edu",
        "aff_unique_abbr": "THU;MIT",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Beijing;Cambridge",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160387",
        "title": "Enforcing the consensus between Trajectory Optimization and Policy Learning for precise robot control",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) and trajectory opti-mization (TO) present strong complementary advantages. On one hand, RL approaches are able to learn global control policies directly from data, but generally require large sample sizes to properly converge towards feasible policies. On the other hand, TO methods are able to exploit gradient-based information extracted from simulators to quickly converge towards a locally optimal control trajectory which is only valid within the vicinity of the solution. Over the past decade, several approaches have aimed to adequately combine the two classes of methods in order to obtain the best of both worlds. Following on from this line of research, we propose several improvements on top of these approaches to learn global control policies quicker, notably by leveraging sensitivity information stemming from TO methods via Sobolev learning, and Augmented Lagrangian (AL) techniques to enforce the consensus between TO and policy learning. We evaluate the benefits of these improvements on various classical tasks in robotics through comparison with existing approaches in the literature.",
        "primary_area": "",
        "author": "Quentin Le Lidec;Wilson Jallet;Ivan Laptev;Cordelia Schmid;Justin Carpentier;Quentin Le Lidec;Wilson Jallet;Ivan Laptev;Cordelia Schmid;Justin Carpentier",
        "authorids": "/37089893754;/37089448726;/37270740700;/37282990700;/37085506841;/37089893754;/37089448726;/37270740700;/37282990700;/37085506841",
        "aff": "Inria - Departement d'Informatique de l'Ecole normale sup\u00e9rieure, PSL Research University; LAAS-CNRS, Toulouse; Inria - Departement d'Informatique de l'Ecole normale sup\u00e9rieure, PSL Research University; Inria - Departement d'Informatique de l'Ecole normale sup\u00e9rieure, PSL Research University; Inria - Departement d'Informatique de l'Ecole normale sup\u00e9rieure, PSL Research University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160387/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=993142319779061982&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Inria;LAAS-CNRS",
        "aff_unique_dep": "Departement d'Informatique de l'Ecole normale sup\u00e9rieure;",
        "aff_unique_url": "https://www.inria.fr;https://www.laas.fr/",
        "aff_unique_abbr": "Inria;LAAS-CNRS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Toulouse",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160833",
        "title": "Enhanced Balance for Legged Robots Using Reaction Wheels",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a reaction wheel system that enhances the balancing capabilities and stability of quadrupedal robots during challenging locomotion tasks. Inspired by both the standard centroidal dynamics model common in legged robotics and models of spacecraft commonly used in the aerospace community, we model the coupled quadruped-reaction-wheel system as a gyrostat, and simplify the dynamics to formulate the problem as a linear discrete-time trajectory optimization problem. Modifications are made to a standard centroidal model-predictive control (MPC) algorithm to solve for both stance foot ground reaction forces and reaction wheel torques simultaneously. The MPC problem is posed as a quadratic program and solved online at 1000 Hz. We demonstrate improved attitude stabilization both in simulation and on hardware compared to a quadruped without reaction wheels, and perform a challenging traversal of a narrow balance beam that would be impossible for a standard quadruped. A video of our experiments is available online1.",
        "primary_area": "",
        "author": "Chi-Yen Lee;Shuo Yang;Benjamin Bokser;Zachary Manchester;Chi-Yen Lee;Shuo Yang;Benjamin Bokser;Zachary Manchester",
        "authorids": "/37089893545;/37088996427;/37089892810;/37086011525;/37089893545;/37088996427;/37089892810;/37086011525",
        "aff": "Robotics Institute, School of Computer Science,Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science,Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science,Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160833/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12700348182556844823&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161051",
        "title": "Enhancing the Efficacy of Lower-body Assistive Devices Through the Understanding of Human Movement in the Real World",
        "track": "main",
        "status": "Poster",
        "abstract": "In previous studies, researchers have successfully measured walking in healthy able-bodied humans to create safe control strategies for lower body assistive devices. measurements used to establish design requirements often come from testing and evaluation that takes place in laboratory settings during steady-state tasks, where participants often select movement strategies that minimize the cost of transport. However, human walking in these conditions does not neces-sarily represent the natural behavior of an individual in the real world. In this work, we conducted a study to characterize human walking in the real world. We combined week-scale free-living measurements of gait with in-lab data collection to: 1) quantify the proportion of steady-state walking in a population of healthy able-bodied adults, and 2) evaluate whether this population favors the selection of a range of walking speeds that minimize their cost of transport in the real world. We found that the majority of walking bouts contain mostly transient walking, suggesting that researchers should complement steady-state characterization with non-steady-state tasks. We also found that the most often used steady-state walking speeds for all participants were higher than the range that minimizes cost of transport, suggesting that individuals are influenced by more than energy economy when moving in the real world. Thus, when developing control strategies for these devices, researchers should consider a variety of optimization objectives to adapt for the multifarious situations of daily life.",
        "primary_area": "",
        "author": "Loubna Baroudi;Stephen M. Cain;K. Alex Shorter;Kira Barton;Loubna Baroudi;Stephen M. Cain;K. Alex Shorter;Kira Barton",
        "authorids": "/37089895220;/37085563577;/38272556200;/37393918000;/37089895220;/37085563577;/38272556200;/37393918000",
        "aff": "Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Chemical and Biomedical Engineering, West Virginia University, Morgantown, WV, USA; Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161051/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17879448481073070762&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Michigan;West Virginia University",
        "aff_unique_dep": "Mechanical Engineering;Chemical and Biomedical Engineering",
        "aff_unique_url": "https://www.umich.edu;https://www.wvu.edu",
        "aff_unique_abbr": "UM;WVU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Ann Arbor;Morgantown",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160749",
        "title": "Ensembles of Compact, Region-specific & Regularized Spiking Neural Networks for Scalable Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Spiking neural networks have significant potential utility in robotics due to their high energy efficiency on specialized hardware, but proof-of-concept implementations have not yet typically achieved competitive performance or capability with conventional approaches. In this paper, we tackle one of the key practical challenges of scalability by introducing a novel modular ensemble network approach, where compact, localized spiking networks each learn and are solely responsible for recognizing places in a local region of the environment only. This modular approach creates a highly scalable system. However, it comes with a high-performance cost where a lack of global regularization at deployment time leads to hyperactive neurons that erroneously respond to places outside their learned region. Our second contribution introduces a regularization approach that detects and removes these problematic hyperactive neurons during the initial environmental learning phase. We evaluate this new scalable modular system on benchmark localization datasets Nordland and Oxford RobotCar, with comparisons to standard techniques NetVLAD, DenseVLAD, and SAD, and a previous spiking neural network system. Our system substantially outperforms the previous SNN system on its small dataset, but also maintains performance on 27 times larger benchmark datasets where the operation of the previous system is computationally infeasible, and performs competitively with the conventional localization systems.",
        "primary_area": "",
        "author": "Somayeh Hussaini;Michael Milford;Tobias Fischer;Somayeh Hussaini;Michael Milford;Tobias Fischer",
        "authorids": "/37089307123;/37283633100;/37085784700;/37089307123;/37283633100;/37085784700",
        "aff": "QUT Centre for Robotics, School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, QLD, Australia; QUT Centre for Robotics, School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, QLD, Australia; QUT Centre for Robotics, School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, QLD, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160749/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15615170750546469663&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "School of Electrical Engineering and Robotics",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160813",
        "title": "Environment Optimization for Multi-Agent Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional approaches to the design of multiagent navigation algorithms consider the environment as a fixed constraint, despite the obvious influence of spatial constraints on agents' performance. Yet hand-designing improved environment layouts and structures is inefficient and potentially expensive. The goal of this paper is to consider the environment as a decision variable in a system-level optimization problem, where both agent performance and environment cost can be accounted for. We begin by proposing a novel environment optimization problem. We show, through formal proofs, under which conditions the environment can change while guaranteeing completeness (i.e., all agents reach their navigation goals). Our solution leverages a model-free reinforcement learning approach. In order to accommodate a broad range of implementation scenarios, we include both online and offline optimization, and both discrete and continuous environment representations. Numerical results corroborate our theoretical findings and validate our approach.",
        "primary_area": "",
        "author": "Zhan Gao;Amanda Prorok;Zhan Gao;Amanda Prorok",
        "authorids": "/37088219159;/37542741000;/37088219159;/37542741000",
        "aff": "Department of Computer Science and Technology, University of Cambridge, England; Department of Computer Science and Technology, University of Cambridge, England",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160813/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17084470378136522016&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161553",
        "title": "Epistemic Prediction and Planning with Implicit Coordination for Multi-Robot Teams in Communication Restricted Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In communication restricted environments, a multi-robot system can be deployed to either: i) maintain constant communication but potentially sacrifice operational efficiency due to proximity constraints or ii) allow disconnections to increase environmental coverage efficiency, challenges on how, when, and where to reconnect (rendezvous problem). In this work we tackle the latter problem and notice that most state-of-the-art methods assume that robots will be able to execute a predetermined plan; however system failures and changes in environmental conditions can cause the robots to deviate from the plan with cascading effects across the multi-robot system. This paper proposes a coordinated epistemic prediction and planning framework to achieve consensus without communicating for exploration and coverage, task discovery and completion, and rendezvous applications. Dynamic epistemic logic is the principal component implemented to allow robots to propagate belief states and empathize with other agents. Propagation of belief states and subsequent coverage of the environment is achieved via a frontier-based method within an artificial physics-based framework. The proposed framework is validated with both simulations and experiments with unmanned ground vehicles in various cluttered environments.",
        "primary_area": "",
        "author": "Lauren Bramblett;Shijie Gao;Nicola Bezzo;Lauren Bramblett;Shijie Gao;Nicola Bezzo",
        "authorids": "/37089628310;/37086940518;/37546843800;/37089628310;/37086940518;/37546843800",
        "aff": "Departments of Engineering Systems and Environment and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Departments of Engineering Systems and Environment and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Departments of Engineering Systems and Environment and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161553/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18187488509781481272&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Departments of Engineering Systems and Environment, Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161459",
        "title": "Error-Domain Conservativity Control to Transparently Increase the Stability Range of Time-Discretized Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "Time-discretization introduces an explicit time dependency for control laws that were originally designed to depend exclusively on an error variable: At different times, the control actions at the same error value might differ. Integrating the control action over the error reveals that this time dependency translates into the energy. It can directly cause active behavior when energy values at given error values decrease over time, potentially destabilizing the system. In this work, we aim to prevent energy values at given error values from decreasing over time. To this end, energies are recorded when error values are encountered for the first time. Linear interpolation of the recorded energy values provides a lower limit for energy as a function of the error value. This limit is enforced using an adaptive damping. The main contributions of this work include increasing the stability range with minimal amplitude control modifications, while promoting a symmetric behavior of control actions and energy. The approach's characteristics are shown in simulation and validated in experiments.",
        "primary_area": "",
        "author": "Michael Rothammer;Jee-Hwan Ryu;Michael Rothammer;Jee-Hwan Ryu",
        "authorids": "/37089448883;/37274994300;/37089448883;/37274994300",
        "aff": "Interactive Robotic Systems laboratory, Korean Advanced Institute of Science and Technology; Interactive Robotic Systems laboratory, Korean Advanced Institute of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161459/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12129996780572780483&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korean Advanced Institute of Science and Technology",
        "aff_unique_dep": "Interactive Robotic Systems laboratory",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160731",
        "title": "Estimating Tactile Models of Heterogeneous Deformable Objects in Real Time",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a method for learning the force response of heterogeneous, deformable objects directly from robot sensor data without prior knowledge. The method estimates an object's force response given robot force or torque measurements using a novel volumetric stiffness field representation and point-based contact simulator. The stiffness of each point colliding with the robot is estimated independently and is updated upon each observed measurement using a projected diagonal Kalman filter. Experiments show that this method can update a stiffness field over 105 points at 23 Hz or higher, and is more accurate than learning-based methods in predicting torque response while touching artificial plants. The method can also be augmented with visual information to help extrapolate stiffness fields to distant parts of the touched object using only a small number of touches.",
        "primary_area": "",
        "author": "Shaoxiong Yao;Kris Hauser;Shaoxiong Yao;Kris Hauser",
        "authorids": "/37089895167;/37543748800;/37089895167;/37543748800",
        "aff": "Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160731/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18110973484831589773&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161399",
        "title": "Estimating the Motion of Drawers From Sound",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots need to understand articulated objects, such as drawers. The state of articulated structures is commonly estimated using vision, but visual perception is limited when objects are occluded, have few salient features, or are not in the camera's field of view. Audio sensing does not face these challenges, since sound propagates in a fundamentally different way than light. Therefore we propose to fuse vision and audio sensing to overcome the challenges faced by vision alone. We estimate motion in several drawers and show that an audio-visual approach estimates drawer motion more reliably than only vision \u2013 even in settings where the purely visual approach completely breaks down. Additionally, we perform an in-depth analysis of the regularities that govern how motion in drawers shapes their sound.",
        "primary_area": "",
        "author": "Manuel Baum;Amelie Froessl;Aravind Battaje;Oliver Brock;Manuel Baum;Amelie Froessl;Aravind Battaje;Oliver Brock",
        "authorids": "/37085674996;/37089894246;/37089354195;/37279727100;/37085674996;/37089894246;/37089354195;/37279727100",
        "aff": "Science of Intelligence (SCIoI), Cluster of Excellence, Berlin, Germany; Robotics and Biology Laboratory, Technische Universit\u00e4t Berlin, Germany; Science of Intelligence (SCIoI), Cluster of Excellence, Berlin, Germany; Science of Intelligence (SCIoI), Cluster of Excellence, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161399/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13011200873470013070&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Science of Intelligence;Technische Universit\u00e4t Berlin",
        "aff_unique_dep": "Cluster of Excellence;Robotics and Biology Laboratory",
        "aff_unique_url": ";https://www.tu-berlin.de",
        "aff_unique_abbr": "SCIoI;TU Berlin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161354",
        "title": "Estimation of continuous environments by robot swarms: Correlated networks and decision-making",
        "track": "main",
        "status": "Poster",
        "abstract": "Collective decision-making is an essential capability of large-scale multi-robot systems to establish autonomy on the swarm level. A large portion of literature on collective decision-making in swarm robotics focuses on discrete decisions selecting from a limited number of options. Here we assign a decentralized robot system with the task of exploring an unbounded environment, finding consensus on the mean of a measurable environmental feature, and aggregating at areas where that value is measured (e.g., a contour line). A unique quality of this task is a causal loop between the robots' dynamic network topology and their decision-making. For example, the network's mean node degree influences time to convergence while the currently agreed-on mean value influences the swarm's aggregation location, hence, also the network structure as well as the precision error. We propose a control algorithm and study it in real-world robot swarm experiments in different environments. We show that our approach is effective and achieves higher precision than a control experiment. We anticipate applications, for example, in containing pollution with surface vehicles.",
        "primary_area": "",
        "author": "Mohsen Raoufi;Pawel Romanczuk;Heiko Hamann;Mohsen Raoufi;Pawel Romanczuk;Heiko Hamann",
        "authorids": "/37086167411;/37089180601;/37683321200;/37086167411;/37089180601;/37683321200",
        "aff": "Department of Electrical Engineering and Computer Science, Technical University of Berlin, Berlin, Germany; Bernstein Center for Computational Neuro-science, Berlin, Germany; Department of Computer and Information Science, University of Konstanz, Konstanz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161354/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8080258854977820138&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Technical University of Berlin;Bernstein Center for Computational Neuroscience;University of Konstanz",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Computational Neuroscience;Department of Computer and Information Science",
        "aff_unique_url": "https://www.tu-berlin.de;https://www.bernstein-center-berlin.de;https://www.uni-konstanz.de",
        "aff_unique_abbr": "TU Berlin;BCCN;",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Berlin;Konstanz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160903",
        "title": "Ethical Assessment of a Hospital Disinfection Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots have the potential to deliver very positive impacts for society, however, it's critical that in preparing for real-world deployments, we recognize and take steps to mitigate against the potential harms, both direct and indirect, that they may cause. In this paper, we explore how the ethics canvas (EC) and the ethical risk assessment (ERA) methodology defined in British Standard 8611 can be combined to better align robot technologies with ethics and their socio-cultural context of operation. We illustrate this through a practical case-study involving the real-world introduction of a disinfection robot to a radiology department in a European hospital. Using the EC, we identified 49 distinct ways that the technology was likely to impact key stakeholders and 11 ways that failure or misuse of the technology was likely to impact service provision. From this data, 8 mitigating measures were identified. Then, using the ERA tool, 9 risks were identified that were considered to represent a high likelihood of occurrence. From these insights, a further 8 mitigation measures were proposed. The combined use of both tools was found to be complementary, since the EC fostered a bottom-up, subjective critical thinking process whereas the ERA provided a broader, more top-down objective view. This example provides a practical template for robotics practitioners to better understand and manage the ethical and socio-cultural dimensions of their work, and contributes towards the standardization of ethical assessments in robotics with an emphasis on the move from principles to practice.",
        "primary_area": "",
        "author": "Conor McGinn;Robert Scott;Niamh Donnelly;Michael F. Cullinan;Alan Winfield;Pat Treusch;Conor McGinn;Robert Scott;Niamh Donnelly;Michael F. Cullinan;Alan Winfield;Pat Treusch",
        "authorids": "/37085714431;/37089893810;/37089894897;/37085707819;/37298178600;/37089894915;/37085714431;/37089893810;/37089894897;/37085707819;/37298178600;/37089894915",
        "aff": "Akara Robotics, Dublin, Ireland; Akara Robotics, Dublin, Ireland; Akara Robotics, Dublin, Ireland; Akara Robotics, Dublin, Ireland; Bristol Robotics Lab, Bristol, UK; School of Engineering, Trinity College Dublin, Ireland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160903/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9050602549576243567&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "Akara Robotics;Bristol Robotics Lab;Trinity College Dublin",
        "aff_unique_dep": ";;School of Engineering",
        "aff_unique_url": ";;https://www.tcd.ie",
        "aff_unique_abbr": ";;TCD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Bristol",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Ireland;United Kingdom"
    },
    {
        "id": "10161011",
        "title": "Evaluating Immersive Teleoperation Interfaces: Coordinating Robot Radiation Monitoring Tasks in Nuclear Facilities",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a virtual reality (VR) teleoperation interface for a ground-based robot, featuring dense 3D environment reconstruction and a low latency video stream, with which operators can immersively explore remote environments. At the UK Atomic Energy Authority's (UKAEA) Remote Applications in Challenging Environments (RACE) facility, we applied the interface in a user study where trained robotics operators completed simulated nuclear monitoring and decommissioning style tasks to compare VR and traditional teleoperation interface designs. We found that operators in the VR condition took longer to complete the experiment, had reduced collisions, and rated the generated 3D map with higher importance when compared to non-VR operators. Additional physiological data suggested that VR operators had a lower objective cognitive workload during the experiment but also experienced increased physical demand. Overall the presented results show that VR interfaces may benefit work patterns in teleoperation tasks within the nuclear industry, but further work is needed to investigate how such interfaces can be integrated into real world decommissioning workflows.",
        "primary_area": "",
        "author": "Harvey Stedman;Basaran Bahadir Kocer;Nejra van Zalk;Mirko Kovac;Vijay M. Pawar;Harvey Stedman;Basaran Bahadir Kocer;Nejra van Zalk;Mirko Kovac;Vijay M. Pawar",
        "authorids": "/37089642730;/37072753900;/37088576023;/37085542534;/38191148100;/37089642730;/37072753900;/37088576023;/37085542534;/38191148100",
        "aff": "Department of Computer Science, Autonomous Manufacturing Laboratory, University College London, London, UK; Department of Aerospace Engineering, University of Bristol, Bristol, UK; Dyson School of Design Engineering, Imperial College London, London, UK; Laboratory of Sustainability Robotics at the Swiss Federal Laboratories for Materials Science and Technology, Switzerland; Department of Computer Science, Autonomous Manufacturing Laboratory, University College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161011/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6451361601878031830&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University College London;University of Bristol;Imperial College London;Swiss Federal Laboratories for Materials Science and Technology",
        "aff_unique_dep": "Department of Computer Science;Department of Aerospace Engineering;Dyson School of Design Engineering;Laboratory of Sustainability Robotics",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.bristol.ac.uk;https://www.imperial.ac.uk;https://www.empa.ch",
        "aff_unique_abbr": "UCL;UoB;Imperial College;EMPA",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "London;Bristol;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United Kingdom;Switzerland"
    },
    {
        "id": "10160840",
        "title": "Evaluating the Feasibility of Magnetic Tools for the Minimum Dynamic Requirements of Microneurosurgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Neurosurgery could benefit from robot-assisted minimally invasive approaches, but existing robot tools are insufficiently small and compact. Magnetic actuation is an attractive approach to medical robotics because it allows small, modular serial mechanisms to be remotely actuated. Despite these advantages, magnetic actuation is relatively weak compared to alternative actuation methods. In this paper, we introduce a novel analytical model for magnetic serial robots, use this model to design two prototypes, and then demonstrate that a 4-mm-diameter prototype without any internal mechanical transmission can produce forces up to 0.181 N: high enough to perform delicate microsurgical tasks. We also demonstrate that the robot can achieve a closed-loop step response rise time of 0.71 seconds with an overshoot of 7.8%: sufficiently fast for surgical motions while maintaining a tip precision of less than 2 mm during a worst-case dynamic motion. These experiments provide strong evidence for the feasibility of directly-driven magnetic tools for neurosurgical applications, and they motivate future investigations in this area.",
        "primary_area": "",
        "author": "Cameron Forbrigger;Erik Fredin;Eric Diller;Cameron Forbrigger;Erik Fredin;Eric Diller",
        "authorids": "/37086690194;/37089891844;/37542880000;/37086690194;/37089891844;/37542880000",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160840/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11854290935785778764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "10161440",
        "title": "Evaluation of Legged Robot Landing Capability Under Aggressive Linear and Angular Velocities",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a method to evaluate the capability of aggressive legged robot landing under significant touchdown linear and angular velocities upon impact. Our approach builds upon the Planar Inverted Pendulum with Flywheel (PIPF) model and introduces a landing framework for the first stance step on a non-dimensional basis. We develop a nonlinear framework with iterative constrained trajectory optimization to stabilize the first stance step prior to N-step Capturability analysis. Performance maps across many different initial conditions reveal approximately linear boundaries as well as the effect of inertia, body incidence angle and leg attacking angle on the boundary shape. Our method also yields the engineering insight that body inertia affects the performance map the most, hence its optimization can be prioritized when the target is to improve robot landing efficacy.",
        "primary_area": "",
        "author": "Keran Ye;Konstantinos Karydis;Keran Ye;Konstantinos Karydis",
        "authorids": "/37088987345;/38252121900;/37088987345;/38252121900",
        "aff": "Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161440/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4571898366497004772&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160532",
        "title": "Event-Triggered Optimal Formation Tracking Control Using Reinforcement Learning for Large-Scale UAV Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Large-scale UAV switching formation tracking control has been widely applied in many fields such as search and rescue, cooperative transportation, and UAV light shows. In order to optimize the control performance and reduce the computational burden of the system, this study proposes an event-triggered optimal formation tracking controller for discrete-time large-scale UAV systems (UASs). And an optimal decision - optimal control framework is completed by introducing the Hungarian algorithm and actor-critic neural networks (NNs) implementation. Finally, a large-scale mixed reality experimental platform is built to verify the effectiveness of the proposed algorithm, which includes large-scale virtual UAV nodes and limited physical UAV nodes. This compensates for the limitations of the experimental field and equipment in real-world scenario, ensures the experimental safety, significantly reduces the experimental cost, and is suitable for realizing large-scale UAV formation light shows.",
        "primary_area": "",
        "author": "Ziwei Yan;Liang Han;Xiaoduo Li;Jinjie Li;Zhang Ren;Ziwei Yan;Liang Han;Xiaoduo Li;Jinjie Li;Zhang Ren",
        "authorids": "/37088522599;/37085691940;/37086058982;/37089448036;/37418980100;/37088522599;/37085691940;/37086058982;/37089448036;/37418980100",
        "aff": "Sino-French Engineer School, Beihang University, Beijing, China; Sino-French Engineer School, Beihang University, Beijing, China; Sino-French Engineer School, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160532/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16993877607433714087&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "Sino-French Engineer School",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161392",
        "title": "Event-based Agile Object Catching with a Quadrupedal Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrupedal robots are conquering various applications in indoor and outdoor environments due to their capability to navigate challenging uneven terrains. Exteroceptive information greatly enhances this capability since perceiving their surroundings allows them to adapt their controller and thus achieve higher levels of robustness. However, sensors such as LiDARs and RGB cameras do not provide sufficient information to quickly and precisely react in a highly dynamic environment since they suffer from a bandwidth-latency trade-off. They require significant bandwidth at high frame rates while featuring significant perceptual latency at lower frame rates, thereby limiting their versatility on resource constrained platforms. In this work, we tackle this problem by equipping our quadruped with an event camera, which does not suffer from this tradeoff due to its asynchronous and sparse operation. In leveraging the low latency of the events, we push the limits of quadruped agility and demonstrate high-speed ball catching for the first time. We show that our quadruped equipped with an event-camera can catch objects with speeds up to 15 m/s from 4 meters, with a success rate of 83%. Using a VGA event camera, our method runs at 100 Hz on an NVIDIA Jetson Orin.",
        "primary_area": "",
        "author": "Benedek Forrai;Takahiro Miki;Daniel Gehrig;Marco Hutter;Davide Scaramuzza;Benedek Forrai;Takahiro Miki;Daniel Gehrig;Marco Hutter;Davide Scaramuzza",
        "authorids": "/37089893470;/37086454028;/37088211963;/37545251000;/37397688400;/37089893470;/37086454028;/37088211963;/37545251000;/37397688400",
        "aff": "Department of Mechanical Engineering, Robotic Systems Lab, ETH Zurich, Switzerland; Department of Mechanical Engineering, Robotic Systems Lab, ETH Zurich, Switzerland; Robotics and Perception Group, University of Zurich, Switzerland; Department of Mechanical Engineering, Robotic Systems Lab, ETH Zurich, Switzerland; Robotics and Perception Group, University of Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161392/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3177728565975745731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "ETH Zurich;University of Zurich",
        "aff_unique_dep": "Department of Mechanical Engineering;Robotics and Perception Group",
        "aff_unique_url": "https://www.ethz.ch;https://www.unizh.ch",
        "aff_unique_abbr": "ETHZ;UZH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10160472",
        "title": "Event-based Real-time Moving Object Detection Based On IMU Ego-motion Compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and timely onboard perception is a prerequisite for mobile robots to operate in highly dynamic scenarios. The bio-inspired event camera can capture more motion details than a traditional camera by triggering each pixel asynchronously and therefore is more suitable in such scenarios. Among various perception tasks based on the event camera, ego-motion removal is one fundamental procedure to reduce perception ambiguities. Recent ego-motion removal methods are mainly based on optimization processes and may be computationally expensive for robot applications. In this paper, we consider the challenging perception task of detecting fast-moving objects from an aggressively operated platform equipped with an event camera, achieving computational cost reduction by directly employing IMU motion measurement. First, we design a nonlinear warping function to capture rotation information from an IMU and to compensate for the camera motion during an asynchronous events stream. The proposed nonlinear warping function improves the compensation accuracy by 10%-15%. Afterward, we segmented the moving parts on the warped image through dynamic threshold segmentation and optical flow calculation, and clustering. Finally, we validate the proposed detection pipeline on public datasets and real-world data streams containing challenging light conditions and fast-moving objects.",
        "primary_area": "",
        "author": "Chunhui Zhao;Yakun Li;Yang Lyu;Chunhui Zhao;Yakun Li;Yang Lyu",
        "authorids": "/38466543000;/37089892652;/37085535967;/38466543000;/37089892652;/37085535967",
        "aff": "School of Automation, Northwestern Polytechnical University, Xi'an, Shaanxi, PR China; School of Automation, Northwestern Polytechnical University, Xi'an, Shaanxi, PR China; School of Automation, Northwestern Polytechnical University, Xi'an, Shaanxi, PR China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160472/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14637157584750935922&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Northwestern Polytechnical University",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "http://www.nwpu.edu.cn",
        "aff_unique_abbr": "NPU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160839",
        "title": "Ex(plainable) Machina: how social-implicit XAI affects complex human-robot teaming tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigated how shared experience-based counterfactual explanations affected people's performance and robots' persuasiveness during a decision-making task in a social HRI context. We used the Connect 4 game as a complex decision-making task where participants and the robot had to play as a team against the computer. We compared two strategies of explanation generation (classical vs shared experience-based) and investigated their differences in terms of team performance, the robot's persuasive power, and participants' perception of the robot and self. Our results showed that the two explanation strategies led to comparable performances. Moreover, shared experience-based explanations - based on the team's previous games - gave higher persuasiveness to the robot's suggestions than classical ones. Finally, we noted that low-performers tend to follow the robot more than high-performers, providing insights into the potential danger for non-expert users interacting with expert explainable robots.",
        "primary_area": "",
        "author": "Marco Matarese;Francesca Cocchella;Francesco Rea;Alessandra Sciutti;Marco Matarese;Francesca Cocchella;Francesco Rea;Alessandra Sciutti",
        "authorids": "/37087238083;/37089891889;/37948228400;/38190743700;/37087238083;/37089891889;/37948228400;/38190743700",
        "aff": "RBCS unit, Italian Institute of Technology, Genoa, Italy; CONTACT unit, Italian Institute of Technology, Genoa, Italy; RBCS unit, Italian Institute of Technology, Genoa, Italy; CONTACT unit, Italian Institute of Technology, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160839/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2565243822102768944&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Italian Institute of Technology",
        "aff_unique_dep": "RBCS unit",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10160761",
        "title": "ExAug: Robot-Conditioned Navigation Policies via Geometric Experience Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine learning techniques rely on large and diverse datasets for generalization. Computer vision, natural language processing, and other applications can often reuse public datasets to train many different models. However, due to differences in physical configurations, it is challenging to leverage public datasets for training robotic control policies on new robot platforms or for new tasks. In this work, we propose a novel framework, ExAug to augment the experiences of different robot platforms from multiple datasets in diverse environments. ExAug leverages a simple principle: by extracting 3D information in the form of a point cloud, we can create much more complex and structured augmentations, utilizing both generating synthetic images and geometric-aware penalization that would have been suitable in the same situation for a different robot, with different size, turning radius, and camera placement. The trained policy is evaluated on two new robot platforms with three different cameras in indoor and outdoor environments with obstacles.",
        "primary_area": "",
        "author": "Noriaki Hirose;Dhruv Shah;Ajay Sridhar;Sergey Levine;Noriaki Hirose;Dhruv Shah;Ajay Sridhar;Sergey Levine",
        "authorids": "/37574851500;/37089000677;/37089893401;/37085481973;/37574851500;/37089000677;/37089893401;/37085481973",
        "aff": "Toyota Motor North America; UC Berkeley; UC Berkeley; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160761/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15288561053524203512&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Toyota Motor Corporation;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.toyota.com;https://www.berkeley.edu",
        "aff_unique_abbr": "Toyota;UC Berkeley",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160776",
        "title": "Expanding Versatility of Agile Locomotion through Policy Transitions Using Latent State Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes the transition-net, a robust transition strategy that expands the versatility of robot locomotion in the real-world setting. To this end, we start by distributing the complexity of different gaits into dedicated locomotion policies applicable to real-world robots. Next, we expand the versatility of the robot by unifying the policies with robust transitions into a single coherent meta-controller by examining the latent state representations. Our approach enables the robot to iteratively expand its skill repertoire and robustly transition between any policy pair in a library. In our framework, adding new skills does not introduce any process that alters the previously learned skills. Moreover, training of a locomotion policy takes less than an hour with a single consumer GPU. Our approach is effective in the real-world and achieves a 19% higher average success rate for the most challenging transition pairs in our experiments compared to existing approaches.",
        "primary_area": "",
        "author": "Guilherme Christmann;Ying-Sheng Luo;Jonathan Hans Soeseno;Wei-Chao Chen;Guilherme Christmann;Ying-Sheng Luo;Jonathan Hans Soeseno;Wei-Chao Chen",
        "authorids": "/37089370773;/37089893377;/37086807217;/37086316944;/37089370773;/37089893377;/37086807217;/37086316944",
        "aff": "Inventec Corporation, Taipei, Taiwan; Inventec Corporation, Taipei, Taiwan; Inventec Corporation, Taipei, Taiwan; Inventec Corporation, Taipei, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160776/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=618713566042701200&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Inventec Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inventec.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161155",
        "title": "Expanding the Deployment Envelope of Behavior Prediction via Adaptive Meta-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based behavior prediction methods are increasingly being deployed in real-world autonomous systems, e.g., in fleets of self-driving vehicles, which are beginning to commercially operate in major cities across the world. Despite their advancements, however, the vast majority of prediction systems are specialized to a set of well-explored geographic regions or operational design domains, complicating deployment to additional cities, countries, or continents. Towards this end, we present a novel method for efficiently adapting behavior prediction models to new environments. Our approach leverages recent advances in meta-learning, specifically Bayesian regression, to augment existing behavior prediction models with an adaptive layer that enables efficient domain transfer via offline fine-tuning, online adaptation, or both. Experiments across multiple real-world datasets demonstrate that our method can efficiently adapt to a variety of unseen environments.",
        "primary_area": "",
        "author": "Boris Ivanovic;James Harrison;Marco Pavone;Boris Ivanovic;James Harrison;Marco Pavone",
        "authorids": "/37086527859;/37085474390;/37307912900;/37086527859;/37085474390;/37307912900",
        "aff": "NVIDIA Research; Google Research, Brain Team; Department of Aeronautics and Astronautics, Stanford University, and with NVIDIA Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161155/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10833215862094181786&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "NVIDIA Corporation;Google;Stanford University",
        "aff_unique_dep": "NVIDIA Research;Google Research;Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.nvidia.com/research;https://research.google;https://www.stanford.edu",
        "aff_unique_abbr": "NVIDIA;Google;Stanford",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Mountain View;Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161397",
        "title": "Experimental Validation of Functional Iterative Learning Control on a One-Link Flexible Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "Performing precise, repetitive motions is essential in many robotic and automation systems. Iterative learning control (ILC) allows determining the necessary control command by using a very rough system model to speed up the process. Functional iterative learning control is a novel technique that promises to solve several limitations of classic ILC. It operates by merging the input space into a large functional space, resulting in an over-determined control task in the iteration domain. In this way, it can deal with systems having more outputs than inputs and accelerate the learning process without resorting to model discretizations. However, the framework lacks so far a validation in experiments. This paper aims to provide such experimental validation in the context of robotics. To this end, we designed and built a one-link flexible arm that is actuated by a stepper motor, which makes the development of an accurate model more challenging and the validation closer to the industrial practice. We provide multiple experimental results across several conditions, proving the feasibility of the method in practice.",
        "primary_area": "",
        "author": "Sjoerd Drost;Pietro Pustina;Franco Angelini;Alessandro De Luca;Gerwin Smit;Cosimo Della Santina;Sjoerd Drost;Pietro Pustina;Franco Angelini;Alessandro De Luca;Gerwin Smit;Cosimo Della Santina",
        "authorids": "/37089892475;/37089318359;/37086154079;/37269180600;/38469684300;/37086156284;/37089892475;/37089318359;/37086154079;/37269180600;/38469684300;/37086156284",
        "aff": "Department of Cognitive Robotics, Delft University of Technology, Delft, Netherlands; Department of Computer, Control and Management Engineering, Sapienza University of Rome, Rome, Italy; Department of Information Engineering, Research Center \u201cEnrico Piaggio\u201d, University of Pisa, Pisa, Italy; Department of Computer, Control and Management Engineering, Sapienza University of Rome, Rome, Italy; Department of Cognitive Robotics, Delft University of Technology, Delft, Netherlands; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Oberpfaffenhofen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161397/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11643136048460641319&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;0;3",
        "aff_unique_norm": "Delft University of Technology;Sapienza University of Rome;University of Pisa;German Aerospace Center",
        "aff_unique_dep": "Department of Cognitive Robotics;Department of Computer, Control and Management Engineering;Department of Information Engineering;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.tudelft.nl;https://www.uniroma1.it;https://www.unipi.it;https://www.dlr.de",
        "aff_unique_abbr": "TUDelft;Sapienza;UNIPi;DLR",
        "aff_campus_unique_index": "0;1;2;1;0;3",
        "aff_campus_unique": "Delft;Rome;Pisa;Oberpfaffenhofen",
        "aff_country_unique_index": "0;1;1;1;0;2",
        "aff_country_unique": "Netherlands;Italy;Germany"
    },
    {
        "id": "10161457",
        "title": "Experimental Workflow Implementation for Automatic Detection of Filament Deviation in 3D Robotic Printing Process",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic 3D Concrete Printing (3DCP) is a process of additive manufacturing using building materials. The system that performs 3DCP is a complex system consisting of multiple parts that are independent of each other. However, conventional 3DCP workflows usually lack automatic monitoring of print quality which can be easily affected for various reasons. This paper proposes an integrated workflow of automatic detection of filament deviation in a 3DCP process. The deformation of the filament is adopted as the criterion for print quality evaluation. A Deep Learning-morphology-based filament width estimation method is developed, and a filament deviation detection algorithm with presence of parametric uncertainties is proposed. This workflow allows to detect width deviations in the printed filament by considering several parameters of the printing system. The integrated workflow is implemented and tested through on-site printing tests.",
        "primary_area": "",
        "author": "Xinrui Yang;Othman Lakhal;Abdelkader Belarouci;Kamal Youcef-Toumi;Rochdi Merzouki;Xinrui Yang;Othman Lakhal;Abdelkader Belarouci;Kamal Youcef-Toumi;Rochdi Merzouki",
        "authorids": "/37088924993;/37085396104;/37087137477;/38271700200;/37299569900;/37088924993;/37085396104;/37087137477;/38271700200;/37299569900",
        "aff": "CRIStAL, CNRS-UMR 9189, University of Lille, Vil-leneuve d'Ascq, France; CRIStAL, CNRS-UMR 9189, University of Lille, Vil-leneuve d'Ascq, France; CRIStAL, CNRS-UMR 9189, University of Lille, Vil-leneuve d'Ascq, France; Department of Mechanical Engineering, Massachusetts Institute of Technolog, Cambridge, MA, USA; CRIStAL, CNRS-UMR 9189, University of Lille, Vil-leneuve d'Ascq, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161457/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:q0zKIwzTCOUJ:scholar.google.com/&scioq=Experimental+Workflow+Implementation+for+Automatic+Detection+of+Filament+Deviation+in+3D+Robotic+Printing+Process&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Lille;Massachusetts Institute of Technology",
        "aff_unique_dep": "CRIStAL;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.univ-lille.fr;https://web.mit.edu",
        "aff_unique_abbr": ";MIT",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Vil-leneuve d'Ascq;Cambridge",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "10161092",
        "title": "Experimental evaluation of a method for improving experiment design in robot identification",
        "track": "main",
        "status": "Poster",
        "abstract": "The control system of industrial robots is often model-based, and the quality of the model of high importance. Therefore, a fast and easy-to-use process for finding the model parameters from a combination of prior knowledge and measurement data is required. It has been shown that the experiment design can be improved in terms of short experiment times and an accurate parameter estimate if the robot configurations for the identification experiments are selected carefully. Estimates of the information matrix can be generated based on simulations for a number of candidate configurations, and an optimization problem can be solved for finding the optimal configurations. This work shows that the proposed method for improved experiment design works with a real manipulator, i.e. it is demonstrated that the experiment time is reduced significantly and the accuracy of the parameter estimate can be maintained or reduced if experiments are conducted only in the optimal manipulator configurations. It is also shown that the model improvement is relevant for realizing accurate control. Finally, the experimental data reveals that, in order to further improve the model accuracy, a more advanced model structure is needed for taking into account the commonly present nonlinear transmission stiffness of the robotic joints.",
        "primary_area": "",
        "author": "Stefanie A. Zimmermann;Martin Enqvist;Svante Gunnarsson;Stig Moberg;Mikael Norrl\u00f6f;Stefanie A. Zimmermann;Martin Enqvist;Svante Gunnarsson;Stig Moberg;Mikael Norrl\u00f6f",
        "authorids": "/37088506401;/37698273100;/37289472400;/37399077300;/37326288000;/37088506401;/37698273100;/37289472400;/37399077300;/37326288000",
        "aff": "Faculty of Electrical Engineering, Link\u00f6ping University, Sweden; Faculty of Electrical Engineering, Link\u00f6ping University, Sweden; Faculty of Electrical Engineering, Link\u00f6ping University, Sweden; ABB Robotics, V\u00e4ster\u00e5s, Sweden; ABB Robotics, V\u00e4ster\u00e5s, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161092/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4119882797845188345&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Link\u00f6ping University;ABB Robotics",
        "aff_unique_dep": "Faculty of Electrical Engineering;",
        "aff_unique_url": "https://www.liu.se;https://new.abb.com/robotics",
        "aff_unique_abbr": "LiU;ABB",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";V\u00e4ster\u00e5s",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "10161050",
        "title": "Experiments in Underwater Feature Tracking with Performance Guarantees Using a Small AUV",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the results of experiments performed using a small autonomous underwater vehicle to determine the location of an isobath within a bounded area. The primary contribution of this work is to implement and integrate several recent developments real-time planning for environmental map-ping, and to demonstrate their utility in a challenging practical example. We model the bathymetry within the operational area using a Gaussian process and propose a reward function that represents the task of mapping a desired isobath. As is common in applications where plans must be continually updated based on real-time sensor measurements, we adopt a receding horizon framework where the vehicle continually computes near-optimal paths. The sequence of paths does not, in general, inherit the optimality properties of each individual path. Our real-time planning implementation incorporates recent results that lead to performance guarantees for receding-horizon planning.",
        "primary_area": "",
        "author": "Benjamin Biggs;Hans He;James McMahon;Daniel J. Stilwell;Benjamin Biggs;Hans He;James McMahon;Daniel J. Stilwell",
        "authorids": "/37087324207;/37089385711;/37085353635;/37283170000;/37087324207;/37089385711;/37085353635;/37283170000",
        "aff": "the Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; the Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Acoustics Division, US Naval Research Laboratory; the Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161050/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16468684489506422908&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Virginia Tech;US Naval Research Laboratory",
        "aff_unique_dep": "Bradley Department of Electrical and Computer Engineering;Acoustics Division",
        "aff_unique_url": "https://www.vt.edu;https://www.nrl.navy.mil",
        "aff_unique_abbr": "VT;NRL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Blacksburg;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160435",
        "title": "Expert-Agnostic Ultrasound Image Quality Assessment using Deep Variational Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultrasound imaging is a commonly used modality for several diagnostic and therapeutic procedures. However, the diagnosis by ultrasound relies heavily on the quality of images assessed manually by sonographers, which diminishes the objectivity of the diagnosis and makes it operator-dependent. The supervised learning-based methods for automated quality assessment require manually annotated datasets, which are highly labour-intensive to acquire. These ultrasound images are low in quality and suffer from noisy annotations caused by inter-observer perceptual variations, which hampers learning efficiency. We propose an UnSupervised UltraSound image Quality assessment Network, US2QNet, that eliminates the burden and uncertainty of manual annotations. US2QNet uses the variational autoencoder embedded with the three modules, pre-processing, clustering and post-processing, to jointly enhance, extract, cluster and visualize the quality feature representation of ultrasound images. The pre-processing module uses filtering of images to point the network's attention towards salient quality features, rather than getting distracted by noise. Post-processing is proposed for visualizing the clusters of feature representations in 2D space. We validated the proposed framework for quality assessment of the urinary bladder ultrasound images. The proposed framework achieved 78% accuracy and superior performance to state-of-the-art clustering methods. The project page with source codes is available at https://sites.google.com/view/US2QNet.",
        "primary_area": "",
        "author": "Deepak Raina;Dimitrios Ntentia;SH Chandrashekhara;Richard Voyles;Subir Kumar Saha;Deepak Raina;Dimitrios Ntentia;SH Chandrashekhara;Richard Voyles;Subir Kumar Saha",
        "authorids": "/37088975582;/37089893796;/37089849855;/37283531400;/37346497700;/37088975582;/37089893796;/37089849855;/37283531400;/37346497700",
        "aff": "Purdue University (PU), Indiana, USA; Berea College, Kentucky, USA; All India Institute of Medical Sciences (AIIMS), Delhi, India; Purdue University (PU), Indiana, USA; Indian Institute of Technology (IIT), Delhi, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160435/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14413290527765603725&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;3",
        "aff_unique_norm": "Purdue University;Berea College;All India Institute of Medical Sciences;Indian Institute of Technology Delhi",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.purdue.edu;https://www.berea.edu;https://www.aiims.edu;https://www.iitdelhi.ac.in",
        "aff_unique_abbr": "PU;Berea College;AIIMS;IIT Delhi",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Delhi",
        "aff_country_unique_index": "0;0;1;0;1",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "10160927",
        "title": "Explain What You See: Open-Ended Segmentation and Recognition of Occluded 3D Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Local-HDP (Local Hierarchical Dirichlet Process) is a hierarchical Bayesian method recently used for open-ended 3D object category recognition. It has been proven to be efficient in real-time robotic applications. However, the method is not robust to a high degree of occlusion. We address this limitation in two steps. First, we propose a novel semantic 3D object-parts segmentation method that has the flexibility of Local-HDP. This method is shown to be suitable for open-ended scenarios where the number of 3D objects or object parts are not fixed and can grow over time. We show that the proposed method has a higher percentage of mean intersection over union, using a smaller number of learning instances. Second, we integrate this technique with a recently introduced argumentation-based online incremental learning method, enabling the model to handle a high degree of occlusion. We show that the resulting model produces explicit explanations for the 3D object category recognition task.",
        "primary_area": "",
        "author": "H. Ayoobi;H. Kasaei;M. Cao;R. Verbrugge;B. Verheij;H. Ayoobi;H. Kasaei;M. Cao;R. Verbrugge;B. Verheij",
        "authorids": "/37087011642;/37088515518;/37293296100;/38275849700;/37087012351;/37087011642;/37088515518;/37293296100;/38275849700;/37087012351",
        "aff": "Bernoulli Institute, University of Groningen, The Netherlands; Bernoulli Institute, University of Groningen, The Netherlands; Bernoulli Institute, University of Groningen, The Netherlands; Bernoulli Institute, University of Groningen, The Netherlands; Bernoulli Institute, University of Groningen, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160927/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10417517072417735950&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Groningen",
        "aff_unique_dep": "Bernoulli Institute",
        "aff_unique_url": "https://www.rug.nl",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10160557",
        "title": "Explainable Action Advising for Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Action advising is a knowledge transfer technique for reinforcement learning based on the teacher-student paradigm. An expert teacher provides advice to a student during training in order to improve the student's sample efficiency and policy performance. Such advice is commonly given in the form of state-action pairs. However, it makes it difficult for the student to reason with and apply to novel states. We introduce Explainable Action Advising, in which the teacher provides action advice as well as associated explanations indicating why the action was chosen. This allows the student to self-reflect on what it has learned, enabling advice generalization and leading to improved sample efficiency and learning performance - even in environments where the teacher is sub-optimal. We empirically show that our framework is effective in both single-agent and multi-agent scenarios, yielding improved policy returns and convergence rates when compared to state-of-the-art methods.",
        "primary_area": "",
        "author": "Yue Guo;Joseph Campbell;Simon Stepputtis;Ruiyu Li;Dana Hughes;Fei Fang;Katia Sycara;Yue Guo;Joseph Campbell;Simon Stepputtis;Ruiyu Li;Dana Hughes;Fei Fang;Katia Sycara",
        "authorids": "/37088528811;/37085810305;/37086175304;/37089892533;/37087472874;/37087228045;/37268476900;/37088528811;/37085810305;/37086175304;/37089892533;/37087472874;/37087228045;/37268476900",
        "aff": "Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160557/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6574368764027125751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161132",
        "title": "Explainable Action Prediction through Self-Supervision on Scene Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "This work explores scene graphs as a distilled representation of high-level information for autonomous driving, applied to future driver-action prediction. Given the scarcity and strong imbalance of data samples, we propose a self-supervision pipeline to infer representative and well-separated embeddings. Key aspects are interpretability and explainability; as such, we embed in our architecture attention mechanisms that can create spatial and temporal heatmaps on the scene graphs. We evaluate our system on the ROAD dataset against a fully-supervised approach, showing the superiority of our training regime.",
        "primary_area": "",
        "author": "Pawit Kochakarn;Daniele De Martini;Daniel Omeiza;Lars Kunze;Pawit Kochakarn;Daniele De Martini;Daniel Omeiza;Lars Kunze",
        "authorids": "/37089892708;/37086404606;/37088976106;/37947285100;/37089892708;/37086404606;/37088976106;/37947285100",
        "aff": "Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161132/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13285056907232911106&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160964",
        "title": "Exploiting Intrinsic Kinematic Null Space for Supernumerary Robotic Limbs Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Supernumerary robotic limbs (SRLs) gained increasing interest in the last years for their applicability as healthcare and assistive technologies. These devices can either support or augment human sensorimotor capabilities, allowing users to complete tasks that are more complex than those feasible for their natural limbs. However, for a successful coordination between natural and artificial limbs, intuitiveness of interaction and perception of autonomy are key enabling features, especially for people suffering from motor disorders and impairments. The development of suitable human-robot interfaces is thus fundamental to foster the adoption of SRLs. With this work, we describe how to control an extra degree of freedom by taking advantage of what we defined the Intrinsic Kinematic Null Space, i.e. the redundancy of the human kinematic chain involved in the ongoing task. Obtained results demonstrated that the proposed control strategy is effective for performing complex tasks with a supernumerary robotic finger, and that practice improves users' control ability.",
        "primary_area": "",
        "author": "T. Lisini Baldi;N. D'Aurizio;S. Gurgone;D. Borzelli;A. D'Avella;D. Prattichizzo;T. Lisini Baldi;N. D'Aurizio;S. Gurgone;D. Borzelli;A. D'Avella;D. Prattichizzo",
        "authorids": "/37085368775;/37088396379;/37089499377;/38469757400;/38152548400;/37276309600;/37085368775;/37088396379;/37089499377;/38469757400;/38152548400;/37276309600",
        "aff": "Department of Humanoids and Human Centered Mechatronics (HHCM), Istituto Italiano di Tecnologia, Genova, Italy; Department of Information Engineering and Mathematics, University of Siena, Siena, Italy; Center for Information and Neural Networks, Advanced ICT Research Institute, National Institute of Information and Communications Technology, Osaka, Japan; IRCCS Fondazione Santa Lucia, Laboratory of Neuromotor Physiology, Rome, Italy; IRCCS Fondazione Santa Lucia, Laboratory of Neuromotor Physiology, Rome, Italy; Department of Humanoids and Human Centered Mechatronics (HHCM), Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160964/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1436994288358012580&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;3;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;University of Siena;National Institute of Information and Communications Technology;IRCCS Fondazione Santa Lucia",
        "aff_unique_dep": "Department of Humanoids and Human Centered Mechatronics (HHCM);Department of Information Engineering and Mathematics;Center for Information and Neural Networks;Laboratory of Neuromotor Physiology",
        "aff_unique_url": "https://www.iit.it;https://www.unisi.it;https://www.nict.go.jp/;",
        "aff_unique_abbr": "IIT;;NICT;",
        "aff_campus_unique_index": "0;1;2;3;3;0",
        "aff_campus_unique": "Genova;Siena;Osaka;Rome",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "Italy;Japan"
    },
    {
        "id": "10160385",
        "title": "Exploiting Trust for Resilient Hypothesis Testing with Malicious Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a resilient binary hypothesis testing frame-work for decision making in adversarial multi-robot crowdsensing tasks. This framework exploits stochastic trust observations between robots to arrive at tractable, resilient decision making at a centralized Fusion Center (FC) even when i) there exist malicious robots in the network and their number may be larger than the number of legitimate robots, and ii) the FC uses one-shot noisy measurements from all robots. We derive two algorithms to achieve this. The first is the Two Stage Approach (2SA) that estimates the legitimacy of robots based on received trust observations, and provably minimizes the probability of detection error in the worst-case malicious attack. Here, the proportion of malicious robots is known but arbitrary. For the case of an unknown proportion of malicious robots, we develop the Adversarial Generalized Likelihood Ratio Test (A-GLRT) that uses both the reported robot measurements and trust observations to estimate the trustworthiness of robots, their reporting strategy, and the correct hypothesis simultaneously. We exploit special problem structure to show that this approach remains computationally tractable despite several unknown problem parameters. We deploy both algorithms in a hardware experiment where a group of robots conducts crowdsensing of traffic conditions on a mock-up road network similar in spirit to Google Maps, subject to a Sybil attack. We extract the trust observations for each robot from actual communication signals which provide statistical information on the uniqueness of the sender. We show that even when the malicious robots are in the majority, the FC can reduce the probability of detection error to 30.5% and 29% for the 2SA and the A-GLRT respectively.",
        "primary_area": "",
        "author": "Matthew Cavorsi;Orhan Eren Akg\u00fcn;Michal Yemini;Andrea J. Goldsmith;Stephanie Gil;Matthew Cavorsi;Orhan Eren Akg\u00fcn;Michal Yemini;Andrea J. Goldsmith;Stephanie Gil",
        "authorids": "/37089228056;/37089893610;/38528997400;/37269021300;/37396689900;/37089228056;/37089893610;/38528997400;/37269021300;/37396689900",
        "aff": "School of Engineering and Applied Sciences, Harvard University, USA; School of Engineering and Applied Sciences, Harvard University, USA; Faculty of Engineering, Bar-Ilan University, Israel; Department of Electrical and Computer Engineering, Princeton University, USA; School of Engineering and Applied Sciences, Harvard University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160385/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2820789398693804478&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Harvard University;Bar-Ilan University;Princeton University",
        "aff_unique_dep": "School of Engineering and Applied Sciences;Faculty of Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.harvard.edu;https://www.biu.ac.il;https://www.princeton.edu",
        "aff_unique_abbr": "Harvard;BIU;Princeton",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "10161441",
        "title": "Exploring An External Approach to Subretinal Drug Delivery via Robot Assistance and B-Mode OCT",
        "track": "main",
        "status": "Poster",
        "abstract": "Injections into specific retinal layers of the eye present a serious challenge to surgeons in terms of accuracy and perception. The emergence of new gene therapies further emphasizes the need for effective tools for localized drug delivery. Unlike the dominant approach of delivering drugs via a transvitreal intraocular pathway, this paper demonstrates the feasibility of delivering injections into the space between the choroid and the retina using an external approach. The design of a cooperative robotic system for enabling robot-assisted extraocular subretinal injections is presented. The system uses a distal micromanipulator that can serve as a hand-held tool for OCT-aided injection or attach to a six degree of freedom (DOF) serial robot arm for cooperative manipulation. The kinematics and control of the robot for constrained cooperative control motions to enable safe needle injection is presented and experimentally evaluated. These results suggest that the proposed external drug delivery approach is feasible, thereby enabling the advantages of preserving the integrity of the retina and omitting the necessity for vitrectomy.",
        "primary_area": "",
        "author": "Elan Z. Ahronovich;Neel Shihora;Jin-Hui Shen;Karen Joos;Nabil Simaan;Elan Z. Ahronovich;Neel Shihora;Jin-Hui Shen;Karen Joos;Nabil Simaan",
        "authorids": "/37089866138;/37089194036;/37077265000;/38246367600;/37282380300;/37089866138;/37089194036;/37077265000;/38246367600;/37282380300",
        "aff": "Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Vanderbilt Eye Institute, Vanderbilt University Medical Center, Nashville, TN; Vanderbilt Eye Institute, Vanderbilt University Medical Center, Nashville, TN; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161441/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14013875957998757089&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Vanderbilt University;Vanderbilt University Medical Center",
        "aff_unique_dep": "Department of Mechanical Engineering;Vanderbilt Eye Institute",
        "aff_unique_url": "https://www.vanderbilt.edu;https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt;VUMC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160867",
        "title": "Exploring Multimodal Gait Rehabilitation and Assistance through an Adaptable Robotic Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "Lower-limb exoskeletons and smart walkers are robotic devices to assist patients in regaining their autonomy after a stroke. The integration of these devices enables gait rehabilitation and functional compensation, promoting natural over-ground walking. This article presents the Adaptable Robotic Platform for Gait Rehabilitation and Assistance (AGoRA V2 platform), which integrates the new AGoRA V2 Smart Walker and the AGoRA V2 unilateral lower-limb exoskeleton. It was evaluated with 14 healthy subjects using physiological and kinematic variables and a perception assessment. The study entailed four conditions: Without exoskeleton (WOE), With Exoskeleton (WE&T), With Walker (WW), and With Platform (WP). Results indicate a reduction in the muscle activity of the Rectus Femoris (18%) and Vastus Lateralis (15%), comparing WE&T and WP, as well as walking without any device (WOE) and using any robotic device (WE&T, WW, WP). Results suggest the importance of combining the exoskeleton with the robotic walker and the assistance of each device independently. Moreover, using the complete platform induces slower gait patterns than the walker, as the mean impulse force and linear velocity decrease by 42% and 44%, respectively. These results demonstrate that the platform contributes to safety, and improvements in gait parameters and muscular activity, indicating the system's potential to act as a modular device according to users' conditions and therapeutic goals.",
        "primary_area": "",
        "author": "Sophia Ot\u00e1lora;Sergio D. Sierra M.;Felipe Ball\u00e9n-Moreno;Marcela M\u00fanera;Carlos A. Cifuentes;Sophia Ot\u00e1lora;Sergio D. Sierra M.;Felipe Ball\u00e9n-Moreno;Marcela M\u00fanera;Carlos A. Cifuentes",
        "authorids": "/37089441457;/37089895551;/37088534063;/37086058142;/37605056400;/37089441457;/37089895551;/37088534063;/37086058142;/37605056400",
        "aff": "Graduate Program of Electrical Engineering, Federal University of Espirito Santo, Vitoria, Brazil; Bristol Robotics Laboratory, University of the West of England, Bristol, UK; Flanders Make, Brussels, Belgium; Biomedical Engineering Program, Colombian School of Engineering Julio Garavito, Bogot\u00e1 D.C., Colombia; The School of Engineering, Science and Technology, Universidad del Rosario, Bogot\u00e1 D.C., Colombia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160867/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8249069863510263093&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "Federal University of Espirito Santo;University of the West of England;Flanders Make;Colombian School of Engineering Julio Garavito;Universidad del Rosario",
        "aff_unique_dep": "Graduate Program of Electrical Engineering;Bristol Robotics Laboratory;;Biomedical Engineering Program;School of Engineering, Science and Technology",
        "aff_unique_url": "https://www.ufes.br;https://www.uwe.ac.uk;https://www.flandersmake.be;;https://www.urosario.edu.co",
        "aff_unique_abbr": "UFES;UWE;;;",
        "aff_campus_unique_index": "0;1;2;3;3",
        "aff_campus_unique": "Vitoria;Bristol;Brussels;Bogot\u00e1 D.C.",
        "aff_country_unique_index": "0;1;2;3;3",
        "aff_country_unique": "Brazil;United Kingdom;Belgium;Colombia"
    },
    {
        "id": "10160989",
        "title": "Exploring Navigation Maps for Learning-Based Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "The prediction of surrounding agents' motion is a key for safe autonomous driving. In this paper, we explore navigation maps as an alternative to the predominant High Definition (HD) maps for learning-based motion prediction. Navigation maps provide topological and geometrical information on road-level, HD maps additionally have centimeter-accurate lane-level information. As a result, HD maps are costly and time-consuming to obtain, while navigation maps with near-global coverage are freely available. We describe an approach to integrate navigation maps into learning-based motion prediction models. To exploit locally available HD maps during training, we additionally propose a model-agnostic method for knowledge distillation. In experiments on the publicly available Argoverse dataset with navigation maps obtained from OpenStreetMap, our approach shows a significant improvement over not using a map at all. Combined with our method for knowledge distillation, we achieve results that are close to the original HD map-reliant models. Our publicly available navigation map API for Argoverse enables researchers to develop and evaluate their own approaches using navigation maps4.",
        "primary_area": "",
        "author": "Julian Schmidt;Julian Jordan;Franz Gritschneder;Thomas Monninger;Klaus Dietmayer;Julian Schmidt;Julian Jordan;Franz Gritschneder;Thomas Monninger;Klaus Dietmayer",
        "authorids": "/37089003903;/37089448067;/37085728665;/37089708681;/37283417900;/37089003903;/37089448067;/37085728665;/37089708681;/37283417900",
        "aff": "Control and Microtechnology, Ulm University, Institute of Measurement, Ulm, Germany; Mercedes-Benz AG Research & Development, Stuttgart, Germany; Mercedes-Benz AG Research & Development, Stuttgart, Germany; Mercedes-Benz Research & Development North America, Sunnyvale, CA, USA; Control and Microtechnology, Ulm University, Institute of Measurement, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160989/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7875940579703762671&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "Ulm University;Mercedes-Benz AG;Mercedes-Benz Research & Development North America",
        "aff_unique_dep": "Institute of Measurement;Research & Development;",
        "aff_unique_url": "https://www.uni-ulm.de;https://www.mercedes-benz.com;https://www.mercedes-benz.com",
        "aff_unique_abbr": ";MB AG;MBRDNA",
        "aff_campus_unique_index": "0;1;1;2;0",
        "aff_campus_unique": "Ulm;Stuttgart;Sunnyvale",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "10160456",
        "title": "Exploring Robot-Assisted Optical Coherence Elastography for Surgical Palpation",
        "track": "main",
        "status": "Poster",
        "abstract": "Optical Coherence Elastography (OCE) is a method that discerns local tissue stiffness using optical information. This method has recently been explored for laryngeal cancer tumor margin detection but has not been widely deployed clinically. Part of the challenge hindering such clinical deployment is the need for controlled high-precision mechanical probing of the tissue. This paper explores the concept of robot-assisted optical coherence elastography(OCE) and presents a preliminary system integration used to demonstrate the approach for stiffness mapping and discerning tumor margins. The approach is demonstrated on a custom Cartesian stage robot, and a custom-built OCE system comprised of an 830 nm broad-band laser with a vector-analysis method for phase gradient estimation and strain imaging. The paper illustrates one of the advantages of robot-controlled probing in terms of increasing the accuracy of the OCE system in a large range of displacement and strain. By leveraging motion information from the robot, online re-calibration of the OCE strain map may be achieved, thereby reducing OCE errors. After calibration, it is shown that the error in estimating the local Young's modulus is 0.485% in the silicon phantom and 0.531% in the agar phantom. These results suggest that future integration of optical coherence tomography(OCT) in clinically deployable robots may offer advantages in enabling local stiffness map estimation using OCE.",
        "primary_area": "",
        "author": "Yeonhee Chang;Elan Z. Ahronovich;Nabil Simaan;Cheol Song;Yeonhee Chang;Elan Z. Ahronovich;Nabil Simaan;Cheol Song",
        "authorids": "/37089638536;/37089866138;/37282380300;/37676950900;/37089638536;/37089866138;/37282380300;/37676950900",
        "aff": "Department of Robotics and Mechatronics Engineering, DGIST, Daegu, South Korea; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Robotics and Mechatronics Engineering, DGIST, Daegu, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160456/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8287058459143921201&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology;Vanderbilt University",
        "aff_unique_dep": "Department of Robotics and Mechatronics Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.dgist.ac.kr;https://www.vanderbilt.edu",
        "aff_unique_abbr": "DGIST;Vanderbilt",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Daegu;Nashville",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "10160892",
        "title": "External Camera-Based Mobile Robot Pose Estimation for Collaborative Perception with Smart Edge Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an approach for estimating a mobile robot's pose w.r.t. the allocentric coordinates of a network of static cameras using multi-view RGB images. The images are processed online, locally on smart edge sensors by deep neural networks to detect the robot and estimate 2D keypoints defined at distinctive positions of the 3D robot model. Robot keypoint detections are synchronized and fused on a central backend, where the robot's pose is estimated via multi-view minimization of reprojection errors. Through the pose estimation from external cameras, the robot's localization can be initialized in an allocentric map from a completely unknown state (kidnapped robot problem) and robustly tracked over time. We conduct a series of experiments evaluating the accuracy and robustness of the camera-based pose estimation compared to the robot's internal navigation stack, showing that our camera-based method achieves pose errors below 3 cm and 1\u00b0 and does not drift over time, as the robot is localized allocentrically. With the robot's pose precisely estimated, its observations can be fused into the allocentric scene model. We show a real-world application, where observations from mobile robot and static smart edge sensors are fused to collaboratively build a 3D semantic map of a ~240 m2 indoor environment.",
        "primary_area": "",
        "author": "Simon Bultmann;Raphael Memmesheimer;Sven Behnke;Simon Bultmann;Raphael Memmesheimer;Sven Behnke",
        "authorids": "/37088219215;/37085706250;/37295987100;/37088219215;/37085706250;/37295987100",
        "aff": "Autonomous Intelligent Systems group, University of Bonn, Germany; Autonomous Intelligent Systems group, University of Bonn, Germany; Autonomous Intelligent Systems group, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160892/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6112299789433393760&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Autonomous Intelligent Systems group",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161525",
        "title": "External Force Estimation of Legged Robots via a Factor Graph Framework with a Disturbance Observer",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, legged robots have been used for various purposes, such as exploring unknown terrain or interacting with the world. For control and planning legged systems during interactive operations, it is essential to estimate and respond to external forces. However, in legged system, it becomes difficult to estimate forces due to highly dynamic situations. There are several studies that use a force sensor on the foot and end effector, but these approaches have disadvantages in terms of cost and sustainability. Therefore, in this paper, we propose an improved method for estimating external forces without a force sensor. First, each leg force was obtained using the system dynamics of the robot with a disturbance observer. Then, by preintegration, it was tightly coupled with other sensors to estimate the pose and external force simultaneously. Despite the impact and slip, we estimate external forces accurately in standing and walking motions. Moreover, we compared pose estimation performance with VINS-Mono [1], and there is no significant accuracy degradation in spite of highly dynamic force residual.",
        "primary_area": "",
        "author": "Jeonguk Kang;Hyun-Bin Kim;Keun Ha Choi;Kyung-Soo Kim;Jeonguk Kang;Hyun-Bin Kim;Keun Ha Choi;Kyung-Soo Kim",
        "authorids": "/37089894668;/37089893282;/37085677870;/37292681500;/37089894668;/37089893282;/37085677870;/37292681500",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Deajeon, South Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Deajeon, South Korea; Daedong-KAIST Research Center for Mobility, Daejeon, South Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Deajeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161525/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6504806489193016774&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;KAIST Research Center for Mobility",
        "aff_unique_dep": "Department of Mechanical Engineering;Research Center for Mobility",
        "aff_unique_url": "https://www.kaist.ac.kr;",
        "aff_unique_abbr": "KAIST;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Deajeon;Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161270",
        "title": "Extracting generalizable skills from a single plan execution using abstraction-critical state detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic task planning is computationally challenging. To reduce planning cost and support life-long operation, we must leverage prior planning experience. To this end, we address the problem of extracting reusable and generalizable abstract skills from successful plan executions. In previous work, we introduced a supporting framework, allowing us, theoretically, to extract an abstract skill from a single execution and later automatically adapt it and reuse it in new domains. We also proved that, given a library of such skills, we can significantly reduce the planning effort for new problems. Nevertheless, until now, abstract-skill extraction could only be performed manually. In this paper, we finally close the automation loop and explain how abstract skills can be practically and automatically extracted. We start by analyzing the desired qualities of an abstract skill and formulate skill extraction as an optimization problem. We then develop two extraction algorithms, based on the novel concept of abstraction-critical state detection. As we show experimentally, the approach is independent of any planning domain.",
        "primary_area": "",
        "author": "Khen Elimelech;Lydia E. Kavraki;Moshe Y. Vardi;Khen Elimelech;Lydia E. Kavraki;Moshe Y. Vardi",
        "authorids": "/37086177972;/37279015600;/37282738000;/37086177972;/37279015600;/37282738000",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161270/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10060290273614760986&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161521",
        "title": "Extraneousness-Aware Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual imitation learning provides an effective framework to learn skills from demonstrations. However, the quality of the provided demonstrations usually significantly affects the ability of an agent to acquire desired skills. Therefore, the standard visual imitation learning assumes near-optimal demonstrations, which are expensive or sometimes prohibitive to collect. Previous works propose to learn from noisy demonstrations; however, the noise is usually assumed to follow a context-independent distribution such as a uniform or gaussian distribution. In this paper, we consider another crucial yet underexplored setting - imitation learning with task-irrelevant yet locally consistent segments in the demonstrations (e.g., wiping sweat while cutting potatoes in a cooking tutorial). We argue that such noise is common in real world data and term them as \u201cextraneous\u201d segments. To tackle this problem, we introduce Extraneousness-Aware Imitation Learning (EIL), a self-supervised approach that learns visuomotor policies from third-person demonstrations with extraneous subsequences. EIL learns action-conditioned observation embeddings in a self-supervised manner and retrieves task-relevant observations across visual demonstrations while excluding the extraneous ones. Experimental results show that EIL outperforms strong baselines and achieves comparable policies to those trained with perfect demonstration on both simulated and real-world robot control tasks. The project page can be found here: https://sites.google.com/view/eil-website.",
        "primary_area": "",
        "author": "Ray Chen Zheng;Kaizhe Hu;Zhecheng Yuan;Boyuan Chen;Huazhe Xu;Ray Chen Zheng;Kaizhe Hu;Zhecheng Yuan;Boyuan Chen;Huazhe Xu",
        "authorids": "/37089893353;/37089894882;/37089896087;/37089893865;/37086242886;/37089893353;/37089894882;/37089896087;/37089893865;/37086242886",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University; Massachusetts Institute of Technology; Shanghai Qi Zhi Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161521/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13854586391329345385&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Tsinghua University;Massachusetts Institute of Technology;Shanghai Qi Zhi Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://web.mit.edu;https://www.qz.io",
        "aff_unique_abbr": "THU;MIT;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160262",
        "title": "Extremum Seeking-Based Adaptive Sliding Mode Control with Sliding Perturbation Observer for Robot Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposed an adaptive robust sliding mode control (SMC) with a nonlinear sliding perturbation observer (SPO) for robot manipulators. SPO estimates the perturbation (nonlinearities, uncertainties, and disturbances) with minimal system information and enhances the controller performance. The estimation is mainly dependent on the selection of SMCSPO gain, and if not tuned well, it might result in increased error dynamics of the system. Therefore, minimizing the error dynamics by improving the estimation is the primary goal of this research. In this regard, the current study accomplishes adaptation of controller gain in real-time by using an optimization technique called extremum seeking (ES). The quality adaptation is controlled with the help of a cost function. Based on the Lyapunov-based stability analysis of SMCSPO, the cost function consisting of the estimation error of the observer and error dynamics is proposed. The unique cost function now guarantees the tracking performance within the defined error tolerance. The effectiveness of the proposed algorithm is illustrated and validated in simulation and experiments. It is shown that the adaptation based on ES with the proposed cost function converges to the optimal control gain enabling the reduced estimation error and error dynamics with enhanced tracking performance.",
        "primary_area": "",
        "author": "Hamza Khan;Min Cheol Lee;Hamza Khan;Min Cheol Lee",
        "authorids": "/37087123833;/37292262200;/37087123833;/37292262200",
        "aff": "School of Mechanical Engineering, Pusan National University, Busan, South Korea; School of Mechanical Engineering, Pusan National University, Busan, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160262/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14523919580098851250&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Pusan National University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.pusan.ac.kr",
        "aff_unique_abbr": "PNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Busan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160505",
        "title": "Extrinsic calibration for highly accurate trajectories reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "In the context of robotics, accurate ground-truth positioning is the cornerstone for the development of mapping and localization algorithms. In outdoor environments and over long distances, total stations provide accurate and precise measurements, that are unaffected by the usual factors that deteriorate the accuracy of Global Navigation Satellite System (GNSS). While a single robotic total station can track the position of a target in three Degrees Of Freedom (DOF), three robotic total stations and three targets are necessary to yield the full six DOF pose reference. Since it is crucial to express the position of targets in a common coordinate frame, we present a novel extrinsic calibration method of multiple robotic total stations with field deployment in mind. The proposed method does not require the manual collection of ground control points during the system setup, nor does it require tedious synchronous measurement on each robotic total station. Based on extensive experimental work, we compare our approach to the classical extrinsic calibration methods used in geomatics for surveying and demonstrate that our approach brings substantial time savings during the deployment. Tested on more than 30 km of trajectories, our new method increases the precision of the extrinsic calibration by 25 % compared to the best state-of-the-art method, which is the one taking manually static ground control points.",
        "primary_area": "",
        "author": "Maxime Vaidis;William Dubois;Alexandre Gu\u00e9nette;Johann Laconte;Vladim\u00edr Kubelka;Fran\u00e7ois Pomerleau;Maxime Vaidis;William Dubois;Alexandre Gu\u00e9nette;Johann Laconte;Vladim\u00edr Kubelka;Fran\u00e7ois Pomerleau",
        "authorids": "/37088414805;/37089892347;/37089892854;/37086937678;/38251946200;/37594916100;/37088414805;/37089892347;/37089892854;/37086937678;/38251946200;/37594916100",
        "aff": "Northern Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Canada; Northern Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Canada; Northern Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Canada; Northern Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Canada; Mobile Robotics and Olfaction lab, AASS research center at \u00d6rebro University, Sweden; Northern Robotics Laboratory, Universit\u00e9 Laval, Qu\u00e9bec City, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160505/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17330554365530671583&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Universit\u00e9 Laval;\u00d6rebro University",
        "aff_unique_dep": "Northern Robotics Laboratory;Mobile Robotics and Olfaction lab, AASS research center",
        "aff_unique_url": "https://www.ulaval.ca;https://www.oru.se",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Qu\u00e9bec City;",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Canada;Sweden"
    },
    {
        "id": "10161421",
        "title": "FDLNet: Boosting Real-time Semantic Segmentation by Image-size Convolution via Frequency Domain Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel real-time semantic segmentation network via frequency domain learning, called FDLNet, which revisits the segmentation task from two critical perspectives: spatial structure description and multilevel feature fusion. We first devise an image-size convolution (IS-Conv) as a global frequency-domain learning operator to capture long-range dependency in a single shot. To model spatial structure information, we construct the global structure representation path (GSRP) based on IS-Conv, which learns a unified edge-region representation with affordable complexity. For efficient and lightweight multi-level feature fusion, we propose the factorized stereoscopic attention (FSA) module, which alleviates semantic confusion and reduces feature redundancy by introducing level-wise attention before channel and spatial attention. Combining the above modules, we propose a concise semantic segmentation framework named FDLNet. We experimentally demonstrate the effectiveness and superiority of the proposed method. FDLNet achieves state-of-the-art performance on the Cityscapes, which reports 76.32% mIoU at 150+ FPS and 79.0% mIoU at 41+ FPS. The code is available at https://github.com/qyan0131/FDLNet.",
        "primary_area": "",
        "author": "Qingqing Yan;Shu Li;Chengju Liu;Ming Liu;Qijun Chen;Qingqing Yan;Shu Li;Chengju Liu;Ming Liu;Qijun Chen",
        "authorids": "/37089298351;/37086349133;/37677379800;/37085398677;/37276133600;/37089298351;/37086349133;/37677379800;/37085398677;/37276133600",
        "aff": "Tongji University, Shanghai, China; Tongji University, Shanghai, China; Tongji Artificial Intelligence (Suzhou) Research Institute, Suzhou, China; Hong Kong University of Science and Technology, Hong Kong; Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161421/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7866354749473255772&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Tongji University;Tongji Artificial Intelligence Research Institute;Hong Kong University of Science and Technology",
        "aff_unique_dep": ";Artificial Intelligence;",
        "aff_unique_url": "https://www.tongji.edu.cn;;https://www.ust.hk",
        "aff_unique_abbr": "Tongji;Tongji AI;HKUST",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Shanghai;Suzhou;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160534",
        "title": "FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "The great potential of unsupervised monocular depth estimation has been demonstrated by many works due to low annotation cost and impressive accuracy comparable to supervised methods. To further improve the performance, recent works mainly focus on designing more complex network structures and exploiting extra supervised information, e.g., semantic segmentation. These methods optimize the models by exploiting the reconstructed relationship between the target and reference images in varying degrees. However, previous methods prove that this image reconstruction optimization is prone to get trapped in local minima. In this paper, our core idea is to guide the optimization with prior knowledge from pretrained Flow-Net. And we show that the bottleneck of unsupervised monocular depth estimation can be broken with our simple but effective framework named FG-Depth. In particular, we propose (i) a flow distillation loss to replace the typical photometric loss that limits the capacity of the model and (ii) a prior flow based mask to remove invalid pixels that bring the noise in training loss. Extensive experiments demonstrate the effectiveness of each component, and our approach achieves state-of-the-art results on both KITTI and NYU-Depth-v2 datasets.",
        "primary_area": "",
        "author": "Junyu Zhu;Lina Liu;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang;Junyu Zhu;Lina Liu;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang",
        "authorids": "/37089893428;/37088691740;/37066946100;/37088687641;/37088690190;/37859161500;/37089893428;/37088691740;/37066946100;/37088687641;/37088690190;/37859161500",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Noah's Ark Lab, Huawei Technologies, Beijing, China; Noah's Ark Lab, Huawei Technologies, Beijing, China; Noah's Ark Lab, Huawei Technologies, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160534/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15132386624636225471&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;1",
        "aff_unique_norm": "Zhejiang University;Huawei Technologies",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;Noah's Ark Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "ZJU;Huawei",
        "aff_campus_unique_index": "0;0;0;1;1;1",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160868",
        "title": "FLYOVER: A Model-Driven Method to Generate Diverse Highway Interchanges for Autonomous Vehicle Testing",
        "track": "main",
        "status": "Poster",
        "abstract": "It has become a consensus that autonomous vehicles (AVs) will first be widely deployed on highways. However, the complexity of highway interchanges becomes the bottleneck for their deployment. An AV should be sufficiently tested under different highway interchanges, which is still challenging due to the lack of available datasets containing diverse highway interchanges. In this paper, we propose a model-driven method, Flyover, to generate a dataset of diverse interchanges with measurable diversity coverage. First, Flyover uses a labeled digraph to model interchange topology. Second, Flyover takes real-world interchanges as input to guarantee topology practicality and extracts different topology equivalence classes by classifying corresponding topology models. Third, for each topology class, Flyover identifies the corresponding geometrical features for the ramps and generates concrete interchanges using k-way combinatorial coverage and differential evolution. To illustrate the diversity and applicability of the generated interchange dataset, we test the built-in traffic flow control algorithm in SUMO and the fuel-optimization trajectory tracking algorithm deployed to Alibaba's autonomous trucks on the dataset. The results show that except for the geometrical difference, the interchanges are diverse in throughput and fuel consumption under the traffic flow control and trajectory tracking algorithms, respectively.",
        "primary_area": "",
        "author": "Yuan Zhou;Gengjie Lin;Yun Tang;Kairui Yang;Wei Jing;Ping Zhang;Junbo Chen;Liang Gong;Yang Liu;Yuan Zhou;Gengjie Lin;Yun Tang;Kairui Yang;Wei Jing;Ping Zhang;Junbo Chen;Liang Gong;Yang Liu",
        "authorids": "/37085401730;/37089894251;/37088999726;/37089895553;/37089852321;/37089194699;/37089196396;/37285929500;/37537575300;/37085401730;/37089894251;/37088999726;/37089895553;/37089852321;/37089194699;/37089196396;/37285929500;/37537575300",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; DAMO Academy, Alibaba Group, China; Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University, Singapore; DAMO Academy, Alibaba Group, China; DAMO Academy, Alibaba Group, China; DAMO Academy, Alibaba Group, China; DAMO Academy, Alibaba Group, China; School of Mechanical Engineering, Shanghai Jiao Tong University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160868/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6158164388021620642&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;1;1;1;1;2;0",
        "aff_unique_norm": "Nanyang Technological University;Alibaba Group;Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Computer Science and Engineering;DAMO Academy;School of Mechanical Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.alibaba.com;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "NTU;Alibaba;SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;1;0;1;1;1;1;1;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "10161191",
        "title": "FOGL: Federated Object Grasping Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Federated learning is a promising technique for training global models in a data-decentralized environment. In this paper, we propose a federated learning approach for robotic object grasping. The main challenge is that the data collected by multiple robots deployed in different environments tends to form heterogeneous data distributions (i.e., non-IID) and that the existing federated learning methods on such data distributions show serious performance degradation. To tackle this problem, we propose federated object grasping learning (FOGL) that uses cross-evaluation in a general federated learning process to assess the training performance of robots. We cluster robots with similar training patterns and perform independent federated learning on each cluster. Finally, we integrate the global models for each cluster through an ensemble inference. We apply FOGL to various federated learning scenarios in robotic object grasping and show state-of-the-art performance on the Cornell grasping dataset.",
        "primary_area": "",
        "author": "Seok\u2013Kyu Kang;Changhyun Choi;Seok\u2013Kyu Kang;Changhyun Choi",
        "authorids": "/37089895973;/37085811337;/37089895973;/37085811337",
        "aff": "HD Hyundai Group, Korea Shipbuilding & Offshore Engineering Co., Ltd. (KSOE), Seoul, South Korea; Department of Electrical and Computer Engineering, University of Minnesota, Twin Cities, Minneapolis, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161191/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17806588993884314625&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "HD Hyundai Group;University of Minnesota",
        "aff_unique_dep": ";Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.hdhynundai.com;https://www.umn.edu",
        "aff_unique_abbr": "HD Hyundai;UMN",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Twin Cities",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "10160771",
        "title": "FRAME: Fast and Robust Autonomous 3D Point Cloud Map-Merging for Egocentric Multi-Robot Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "This article presents a 3D point cloud map-merging framework for egocentric heterogeneous multi-robot exploration, based on overlap detection and alignment, that is independent of a manual initial guess or prior knowledge of the robots' poses. The novel proposed solution utilizes state-of-the-art place recognition learned descriptors, that through the framework's main pipeline, offer a fast and robust region overlap estimation, hence eliminating the need for the time-consuming global feature extraction and feature matching process that is typically used in 3D map integration. The region overlap estimation provides a homogeneous rigid transform that is applied as an initial condition in the point cloud registration algorithm Fast-GICP, which provides the final and refined alignment. The efficacy of the proposed framework is experimentally evaluated based on multiple field multi-robot exploration missions in underground environments, where both ground and aerial robots are deployed, with different sensor configurations.",
        "primary_area": "",
        "author": "Nikolaos Stathoulopoulos;Anton Koval;Ali-akbar Agha-mohammadi;George Nikolakopoulos;Nikolaos Stathoulopoulos;Anton Koval;Ali-akbar Agha-mohammadi;George Nikolakopoulos",
        "authorids": "/37089894214;/37086080065;/38274170800;/37301305200;/37089894214;/37086080065;/38274170800;/37301305200",
        "aff": "Department of Computer, Electrical and Space Engineering, Robotics and AI Group, Lule\u00e5 University of Technology, Lule\u00e5, Sweden; Department of Computer, Electrical and Space Engineering, Robotics and AI Group, Lule\u00e5 University of Technology, Lule\u00e5, Sweden; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Department of Computer, Electrical and Space Engineering, Robotics and AI Group, Lule\u00e5 University of Technology, Lule\u00e5, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160771/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13448451316529194472&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Lule\u00e5 University of Technology;California Institute of Technology",
        "aff_unique_dep": "Department of Computer, Electrical and Space Engineering, Robotics and AI Group;Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.ltu.se;https://www.caltech.edu",
        "aff_unique_abbr": "LTU;Caltech",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Lule\u00e5;Pasadena",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "10160702",
        "title": "FRIDA: A Collaborative Robot Painter with a Differentiable, Real2Sim2Real Planning Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Painting is an artistic process of rendering visual content that achieves the high-level communication goals of an artist that may change dynamically throughout the creative process. In this paper, we present a Framework and Robotics Initiative for Developing Arts (FRIDA) that enables humans to produce paintings on canvases by collaborating with a painter robot using simple inputs such as language descriptions or images. FRIDA introduces several technical innovations for computationally modeling a creative painting process. First, we develop a fully differentiable simulation environment for painting, adopting the idea of real to simulation to real (real2sim2real). We show that our proposed simulated painting environment is higher fidelity to reality than existing simulation environments used for robot painting. Second, to model the evolving dynamics of a creative process, we develop a planning approach that can continuously optimize the painting plan based on the evolving canvas with respect to the high-level goals. In contrast to existing approaches where the content generation process and action planning are performed independently and sequentially, FRIDA adapts to the stochastic nature of using paint and a brush by continually re-planning and re-assessing its semantic goals based on its visual perception of the painting progress. We describe the details on the technical approach as well as the system integration. FRIDA software is freely available at: https://github.com/cmubig/Frida.",
        "primary_area": "",
        "author": "Peter Schaldenbrand;James McCann;Jean Oh;Peter Schaldenbrand;James McCann;Jean Oh",
        "authorids": "/37089893221;/37088910733;/37933996900;/37089893221;/37088910733;/37933996900",
        "aff": "The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160702/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13215957441049526549&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160618",
        "title": "FSG-Net: a Deep Learning model for Semantic Robot Grasping through Few-Shot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot grasping has been widely studied in the last decade. Recently, Deep Learning made possible to achieve remarkable results in grasp pose estimation, using depth and RGB images. However, only few works consider the choice of the object to grasp. Moreover, they require a huge amount of data for generalizing to unseen object categories. For this reason, we introduce the Few-shot Semantic Grasping task where the objective is inferring a correct grasp given only five labelled images of a target unseen object. We propose a new deep learning architecture able to solve the aforementioned problem, leveraging on a Few-shot Semantic Segmentation module. We have evaluated the proposed model both in the Graspnet dataset and in a real scenario. In Graspnet, we achieve 40,95% accuracy in the Few-shot Semantic Grasping task, outperforming baseline approaches. In the real experiments, the results confirmed the generalization ability of the network.",
        "primary_area": "",
        "author": "Leonardo Barcellona;Alberto Bacchin;Alberto Gottardi;Emanuele Menegatti;Stefano Ghidoni;Leonardo Barcellona;Alberto Bacchin;Alberto Gottardi;Emanuele Menegatti;Stefano Ghidoni",
        "authorids": "/37089228694;/37089317033;/37089381520;/37317887300;/37394223200;/37089228694;/37089317033;/37089381520;/37317887300;/37394223200",
        "aff": "Politecnico di Torino, Torino, Italy; Department of Information Engineering, Intelligent Autonomous System Lab, University of Padova, Padua, Italy; IT +Robotics srl, Vicenza, Italy; Department of Information Engineering, Intelligent Autonomous System Lab, University of Padova, Padua, Italy; Department of Information Engineering, Intelligent Autonomous System Lab, University of Padova, Padua, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160618/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5562940030618518034&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2+3;1;1",
        "aff_unique_norm": "Politecnico di Torino;University of Padova;Information Technology;Robotics srl",
        "aff_unique_dep": ";Department of Information Engineering;;",
        "aff_unique_url": "https://www.polito.it;https://www.unipd.it;;",
        "aff_unique_abbr": "Polito;UNIPD;;",
        "aff_campus_unique_index": "0;1;;1;1",
        "aff_campus_unique": "Torino;Padua;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy;"
    },
    {
        "id": "10161522",
        "title": "Factor Graph Fusion of Raw GNSS Sensing with IMU and Lidar for Precise Robot Localization without a Base Station",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate localization is a core component of a robot's navigation system. To this end, global navigation satellite systems (GNSS) can provide absolute measurements outdoors and, therefore, eliminate long-term drift. However, fusing GNSS data with other sensor data is not trivial, especially when a robot moves between areas with and without sky view. We propose a robust approach that tightly fuses raw GNSS receiver data with inertial measurements and, optionally, lidar observations for precise and smooth mobile robot localization. A factor graph with two types of GNSS factors is proposed. First, factors based on pseudoranges, which allow for global localization on Earth. Second, factors based on carrier phases, which enable highly accurate relative localization, which is useful when other sensing modalities are challenged. Unlike traditional differential GNSS, this approach does not require a connection to a base station. On a public urban driving dataset, our approach achieves accuracy comparable to a state-of-the-art algorithm that fuses visual inertial odometry with GNSS data-despite our approach not using the camera, just inertial and GNSS data. We also demonstrate the robustness of our approach using data from a car and a quadruped robot moving in environments with little sky visibility, such as a forest. The accuracy in the global Earth frame is still 1\u20132 m, while the estimated trajectories are discontinuity-free and smooth. We also show how lidar measurements can be tightly integrated. We believe this is the first system that fuses raw GNSS observations (as opposed to fixes) with lidar in a factor graph.",
        "primary_area": "",
        "author": "Jonas Beuchert;Marco Camurri;Maurice Fallon;Jonas Beuchert;Marco Camurri;Maurice Fallon",
        "authorids": "/37086527926;/37085638130;/37540365100;/37086527926;/37085638130;/37540365100",
        "aff": "Dept. of Eng. Science, Oxford Robotics Inst., Univ. of Oxford, UK; Faculty of Science & Technology, Free Univ. of Bozen-Bolzano, Italy; Dept. of Computer Science, Univ. of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161522/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16596993669920885232&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Oxford;Free University of Bozen-Bolzano",
        "aff_unique_dep": "Department of Engineering Science;Faculty of Science & Technology",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.unibz.it",
        "aff_unique_abbr": "Oxford;Free Univ. of Bozen-Bolzano",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oxford;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Italy"
    },
    {
        "id": "10160615",
        "title": "Failure Detection and Fault Tolerant Control of a Jet-Powered Flying Humanoid Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Failure detection and fault tolerant control are fundamental safety features of any aerial vehicle. With the emer-gence of complex, multi-body flying systems such as jet-powered humanoid robots, it becomes of crucial importance to design fault detection and control strategies for these systems, too. In this paper we propose a fault detection and control framework for the flying humanoid robot iRonCub in case of loss of one turbine. The framework is composed of a failure detector based on turbines rotational speed, a momentum-based flight control for fault response, and an offline reference generator that produces far-from-singularities configurations and accounts for self and jet exhausts collision avoidance. Simulation results with Gazebo and MATLAB prove the effectiveness of the proposed control strategy.",
        "primary_area": "",
        "author": "Gabriele Nava;Daniele Pucci;Gabriele Nava;Daniele Pucci",
        "authorids": "/37086044221;/37706167200;/37086044221;/37706167200",
        "aff": "Artificial and Mechanical Intelligence Laboratory, Fondazione Istituto Italiano di Tecnologia, Genoa, Italy; School of Computer Science, University of Manchester, Manchester, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160615/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16874530418468682374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Fondazione Istituto Italiano di Tecnologia;University of Manchester",
        "aff_unique_dep": "Artificial and Mechanical Intelligence Laboratory;School of Computer Science",
        "aff_unique_url": "https://www.iit.it;https://www.manchester.ac.uk",
        "aff_unique_abbr": "IIT;UoM",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Genoa;Manchester",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "10160596",
        "title": "Failure Detection for Motion Prediction of Autonomous Driving: An Uncertainty Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion prediction is essential for safe and efficient autonomous driving. However, the inexplicability and uncertainty of complex artificial intelligence models may lead to unpredictable failures of the motion prediction module, which may mislead the system to make unsafe decisions. Therefore, it is necessary to develop methods to guarantee reliable autonomous driving, where failure detection is a potential direction. Uncertainty estimates can be used to quantify the degree of confidence a model has in its predictions and may be valuable for failure detection. We propose a framework of failure detection for motion prediction from the uncertainty perspective, considering both motion uncertainty and model uncertainty, and formulate various uncertainty scores according to different prediction stages. The proposed approach is evaluated based on different motion prediction algorithms, uncertainty estimation methods, uncertainty scores, etc., and the results show that uncertainty is promising for failure detection for motion prediction but should be used with caution.",
        "primary_area": "",
        "author": "Wenbo Shao;Yanchao Xu;Liang Peng;Jun Li;Hong Wang;Wenbo Shao;Yanchao Xu;Liang Peng;Jun Li;Hong Wang",
        "authorids": "/37086882261;/37089581488;/37089630268;/37088999341;/37086050700;/37086882261;/37089581488;/37089630268;/37088999341;/37086050700",
        "aff": "School of Veh icle and Mobility, Tsinghua University, Beijing, China; School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China; School of Veh icle and Mobility, Tsinghua University, Beijing, China; School of Veh icle and Mobility, Tsinghua University, Beijing, China; School of Veh icle and Mobility, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160596/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8762073844300965958&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Tsinghua University;Beijing Institute of Technology",
        "aff_unique_dep": "School of Vehicle and Mobility;School of Mechanical Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://www.bit.edu.cn",
        "aff_unique_abbr": "Tsinghua;BIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160889",
        "title": "Failure-aware Policy Learning for Self-assessable Robotics Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-assessment rules play an essential role in safe and effective real-world robotic applications, which verify the feasibility of the selected action before actual execution. But how to utilize the self-assessment results to re-choose actions remains a challenge. Previous methods eliminate the selected action evaluated as failed by the self-assessment rules, and re-choose one with the next-highest affordance (i.e. process-of-elimination strategy [1]), which ignores the dependency between the self-assessment results and the remaining untried actions. However, this dependency is important since the previous failures might help trim the remaining over-estimated actions. In this paper, we set to investigate this dependency by learning a failure-aware policy. We propose two architectures for the failure-aware policy by representing the self-assessment results of previous failures as the variable state, and leveraging recurrent neural networks to implicitly memorize the previous failures. Experiments conducted on three tasks demonstrate that our method can achieve better performances with higher task success rates by less trials. Moreover, when the actions are correlated, learning a failure-aware policy can achieve better performance than the process-of-elimination strategy.",
        "primary_area": "",
        "author": "Kechun Xu;Runjian Chen;Shuqi Zhao;Zizhang Li;Hongxiang Yu;Ci Chen;Yue Wang;Rong Xiong;Kechun Xu;Runjian Chen;Shuqi Zhao;Zizhang Li;Hongxiang Yu;Ci Chen;Yue Wang;Rong Xiong",
        "authorids": "/37088916597;/37087245952;/37089892193;/37089893890;/37086345520;/37089515536;/37072299700;/37271511300;/37088916597;/37087245952;/37089892193;/37089893890;/37086345520;/37089515536;/37072299700;/37271511300",
        "aff": "Zhejiang University, Hangzhou, China; The University of Hong Kong; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160889/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7068486407640475853&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University;The University of Hong Kong",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.hku.hk",
        "aff_unique_abbr": "ZJU;HKU",
        "aff_campus_unique_index": "0;1;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160727",
        "title": "Fast Event-based Double Integral for Real-time Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion deblurring is a critical ill-posed problem that is important in many vision-based robotics applications. The recently proposed event-based double integral (EDI) provides a theoretical framework for solving the deblurring prob-lem with the event camera and generating clear images at high frame-rate. However, the original EDI is mainly designed for offline computation and does not support real-time requirement in many robotics applications. In this paper, we propose the fast EDI, an efficient implementation of EDI that can achieve real-time online computation on single-core CPU devices, which is common for physical robotic platforms used in practice. In experiments, our method can handle event rates at as high as 13 million event per second in a wide variety of challenging lighting conditions. We demonstrate the benefit on multiple downstream real-time applications, including localization, vi-sual tag detection, and feature matching.",
        "primary_area": "",
        "author": "Shijie Lin;Yingqiang Zhang;Dongyue Huang;Bin Zhou;Xiaowei Luo;Jia Pan;Shijie Lin;Yingqiang Zhang;Dongyue Huang;Bin Zhou;Xiaowei Luo;Jia Pan",
        "authorids": "/37088486923;/37089895259;/37089895414;/38021654800;/37086376788;/37535628800;/37088486923;/37089895259;/37089895414;/38021654800;/37086376788;/37535628800",
        "aff": "Peng Cheng Laboratory, Shenzhen, Guangdong, China; Department of Computer Science, The University of Hong Kong, Hong Kong SAR, China; Peng Cheng Laboratory, Shenzhen, Guangdong, China; Peng Cheng Laboratory, Shenzhen, Guangdong, China; Department of Architecture and Civil En-gineering, City University of Hong Kong, Hong Kong SAR, China; Department of Computer Science, The University of Hong Kong, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160727/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3918899939770688746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;1",
        "aff_unique_norm": "Peng Cheng Laboratory;The University of Hong Kong;City University of Hong Kong",
        "aff_unique_dep": ";Department of Computer Science;Department of Architecture and Civil Engineering",
        "aff_unique_url": ";https://www.hku.hk;https://www.cityu.edu.hk",
        "aff_unique_abbr": ";HKU;CityU",
        "aff_campus_unique_index": "0;1;0;0;1",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161187",
        "title": "Fast Extrinsic Calibration for Multiple Inertial Measurement Units in Visual-Inertial System",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a fast extrinsic calibration method for fusing multiple inertial measurement units (MIMU) to improve visual-inertial odometry (VIO) localization accuracy. Currently, data fusion algorithms for MIMU highly depend on the number of inertial sensors. Based on the assumption that extrinsic parameters between inertial sensors are perfectly calibrated, the fusion algorithm provides better localization accuracy with more IMUs, while neglecting the effect of extrinsic calibration error. Our method builds two non-linear least-squares problems to estimate the MIMU relative position and orientation separately, independent of external sensors and inertial noises online estimation. Then we give the general form of the virtual IMU (VIMU) method and propose its propagation on manifold. We perform our method on datasets, our self-made sensor board, and board with different IMUs, validating the superiority of our method over competing methods concerning speed, accuracy, and robustness. In the simulation experiment, we show that only fusing two IMUs with our calibration method to predict motion can rival nine IMUs. Real-world experiments demonstrate better localization accuracy of the VIO integrated with our calibration method and VIMU propagation on manifold.",
        "primary_area": "",
        "author": "Youwei Yu;Yanqing Liu;Fengjie Fu;Sihan He;Dongchen Zhu;Lei Wang;Xiaolin Zhang;Jiamao Li;Youwei Yu;Yanqing Liu;Fengjie Fu;Sihan He;Dongchen Zhu;Lei Wang;Xiaolin Zhang;Jiamao Li",
        "authorids": "/37089895977;/37086418759;/37089313278;/37089895701;/37086420004;/37088421432;/37085830972;/37086083391;/37089895977;/37086418759;/37089313278;/37089895701;/37086420004;/37088421432;/37085830972;/37086083391",
        "aff": "Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Science and Technology of China, Hefei, China; Xiongan Institute of Innovation, Xiongan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161187/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18353246168807382096&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;0;1;1;2;3",
        "aff_unique_norm": "Shanghai Institute of Microsystem and Information Technology;University of Chinese Academy of Sciences;University of Science and Technology of China;Xiongan Institute of Innovation",
        "aff_unique_dep": "Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology;;;",
        "aff_unique_url": "http://www.sIMIT.ac.cn;http://www.ucas.ac.cn;http://www.ustc.edu.cn;",
        "aff_unique_abbr": "SIMIT;UCAS;USTC;",
        "aff_campus_unique_index": "0;1;1;0;1;1;2;3",
        "aff_campus_unique": "Shanghai;Beijing;Hefei;Xiongan",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161156",
        "title": "Fast Region of Interest Proposals on Maritime UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned aerial vehicles assist in maritime search and rescue missions by flying over large search areas to autonomously search for objects or people. Reliably detecting objects of interest requires fast models to employ on embedded hardware. Moreover, with increasing distance to the ground station only part of the video data can be transmitted. In this work, we consider the problem of finding meaningful region of interest proposals in a video stream on an embedded GPU. Current object or anomaly detectors are not suitable due to their slow speed, especially on limited hardware and for large image resolutions. Lastly, objects of interest, such as pieces of wreckage, are often not known a priori. Therefore, we propose an end-to-end future frame prediction model running in real-time on embedded GPUs to generate region proposals. We analyze its performance on large-scale maritime data sets and demonstrate its benefits over traditional and modern methods.",
        "primary_area": "",
        "author": "Benjamin Kiefer;Andreas Zell;Benjamin Kiefer;Andreas Zell",
        "authorids": "/37089226266;/37276583400;/37089226266;/37276583400",
        "aff": "Faculty of Computer Science, University of Tuebingen, Germany; Faculty of Computer Science, University of Tuebingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161156/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11716064963636001093&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Tuebingen",
        "aff_unique_dep": "Faculty of Computer Science",
        "aff_unique_url": "https://www.uni-tuebingen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160258",
        "title": "Fast Staircase Detection and Estimation using 3D Point Clouds with Multi-detection Merging for Heterogeneous Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic systems need advanced mobility capabili-ties to operate in complex, three-dimensional environments designed for human use, e.g., multi-level buildings. Incorporating some level of autonomy enables robots to operate robustly, reliably, and efficiently in such complex environments, e.g., automatically \u201creturning home\u201d if communication between an operator and robot is lost during deployment. This work presents a novel method that enables mobile robots to robustly operate in multi-level environments by making it possible to autonomously locate and climb a range of different staircases. We present results wherein a wheeled robot works together with a quadrupedal system to quickly detect different staircases and reliably climb them. The performance of this novel staircase detection algorithm that is able to run on the heterogeneous platforms is compared to the current state-of-the-art detection algorithm. We show that our approach significantly increases the accuracy and speed at which detections occur.",
        "primary_area": "",
        "author": "Prasanna Sriganesh;Namya Bagree;Bhaskar Vundurthy;Matthew Travers;Prasanna Sriganesh;Namya Bagree;Bhaskar Vundurthy;Matthew Travers",
        "authorids": "/37089641743;/37089896109;/37085769792;/37545390200;/37089641743;/37089896109;/37085769792;/37545390200",
        "aff": "The Robotics Institute, Carnegie Mellon University, USA; Department of Mechanical Engineering, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160258/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2691144633591975203&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160610",
        "title": "Fast Untethered Soft Robotic Crawler with Elastic Instability",
        "track": "main",
        "status": "Poster",
        "abstract": "Enlightened by the fast-running gait of mammals like cheetahs and wolves, we design and fabricate a single-actuated untethered compliant robot that is capable of galloping at a speed of 313 mm/s or 1.56 body length per second (BL/s), faster than most reported soft crawlers in mm/s and BL/s. An in-plane prestressed hair clip mechanism (HCM) made up of semirigid materials, i.e. plastics are used as the supporting chassis, the compliant spine, and the force amplifier of the robot at the same time, enabling the robot to be simple, rapid, and strong. With experiments, we find that the HCM robotic locomotion speed is linearly related to actuation frequencies and substrate friction differences except for concrete surface, that tethering slows down the crawler, and that asymmetric actuation creates a new galloping gait. This paper demonstrates the potential of HCM-based soft robots.",
        "primary_area": "",
        "author": "Zechen Xiong;Yufeng Su;Hod Lipson;Zechen Xiong;Yufeng Su;Hod Lipson",
        "authorids": "/37089892328;/37089893449;/37278575000;/37089892328;/37089893449;/37278575000",
        "aff": "Dept. of Earth and Environment Engineering, Columbia University, New York, NY, USA; Dept. of Mechanical Engineering, Columbia University, New York, NY, USA; Dept. of Mechanical Engineering, Columbia University, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160610/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7659884040935051105&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Dept. of Earth and Environment Engineering",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161445",
        "title": "Fast and Scalable Signal Inference for Active Robotic Source Seeking",
        "track": "main",
        "status": "Poster",
        "abstract": "In active source seeking, a robot takes repeated measurements in order to locate a signal source in a cluttered and unknown environment. A key component of an active source seeking robot planner is a model that can produce estimates of the signal at unknown locations with uncertainty quantification. This model allows the robot to plan for future measurements in the environment. Traditionally, this model has been in the form of a Gaussian process, which has difficulty scaling and cannot represent obstacles. We propose a global and local factor graph model for active source seeking, which allows the model to scale to a large number of measurements and represent unknown obstacles in the environment. We combine this model with extensions to a highly scalable planner to form a system for large-scale active source seeking. We demonstrate that our approach outperforms baseline methods in both simulated and real robot experiments.",
        "primary_area": "",
        "author": "Christopher E. Denniston;Oriana Peltzer;Joshua Ott;Sangwoo Moon;Sung-Kyun Kim;Gaurav S. Sukhatme;Mykel J. Kochenderfer;Mac Schwager;Ali-akbar Agha-mohammadi;Christopher E. Denniston;Oriana Peltzer;Joshua Ott;Sangwoo Moon;Sung-Kyun Kim;Gaurav S. Sukhatme;Mykel J. Kochenderfer;Mac Schwager;Ali-akbar Agha-mohammadi",
        "authorids": "/37086855837;/37088505805;/37089662054;/37089894412;/37598024600;/37278934100;/37596929200;/37424620600;/38274170800;/37086855837;/37088505805;/37089662054;/37089894412;/37598024600;/37278934100;/37596929200;/37424620600;/38274170800",
        "aff": "University of Southern California; Stanford University; Stanford University; NASA Jet Propulsion Laboratory, Caltech; NASA Jet Propulsion Laboratory, Caltech; University of Southern California; Stanford University; Stanford University; NASA Jet Propulsion Laboratory, Caltech",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161445/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11277545536799520234&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;2;2;0;1;1;2",
        "aff_unique_norm": "University of Southern California;Stanford University;California Institute of Technology",
        "aff_unique_dep": ";;NASA Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.usc.edu;https://www.stanford.edu;https://www.jpl.nasa.gov",
        "aff_unique_abbr": "USC;Stanford;Caltech",
        "aff_campus_unique_index": "0;1;1;0;1;1",
        "aff_campus_unique": "Los Angeles;Stanford;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160318",
        "title": "Fast, Reliable Constrained Manipulation Using a VSA Driven Planar Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design and performance of a planar 3R robot capable of dexterous constrained manipulation when interacting with a stiff environment. A novel variable stiffness actuator (VSA) having a stiffness ratio of approximately 500 is also described. Variable stiffness actuation, together with a combined position/compliance manipulation path, is used to: 1) allow the robot to passively comply with its environment along kinematically constrained directions despite model error in constraint locations, and 2) generate high stiffness for accurate motion control along kinematically unconstrained directions despite resisting forces. This manipulation strategy provides dexterity for cases in which mechanical work must be performed while complying with constraints. The manipulation strategy and robot performance were evaluated with the task of turning a steel crank to lift a weight. Results show that, when using passive compliance control, the robot completed the task 29 times faster with constraint forces 80% lower than when using traditional active compliance control (with VSAs at their highest stiffness).",
        "primary_area": "",
        "author": "Andrew L. Bernhard;Joseph M. Schimmels;Andrew L. Bernhard;Joseph M. Schimmels",
        "authorids": "/37089893848;/37278618100;/37089893848;/37278618100",
        "aff": "Argonne National Laboratory, X-Ray Science, Beamline Instrumentation, Lemont, IL, USA; Department of Mechanical Engineering, Marquette University, Milwaukee, WI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160318/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4475475465027516251&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Argonne National Laboratory;Marquette University",
        "aff_unique_dep": "X-Ray Science, Beamline Instrumentation;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.anl.gov;https://www.marquette.edu",
        "aff_unique_abbr": "ANL;Marquette",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Lemont;Milwaukee",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160314",
        "title": "Fast-Grasp'D: Dexterous Multi-finger Grasp Generation Through Differentiable Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-finger grasping relies on high quality training data, which is hard to obtain: human data is hard to transfer and synthetic data relies on simplifying assumptions that reduce grasp quality. By making grasp simulation differentiable, and contact dynamics amenable to gradient-based optimization, we accelerate the search for high-quality grasps with fewer limiting assumptions. We present Grasp'D-1M: a large-scale dataset for multi-finger robotic grasping, synthesized with Fast-Grasp'D, a novel differentiable grasping simulator. Grasp'D-1M contains one million training examples for three robotic hands (three, four and five-fingered), each with multimodal visual inputs (RGB+depth+segmentation, available in mono and stereo). Grasp synthesis with Fast-Grasp'D is 10x faster than GraspIt! [1] and 20x faster than the prior Grasp'D differentiable simulator [2]. Generated grasps are more stable and contact-rich than GraspIt! grasps, regardless of the distance threshold used for contact generation. We validate the usefulness of our dataset by retraining an existing vision-based grasping pipeline [3] on Grasp'D-1M, and showing a dramatic increase in model performance, predicting grasps with 30% more contact, a 33% higher epsilon metric, and 35% lower simulated displacement. Additional details at fast-graspd.github.io.",
        "primary_area": "",
        "author": "Dylan Turpin;Tao Zhong;Shutong Zhang;Guanglei Zhu;Eric Heiden;Miles Macklin;Stavros Tsogkas;Sven Dickinson;Animesh Garg;Dylan Turpin;Tao Zhong;Shutong Zhang;Guanglei Zhu;Eric Heiden;Miles Macklin;Stavros Tsogkas;Sven Dickinson;Animesh Garg",
        "authorids": "/37089542144;/37089892977;/37089893192;/37089895758;/37990849700;/37086938482;/37085499222;/37273151200;/37086330576;/37089542144;/37089892977;/37089893192;/37089895758;/37990849700;/37086938482;/37085499222;/37273151200;/37086330576",
        "aff": "Nvidia; Vector Institute; Vector Institute; Vector Institute; Nvidia; Nvidia; Samsung; Samsung; Nvidia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160314/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8830751966239955560&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;0;0;2;2;0",
        "aff_unique_norm": "NVIDIA Corporation;Vector Institute;Samsung",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nvidia.com;https://vectorinstitute.ai/;https://www.samsung.com",
        "aff_unique_abbr": "NVIDIA;Vector Institute;Samsung",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;0;0;2;2;0",
        "aff_country_unique": "United States;Canada;South Korea"
    },
    {
        "id": "10160862",
        "title": "Feature Extraction for Effective and Efficient Deep Reinforcement Learning on Real Robotic Platforms",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (DRL) methods can solve complex continuous control tasks in simulated environments by taking actions based solely on state observations at each decision point. Because of the dynamics involved, individual snapshots of real-world sensor measurements afford only partial state observability, so it is typical to use a history of observations to improve training and policy performance. Such intertemporal information can be further exploited using a recurrent neural network (RNN) to reduce the dimensionality of the dynamic state representation. However, using RNNs as an internal part of a DRL network presents challenges of its own; and even then, the improvements in resulting policies are usually limited. To address these shortcomings, we propose using gated feature extraction to improve DRL training of real-world robots. Specifically, we use an untrained gated recurrent unit (GRU) to encode a low-dimension representation of the state observation sequence before passing it to the DRL training procedure. In addition to dimensionality reduction, this allows us to unroll the RNN by encoding the observations cumulatively as they are collected, thereby avoiding same-length input requirements, and train the RL network on the raw observations at the current step combined with the GRU-encoding of the preceding steps. Our simulation experiments employ gated feature extraction with the TD3 algorithm. Our results show that the GRU-encoded state observations improve the training speed and execution performance of the TD3 algorithm, improving the learned policies in all 19 test cases, exceeding the maximum achieved reward by over 38% in 8 and doubling the maximum achieved reward in three, while also outperforming a baseline implementation of SAC in 17 out of 19 environments. Moreover, the greatest improvement is seen in real-world experiments, where our approach successfully learns to balance a pendulum as well as a complex quadrupedal locomotion task. In c... Show More",
        "primary_area": "",
        "author": "Peter B\u00f6hm;Pauline Pounds;Archie C. Chapman;Peter B\u00f6hm;Pauline Pounds;Archie C. Chapman",
        "authorids": "/37089658275;/37571590000;/37078347500;/37089658275;/37571590000;/37078347500",
        "aff": "The University of Queensland, Australia; The University of Queensland, Australia; The University of Queensland, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160862/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11910159332226567213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Queensland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uq.edu.au",
        "aff_unique_abbr": "UQ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160800",
        "title": "Feature-Realistic Neural Fusion for Real-Time, Open Set Scene Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "General scene understanding for robotics requires flexible semantic representation, so that novel objects and structures which may not have been known at training time can be identified, segmented and grouped. We present an algorithm which fuses general learned features from a standard pre-trained network into a highly efficient 3D geometric neural field representation during real-time SLAM. The fused 3D feature maps inherit the coherence of the neural field's geometry representation. This means that tiny amounts of human labelling interacting at runtime enable objects or even parts of objects to be robustly and accurately segmented in an open set manner. Project page: https://makezur.github.io/FeatureRealisticFusion/",
        "primary_area": "",
        "author": "Kirill Mazur;Edgar Sucar;Andrew J. Davison;Kirill Mazur;Edgar Sucar;Andrew J. Davison",
        "authorids": "/37089314345;/37086453728;/37293837200;/37089314345;/37086453728;/37293837200",
        "aff": "Dyson Robotics Lab, Imperial College, London, UK; Dyson Robotics Lab, Imperial College, London, UK; Dyson Robotics Lab, Imperial College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160800/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16224596948287628256&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dyson Robotics Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160429",
        "title": "Few-Shot Point Cloud Semantic Segmentation via Contrastive Self-Supervision and Multi-Resolution Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an effective few-shot point cloud semantic segmentation approach for real-world applications. Existing few-shot segmentation methods on point cloud heavily rely on the fully-supervised pretrain with large annotated datasets, which causes the learned feature extraction bias to those pretrained classes. However, as the purpose of few-shot learning is to handle unknown/unseen classes, such class-specific feature extraction in pretrain is not ideal to generalize into new classes for few-shot learning. Moreover, point cloud datasets hardly have a large number of classes due to the annotation difficulty. To address these issues, we propose a contrastive self-supervision framework for few-shot learning pretrain, which aims to eliminate the feature extraction bias through class-agnostic contrastive supervision. Specifically, we implement a novel contrastive learning approach with a learnable augmentor for a 3D point cloud to achieve point-wise differentiation, so that to enhance the pretrain with managed overfitting through the self-supervision. Furthermore, we develop a multi-resolution attention module using both the nearest and farthest points to extract the local and global point information more effectively, and a center-concentrated multi-prototype is adopted to mitigate the intra-class sparsity. Comprehensive experiments are conducted to evaluate the proposed approach, which shows our approach achieves state-of-the-art performance. Moreover, a case study on practical CAM/CAD segmentation is presented to demonstrate the effectiveness of our approach for real-world applications.",
        "primary_area": "",
        "author": "Jiahui Wang;Haiyue Zhu;Haoren Guo;Abdullah Al Mamun;Cheng Xiang;Tong Heng Lee;Jiahui Wang;Haiyue Zhu;Haoren Guo;Abdullah Al Mamun;Cheng Xiang;Tong Heng Lee",
        "authorids": "/37085624474;/37085409877;/37089640981;/37273445600;/37282223900;/37277268600;/37085624474;/37085409877;/37089640981;/37273445600;/37282223900;/37277268600",
        "aff": "College of Design and Engineering, Electrical and Computer Engineering, National University of Singapore, Singapore; Agency for Science, Technology and Research (A*STAR), Singapore Institute of Manufacturing Technology (SIMTech), Singapore, Republic of Singapore; College of Design and Engineering, Electrical and Computer Engineering, National University of Singapore, Singapore; College of Design and Engineering, Electrical and Computer Engineering, National University of Singapore, Singapore; College of Design and Engineering, Electrical and Computer Engineering, National University of Singapore, Singapore; College of Design and Engineering, Electrical and Computer Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160429/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6896481667560723313&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "National University of Singapore;Agency for Science, Technology and Research (A*STAR)",
        "aff_unique_dep": "Electrical and Computer Engineering;Singapore Institute of Manufacturing Technology (SIMTech)",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.a-star.edu.sg",
        "aff_unique_abbr": "NUS;A*STAR",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160674",
        "title": "Few-shot 3D LiDAR Semantic Segmentation for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "In autonomous driving, the novel objects and lack of annotations challenge the traditional 3D LiDAR semantic segmentation based on deep learning. Few-shot learning is a feasible way to solve these issues. However, currently few-shot semantic segmentation methods focus on camera data, and most of them only predict the novel classes without considering the base classes. This setting cannot be directly applied to autonomous driving due to safety concerns. Thus, we propose a few-shot 3D LiDAR semantic segmentation method that predicts both novel and base classes simultaneously. Our method tries to solve the background ambiguity problem in generalized few-shot semantic segmentation. We first review the original cross-entropy and knowledge distillation losses, then propose a new loss function that incorporates the background information to achieve 3D LiDAR few-shot semantic segmentation. Extensive experiments on SemanticKITTI demonstrate the effectiveness of our method.",
        "primary_area": "",
        "author": "Jilin Mei;Junbao Zhou;Yu Hu;Jilin Mei;Junbao Zhou;Yu Hu",
        "authorids": "/37086269220;/37089893985;/37277445400;/37086269220;/37089893985;/37277445400",
        "aff": "Research Center for Intelligent Computing Systems, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160674/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13269087049560543574&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Chinese Academy of Sciences;University of Chinese Academy of Sciences",
        "aff_unique_dep": "Institute of Computing Technology;School of Computer Science and Technology",
        "aff_unique_url": "http://www.cas.cn;http://www.ucas.ac.cn",
        "aff_unique_abbr": "CAS;UCAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161143",
        "title": "FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce the Few-Shot Object Learning (FEWSOL) dataset for object recognition with a few images per object. We captured 336 real-world objects with 9 RGB-D images per object from different views. Fewsol has object segmentation masks, poses, and attributes. In addition, synthetic images generated using 330 3D object models are used to augment the dataset. We investigated (i) few-shot object classification and (ii) joint object segmentation and few-shot classification with state-of-the-art methods for few-shot learning and meta-learning using our dataset. The evaluation results show the presence of a large margin to be improved for few-shot object classification in robotic environments, and our dataset can be used to study and enhance few-shot object recognition for robot perception 11Dataset and code available at https://irvlutd.github.io/FewSOL.",
        "primary_area": "",
        "author": "Jishnu Jaykumar P;Yu-Wei Chao;Yu Xiang;Jishnu Jaykumar P;Yu-Wei Chao;Yu Xiang",
        "authorids": "/37088866424;/37088503888;/37087234731;/37088866424;/37088503888;/37087234731",
        "aff": "Department of Computer Science, University of Texas at Dallas, Richardson, TX, USA; NVIDIA, Seattle, WA, USA; Department of Computer Science, University of Texas at Dallas, Richardson, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161143/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1431101539798253272&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Texas at Dallas;NVIDIA",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.utdallas.edu;https://www.nvidia.com",
        "aff_unique_abbr": "UT Dallas;NV",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Richardson;Seattle",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160555",
        "title": "Finding Optimal Modular Robots for Aerial Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional aerial vehicles have limitations in their capabilities due to actuator constraints, such as motor saturation. The hardware components and their arrangement are designed to satisfy specific requirements and are difficult to modify during operation. To address this problem, we introduce a versatile modular multi-rotor vehicle that can change its capabilities by reconfiguration. Our modular robot consists of homogeneous cuboid modules, propelled by quadrotors with tilted rotors. Depending on the number of modules and their configuration, the robot can expand its actuation capabilities. In this paper, we build a mathematical model for the actuation capability of a modular multi-rotor vehicle and develop methods to determine if a vehicle is capable of satisfying a task requirement. Based on this result, we find the optimal configurations for a given task. Our approach is validated in realistic \\mathbf{3D}\\mathbf{3D} simulations, showing that our modular system can adapt to tasks with varying requirements.",
        "primary_area": "",
        "author": "Jiawei Xu;David Salda\u00f1a;Jiawei Xu;David Salda\u00f1a",
        "authorids": "/37088996257;/38543033800;/37088996257;/38543033800",
        "aff": "Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, PA, USA; Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160555/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5869144384188259790&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Lehigh University",
        "aff_unique_dep": "Autonomous and Intelligent Robotics Laboratory (AIRLab)",
        "aff_unique_url": "https://www.lehigh.edu",
        "aff_unique_abbr": "Lehigh",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "PA",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160490",
        "title": "Finding Things in the Unknown: Semantic Object-Centric Exploration with an MAV",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploration of unknown space with an autonomous mobile robot is a well-studied problem. In this work we broaden the scope of exploration, moving beyond the pure geometric goal of uncovering as much free space as possible. We believe that for many practical applications, exploration should be contextualised with semantic and object-level understanding of the environment for task-specific exploration. Here, we study the task of bothfinding specific objects in unknown space as well as reconstructing them to a target level of detail. We therefore extend our environment reconstruction to not only consist of a background map, but also object-level and semantically fused submaps. Importantly, we adapt our previous objective function of uncovering as much free space as possible in as little time as possible with two additional elements: first, we require a maximum observation distance of background surfaces to ensure target objects are not missed by image-based detectors because they are too small to be detected. Second, we require an even smaller maximum distance to the found objects in order to reconstruct them with the desired accuracy. We further created a Micro Aerial Vehicle (MAV) semantic exploration simulator based on Habitat in order to quantitatively demonstrate how our framework can be used to efficiently find specific objects as part of exploration. Finally, we showcase this capability can be deployed in real-world scenes involving our drone equipped with an Intel RealSense D455 RGB-D camera.",
        "primary_area": "",
        "author": "Sotiris Papatheodorou;Nils Funk;Dimos Tzoumanikas;Christopher Choi;Binbin Xu;Stefan Leutenegger;Sotiris Papatheodorou;Nils Funk;Dimos Tzoumanikas;Christopher Choi;Binbin Xu;Stefan Leutenegger",
        "authorids": "/37085837932;/37086189909;/37085755526;/37089660169;/37086936010;/37698403100;/37085837932;/37086189909;/37085755526;/37089660169;/37086936010;/37698403100",
        "aff": "Munich Institute of Robotics and Machine Intelligence (MIRMI); Department of Computing, Smart Robotics Lab, Imperial College, London; Department of Computing, Smart Robotics Lab, Imperial College, London; Department of Computing, Smart Robotics Lab, Imperial College, London; University of Toronto Robotics Institute, University of Toronto; Munich Institute of Robotics and Machine Intelligence (MIRMI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160490/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7740676801252342246&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;2;0",
        "aff_unique_norm": "Munich Institute of Robotics and Machine Intelligence;Imperial College London;University of Toronto",
        "aff_unique_dep": "Robotics and Machine Intelligence;Department of Computing;Robotics Institute",
        "aff_unique_url": ";https://www.imperial.ac.uk;https://www.utoronto.ca",
        "aff_unique_abbr": "MIRMI;ICL;U of T",
        "aff_campus_unique_index": "0;1;1;1;2;0",
        "aff_campus_unique": "Munich;London;Toronto",
        "aff_country_unique_index": "0;1;1;1;2;0",
        "aff_country_unique": "Germany;United Kingdom;Canada"
    },
    {
        "id": "10160936",
        "title": "Finding the Optimal Incision Point in Robotic Assisted Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "In robotic assisted surgeries, surgical tools are inserted into the human body via an incision point in the abdominal wall, which is imposed as a remote center of motion (RCM). The selection of the incision's point location in the human body is critical for the success of the surgical procedure. In this paper, we propose a simulation tool for finding the optimal incision point location, which can be utilized by the surgeon during the preoperative stage. The surgeon can plan the path/region of intervention as well as sensitive regions which should be protected from unintentional damage by the surgical tool on the preoperative images of internal organs. A target admittance model that enforces a candidate incision as a RCM is utilized in the simulation enhanced by a term for following the planned path. We propose a cost evaluation function taking into account metrics involving the distance of the tool from sensitive areas, the tool links maximum pressure on tumors and the robot's dexterity measure. The example of a tumor resection task is used with the simulation tool to demonstrate its use in finding the incision points that ensures minimal intraoperative risks and accurate task execution.",
        "primary_area": "",
        "author": "Kyriakos Almpanidis;Theodora Kastritsi;Zoe Doulgeri;Kyriakos Almpanidis;Theodora Kastritsi;Zoe Doulgeri",
        "authorids": "/37089891899;/37086427599;/37274011500;/37089891899;/37086427599;/37274011500",
        "aff": "Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160936/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3986418109684699204&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "10161489",
        "title": "FingerSLAM: Closed-loop Unknown Object Localization and Reconstruction from Visuo-tactile Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the problem of using visuo-tactile feedback for 6-DoF localization and 3D reconstruction of unknown in-hand objects. We propose FingerSLAM, a closed-loop factor graph-based pose estimator that combines local tactile sensing at finger-tip and global vision sensing from a wrist-mount camera. FingerSLAM is constructed with two constituent pose estimators: a multi-pass refined tactile-based pose estimator that captures movements from detailed local textures, and a single-pass vision-based pose estimator that predicts from a global view of the object. We also design a loop closure mechanism that actively matches current vision and tactile images to previously stored key-frames to reduce accumulated error. FingerSLAM incorporates the two sensing modalities of tactile and vision, as well as the loop closure mechanism with a factor graph-based optimization framework. Such a framework produces an optimized pose estimation solution that is more accurate than the standalone estimators. The estimated poses are then used to reconstruct the shape of the unknown object incrementally by stitching the local point clouds recovered from tactile images. We train our system on real-world data collected with 20 objects. We demonstrate reliable visuo-tactile pose estimation and shape reconstruction through quantitative and qualitative real-world evaluations on 6 objects that are unseen during training.",
        "primary_area": "",
        "author": "Jialiang Zhao;Maria Bauza;Edward H. Adelson;Jialiang Zhao;Maria Bauza;Edward H. Adelson",
        "authorids": "/37089895198;/37086003399;/37349732300;/37089895198;/37086003399;/37349732300",
        "aff": "Mechanical Engineering, Massachusetts Institute of Technology; Mechanical Engineering, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161489/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15199148607151458849&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161136",
        "title": "Fisher Information Based Active Planning for Aerial Photogrammetry",
        "track": "main",
        "status": "Poster",
        "abstract": "Small uncrewed aerial systems (sUASs) are useful tools for 3D reconstruction due to their speed, ease of use, and ability to access high-utility viewpoints. Today, most aerial survey approaches generate a preplanned coverage pattern assuming a planar target region. However, this is inefficient since it results in superfluous overlap and suboptimal viewing angles and does not utilize the entire flight envelope. In this work, we propose active path planning for photogrammetric reconstruction. Our main contribution is a view utility function based on Fisher information approximating the offline reconstruction uncertainty. The metric enables online path planning to make in-flight decisions to collect geometrically informative image data in complex terrain. We evaluate our approach in a photorealistic simulation. A viewpoint selection study shows that our metric leads to faster and more precise reconstruction than state-of-the-art active planning metrics and adapts to different camera resolutions. Comparing our online planning approach to an ordinary fixed-wing aerial survey yields 3.2 \u00d7 faster coverage of 16 ha undulated terrain without sacrificing precision.",
        "primary_area": "",
        "author": "Jaeyoung Lim;Nicholas Lawrance;Florian Achermann;Thomas Stastny;Rik B\u00e4hnemann;Roland Siegwart;Jaeyoung Lim;Nicholas Lawrance;Florian Achermann;Thomas Stastny;Rik B\u00e4hnemann;Roland Siegwart",
        "authorids": "/37089895137;/37571923900;/37086866506;/37085387015;/37086172378;/37281398300;/37089895137;/37571923900;/37086866506;/37085387015;/37086172378;/37281398300",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; The Robotics and Autonomous Systems Group, CSIRO Data61, QLD, Australia; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Auterion AG, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161136/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6423186005321635543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich;CSIRO Data61;Auterion AG",
        "aff_unique_dep": "Autonomous Systems Lab;The Robotics and Autonomous Systems Group;",
        "aff_unique_url": "https://www.ethz.ch;https://www.csiro.au/en/Research/Data61;",
        "aff_unique_abbr": "ETH;CSIRO Data61;",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Z\u00fcrich;QLD;",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "Switzerland;Australia"
    },
    {
        "id": "10160774",
        "title": "Flipbot: Learning Continuous Paper Flipping via Coarse-to-Fine Exteroceptive-Proprioceptive Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper tackles the task of singulating and grasping paper-like deformable objects. We refer to such tasks as paper-flipping. In contrast to manipulating deformable objects that lack compression strength (such as shirts and ropes), minor variations in the physical properties of the paper-like deformable objects significantly impact the results, making manipulation highly challenging. Here, we present Flipbot, a novel solution for flipping paper-like deformable objects. Flipbot allows the robot to capture object physical properties by integrating exteroceptive and proprioceptive perceptions that are indispensable for manipulating deformable objects. Furthermore, by incorporating a proposed coarse-to-fine exploration process, the system is capable of learning the optimal control parameters for effective paper-flipping through proprioceptive and exteroceptive inputs. We deploy our method on a real-world robot with a soft gripper and learn in a self-supervised manner. The resulting policy demonstrates the effectiveness of Flipbot on paper-flipping tasks with various settings beyond the reach of prior studies, including but not limited to flipping pages throughout a book and emptying paper sheets in a box. The code is available here: https://robotll.github.io/Flipbot/.",
        "primary_area": "",
        "author": "Chao Zhao;Chunli Jiang;Junhao Cai;Michael Yu Wang;Hongyu Yu;Qifeng Chen;Chao Zhao;Chunli Jiang;Junhao Cai;Michael Yu Wang;Hongyu Yu;Qifeng Chen",
        "authorids": "/37089447535;/37089640314;/37086455338;/37280913900;/37089893119;/37089895732;/37089447535;/37089640314;/37086455338;/37280913900;/37089893119;/37089895732",
        "aff": "The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian,Shenzhen; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian,Shenzhen; The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160774/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17419155639452239159&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "The Hong Kong University of Science and Technology;Hong Kong University of Science and Technology",
        "aff_unique_dep": ";Collaborative Innovation Research Institute",
        "aff_unique_url": "https://www.ust.hk;https://www.ust.hk",
        "aff_unique_abbr": "HKUST;HKUST",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160977",
        "title": "FloorplanNet: Learning Topometric Floorplan Matching for Robot Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Given a building floorplan, humans can localize themselves by matching the observation of the environment with the floorplan using geometric, semantic, and topological clues. Inspired by this insight, this paper proposes a learning- based topometric robot localization method FloorplanNet, which implements a match between a metric robot map and the potentially inaccurate building floorplan in nonuniform scales and different shapes by semantic information. The method uses a novel Graph Neural Network to learn descriptors of nodes from topometric graphs generated from the input maps. We demonstrate that our method can match the 3D point cloud sub-map generated by the robot during the SLAM process with the 2D map. Furthermore, we apply our map-matching algorithm for real-world robot localization. We evaluate our method on several publicly available real-world datasets. Even though our network is solely trained using simulation data, our method demonstrates high robustness and effectiveness in real- world indoor environments and outperforms the existing SOTA map-matching algorithms. We further develop a simulator that automatically creates and annotates the required training data to train our neural networks. The method and simulator are released at: https://github.com/fengdelin/FloorplanNet.git",
        "primary_area": "",
        "author": "Delin Feng;Zhenpeng He;Jiawei Hou;S\u00f6ren Schwertfeger;Liangjun Zhang;Delin Feng;Zhenpeng He;Jiawei Hou;S\u00f6ren Schwertfeger;Liangjun Zhang",
        "authorids": "/37089328694;/37087244349;/37087245958;/37391715800;/37089893537;/37089328694;/37087244349;/37087245958;/37391715800;/37089893537",
        "aff": "RAL; RAL; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Robotics and Auto-Driving Laboratory (RAL), Baidu Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160977/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16514372035007437591&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;2",
        "aff_unique_norm": "RAL;ShanghaiTech University;Baidu Research",
        "aff_unique_dep": ";School of Information Science and Technology;Robotics and Auto-Driving Laboratory (RAL)",
        "aff_unique_url": ";https://www.shanghaitech.edu.cn;https://baidu.com",
        "aff_unique_abbr": ";ShanghaiTech;Baidu",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "1;1;1",
        "aff_country_unique": ";China"
    },
    {
        "id": "10161430",
        "title": "Flow-Based Rendezvous and Docking for Marine Modular Robots in Gyre-Like Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular self-assembling systems typically assume that modules are present to assemble. But in sparsely observed ocean environments modules of an aquatic modular robotic system may be separated by distances they do not have the energy to cross, and the information needed for optimal path planning is often unavailable. In this work we present a flow-based rendezvous and docking controller that allows aquatic robots in gyre-like environments to rendezvous with and dock to a target by leveraging environmental forces. This approach does not require complete knowledge of the flow, but suffices with imperfect knowledge of the flow's center and shape. We validate the performance of this control approach in both simulations and experiments relative to naive rendezvous and docking strategies and show that energy efficiency improves as the scale of the gyre increases.",
        "primary_area": "",
        "author": "Gedaliah Knizhnik;Peihan Li;Mark Yim;M. Ani Hsieh;Gedaliah Knizhnik;Peihan Li;Mark Yim;M. Ani Hsieh",
        "authorids": "/37086285239;/37089447950;/37274063600;/38238444800;/37086285239;/37089447950;/37274063600;/38238444800",
        "aff": "GRASP Laboratory, University of Pensylvannia, Philadelphia, PA; GRASP Laboratory, University of Pensylvannia, Philadelphia, PA; GRASP Laboratory, University of Pensylvannia, Philadelphia, PA; GRASP Laboratory, University of Pensylvannia, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161430/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16761051567729411622&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160454",
        "title": "FlowDrone: Wind Estimation and Gust Rejection on UAVs Using Fast-Response Hot-Wire Flow Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned aerial vehicles (UAVs) are finding use in applications that place increasing emphasis on robustness to external disturbances including extreme wind. However, traditional multirotor UAV platforms do not directly sense wind; conventional flow sensors are too slow, insensitive, or bulky for widespread integration on UAVs. Instead, drones typically observe the effects of wind indirectly through accumulated errors in position or trajectory tracking. In this work, we integrate a novel flow sensor based on micro-electro-mechanical systems (MEMS) hot-wire technology developed in our prior work [1] onto a multirotor UAV for wind estimation. Our sensor is omnidirectional (in the plane), lightweight, fast, and accurate. In order to achieve superior hover performance in windy conditions, we train a \u2018wind-aware\u2019 residual-based controller via reinforcement learning using simulated wind gusts and their aerodynamic effects on the drone. In extensive hardware experiments, we demonstrate the wind-aware controller out-performing two strong \u2018wind-unaware\u2019 baseline controllers in challenging windy conditions. See: youtu.be/KWqkH9Z-338.",
        "primary_area": "",
        "author": "Nathaniel Simon;Allen Z. Ren;Alexander Piqu\u00e9;David Snyder;Daphne Barretto;Marcus Hultmark;Anirudha Majumdar;Nathaniel Simon;Allen Z. Ren;Alexander Piqu\u00e9;David Snyder;Daphne Barretto;Marcus Hultmark;Anirudha Majumdar",
        "authorids": "/37089894767;/37089231729;/37089894904;/37089896089;/37089891890;/37089895309;/37086027485;/37089894767;/37089231729;/37089894904;/37089896089;/37089891890;/37089895309;/37086027485",
        "aff": "Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ; Department of Computer Science, Princeton University, Princeton, NJ; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160454/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8259375807788233758&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Princeton",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161326",
        "title": "FlowMap: Path Generation for Automated Vehicles in Open Space Using Traffic Flow",
        "track": "main",
        "status": "Poster",
        "abstract": "There is extensive literature on perceiving road structures by fusing various sensor inputs such as lidar point clouds and camera images using deep neural nets. Leveraging the latest advance of neural architects (such as transformers) and bird-eye-view (BEV) representation, the road cognition accuracy keeps improving. However, how to cognize the \u201croad\u201d for automated vehicles where there is no well-defined \u201croads\u201d remains an open problem. For example, how to find paths inside intersections without HD maps is hard since there is neither an explicit definition for \u201croads\u201d nor explicit features such as lane markings. The idea of this paper comes from a proverb: it becomes a way when people walk on it. Although there are no \u201croads\u201d from sensor readings, there are \u201croads\u201d from tracks of other vehicles. In this paper, we propose FlowMap, a path generation framework for automated vehicles based on traffic flows. FlowMap is built by extending our previous work RoadMap [1], a light-weight semantic map, with an additional traffic flow layer. A path generation algorithm on traffic flow fields (TFFs) is proposed to generate human-like paths. The proposed framework is validated using real-world driving data and is amenable to generating paths for super complicated intersections without using HD maps.",
        "primary_area": "",
        "author": "Wenchao Ding;Jieru Zhao;Yubin Chu;Haihui Huang;Tong Qin;Chunjing Xu;Yuxiang Guan;Zhongxue Gan;Wenchao Ding;Jieru Zhao;Yubin Chu;Haihui Huang;Tong Qin;Chunjing Xu;Yuxiang Guan;Zhongxue Gan",
        "authorids": "/37086295360;/37086280541;/37089447486;/37089893563;/37086218149;/37088215580;/37089892504;/37087467032;/37086295360;/37086280541;/37089447486;/37089893563;/37086218149;/37088215580;/37089892504;/37087467032",
        "aff": "Academy for Engineering and Technology, Fudan University, China; Dept. of Computer Science and Engineering, Shanghai Jiao Tong University, China; IAS BU Smart Driving Product Dept, Huawei Technologies, China; IAS BU Smart Driving Product Dept, Huawei Technologies, China; IAS BU Smart Driving Product Dept, Huawei Technologies, China; IAS BU Smart Driving Product Dept, Huawei Technologies, China; Academy for Engineering and Technology, Fudan University, China; Academy for Engineering and Technology, Fudan University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161326/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11900679605803911432&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;2;2;2;0;0",
        "aff_unique_norm": "Fudan University;Shanghai Jiao Tong University;Huawei Technologies",
        "aff_unique_dep": "Academy for Engineering and Technology;Dept. of Computer Science and Engineering;Smart Driving Product Dept",
        "aff_unique_url": "https://www.fudan.edu.cn;https://www.sjtu.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "Fudan;SJTU;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161366",
        "title": "Focused Adaptation of Dynamics Models for Deformable Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to efficiently learn a dynamics model for a task in a new environment, one can adapt a model learned in a similar source environment. However, existing adaptation methods can fail when the target dataset contains transitions where the dynamics are very different from the source environment. For example, the source environment dynamics could be of a rope manipulated in free space, whereas the target dynamics could involve collisions and deformation on obstacles. Our key insight is to improve data efficiency by focusing model adaptation on only the regions where the source and target dynamics are similar. In the rope example, adapting the free-space dynamics requires significantly less data than adapting the free-space dynamics while also learning collision dynamics. We propose a new method for adaptation that is effective in adapting to regions of similar dynamics. Additionally, we combine this adaptation method with prior work on planning with unreliable dynamics to make a method for data-efficient online adaptation, called FOCUS. We first demonstrate that the proposed adaptation method achieves statistically significantly lower prediction error in regions of similar dynamics on simulated rope manipulation and plant watering tasks. We then show on a bimanual rope manipulation task that FOCUS achieves data-efficient online learning, in simulation and in the real world.",
        "primary_area": "",
        "author": "Peter Mitrano;Alex LaGrassa;Oliver Kroemer;Dmitry Berenson;Peter Mitrano;Alex LaGrassa;Oliver Kroemer;Dmitry Berenson",
        "authorids": "/37087091650;/37088689868;/37593222300;/37542925700;/37087091650;/37088689868;/37593222300;/37542925700",
        "aff": "Department of Robotics, University of Michigan, United States; Robotics Institute, Carnegie Mellon University, United States; Robotics Institute, Carnegie Mellon University, United States; Department of Robotics, University of Michigan, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161366/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9308424654648284935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Michigan;Carnegie Mellon University",
        "aff_unique_dep": "Department of Robotics;Robotics Institute",
        "aff_unique_url": "https://www.umich.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UM;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161307",
        "title": "FogROS2: An Adaptive Platform for Cloud and Fog Robotics Using ROS 2",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobility, power, and price points often dictate that robots do not have sufficient computing power on board to run contemporary robot algorithms at desired rates. Cloud computing providers such as AWS, GCP, and Azure offer immense computing power and increasingly low latency on demand, but tapping into that power from a robot is non-trivial. We present FogROS2, an open-source platform to facilitate cloud and fog robotics that is included in the Robot Operating System 2 (ROS 2) distribution. FogROS2 is distinct from its predecessor FogROS1 in 9 ways, including lower latency, overhead, and startup times; improved usability, and additional automation, such as region and computer type selection. Additionally, FogROS2 gains performance, timing, and additional improvements associated with ROS 2. In common robot applications, FogROS2 reduces SLAM latency by 50 %, reduces grasp planning time from 14 s to 1.2 s, and speeds up motion planning 45x. When compared to FogROS1, FogROS2 reduces network utilization by up to 3.8x, improves startup time by 63 %, and network round-trip latency by 97 % for images using video compression. The source code, examples, and documentation for FogROS2 are available at https://github.com/BerkeleyAutomation/FogROS2, and is available through the official ROS 2 repository at https://index.ros.org/p/FogROS2/.",
        "primary_area": "",
        "author": "Jeffrey Ichnowski;Kaiyuan Chen;Karthik Dharmarajan;Simeon Adebola;Michael Danielczuk;V\u00edctor Mayoral-Vilches;Nikhil Jha;Hugo Zhan;Edith Llontop;Derek Xu;Camilo Buscaron;John Kubiatowicz;Ion Stoica;Joseph Gonzalez;Ken Goldberg;Jeffrey Ichnowski;Kaiyuan Chen;Karthik Dharmarajan;Simeon Adebola;Michael Danielczuk;V\u00edctor Mayoral-Vilches;Nikhil Jha;Hugo Zhan;Edith Llontop;Derek Xu;Camilo Buscaron;John Kubiatowicz;Ion Stoica;Joseph Gonzalez;Ken Goldberg",
        "authorids": "/38541287200;/37089893936;/37089579801;/37089005515;/37086541913;/37088594953;/37088986945;/37089895408;/37089896079;/37089894723;/37089894171;/37271987200;/37284373600;/37086566024;/37273026700;/38541287200;/37089893936;/37089579801;/37089005515;/37086541913;/37088594953;/37088986945;/37089895408;/37089896079;/37089894723;/37089894171;/37271987200;/37284373600;/37086566024;/37273026700",
        "aff": "The AUTOLab, UC Berkeley; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; System Security Group, Universit\u00e4t Klagenfurt, Klagenfurt, Austria; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; The AUTOLab, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161307/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17206758037625904613&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 30,
        "aff_unique_index": "0;0;0;0;0;1;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley;Universit\u00e4t Klagenfurt",
        "aff_unique_dep": "The AUTOLab;System Security Group",
        "aff_unique_url": "https://www.berkeley.edu;https://www.aau.at",
        "aff_unique_abbr": "UC Berkeley;",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley;Klagenfurt",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States;Austria"
    },
    {
        "id": "10160953",
        "title": "Follow The Rules: Online Signal Temporal Logic Tree Search for Guided Imitation Learning in Stochastic Domains",
        "track": "main",
        "status": "Poster",
        "abstract": "Seamlessly integrating rules in Learning-from-Demonstrations (LfD) policies is a critical requirement to enable the real-world deployment of AI agents. Recently, Signal Temporal Logic (STL) has been shown to be an effective language for encoding rules as spatio-temporal constraints. This work uses Monte Carlo Tree Search (MCTS) as a means of integrating STL specification into a vanilla LfD policy to improve constraint satisfaction. We propose augmenting the MCTS heuristic with STL robustness values to bias the tree search towards branches with higher constraint satisfaction. While the domain-independent method can be applied to integrate STL rules online into any pre-trained LfD algorithm, we choose goal-conditioned Generative Adversarial Imitation Learning as the offline LfD policy. We apply the proposed method to the domain of planning trajectories for General Aviation aircraft around a non-towered airfield. Results using the simulator trained on real-world data showcase 60% improved performance over baseline LfD methods that do not use STL heuristics. [Code]11Codebase: https://github.com/castacks/mcts-stl-planning [Video]22Video: https://youtu.be/fiFCwc57MQs",
        "primary_area": "",
        "author": "Jasmine Jerry Aloor;Jay Patrikar;Parv Kapoor;Jean Oh;Sebastian Scherer;Jasmine Jerry Aloor;Jay Patrikar;Parv Kapoor;Jean Oh;Sebastian Scherer",
        "authorids": "/37089895998;/37086449345;/37089894255;/37933996900;/37584159000;/37089895998;/37086449345;/37089894255;/37933996900;/37584159000",
        "aff": "Department of Aerospace Engineering, Indian Institute of Technology, Carnegie Mellon University, Kharagpur, WB, India; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160953/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17483969107248735785&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Indian Institute of Technology Kharagpur;Carnegie Mellon University",
        "aff_unique_dep": "Department of Aerospace Engineering;Robotics Institute",
        "aff_unique_url": "https://www.iitkgp.ac.in;https://www.cmu.edu",
        "aff_unique_abbr": "IIT Kharagpur;CMU",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Kharagpur;Pittsburgh",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "10160297",
        "title": "Foot Stepping Algorithm of Humanoids with Double Support Time Adjustment based on Capture Point Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, foot stepping strategies of humanoid robots have been actively developed for robust balancing of humanoids against disturbances. In this paper, a novel stepping algorithm adjusting double support phase (DSP) time is proposed. First, the stepping algorithm is proposed based on a model predictive control (MPC) framework for capture point (CP) control and footstep adjustment. Next, when the remaining step time is not enough to adjust the footstep, the DSP scaling method brings the next swing phase forward by reducing the DSP time, which enables the robot to maintain the balance robustly. The robust balance control performance of the proposed method is validated through simulations and experiments when the robot is walking in the presence of external pushes. A more stable balancing performance is realized compared to state-of-the-art stepping controllers.",
        "primary_area": "",
        "author": "Myeong-Ju Kim;Daegyu Lim;Gyeongjae Park;Jaeheung Park;Myeong-Ju Kim;Daegyu Lim;Gyeongjae Park;Jaeheung Park",
        "authorids": "/37089659059;/37086934345;/37089663810;/37281014000;/37089659059;/37086934345;/37089663810;/37281014000",
        "aff": "Department of Intelligence and Information, Seoul National University, Republic of Korea; Department of Intelligence and Information, Seoul National University, Republic of Korea; Department of Intelligence and Information, Seoul National University, Republic of Korea; ASRI, RICS, Seoul National University, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160297/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11301085393592466774&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Intelligence and Information",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160368",
        "title": "Foot gestures to control the grasping of a surgical robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Many surgical tasks require three or more tools working together, where a hands-free interface could extend a surgeon's actions to control a third surgical tool. However, most current interfaces do not allow skilled control of grasping critical to robotic manipulation. Here we first present a systematic study to identify efficient and intuitive interaction strategies to control grasping of a surgical tool. A series of experiments were conducted to evaluate six foot pressure-based gestures. Based on the results, three modular novel foot-machine interfaces were developed, which can be integrated with other motion control interfaces. The identified interaction strategies were implemented to control a laparoscopic tool in a surgical simulator, and evaluated in a user study. The results illustrate how naive participants can operate grasping yielding smooth and pick & place operation.",
        "primary_area": "",
        "author": "Yijun Cheng;Yanpei Huang;Ziwei Wang;Etienne Burdet;Yijun Cheng;Yanpei Huang;Ziwei Wang;Etienne Burdet",
        "authorids": "/37089894166;/37086914602;/37086179280;/37275851600;/37089894166;/37086914602;/37086179280;/37275851600",
        "aff": "Department of Bioengineering, Imperial College of Science, Technology and Medicine, London, UK; Department of Bioengineering, Imperial College of Science, Technology and Medicine, London, UK; School of Engineering, Lancaster University, Lancaster, UK; Department of Bioengineering, Imperial College of Science, Technology and Medicine, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160368/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3934880571756418314&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Imperial College of Science, Technology and Medicine;Lancaster University",
        "aff_unique_dep": "Department of Bioengineering;School of Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.lancaster.ac.uk",
        "aff_unique_abbr": "Imperial College;Lancaster",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "London;Lancaster",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161080",
        "title": "Force control for Robust Quadruped Locomotion: A Linear Policy Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a simple linear policy for direct force control for quadrupedal robot locomotion. The motivation is that force control is essential for highly dynamic and agile motions. We learn a linear policy to generate end-foot trajectory parameters and a centroidal wrench, which is then distributed among the legs based on the foot contact information using a quadratic program (QP) to get the desired ground reaction forces. Unlike the majority of the existing works that use complex nonlinear function approximators to represent the RL policy or model predictive control (MPC) methods with many optimization variables in the order of hundred, our controller uses a simple linear function approximator to represent policy along with only a twelve variable QP for the force distribution. A centroidal dynamics-based MPC method is used to generate reference trajectory data, and then the linear policy is trained using imitation learning to minimize the deviations from the reference trajectory. We demonstrate this compute-efficient controller on our robot Stoch3 in simulation and real-world experiments on indoor and outdoor terrains with push recovery.",
        "primary_area": "",
        "author": "Aditya Shirwatkar;Vamshi Kumar Kurva;Devaraju Vinoda;Aman Singh;Aditya Sagi;Himanshu Lodha;Bhavya Giri Goswami;Shivam Sood;Ketan Nehete;Shishir Kolathaya;Aditya Shirwatkar;Vamshi Kumar Kurva;Devaraju Vinoda;Aman Singh;Aditya Sagi;Himanshu Lodha;Bhavya Giri Goswami;Shivam Sood;Ketan Nehete;Shishir Kolathaya",
        "authorids": "/37089892963;/37089893135;/37089892402;/37089448031;/37087235772;/37089448522;/37089892237;/37089749736;/37089893702;/37060909000;/37089892963;/37089893135;/37089892402;/37089448031;/37087235772;/37089448522;/37089892237;/37089749736;/37089893702;/37060909000",
        "aff": "Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bengaluru; Department of Computer Science & Automation, Indian Institute of Science, Bengaluru; Department of Computer Science & Automation, Indian Institute of Science, Bengaluru; Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bengaluru; Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bengaluru; Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bengaluru; Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bengaluru; Indian Institute of Technology, Kharagpur; Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bengaluru; Department of Computer Science & Automation, Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bengaluru",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161080/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9442031920529633441&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Indian Institute of Science;Indian Institute of Technology",
        "aff_unique_dep": "Robert Bosch Center for Cyber Physical Systems;",
        "aff_unique_url": "https://www.iisc.ac.in;https://www.iitkgp.ac.in",
        "aff_unique_abbr": "IISc;IIT Kharagpur",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Bengaluru;Kharagpur",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "10161257",
        "title": "Force/Torque Sensing for Soft Grippers using an External Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulation can benefit from wrist-mounted force/torque (F/T) sensors, but conventional F/T sensors can be expensive, difficult to install, and damaged by high loads. We present Visual Force/Torque Sensing (VFTS), a method that visually estimates the 6-axis F/T measurement that would be reported by a conventional F/T sensor. In contrast to approaches that sense loads using internal cameras placed behind soft exterior surfaces, our approach uses an external camera with a fisheye lens that observes a soft gripper. VFTS includes a deep learning model that takes a single RGB image as input and outputs a 6-axis F/T estimate. We trained the model with sensor data collected while teleoperating a robot (Stretch RE1 from Hello Robot Inc.) to perform manipulation tasks. VFTS outperformed F/T estimates based on motor currents, generalized to a novel home environment, and supported three autonomous tasks relevant to healthcare: grasping a blanket, pulling a blanket over a manikin, and cleaning a manikin's limbs. VFTS also performed well with a manually operated pneumatic gripper. Overall, our results suggest that an external camera observing a soft gripper can perform useful visual force/torque sensing for a variety of manipulation tasks.",
        "primary_area": "",
        "author": "Jeremy A. Collins;Patrick Grady;Charles C. Kemp;Jeremy A. Collins;Patrick Grady;Charles C. Kemp",
        "authorids": "/37089282224;/37087231294;/37266709400;/37089282224;/37087231294;/37266709400",
        "aff": "Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology (GT); Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology (GT); Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology (GT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161257/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11728700263216441286&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "GT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160741",
        "title": "Forming and Controlling Hitches in Midair Using Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of cables for aerial manipulation has shown to be a lightweight and versatile way to interact with objects. However, fastening objects using cables is still a challenge and human is required. In this work, we propose a novel way to secure objects using hitches. The hitch can be formed and morphed in midair using a team of aerial robots with cables. The hitch's shape is modeled as a convex polygon, making it versatile and adaptable to a wide variety of objects. We propose an algorithm to form the hitch systematically. The steps can run in parallel, allowing hitches with a large number of robots to be formed in constant time. We develop a set of actions that include different actions to change the shape of the hitch. We demonstrate our methods using a team of aerial robots via simulation and actual experiments.",
        "primary_area": "",
        "author": "Diego S. D\u2019Antonio;Subhrajit Bhattacharya;David Salda\u00f1a;Diego S. D\u2019Antonio;Subhrajit Bhattacharya;David Salda\u00f1a",
        "authorids": "/37088760719;/37534178000;/38543033800;/37088760719;/37534178000;/38543033800",
        "aff": "Autonomous and Intelligent Robotics Laboratory -AIRLab-, Lehigh University, Bethlehem, PA, USA; Autonomous and Intelligent Robotics Laboratory -AIRLab-, Lehigh University, Bethlehem, PA, USA; Autonomous and Intelligent Robotics Laboratory -AIRLab-, Lehigh University, Bethlehem, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160741/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10184591655003454012&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Lehigh University",
        "aff_unique_dep": "Autonomous and Intelligent Robotics Laboratory -AIRLab-",
        "aff_unique_url": "https://www.lehigh.edu",
        "aff_unique_abbr": "Lehigh",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bethlehem",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161363",
        "title": "FourStr: When Multi-sensor Fusion Meets Semi-supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This research proposes a novel semi-supervised learning framework FourStr (Four-Stream formed by two two-stream models) that focuses on the improvement of fusion and labeling efficiency for 3D multi-sensor detector. FourStr adopts a multi-sensor single-stage detector named adaptive fusion network (AFNet) as the backbone and trains it through the semi-supervision learning (SSL) strategy Stereo Fusion. Note that multi-sensor AFNet and SSL Stereo Fusion can benefit each other. On the one hand, the Four-stream composed of two AFNets naturally provides rich inputs and large models for SSL Stereo Fusion. While other SSL works have to use massive augmentation to obtain rich inputs, and deepen and widen the network for large models. On the other hand, by the novel three fusion stages and Loss Pruning, Stereo Fusion improves the fusion and labeling efficiency for AFNet. Finally, extensive experiments demonstrate that FourStr performs excellently on outdoor dataset (KITTI and Waymo Open Dataset) and indoor dataset (SUN RGB-D), especially for the small contour objects. And compared to the fully-supervised methods, FourStr achieves similar accuracy with only 2% labeled data on KITTI (or with 50% labeled data on SUN RGB-D).",
        "primary_area": "",
        "author": "Bangquan Xie;Liang Yang;Zongming Yang;Ailin Wei;Xiaoxiong Weng;Bing Li;Bangquan Xie;Liang Yang;Zongming Yang;Ailin Wei;Xiaoxiong Weng;Bing Li",
        "authorids": "/37089479613;/37085495533;/37089480564;/37089481312;/37086188826;/37405869400;/37089479613;/37085495533;/37089480564;/37089481312;/37086188826;/37405869400",
        "aff": "Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC, USA; City College of New York, New York, USA; Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC, USA; Department of Bioengineering, Clemson University, Clemson, SC, USA; School of Civil Engineering and Transportation at South China University of Technology, Guangzhou, China; Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161363/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=133808640008877054&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;0",
        "aff_unique_norm": "Clemson University;City College of New York;South China University of Technology",
        "aff_unique_dep": "Department of Automotive Engineering;;School of Civil Engineering and Transportation",
        "aff_unique_url": "https://www.clemson.edu;https://www.ccny.cuny.edu;http://www.scut.edu.cn",
        "aff_unique_abbr": "Clemson;CCNY;SCUT",
        "aff_campus_unique_index": "0;1;0;2;3;0",
        "aff_campus_unique": "Greenville;New York;Clemson;Guangzhou",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "10161142",
        "title": "FreDSNet: Joint Monocular Depth and Semantic Segmentation with Fast Fourier Convolutions from Single Panoramas",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we present FreDSNet, a deep learning solution which obtains semantic 3D understanding of indoor environments from single panoramas. Omnidirectional images reveal task-specific advantages when addressing scene understanding problems due to the 360-degree contextual information about the entire environment they provide. However, the inherent characteristics of the omnidirectional images add additional problems to obtain an accurate detection and segmentation of objects or a good depth estimation. To overcome these problems, we exploit convolutions in the frequential domain obtaining a wider receptive field in each convolutional layer. These convolutions allow to leverage the whole context information from omnidirectional images. FreDSNet is the first network that jointly provides monocular depth estimation and semantic segmentation from a single panoramic image exploiting fast Fourier convolutions. Our experiments show that FreDSNet has slight better performance than the sole state-of-the-art method that obtains both semantic segmentation and depth estimation from panoramas. FreDSNet code is publicly available in https://github.com/Sbrunoberenguel/FreDSNet",
        "primary_area": "",
        "author": "Bruno Berenguel-Baeta;Jesus Bermudez-Cameo;Jose J. Guerrero;Bruno Berenguel-Baeta;Jesus Bermudez-Cameo;Jose J. Guerrero",
        "authorids": "/37088645233;/37085568777;/37533721000;/37088645233;/37085568777;/37533721000",
        "aff": "Instituto de Investigacion en Ingenieria de Aragon, I3A, Universidad de Zaragoza, Spain; Instituto de Investigacion en Ingenieria de Aragon, I3A, Universidad de Zaragoza, Spain; Instituto de Investigacion en Ingenieria de Aragon, I3A, Universidad de Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161142/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9810938687092282718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Instituto de Investigacion en Ingenieria de Aragon, I3A",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10160447",
        "title": "From Concept to Field Tests: Accelerated Development of Multi-AUV Missions Using a High-Fidelity Faster-than-Real-Time Simulator",
        "track": "main",
        "status": "Poster",
        "abstract": "We designed and validated a novel simulator for efficient development of multi-robot marine missions. To accelerate development of cooperative behaviors, the simulator models the robots' operating conditions with moderately high fidelity and runs significantly faster than real time, including acoustic communications, dynamic environmental data, and high-resolution bathymetry in large worlds. The simulator's ability to exceed a real-time factor (RTF) of 100 has been stress-tested with a robust continuous integration suite and was used to develop a multi-robot field experiment.",
        "primary_area": "",
        "author": "Timothy R. Player;Arjo Chakravarty;Mabel M. Zhang;Ben Yair Raanan;Brian Kieft;Yanwu Zhang;Brett Hobson;Timothy R. Player;Arjo Chakravarty;Mabel M. Zhang;Ben Yair Raanan;Brian Kieft;Yanwu Zhang;Brett Hobson",
        "authorids": "/37089550665;/37089895213;/37089625436;/37085702225;/37592480100;/37405821800;/37590308300;/37089550665;/37089895213;/37089625436;/37085702225;/37592480100;/37405821800;/37590308300",
        "aff": "Oregon State University, Corvallis, Oregon, USA; Singapore University of Technology and Design, Singapore; Open Robotics, Mountain View, California, USA; Monterey Bay Aquarium Research Institute, California, USA; Monterey Bay Aquarium Research Institute, California, USA; Monterey Bay Aquarium Research Institute, California, USA; Monterey Bay Aquarium Research Institute, California, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160447/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3097102593496239067&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;3;3;3",
        "aff_unique_norm": "Oregon State University;Singapore University of Technology and Design;Open Robotics;Monterey Bay Aquarium Research Institute",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://oregonstate.edu;https://www.sutd.edu.sg;https://openrobotics.org;https://www.mbARI.org",
        "aff_unique_abbr": "OSU;SUTD;;MBARI",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Corvallis;;Mountain View",
        "aff_country_unique_index": "0;1;0;0;0;0;0",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "10161273",
        "title": "From Semi-supervised to Omni-supervised Room Layout Estimation Using Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Room layout estimation is a long-existing robotic vision task that benefits both environment sensing and motion planning. However, layout estimation using point clouds (PCs) still suffers from data scarcity due to annotation difficulty. As such, we address the semi-supervised setting of this task based upon the idea of model exponential moving averaging. But adapting this scheme to the state-of-the-art (SOTA) solution for PC-based layout estimation is not straightforward. To this end, we define a quad set matching strategy and several consistency losses based upon metrics tailored for layout quads. Besides, we propose a new online pseudo-label harvesting algorithm that decomposes the distribution of a hybrid distance measure between quads and PC into two components. This technique does not need manual threshold selection and intuitively encourages quads to align with reliable layout points. Surprisingly, this framework also works for the fully-supervised setting, achieving a new SOTA on the ScanNet benchmark. Last but not least, we also push the semi-supervised setting to the realistic omni-supervised setting, demonstrating significantly promoted performance on a newly annotated ARKitScenes testing set. Our codes, data and models are made publicly available**Code: https://github.com/AIR-DISCOVER/Omni-PQ.",
        "primary_area": "",
        "author": "Huan-ang Gao;Beiwen Tian;Pengfei Li;Xiaoxue Chen;Hao Zhao;Guyue Zhou;Yurong Chen;Hongbin Zha;Huan-ang Gao;Beiwen Tian;Pengfei Li;Xiaoxue Chen;Hao Zhao;Guyue Zhou;Yurong Chen;Hongbin Zha",
        "authorids": "/37089892178;/37089895365;/37089893178;/37088774147;/37086217629;/37085489402;/37407084900;/37271683200;/37089892178;/37089895365;/37089893178;/37088774147;/37086217629;/37085489402;/37407084900;/37271683200",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Intel Labs, China; Peking University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161273/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13612804322296467315&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;2",
        "aff_unique_norm": "Tsinghua University;Intel Labs;Peking University",
        "aff_unique_dep": "Institute for AI Industry Research (AIR);;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.intel.com/content/www/us/en/research/labs.html;http://www.pku.edu.cn",
        "aff_unique_abbr": "Tsinghua;Intel;Peking U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161059",
        "title": "Frontier Semantic Exploration for Visual Target Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work focuses on the problem of visual target navigation, which is very important for autonomous robots as it is closely related to high-level tasks. To find a special object in unknown environments, classical and learning-based approaches are fundamental components of navigation that have been investigated thoroughly in the past. However, due to the difficulty in the representation of complicated scenes and the learning of the navigation policy, previous methods are still not adequate, especially for large unknown scenes. Hence, we propose a novel framework for visual target navigation using the frontier semantic policy. In this proposed framework, the semantic map and the frontier map are built from the current observation of the environment. Using the features of the maps and object category, deep reinforcement learning enables to learn a frontier semantic policy which can be used to select a frontier cell as a long-term goal to explore the environment efficiently. Experiments on Gibson and Habitat-Matterport 3D (HM3D) demonstrate that the proposed framework significantly outperforms existing map-based methods in terms of success rate and efficiency. Ablation analysis also indicates that the proposed approach learns a more efficient exploration policy based on the frontiers. A demonstration is provided to verify the applicability of applying our model to real-world transfer. The supplementary video and code can be accessed via the following link: https://sites.google.com/view/fsevn.",
        "primary_area": "",
        "author": "Bangguo Yu;Hamidreza Kasaei;Ming Cao;Bangguo Yu;Hamidreza Kasaei;Ming Cao",
        "authorids": "/37088464424;/37088515518;/37293296100;/37088464424;/37088515518;/37293296100",
        "aff": "the Faculty of Science and Engineering, University of Groningen, Groningen, the Netherlands; the Faculty of Science and Engineering, University of Groningen, Groningen, the Netherlands; the Faculty of Science and Engineering, University of Groningen, Groningen, the Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161059/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15101169833633986623&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Groningen",
        "aff_unique_dep": "Faculty of Science and Engineering",
        "aff_unique_url": "https://www.rug.nl",
        "aff_unique_abbr": "RUG",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Groningen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10161350",
        "title": "Fruit Tracking Over Time Using High-Precision Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Monitoring the traits of plants and fruits is a fundamental task in horticulture. With accurate measurements, farmers can predict the yield of their crops and use this information for making informed management decisions, and breeders can use it for variety selection. Agricultural robotic applications promise to automate this monitoring task. In this paper, we address the problem of monitoring fruit growth and investigate the matching of fruits recorded in commercial greenhouses at different growth stages based on data recorded from terrestrial laser scanners. This is challenging as fruits appear highly similar, change over time, and are subject to severe occlusions. We first propose a fruit descriptor, which captures the topology of the fruit surroundings to facilitate the matching between different points in time. We capture and describe the relationship between a fruit and its neighbors such that our descriptors are less affected by the growth over time. Furthermore, we define a matching cost function and use an optimal assignment algorithm to match the fruit observations taken in different weeks. The experiments show that our descriptor achieves a high spatio-temporal matching accuracy, which is superior to the commonly used geometric point cloud descriptors.",
        "primary_area": "",
        "author": "Alessandro Riccardi;Shane Kelly;Elias Marks;Federico Magistri;Tiziano Guadagnino;Jens Behley;Maren Bennewitz;Cyrill Stachniss;Alessandro Riccardi;Shane Kelly;Elias Marks;Federico Magistri;Tiziano Guadagnino;Jens Behley;Maren Bennewitz;Cyrill Stachniss",
        "authorids": "/37089894973;/37089893367;/37089447007;/37086805350;/37087324270;/37593243900;/37324765000;/37329668600;/37089894973;/37089893367;/37089447007;/37086805350;/37087324270;/37593243900;/37324765000;/37329668600",
        "aff": "University of Bonn, DE., Germany; ETH Zurich, CH, Switzerland; University of Bonn, DE., Germany; University of Bonn, DE., Germany; University of Bonn, DE., Germany; University of Bonn, DE., Germany; University of Bonn, DE., Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, DE, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161350/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9680840479579660534&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;0;0;0;2",
        "aff_unique_norm": "University of Bonn;ETH Zurich;Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.ethz.ch;",
        "aff_unique_abbr": "UBonn;ETHZ;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0;0;0;0",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "10161148",
        "title": "Fully Robotized 3D Ultrasound Image Acquisition for Artery",
        "track": "main",
        "status": "Poster",
        "abstract": "Current imaging of the artery relies primarily on computed tomography angiography (CTA), which requires contrast injections and exposure to radiation. In this paper, we present a method for fully autonomous artery 3D image acquisition using a linear ultrasound (US) probe and a 6 DoFs robot arm with a 3D camera. Robotic vessel acquisition can minimize tissue deformation and permit the reproduction of scans. Additionally, the robotic-based acquisition can provide more precise vessel position data that can be utilized for 3D reconstruction as a preoperative image. The first scanning point is determined by the 3D camera using a neural network for leg area estimation. A visual servo algorithm adjusts the in-plane motions using a cross-sectional vessel segmentation produced by a neural network with a UNet structure, while a US confidence map regulates the in-plane rotation. The robot is equipped with impedance control to maintain a constant and safe scan. Experiments on a leg phantom and a volunteer indicate that the robot can follow the vessel and modify its position to provide a sharper US image. The average error of phantom scanning in y-axis and z-axis are 0.2536mm and 0.2928mm, respectively, while the root means square error (RMSE) of contact force in the volunteer experiment is 0.2664N. In addition, a 3D vessel reconstruction demonstrates the possibility of robotic US acquisition as a preoperative image.",
        "primary_area": "",
        "author": "Mingcong Chen;Yuanrui Huang;Jian Chen;Tongxi Zhou;Jiuan Chen;Hongbin Liu;Mingcong Chen;Yuanrui Huang;Jian Chen;Tongxi Zhou;Jiuan Chen;Hongbin Liu",
        "authorids": "/37089895490;/37089894502;/37089893250;/37089892103;/37089893156;/37537718900;/37089895490;/37089894502;/37089893250;/37089892103;/37089893156;/37537718900",
        "aff": "Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science and Innovation, Chinese Academy of Sciences, Hong Kong; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161148/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7966958185057875355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;2;3",
        "aff_unique_norm": "Hong Kong Institute of Science and Innovation, Chinese Academy of Sciences;University of Chinese Academy of Sciences;Chinese Academy of Sciences;King's College London",
        "aff_unique_dep": "Centre for Artificial Intelligence and Robotics;School of Artificial Intelligence;Institute of Automation;School of Biomedical Engineering and Imaging Sciences",
        "aff_unique_url": ";http://www.ucas.ac.cn;http://www.ia.cas.cn;https://www.kcl.ac.uk",
        "aff_unique_abbr": ";UCAS;CAS;KCL",
        "aff_campus_unique_index": "0;1;1;1;1;2",
        "aff_campus_unique": "Hong Kong;Beijing;London",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10160681",
        "title": "Fusing Event-based Camera and Radar for SLAM Using Spiking Neural Networks with Continual STDP Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a first-of-its-kind SLAM architecture fusing an event-based camera and a Frequency Modulated Continuous Wave (FMCW) radar for drone navigation. Each sensor is processed by a bio-inspired Spiking Neural Network (SNN) with continual Spike-Timing-Dependent Plasticity (STDP) learning, as observed in the brain. In contrast to most learning-based SLAM systems, our method does not require any offline training phase, but rather the SNN continuously learns features from the input data on the fly via STDP. At the same time, the SNN outputs are used as feature descriptors for loop closure detection and map correction. We conduct numerous experiments to benchmark our system against state-of-the-art RGB methods and we demonstrate the robustness of our DVS-Radar SLAM approach under strong lighting variations.",
        "primary_area": "",
        "author": "Ali Safa;Tim Verbelen;Ilja Ocket;Andr\u00e9 Bourdoux;Hichem Sahli;Francky Catthoor;Georges Gielen;Ali Safa;Tim Verbelen;Ilja Ocket;Andr\u00e9 Bourdoux;Hichem Sahli;Francky Catthoor;Georges Gielen",
        "authorids": "/37088969150;/37072400100;/37303047100;/37296640900;/37273821300;/37275971400;/37275184800;/37088969150;/37072400100;/37303047100;/37296640900;/37273821300;/37275971400;/37275184800",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160681/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6358736378099290939&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14
    },
    {
        "id": "10161098",
        "title": "Fusion of Events and Frames using 8-DOF Warping Model for Robust Feature Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Event cameras are asynchronous neuromorphic vision sensors with high temporal resolution and no motion blur, offering advantages over standard frame-based cameras especially in high-speed motions and high dynamic range conditions. However, event cameras are unable to capture the overall context of the scene, and produce different events for the same scenery depending on the direction of the motion, creating a challenge in data association. Standard camera, on the other hand, provides frames at a fixed rate that are independent of the motion direction, and are rich in context. In this paper, we present a robust feature tracking method that employs 8-DOF warping model in minimizing the difference between brightness increment patches from events and frames, exploiting the complementary nature of the two data types. Unlike previous works, the proposed method enables tracking of features under complex motions accompanying distortions. Extensive quantitative evaluation over publicly available datasets was performed where our method shows an improvement over state-of-the-art methods in robustness with greatly prolonged feature age and in accuracy for challenging scenarios.",
        "primary_area": "",
        "author": "Min Seok Lee;Ye Jun Kim;Jae Hyung Jung;Chan Gook Park;Min Seok Lee;Ye Jun Kim;Jae Hyung Jung;Chan Gook Park",
        "authorids": "/37089874526;/37089894753;/37086436394;/37614648200;/37089874526;/37089894753;/37086436394;/37614648200",
        "aff": "Department of Aerospace Engineering, Navigation and Electronic System Laboratory, Seoul National University, Seoul, Republic of Korea; Hyundai motor group, Seoul, Republic of Korea; Department of Aerospace Engineering, Navigation and Electronic System Laboratory, Seoul National University, Seoul, Republic of Korea; Department of Aerospace Engineering, Navigation and Electronic System Laboratory, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161098/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17554789568900373217&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Seoul National University;Hyundai Motor Group",
        "aff_unique_dep": "Department of Aerospace Engineering;",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.hyundaimotorgroup.com",
        "aff_unique_abbr": "SNU;HMG",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160939",
        "title": "GAN-Based Interactive Reinforcement Learning from Demonstration and Human Evaluative Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative adversarial imitation learning (GAIL) \u2014 a general model-free imitation learning method, allows robots to directly learn policies from expert trajectories in large environments. However, GAIL shares the limitation of other imitation learning methods that they can seldom surpass the performance of demonstrations. In this paper, to address the limit of GAIL, we propose GAN-based interactive reinforcement learning (GAIRL) from demonstrations and human evaluative feedback, by combining the advantages of GAIL and interactive reinforcement learning. We test GAIRL in six physics-based control tasks, ranging from simple low-dimensional control tasks \u2014 Cart Pole, Mountain Car and Lunar Lander, to difficult high-dimensional tasks \u2014 Inverted Double Pendulum, Hopper and HalfCheetah. Our results suggest that, the GAIRL agent can generally surpass the performance of demonstrations in both low-dimensional and high-dimensional tasks and get an optimal or close to optimal policy.",
        "primary_area": "",
        "author": "Jie Huang;Jiangshan Hao;Rongshun Juan;Randy Gomez;Keisuke Nakamura;Guangliang Li;Jie Huang;Jiangshan Hao;Rongshun Juan;Randy Gomez;Keisuke Nakamura;Guangliang Li",
        "authorids": "/37089196244;/37089893809;/37089195007;/37979526500;/37534198900;/37086047680;/37089196244;/37089893809;/37089195007;/37979526500;/37534198900;/37086047680",
        "aff": "College of Information Science and Engineering, Ocean University of China; College of Information Science and Engineering, Ocean University of China; College of Information Science and Engineering, Ocean University of China; Honda Research Institute Japan Co., Ltd, Wako, Japan; Honda Research Institute Japan Co., Ltd, Wako, Japan; College of Information Science and Engineering, Ocean University of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160939/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=497294059262313153&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Ocean University of China;Honda Research Institute Japan Co., Ltd",
        "aff_unique_dep": "College of Information Science and Engineering;",
        "aff_unique_url": "http://www.ouc.edu.cn;https://www.honda-ri.jp/english/",
        "aff_unique_abbr": ";HRI-JP",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Wako",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "10160468",
        "title": "GANet: Goal Area Network for Motion Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the future motion of road participants is crucial for autonomous driving but is extremely challenging due to staggering motion uncertainty. Recently, most motion forecasting methods resort to the goal-based strategy, i.e., predicting endpoints of motion trajectories as conditions to regress the entire trajectories, so that the search space of solution can be reduced. However, accurate goal coordinates are hard to predict and evaluate. In addition, the point representation of the destination limits the utilization of a rich road context, leading to inaccurate prediction results in many cases. Goal area, i.e., the possible destination area, rather than goal coordinate, could provide a more soft constraint for searching potential trajectories by involving more tolerance and guidance. In view of this, we propose a new goal area-based framework, named Goal Area Network (GANet), for motion forecasting, which models goal areas as preconditions for trajectory prediction, performing more robustly and accurately. Specifically, we propose a GoICrop (Goal Area of Interest) operator to effectively aggregate semantic lane features in goal areas and model actors' future interactions as feedback, which benefits a lot for future trajectory estimations. GANet ranks the 1st on the leaderboard of Argoverse Challenge among all public literature (till the paper submission). Code will be available at https://github.com/kingwmk/GANet.",
        "primary_area": "",
        "author": "Mingkun Wang;Xinge Zhu;Changqian Yu;Wei Li;Yuexin Ma;Ruochun Jin;Xiaoguang Ren;Dongchun Ren;Mingxu Wang;Wenjing Yang;Mingkun Wang;Xinge Zhu;Changqian Yu;Wei Li;Yuexin Ma;Ruochun Jin;Xiaoguang Ren;Dongchun Ren;Mingxu Wang;Wenjing Yang",
        "authorids": "/37087881107;/37086492460;/37086575728;/37086404377;/37089018085;/37086478586;/37085830008;/37086800405;/37089370022;/37085869205;/37087881107;/37086492460;/37086575728;/37086404377;/37089018085;/37086478586;/37085830008;/37086800405;/37089370022;/37085869205",
        "aff": "Peking University; The Chinese University of Hong Kong; Meituan; Inceptio; ShanghaiTech University; National University of Defense Technology; Academy of Military Sciences; Meituan; Fudan University; National University of Defense Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160468/",
        "gs_citation": 89,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=172243193525345819&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;2;3;4;5;6;2;7;5",
        "aff_unique_norm": "Peking University;The Chinese University of Hong Kong;Meituan;Inceptio;ShanghaiTech University;National University of Defense Technology;Academy of Military Sciences;Fudan University",
        "aff_unique_dep": ";;;;;;;",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.cuhk.edu.hk;https://www.meituan.com;;https://www.shanghaitech.edu.cn;http://www.nudt.edu.cn/;;https://www.fudan.edu.cn",
        "aff_unique_abbr": "Peking U;CUHK;Meituan;;ShanghaiTech;NUDT;;Fudan",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "10160356",
        "title": "GDIP: Gated Differentiable Image Processing for Object Detection in Adverse Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting objects under adverse weather and lighting conditions is crucial for the safe and continuous operation of an autonomous vehicle, and remains an unsolved problem. We present a Gated Differentiable Image Processing (GDIP) block, a domain-agnostic network architecture, which can be plugged into existing object detection networks (e.g., Yolo) and trained end-to-end with adverse condition images such as those captured under fog and low lighting. Our pro-posed GDIP block learns to enhance images directly through the downstream object detection loss. This is achieved by learning parameters of multiple image pre-processing (IP) techniques that operate concurrently, with their outputs combined using weights learned through a novel gating mechanism. We further improve GDIP through a multi-stage guidance procedure for progressive image enhancement. Finally, trading off accuracy for speed, we propose a variant of GDIP that can be used as a regularizer for training Yolo, which eliminates the need for GDIP-based image enhancement during inference, resulting in higher throughput and plausible real-world deployment. We demonstrate significant improvement in detection performance over several state-of-the-art methods through quantitative and qualitative studies on synthetic datasets such as PascalVOC, and real-world foggy (RTTS) and low-lighting (ExDark) datasets.",
        "primary_area": "",
        "author": "Sanket Kalwar;Dhruv Patel;Aakash Aanegola;Krishna Reddy Konda;Sourav Garg;K Madhava Krishna;Sanket Kalwar;Dhruv Patel;Aakash Aanegola;Krishna Reddy Konda;Sourav Garg;K Madhava Krishna",
        "authorids": "/37089894561;/222595252484074;/37089895726;/37584240200;/37086209418;/38201465600;/37089894561;/222595252484074;/37089895726;/37584240200;/37086209418;/38201465600",
        "aff": "RRC, IIIT, Hyderabad, India; RRC, IIIT, Hyderabad, India; RRC, IIIT, Hyderabad, India; ZF TCI, Hyderabad, India; QUT Centre for Robotics at the Queensland University of Technology (QUT), Brisbane, Australia; RRC, IIIT, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160356/",
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10712200831467363510&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad;ZF TCI;Queensland University of Technology",
        "aff_unique_dep": "Not Available;;Centre for Robotics",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;;https://www.qut.edu.au",
        "aff_unique_abbr": "IIIT Hyderabad;;QUT",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "Hyderabad;;Brisbane",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "India;Australia"
    },
    {
        "id": "10160415",
        "title": "GIDP: Learning a Good Initialization and Inducing Descriptor Post-enhancing for Large-scale Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Large-scale place recognition is a fundamental but challenging task, which plays an increasingly important role in autonomous driving and robotics. Existing methods have achieved acceptable good performance, however, most of them are concentrating on designing elaborate global descriptor learning network structures. The importance of feature generalization and descriptor post-enhancing has long been neglected. In this work, we propose a novel method named GIDP to learn a Good Initialization and Inducing Descriptor Pose-enhancing for Large-scale Place Recognition. In particular, an unsupervised momentum contrast point cloud pretraining module and a reranking-based descriptor post-enhancing module are proposed respectively in GIDP. The former aims at learning a good initialization for the point cloud encoding network before training the place recognition model, while the later aims at post-enhancing the predicted global descriptor through reranking at inference time. Ex-tensive experiments on both indoor and outdoor datasets demonstrate that our method can achieve state-of-the-art performance using simple and general point cloud encoding backbones.",
        "primary_area": "",
        "author": "Zhaoxin Fan;Zhenbo Song;Hongyan Liu;Jun He;Zhaoxin Fan;Zhenbo Song;Hongyan Liu;Jun He",
        "authorids": "/37088595019;/37088504117;/37440415200;/37089267726;/37088595019;/37088504117;/37440415200;/37089267726",
        "aff": "Renmin University of China; Nanjing University of Science and Technology; Tsinghua University; Renmin University of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160415/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:0sS9we5MeQwJ:scholar.google.com/&scioq=GIDP:+Learning+a+Good+Initialization+and+Inducing+Descriptor+Post-enhancing+for+Large-scale+Place+Recognition&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Renmin University of China;Nanjing University of Science and Technology;Tsinghua University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.ruc.edu.cn;http://www.nust.edu.cn/;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "RUC;NUST;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161215",
        "title": "GMCR: Graph-based Maximum Consensus Estimation for Point Cloud Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "Point cloud registration is a fundamental and challenging problem for autonomous robots interacting in unstructured environments for applications such as object pose estimation, simultaneous localization and mapping, robot-sensor calibration, and so on. In global correspondence-based point cloud registration, data association is a highly brittle task and commonly produces high amounts of outliers. Failure to reject outliers can lead to errors propagating to downstream perception tasks. Maximum Consensus (MC) is a widely used technique for robust estimation, which is however known to be NP-hard. Exact methods struggle to scale to realistic problem instances, whereas high outlier rates are challenging for approximate methods. To this end, we propose Graph-based Maximum Consensus Registration (GMCR), which is highly robust to outliers and scales to realistic problem instances. We propose novel consensus functions to map the decoupled MC-objective to the graph domain, wherein we find a tight approximation to the maximum consensus set as the maximum clique. The final pose estimate is given in closed-form. We extensively evaluated our proposed GMCR on a synthetic registration benchmark, robotic object localization task, and additionally on a scan matching benchmark. Our proposed method shows high accuracy and time efficiency compared to other state-of-the-art MC methods and compares favorably to other robust registration methods.",
        "primary_area": "",
        "author": "Michael Gentner;Prajval Kumar Murali;Mohsen Kaboli;Michael Gentner;Prajval Kumar Murali;Mohsen Kaboli",
        "authorids": "/37089195346;/37089891860;/37085362292;/37089195346;/37089891860;/37085362292",
        "aff": "Technical University of Munich, Germany; University of Glasgow, Scotland; Donders Institute for Brain and Cognition, Radboud University, Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161215/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7800045636304606908&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Technical University of Munich;University of Glasgow;Radboud University",
        "aff_unique_dep": ";;Donders Institute for Brain and Cognition",
        "aff_unique_url": "https://www.tum.de;https://www.gla.ac.uk;https://www.ru.nl",
        "aff_unique_abbr": "TUM;Glasgow;RU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "Germany;United Kingdom;Netherlands"
    },
    {
        "id": "10160697",
        "title": "GMM Registration: a Probabilistic scan matching approach for sonar-based AUV navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Acoustic perception in underwater environments is challenging due to the low frequency of the acquisition system and multiple and huge sources of noise. Therefore, point clouds built by profiling sonars mounted on Autonomous Underwater Vehicles (AUV) are sparse and noisy. To solve the mapping task, AUVs need a registration algorithm to prevent maps from inconsistencies. Many scan matching algorithms are available, however, a few of them are specialized in acoustic data. In this paper, a probabilistic scan matching methodology based on Gaussian Mixtures Models (GMM) is presented and, for the first time, the Bayesian-GMM algorithm is applied in this context to model acoustic data. The scan matching problem is properly formulated using Lie groups to define pose. In addition, this methodology can return an uncertainty measure for the matching result, which is fundamental in Pose SLAM applications. This tool is implemented in a public C++library11The library repository can be found in https://bitbucket.org/gmmregistration/gmm_registration. that can process in real-time 2D and 3D scans acquired by a profiling sonar. Theoretical justification and results with real data are provided to benchmark our method against the state-of-the-art Normal Distributions Transforms (NDT) technique.",
        "primary_area": "",
        "author": "Pau Vial;Miguel Malag\u00f3n;Ricard Segura;Narc\u00eds Palomeras;Marc Carreras;Pau Vial;Miguel Malag\u00f3n;Ricard Segura;Narc\u00eds Palomeras;Marc Carreras",
        "authorids": "/37089892984;/37089893678;/37089892825;/37546439000;/38358849300;/37089892984;/37089893678;/37089892825;/37546439000;/38358849300",
        "aff": "Computer Vision and Robotics Research Institute (VICOROB), Universitat de Girona, Girona, Catalonia; Computer Vision and Robotics Research Institute (VICOROB), Universitat de Girona, Girona, Catalonia; Computer Vision and Robotics Research Institute (VICOROB), Universitat de Girona, Girona, Catalonia; Computer Vision and Robotics Research Institute (VICOROB), Universitat de Girona, Girona, Catalonia; Computer Vision and Robotics Research Institute (VICOROB), Universitat de Girona, Girona, Catalonia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160697/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2922973995559999642&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universitat de Girona",
        "aff_unique_dep": "Computer Vision and Robotics Research Institute (VICOROB)",
        "aff_unique_url": "https://www.udg.edu",
        "aff_unique_abbr": "UDG",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Girona",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10161227",
        "title": "GNM: A General Navigation Model to Drive Any Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning provides a powerful tool for vision-based navigation, but the capabilities of learning-based policies are constrained by limited training data. If we could combine data from all available sources, including multiple kinds of robots, we could train more powerful navigation models. In this paper, we study how a general goal-conditioned model for vision-based navigation can be trained on data obtained from many distinct but structurally similar robots, and enable broad generalization across environments and embodiments. We analyze the necessary design decisions for effective data sharing across robots, including the use of temporal context and standardized action spaces, and demonstrate that an omnipolicy trained from heterogeneous datasets outperforms policies trained on any single dataset. We curate 60 hours of navigation trajectories from 6 distinct robots, and deploy the trained GNM on a range of new robots, including an underactuated quadrotor. We find that training on diverse data leads to robustness against degradation in sensing and actuation. Using a pre-trained navigation model with broad generalization capabilities can bootstrap applications on novel robots going forward, and we hope that the GNM represents a step in that direction. For more information on the datasets, code, and videos, please check out our project page11sites.google.com/view/drive-any-robot.",
        "primary_area": "",
        "author": "Dhruv Shah;Ajay Sridhar;Arjun Bhorkar;Noriaki Hirose;Sergey Levine;Dhruv Shah;Ajay Sridhar;Arjun Bhorkar;Noriaki Hirose;Sergey Levine",
        "authorids": "/37089000677;/37089893401;/37089892587;/37574851500;/37085481973;/37089000677;/37089893401;/37089892587;/37574851500;/37085481973",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; Toyota Motor North America; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161227/",
        "gs_citation": 120,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4712983392360491380&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Toyota Motor Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.toyota.com",
        "aff_unique_abbr": "UC Berkeley;Toyota",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160932",
        "title": "GNN-Based Point Cloud Maps Feature Extraction and Residual Feature Fusion for 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR detection of long-range vehicles is challenging because very few and sparse points are measured in long distances and vehicles with similar shapes of targets could lead to false positives easily. To tackle these challenges, taking the environment information (HD maps) into account could be beneficial to predetermine where targets are more or less likely to appear. Compared with semantic maps, HD maps formed by point clouds provide much richer information from surrounding static objects and scenes. In this work, we construct a GNN-based feature extraction of point cloud maps to increase the receptive fields of learning map features. Our work is based on PVRCNN, the state-of-the-art LiDAR object detection method. With point-wise and voxel-wise features obtained from PVRCNN, residual feature fusion is proposed to fuse the features from PVRCNN and the map features from GNN. Our approach is evaluated on NuScenes dataset. It achieves a 24.78% average precision improvement for long-range objects at 40\u201350 meters, the farthest areas with ground truth annotation. Our approach also has a 4.22% reduction of false positives in the entire sensing areas.",
        "primary_area": "",
        "author": "Wei-Hsiang Liao;Chieh-Chih Wang;Wen-Chieh Lin;Wei-Hsiang Liao;Chieh-Chih Wang;Wen-Chieh Lin",
        "authorids": "/37089299177;/37088493330;/37291223500;/37089299177;/37088493330;/37291223500",
        "aff": "Graduate Degree Program of Artificial Intelligence, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Mechanical and Mechatronics Systems Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan; Institute of Multimedia Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160932/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13456035800624786220&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "National Yang Ming Chiao Tung University;Industrial Technology Research Institute",
        "aff_unique_dep": "Graduate Degree Program of Artificial Intelligence;Mechanical and Mechatronics Systems Research Laboratories",
        "aff_unique_url": "https://www.nycu.edu.tw;https://www.itri.org.tw",
        "aff_unique_abbr": "NYCU;ITRI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161230",
        "title": "GP-Frontier for Local Mapless Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new frontier concept called the Gaussian Process Frontier (GP-Frontier) that can be used to locally navigate a robot towards a goal without building a map. The GP-Frontier is built on the uncertainty assessment of an efficient variant of sparse Gaussian Process. Based only on local ranging sensing measurement, the GP-Frontier can be used for navigation in both known and unknown environments. The proposed method is validated through intensive evaluations, and the results show that the GP-Frontier can navigate the robot in a safe and persistent way, i.e., the robot moves in the most open space (thus reducing the risk of collision) without relying on a map or a path planner. A supplementary video that demonstrates the robot navigation behavior is available at https://youtu.be/ndpqTNYqGfw.",
        "primary_area": "",
        "author": "Mahmoud Ali;Lantao Liu;Mahmoud Ali;Lantao Liu",
        "authorids": "/37089892070;/37085785167;/37089892070;/37085785167",
        "aff": "Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161230/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11787730211690382764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indiana University",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering",
        "aff_unique_url": "https://www.indiana.edu",
        "aff_unique_abbr": "IU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bloomington",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160804",
        "title": "GPF-BG: A Hierarchical Vision-Based Planning Framework for Safe Quadrupedal Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe quadrupedal navigation through unknown environments is a challenging problem. This paper proposes a hierarchical vision-based planning framework (GPF-BG) integrating our previous Global Path Follower (GPF) navigation system and a gap-based local planner using B\u00e9zier curves, so called BB\u00e9zier Gap (BG). This BG-based trajectory synthesis can generate smooth trajectories and guarantee safety for point-mass robots. With a gap analysis extension based on non-point, rectangular geometry, safety is guaranteed for an idealized quadrupedal motion model and significantly improved for an actual quadrupedal robot model. Stabilized perception space improves performance under oscillatory internal body motions that impact sensing. Simulation-based and real experiments under different benchmarking configurations test safe navigation performance. GPF-BG has the best safety outcomes across all experiments.",
        "primary_area": "",
        "author": "Shiyu Feng;Ziyi Zhou;Justin S. Smith;Max Asselmeier;Ye Zhao;Patricio A. Vela;Shiyu Feng;Ziyi Zhou;Justin S. Smith;Max Asselmeier;Ye Zhao;Patricio A. Vela",
        "authorids": "/37088958834;/37088485262;/37085636293;/37088489179;/37088450720;/37329553400;/37088958834;/37088485262;/37085636293;/37088489179;/37088450720;/37329553400",
        "aff": "School of Mechanical Engineering and the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Mechanical Engineering and the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; School of Mechanical Engineering and the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Mechanical Engineering and the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160804/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2308752687386506943&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160994",
        "title": "GRM: Gradient Rectification Module for Visual Place Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual place retrieval aims to search images in the database that depict similar places as the query image. However, global descriptors encoded by the network usually fall into a low dimensional principal space, which is harmful to the retrieval performance. We first analyze the cause of this phenomenon, pointing out that it is due to degraded distribution of the gradients of descriptors. Then, we propose Gradient Rectification Module (GRM) to alleviate this issue. GRM is appended after the final pooling layer and can rectify gradients to the complementary space of the principal space. With GRM, the network is encouraged to generate descriptors more uniformly in the whole space. At last, we conduct experiments on multiple datasets and generalize our method to classification task under prototype learning framework.",
        "primary_area": "",
        "author": "Boshu Lei;Wenjie Ding;Limeng Qiao;Xi Qiu;Boshu Lei;Wenjie Ding;Limeng Qiao;Xi Qiu",
        "authorids": "/37089892408;/37089893685;/37088214998;/37089018028;/37089892408;/37089893685;/37088214998;/37089018028",
        "aff": "Faculty of Automation, Xi'an Jiaotong Univerisity, Xi'an, China; MEGVII Inc.; MEGVII Inc.; MEGVII Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160994/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:FvZUC0u37fEJ:scholar.google.com/&scioq=GRM:+Gradient+Rectification+Module+for+Visual+Place+Retrieval&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Xi'an Jiaotong University;MEGVII",
        "aff_unique_dep": "Faculty of Automation;",
        "aff_unique_url": "http://www.xjtu.edu.cn;https://www.megvii.com",
        "aff_unique_abbr": "XJTU;MEGVII",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Xi'an;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161009",
        "title": "GSMR-CNN: An End-to-End Trainable Architecture for Grasping Target Objects from Multi-Object Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an end-to-end trainable multi-task model that locates and retrieves target objects from multi-object scenes. The model is an extension of the Siamese Mask R-CNN, which combines the components of Siamese Neural Networks (SNNs) and Mask R-CNN for performing one-shot instance segmentation. The proposed network, called Grasping Siamese Mask R-CNN (GSMR-CNN), extends Siamese Mask R-CNN by adding an additional branch for grasp detection in parallel to the previous object detection head branches. This allows our model to identify a target object with a suitable grasp simultaneously, as opposed to other approaches that require the training of separate models to achieve the same task. The inherent SNN properties enable the proposed model to generalize and recognize new object categories that were not present during training, which is beyond the capabilities of standard object detectors. Moreover, an end-to-end solution uses shared features entailing less model parameters. The model achieves grasp accuracy scores of 92.1 % and 90.4% on the OCID grasp dataset on image-wise and object-wise splits. Physical experiments show that the model achieves a grasp success rate of 76.4 % when correctly identifying the object. Code and models are available at https://github.com/valerijah/grasping_siamese_mask_rcnn",
        "primary_area": "",
        "author": "Valerija Holomjova;Andrew J. Starkey;Pascal Mei\u00dfner;Valerija Holomjova;Andrew J. Starkey;Pascal Mei\u00dfner",
        "authorids": "/37089894011;/37085722579;/37087948062;/37089894011;/37085722579;/37087948062",
        "aff": "University of Aberdeen; University of Aberdeen; University of Aberdeen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161009/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13987347703832610414&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Aberdeen",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.abdn.ac.uk",
        "aff_unique_abbr": "Aberdeen",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160688",
        "title": "GSNet: Model Reconstruction Network for Category-level 6D Object Pose and Size Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Category-level 6D pose and size estimation is to estimate the rotation, translation and size of the observed instance objects from an arbitrary angle in a cluttered scene. Compared with instance-level 6D pose estimation, there are two main challenges for category-level 6D pose estimation. One is that the algorithm needs to estimate the 6D pose and size of unseen objects, and no 3D models are available. Another is that different instance objects of the same class of objects differ greatly in shape. This paper propose a novel method to estimate the 6D pose and size of unseen objects from an RGB-D image. To handle intra-class shape variation, we propose an autoencoder-decoder that is trained on a set of object models to learn structural feature-invariant and shape-variant features of intra-class objects, and constructs a category-level priori model containing the structure feature and shape feature. To solve the problem of 3D model, this paper proposes a model reconstruction network including 3D graph convolution and spherical convolution (GSNet), which can reconstruct the 3D model of the observed instance object from the input RGB-D image and the priori model, and establish a dense correspon-dence between the 3D model and the observed instance object. Finally, random sample consensus (RANSAC) algorithm and Umeyama algorithm are used to estimate the 6D pose and size of the object. Extensive experiments on benchmark datasets show that the proposed method achieves state-of-the-art performance in category-level 6D object pose estimation. In order to prove that our method can be applied to the grasping and operation tasks of robots in industry and life, we deploy our method to a physical UR5 robot to perform grasping tasks on unseen but category known instances, and the results validate the efficacy of our proposed method.",
        "primary_area": "",
        "author": "Penglei Liu;Qieshi Zhang;Jun Cheng;Penglei Liu;Qieshi Zhang;Jun Cheng",
        "authorids": "/37088988776;/37086091868;/37277385900;/37088988776;/37086091868;/37277385900",
        "aff": "The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160688/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4592843227228905331&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160597",
        "title": "GUTS: Generalized Uncertainty-Aware Thompson Sampling for Multi-Agent Active Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic solutions for quick disaster response are essential to ensure minimal loss of life, especially when the search area is too dangerous or too vast for human rescuers. We model this problem as an asynchronous multi-agent active-search task where each robot aims to efficiently seek objects of interest (OOIs) in an unknown environment. This formulation addresses the requirement that search missions should focus on quick recovery of OO1s rather than full coverage of the search region. Previous approaches fail to accurately model sensing uncertainty, account for occlusions due to foliage or terrain, or consider the requirement for heterogeneous search teams and robustness to hardware and communication failures. We present the Generalized Uncertainty-aware Thompson Sampling (GUTS) algorithm, which addresses these issues and is suitable for deployment on heterogeneous multi-robot systems for active search in large unstructured environments. We show through simulation experiments that GUTS consistently outperforms existing methods such as parallelized Thompson Sampling and exhaustive search, recovering all OOIs in 80% of all runs. In contrast, existing approaches recover all OOIs in less than 40% of all runs. We conduct field tests using our multirobot system in an unstructured environment with a search area of \u224875,000 m2. Our system demonstrates robustness to various failure modes, achieving full recovery of OOIs (where feasible) in every field run, and significantly outperforming our baseline.",
        "primary_area": "",
        "author": "Nikhil Angad Bakshi;Tejus Gupta;Ramina Ghods;Jeff Schneider;Nikhil Angad Bakshi;Tejus Gupta;Ramina Ghods;Jeff Schneider",
        "authorids": "/37090018380;/37089892557;/37085690543;/37281084800;/37090018380;/37089892557;/37085690543;/37281084800",
        "aff": "Robotics Institute,School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute,School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute,School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute,School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160597/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1451464503515110806&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160726",
        "title": "GaPT: Gaussian Process Toolkit for Online Regression with Application to Learning Quadrotor Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Gaussian Processes (GPs) are expressive models for capturing signal statistics and expressing prediction uncer-tainty. As a result, the robotics community has gathered interest in leveraging these methods for inference, planning, and control. Unfortunately, despite providing a closed-form inference solution, GPs are non-parametric models that typically scale cubically with the dataset size, hence making them difficult to be used especially on onboard Size, Weight, and Power (SWaP) constrained aerial robots. In addition, the integration of popular libraries with GPs for different kernels is not trivial. In this paper, we propose GaPT, a novel toolkit that converts GPs to their state space form and performs regression in linear time. GaPT is designed to be highly compatible with several optimizers popular in robotics. We thoroughly validate the proposed approach for learning quadrotor dynamics on both single and multiple input GP settings. GaPT accurately captures the system behavior in multiple flight regimes and operating conditions, including those producing highly nonlin-ear effects such as aerodynamic forces and rotor interactions. Moreover, the results demonstrate the superior computational performance of GaPT compared to a classical GP inference approach on both single and multi-input settings especially when considering large number of data points, enabling real-time regression speed on embedded platforms used on SWaP-constrained aerial robots.",
        "primary_area": "",
        "author": "Francesco Crocetti;Jeffrey Mao;Alessandro Saviolo;Gabriele Costante;Giuseppe Loianno;Francesco Crocetti;Jeffrey Mao;Alessandro Saviolo;Gabriele Costante;Giuseppe Loianno",
        "authorids": "/37085535873;/37089195746;/37089311932;/38541290800;/37085496544;/37085535873;/37089195746;/37089311932;/38541290800;/37085496544",
        "aff": "Department of Engineering, University of Perugia, Perugia, Italy; New York University, Tandon School of Engineering, Brooklyn, NY, USA; New York University, Tandon School of Engineering, Brooklyn, NY, USA; Department of Engineering, University of Perugia, Perugia, Italy; New York University, Tandon School of Engineering, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160726/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12273949348111189747&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "University of Perugia;New York University",
        "aff_unique_dep": "Department of Engineering;Tandon School of Engineering",
        "aff_unique_url": "https://www.unipg.it;https://www.nyu.edu",
        "aff_unique_abbr": ";NYU",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Perugia;Brooklyn",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "10161102",
        "title": "Gait Event Detection with Proprioceptive Force Sensing in a Powered Knee-Ankle Prosthesis: Validation over Walking Speeds and Slopes",
        "track": "main",
        "status": "Poster",
        "abstract": "Many powered prosthetic devices use load cells to detect ground interaction forces and gait events. These sensors introduce additional weight and cost in the device. Recent proprioceptive actuators enable an algebraic relationship between actuator torques and ground contact forces. This paper presents a proprioceptive force sensing paradigm which estimates ground reaction forces as a solution to detect gait events without a load cell. A floating body dynamic model is obtained with constraints at the center of pressure representing foot-ground interaction. Constraint forces are derived to estimate ground reaction forces and subsequently timing of gait events. A treadmill experiment is conducted with a powered knee-ankle prosthesis used by an able-bodied subject walking at various speeds and slopes. Results show accurate gait event timing, with pooled data showing heel strike detection lagging by only 6.7 \u00b1 7.2 ms and toe off detection leading by 30.4 \u00b1 11.0 ms compared to values obtained from the load cell. These results establish proof of concept for predicting gait events without a load cell in powered prostheses with proprioceptive actuators.",
        "primary_area": "",
        "author": "Emily G. Keller;Curt A. Laubscher;Robert D. Gregg;Emily G. Keller;Curt A. Laubscher;Robert D. Gregg",
        "authorids": "/37089892465;/37086921353;/37547699100;/37089892465;/37086921353;/37547699100",
        "aff": "Department of Robotics, University of Michigan, Ann Arbor, MI; Department of Robotics, University of Michigan, Ann Arbor, MI; Department of Robotics, University of Michigan, Ann Arbor, MI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161102/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=562077874270362699&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160866",
        "title": "Gaka-Chu: A Self-Employed Autonomous Robot Artist",
        "track": "main",
        "status": "Poster",
        "abstract": "The physical autonomy of robots is well understood both theoretically and practically. By contrast, there is almost no research exploring their potential economic autonomy. In this paper, we present the first economically autonomous robot-a robot able to produce marketable goods while having full control over the use of its generated income. Gaka-chu (\u201cpainter\u201d in Japanese) is a 6-axis robot arm that creates paintings of Japanese characters from an autoselected keyword. By using a blockchain-based smart contract, Gaka-chu can autonomously list a painting it made for sale in an online auction. In this transaction, the robot interacts with the human bidders as a peer not as a tool. Using the blockchain-based smart contract, Gaka-chu can then use its income from selling paintings to replenish its resources by autonomously ordering materials from an online art shop. We built the Gaka-chu prototype with an Ethereum-based smart contract and ran a 6-month long experiment, during which the robot created and sold four paintings, simultaneously using its income to purchase supplies and repay initial investors. In this work, we present the results of the experiments conducted and discuss the implications of economically autonomous robots.",
        "primary_area": "",
        "author": "Eduardo Castell\u00f3 Ferrer;Ivan Berman;Aleksandr Kapitonov;Vadim Manaenko;Makar Chernyaev;Pavel Tarasov;Eduardo Castell\u00f3 Ferrer;Ivan Berman;Aleksandr Kapitonov;Vadim Manaenko;Makar Chernyaev;Pavel Tarasov",
        "authorids": "/37086579688;/37086226717;/37085445138;/37087995317;/37089893240;/37089894458;/37086579688;/37086226717;/37085445138;/37087995317;/37089893240;/37089894458",
        "aff": "MIT Connection Science, Massachusetts Institute of Technology, Cambridge, USA; M2M Economy, Inc (\u201cMerklebot\u201d), San Francisco, CA, USA; M2M Economy, Inc (\u201cMerklebot\u201d), San Francisco, CA, USA; M2M Economy, Inc (\u201cMerklebot\u201d), San Francisco, CA, USA; M2M Economy, Inc (\u201cMerklebot\u201d), San Francisco, CA, USA; M2M Economy, Inc (\u201cMerklebot\u201d), San Francisco, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160866/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1320007032329187966&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;M2M Economy, Inc",
        "aff_unique_dep": "MIT Connection Science;",
        "aff_unique_url": "https://www.mit.edu;",
        "aff_unique_abbr": "MIT;M2M Economy",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160667",
        "title": "GenDexGrasp: Generalizable Dexterous Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating dexterous grasping has been a long-standing and challenging robotic task. Despite recent progress, existing methods primarily suffer from two issues. First, most prior art focuses on a specific type of robot hand, lacking generalizable capability of handling unseen ones. Second, prior arts oftentimes fail to rapidly generate diverse grasps with a high success rate. To jointly tackle these challenges with a unified solution, we propose the GenDexGrasp, a novel hand-agnostic grasping algorithm for generalizable grasping. GenDexGrasp is trained on our proposed large-scale multi-hand grasping dataset MultiDex synthesized with force closure optimization. By leveraging the contact map as a hand-agnostic intermediate representation, GenDexGrasp efficiently generates diverse and plausible grasping poses with a high success rate and can transfer among diverse multi-fingered robotic hands. Compared with previous methods, GenDexGrasp achieves a three-way trade-off among success rate, inference speed, and diversity.",
        "primary_area": "",
        "author": "Puhao Li;Tengyu Liu;Yuyang Li;Yiran Geng;Yixin Zhu;Yaodong Yang;Siyuan Huang;Puhao Li;Tengyu Liu;Yuyang Li;Yiran Geng;Yixin Zhu;Yaodong Yang;Siyuan Huang",
        "authorids": "/37089893346;/37089165200;/37089892577;/37089895146;/37086172463;/37089659781;/37086322935;/37089893346;/37089165200;/37089892577;/37089895146;/37086172463;/37089659781;/37086322935",
        "aff": "Tsinghua University; Beijing Institute of General Artificial Intelligence (BIGAI); Tsinghua University; Peking University; Peking University; Peking University; Beijing Institute of General Artificial Intelligence (BIGAI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160667/",
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3933103659748754303&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;2;2;1",
        "aff_unique_norm": "Tsinghua University;Beijing Institute of General Artificial Intelligence;Peking University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://www.bigmodel.cn/;http://www.pku.edu.cn",
        "aff_unique_abbr": "THU;BIGAI;Peking U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160691",
        "title": "General, Single-shot, Target-less, and Automatic LiDAR-Camera Extrinsic Calibration Toolbox",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an open source LiDAR-camera calibration toolbox that is general to LiDAR and cam-era projection models, requires only one pairing of LiDAR and camera data without a calibration target, and is fully automatic. For automatic initial guess estimation, we employ the Super-Glue image matching pipeline to find 2D-3D correspondences between LiDAR and camera data and estimate the LiDAR-camera transformation via RANSAC. Given the initial guess, we refine the transformation estimate with direct LiDAR-camera registration based on the normalized information distance, a mutual information-based cross-modal distance metric. For a handy calibration process, we also present several assistance capabilities (e.g., dynamic LiDAR data integration and user interface for making 2D-3D correspondence manually). The experimental results show that the proposed toolbox enables calibration of any combination of spinning and non-repetitive scan LiDARs and pinhole and omnidirectional cameras, and shows better calibration accuracy and robustness than those of the state-of-the-art edge-alignment-based calibration method.",
        "primary_area": "",
        "author": "Kenji Koide;Shuji Oishi;Masashi Yokozuka;Atsuhiko Banno;Kenji Koide;Shuji Oishi;Masashi Yokozuka;Atsuhiko Banno",
        "authorids": "/37086179385;/37085895378;/38230409400;/37391486400;/37086179385;/37085895378;/38230409400;/37391486400",
        "aff": "Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160691/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12702280513278959100&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of Information Technology and Human Factors",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tsukuba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160462",
        "title": "Generalizable Movement Intention Recognition with Multiple Heterogeneous EEG Datasets",
        "track": "main",
        "status": "Poster",
        "abstract": "Human movement intention recognition is important for human-robot interaction. Existing work based on motor imagery electroencephalogram (EEG) provides a non-invasive and portable solution for intention detection. However, the data-driven methods may suffer from the limited scale and diversity of the training datasets, which result in poor generalization performance on new test subjects. It is practically difficult to directly aggregate data from multiple datasets for training, since they often employ different channels and collected data suffers from significant domain shifts caused by different devices, experiment setup, etc. On the other hand, the inter-subject heterogeneity is also substantial due to individual differences in EEG representations. In this work, we developed two networks to learn from both the shared and the complete channels across datasets, handling inter-subject and inter-dataset heterogeneity respectively. Based on both networks, we further developed an online knowledge co-distillation framework to collaboratively learn from both networks, achieving coherent performance boosts. Experimental results have shown that our proposed method can effectively aggregate knowledge from multiple datasets, demonstrating better generalization in the context of cross-subject validation.",
        "primary_area": "",
        "author": "Xiao Gu;Jinpei Han;Guang-Zhong Yang;Benny Lo;Xiao Gu;Jinpei Han;Guang-Zhong Yang;Benny Lo",
        "authorids": "/37086360965;/37088941596;/37276270800;/38183567000;/37086360965;/37088941596;/37276270800;/38183567000",
        "aff": "Hamlyn Centre, Imperial College London, London, United Kingdom; Brain & Behaviour Lab, Imperial College London, London, United Kingdom; Institute of Medical Robotics and School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Hamlyn Centre, Imperial College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160462/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3442301718536939959&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Imperial College London;Shanghai Jiao Tong University",
        "aff_unique_dep": "Hamlyn Centre;Institute of Medical Robotics, School of Biomedical Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "Imperial College;SJTU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "London;Shanghai",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "10161162",
        "title": "Generalizable Pose Estimation Using Implicit Scene Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "6-DoF pose estimation is an essential component of robotic manipulation pipelines. However, it usually suffers from a lack of generalization to new instances and object types. Most widely used methods learn to infer the object pose in a discriminative setup where the model filters useful information to infer the exact pose of the object. While such methods offer accurate poses, the model does not store enough information to generalize to new objects. In this work, we address the generalization capability of pose estimation using models that contain enough information about the object to render it in different poses. We follow the line of work that inverts neural renderers to infer the pose. We propose i-\u03c3SRN to maximize the information flowing from the input pose to the rendered scene and invert them to infer the pose given an input image. Specifically, we extend Scene Representation Networks (SRNs) by incorporating a separate network for density estimation and introduce a new way of obtaining a weighted scene representation. We investigate several ways of initial pose estimates and losses for the neural renderer. Our final evaluation shows a significant improvement in inference performance and speed compared to existing approaches.",
        "primary_area": "",
        "author": "Vaibhav Saxena;Kamal Rahimi Malekshan;Linh Tran;Yotto Koga;Vaibhav Saxena;Kamal Rahimi Malekshan;Linh Tran;Yotto Koga",
        "authorids": "/37089893073;/38233048700;/37089540989;/37088904896;/37089893073;/38233048700;/37089540989;/37088904896",
        "aff": "Georgia Institute of Technology; Autodesk Research; Autodesk Research; Autodesk Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161162/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2498714716668635064&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Georgia Institute of Technology;Autodesk",
        "aff_unique_dep": ";Autodesk Research",
        "aff_unique_url": "https://www.gatech.edu;https://research.autodesk.com",
        "aff_unique_abbr": "Georgia Tech;Autodesk",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160613",
        "title": "Generalization of Impact Response Factors for Proprioceptive Collaborative Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Physical Human-Robot Interaction(pHRI) re-quires taking safety into account from the design board to the collaborative operation of any robot. For collaborative robotic environments, where human and machine are sharing space and interacting physically, the analysis and quantification of impacts becomes very relevant and necessary. Furthermore, analyses of this kind are a valuable source of information for the design of safer, more efficient pHRI. In the definition of the first parameter for dynamic impact analysis, the dynamic impact mitigation capacity was considered for certain configurations of the robot, but the design characteristics of the robot, such as the inertia of actuators, were not included. This paradigm changed when MIT presented the \u201cimpact mitigation factor\u201d (IMF) with which, in addition to considering the ability of a certain robot to mitigate impacts for every configuration, it was possible to quantify backdriveability by taking the inertia of actuators into account for the calculation of the factor. However, IMF was proposed as a method to analyse floating robots like. This paper presents the Generalised Impact Absorption Factor (GIAF), suitable for both floating and fixed-base robots. GIAF is a valuable design parameter, as it provides information about the backdriveability of each joint, while allowing the comparison of impact response between floating and fixed-base robotic platforms. In this work, the mathematical definition of GIAF is developed and examples of possible uses of GIAF are presented.",
        "primary_area": "",
        "author": "Carlos Rela\u00f1o;Daniel Sanz-Merodio;Miguel L\u00f3pez;Concepci\u00f3n A. Monje;Carlos Rela\u00f1o;Daniel Sanz-Merodio;Miguel L\u00f3pez;Concepci\u00f3n A. Monje",
        "authorids": "/37089895122;/37077270500;/37089894818;/37294059000;/37089895122;/37077270500;/37089894818;/37294059000",
        "aff": "Systems Engineering and Automation Department, University Carlos III of Madrid, Madrid, Spain; ARC Robotics, Arquimea Research Center, Santa Cruz de Tenerife, Spain; ARC Robotics, Arquimea Research Center, Santa Cruz de Tenerife, Spain; Systems Engineering and Automation Department, University Carlos III of Madrid, Madrid, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160613/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6305052330259117202&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University Carlos III of Madrid;ARC Robotics",
        "aff_unique_dep": "Systems Engineering and Automation Department;",
        "aff_unique_url": "https://www.uc3m.es;",
        "aff_unique_abbr": "UC3M;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Madrid;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10160600",
        "title": "Generating Formal Safety Assurances for High-Dimensional Reachability",
        "track": "main",
        "status": "Poster",
        "abstract": "Providing formal safety and performance guarantees for autonomous systems is becoming increasingly important. Hamilton-Jacobi (HJ) reachability analysis is a popular formal verification tool for providing these guarantees, since it can handle general nonlinear system dynamics, bounded adversarial system disturbances, and state and input constraints. However, it involves solving a PDE, whose computational and memory complexity scales exponentially with respect to the state dimensionality, making its direct use on large-scale systems intractable. A recently proposed method called DeepReach overcomes this challenge by leveraging a sinusoidal neural PDE solver for high-dimensional reachability problems, whose computational requirements scale with the complexity of the underlying reachable tube rather than the state space dimension. Unfortunately, neural networks can make errors and thus the computed solution may not be safe, which falls short of achieving our overarching goal to provide formal safety assurances. In this work, we propose a method to compute an error bound for the DeepReach solution. This error bound can then be used for reachable tube correction, resulting in a safe approximation of the true reachable tube. We also propose a scenario-based optimization approach to compute a probabilistic bound on this error correction for general nonlinear dynamical systems. We demonstrate the efficacy of the proposed approach in obtaining probabilistically safe reachable tubes for high-dimensional rocket-landing and multi-vehicle collision-avoidance problems.",
        "primary_area": "",
        "author": "Albert Lin;Somil Bansal;Albert Lin;Somil Bansal",
        "authorids": "/37089895236;/37085404900;/37089895236;/37085404900",
        "aff": "CS at Princeton; ECE at University of Southern California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160600/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15610872265302439130&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Princeton University;University of Southern California",
        "aff_unique_dep": "Department of Computer Science;Electrical and Computer Engineering",
        "aff_unique_url": "https://www.princeton.edu;https://www.usc.edu",
        "aff_unique_abbr": "Princeton;USC",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Princeton;Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160494",
        "title": "Generating Stable and Collision-Free Policies through Lyapunov Function Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The need for rapid and reliable robot deployment is on the rise. Imitation Learning (IL) has become popular for producing motion planning policies from a set of demonstrations. However, many methods in IL are not guaranteed to produce stable policies. The generated policy may not converge to the robot target, reducing reliability, and may collide with its environment, reducing the safety of the system. Stable Estimator of Dynamic Systems (SEDS) produces stable policies by constraining the Lyapunov stability criteria during learning, but the Lyapunov candidate function had to be manually selected. In this work, we propose a novel method for learning a Lyapunov function and a collision-free policy using a single neural network model. The method can be equipped with an obstacle avoidance module for convex object pairs to guarantee no collisions. We demonstrated our method is capable of finding policies in several simulation environments and transfer to a real-world scenario.",
        "primary_area": "",
        "author": "Alexandre Coulombe;Hsiu-Chin Lin;Alexandre Coulombe;Hsiu-Chin Lin",
        "authorids": "/37089892314;/37085366909;/37089892314;/37085366909",
        "aff": "Department of Electrical and Computer Engineering, McGill University, Canada; Department of Electrical and Computer Engineering, School of Computer Science, McGill University, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160494/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2408482323218096847&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Montreal;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160522",
        "title": "Generating a Terrain-Robustness Benchmark for Legged Locomotion: A Prototype via Terrain Authoring and Active Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Terrain-aware locomotion has become an emerging topic in legged robotics. However, it is hard to generate diverse, challenging, and realistic unstructured terrains in simulation, which limits the way researchers evaluate their locomotion policies. In this paper, we prototype the generation of a terrain dataset via terrain authoring and active learning, and the learned samplers can stably generate diverse high-quality terrains. We expect the generated dataset to make a terrain-robustness benchmark for legged locomotion. The dataset, the code implementation, and some policy evaluations are released at https://bit.ly/3bn4j7f.",
        "primary_area": "",
        "author": "Chong Zhang;Lizhi Yang;Chong Zhang;Lizhi Yang",
        "authorids": "/37089450912;/37090020878;/37089450912;/37090020878",
        "aff": "Department of Mechanical and Process Engineering, ETH Zurich, Switzerland; Department of Mechanical and Civil Engineering, California Institute of Technology, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160522/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7872788712109368122&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "ETH Zurich;California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Process Engineering;Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.ethz.ch;https://www.caltech.edu",
        "aff_unique_abbr": "ETHZ;Caltech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Pasadena",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "10160737",
        "title": "Getting Air: Modelling and Control of a Hybrid Pneumatic-Electric Legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "With their combination of power and compliance, pneumatic actuators have great potential for enabling dynamic and agile behaviors in legged robots, but their complex dynam-ics impose control challenges that have hindered widespread use. In this paper, we describe the development of a tractable model and characterization procedure of an off-the-shelf double acting pneumatic cylinder controlled by on/off solenoid valves for use in trajectory optimization. With this we are able to generate motions which incorporate both the body and actuator dynamics of our robot Kemba: a novel quadrupedal robot prototype with a combination of electric and pneumatic actu-ators. We demonstrate both a 0.5 m jump and land maneuver, and a maximal 1 m jump, approximately 2.2 times its leg length, on the physical hardware with the proposed model and approach. The hardware matches the desired trajectory with a maximum height error of only 5 cm without any feedback on the pneumatic joints, demonstrating the utility of the model in high-level motion generation, and capability of the physical robot.",
        "primary_area": "",
        "author": "Christopher Mailer;Stacey Shield;Reuben Govender;Amir Patel;Christopher Mailer;Stacey Shield;Reuben Govender;Amir Patel",
        "authorids": "/37089893774;/37085618790;/37088997516;/38029333400;/37089893774;/37085618790;/37088997516;/38029333400",
        "aff": "Department of Electrical Engineering, University of Cape Town; Department of Electrical Engineering, University of Cape Town; Department of Mechanical Engineering, University of Cape Town, South Africa; Department of Electrical Engineering, University of Cape Town",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160737/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3501866073106799396&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Cape Town",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.uct.ac.za",
        "aff_unique_abbr": "UCT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "id": "10161479",
        "title": "Global Localization in Repetitive and Ambiguous Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate global localization is an essential ingredient for autonomous mobile robots (AMRs) operating in enclosed or partially enclosed repetitive environments (e.g., office corridors, industrial warehouses, transportation centers). In such environments, the Global Navigation Satellite System (GNSS) signals are unreliable or severely degraded. The highly ambiguous structures in such challenging scenarios would also lead the ordinary geometric feature-based LiDAR/visual localization methods to fail. The ambient magnetic field (MF) has exhibited high distinctiveness at different location, which makes it a viable alternative for infrastructure-free AMR localization. However, few of the previous research has been focused on the orientation-dependency and similar-sequential-route limitations of MF-based localization. Thus, this paper proposes a novel probabilistic global localization system with 2-D LiDAR and rotation-invariant magnetic field for AMRs operating in challenging repetitive and ambiguous environments. The proposed localization system mainly consists of: 1) Two-step Initialization: laser distance and MF sequence based matching, and 2) MF-based Pose Tracking: recursive multi-dimensional MF sequence based matching. Extensive experimental results demonstrate the advantageous localization performances of the proposed localization system over the existing methods.",
        "primary_area": "",
        "author": "Zhenyu Wu;Wei Wang;Jun Zhang;Qiyang Lyu;Haoyuan Zhang;Danwei Wang;Zhenyu Wu;Wei Wang;Jun Zhang;Qiyang Lyu;Haoyuan Zhang;Danwei Wang",
        "authorids": "/37088406849;/37085687050;/37086009222;/37089446613;/37088405191;/37279547600;/37088406849;/37085687050;/37086009222;/37089446613;/37088405191;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161479/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2008862711550647337&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160965",
        "title": "Global and Reactive Motion Generation with Geometric Fabric Command Sequences",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion generation seeks to produce safe and feasible robot motion from start to goal. Various tools at different levels of granularity have been developed. On one extreme, sampling-based motion planners focus on completeness - a solution, if it exists, would eventually be found. However, produced paths are often of low quality, and contain superfluous motion. On the other, reactive methods optimise the immediate cost to obtain the next controls, producing smooth and legible motion that can quickly adapt to perturbations, uncertainties, and changes in the environment. However, reactive methods are highly local, and often produce motion that become trapped in non-convex regions of the environment. This paper contributes, Geometric Fabric Command Sequences, a method that lies in the middle ground. It can produce globally optimal motion that is smooth and intuitive, while being also reactive. We model motion via a reactive Geometric Fabric policy that ingests a sequence of attractor states, or commands, and then apply global optimisation over the space of commands. We postulate that solutions for different problems and scenes are highly transferable when conditioned on environmental features. Therefore, an implicit generative model is trained on solutions from optimisation and environment features in a self-supervised manner. That is, faced with multiple motion generation problems, the learning and optimisation are contained within the same loop: the optimisation generates labels for learning, while the learning improves the optimisation for the next problem, which in turn provides higher quality labels. We empirically validate our method in both simulation and on a real-world 6-DOF JACO arm.",
        "primary_area": "",
        "author": "Weiming Zhi;Iretiayo Akinola;Karl Van Wyk;Nathan D. Ratliff;Fabio Ramos;Weiming Zhi;Iretiayo Akinola;Karl Van Wyk;Nathan D. Ratliff;Fabio Ramos",
        "authorids": "/37086936558;/37086319261;/37085779307;/37579950900;/37285364500;/37086936558;/37086319261;/37085779307;/37579950900;/37285364500",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; NVIDIA, USA; NVIDIA, USA; NVIDIA, USA; School of Computer Science, the University of Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160965/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11532820930685612583&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Carnegie Mellon University;NVIDIA;University of Sydney",
        "aff_unique_dep": "Robotics Institute;;School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu;https://www.nvidia.com;https://www.sydney.edu.au",
        "aff_unique_abbr": "CMU;NV;USYD",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Pittsburgh;;Sydney",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "10160860",
        "title": "Globally Defined Dynamic Modelling and Geometric Tracking Controller Design for Aerial Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "This study presents a globally defined dynamics for a conventional multirotor equipped with a single n\\mathbf{-DOF}n\\mathbf{-DOF} manipulator using modified Lagrangian dynamics. This enables the reformulation of entire dynamics directly on \\text{SO}(3)\\text{SO}(3) without exploiting any local coordinates, and thus problems such as the singularity of Euler angles can be avoided. Since skew-symmetric property of Coriolis matrix CC and inertia matrix facilitates stability analysis, we propose a method to compute CC which guarantees the skew-symmetric property by considering CC as a summation of two sub-matrices. Then, a geometric tracking controller is designed based on decoupled dynamics applying passive decomposition. The proposed controller guarantees almost global region of attraction. We validate our method via consecutive aerial flipping experiments.",
        "primary_area": "",
        "author": "Byeongjun Kim;Dongjae Lee;Jeonghyun Byun;H. Jin Kim;Byeongjun Kim;Dongjae Lee;Jeonghyun Byun;H. Jin Kim",
        "authorids": "/37089895267;/37086933985;/37089194964;/37599626400;/37089895267;/37086933985;/37089194964;/37599626400",
        "aff": "Institute of Advanced Aerospace Technology(IAAT), Seoul National University, Seoul, South Korea; Institute of Advanced Aerospace Technology(IAAT), Seoul National University, Seoul, South Korea; Institute of Advanced Aerospace Technology(IAAT), Seoul National University, Seoul, South Korea; Institute of Advanced Aerospace Technology(IAAT), Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160860/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2443413769768642428&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10160379",
        "title": "Globally Guided Trajectory Planning in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigating mobile robots through environments shared with humans is challenging. From the perspective of the robot, humans are dynamic obstacles that must be avoided. These obstacles make the collision-free space nonconvex, which leads to two distinct passing behaviors per obstacle (passing left or right). For local planners, such as receding-horizon trajectory optimization, each behavior presents a local optimum in which the planner can get stuck. This may result in slow or unsafe motion even when a better plan exists. In this work, we identify trajectories for multiple locally optimal driving behaviors, by considering their topology. This identification is made consistent over successive iterations by propagating the topology information. The most suitable high-level trajectory guides a local optimization-based planner, resulting in fast and safe motion plans. We validate the proposed planner on a mobile robot in simulation and real-world experiments.",
        "primary_area": "",
        "author": "Oscar de Groot;Laura Ferranti;Dariu Gavrila;Javier Alonso\u2013Mora;Oscar de Groot;Laura Ferranti;Dariu Gavrila;Javier Alonso\u2013Mora",
        "authorids": "/37088866244;/37085778570;/37284630500;/38271697300;/37088866244;/37085778570;/37284630500;/38271697300",
        "aff": "Dept. of Cognitive Robotics, TU Delft, CD Delft, The Netherlands; Dept. of Cognitive Robotics, TU Delft, CD Delft, The Netherlands; Dept. of Cognitive Robotics, TU Delft, CD Delft, The Netherlands; Dept. of Cognitive Robotics, TU Delft, CD Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160379/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17933981436642447303&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Department of Cognitive Robotics",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10160984",
        "title": "GoRela: Go Relative for Viewpoint-Invariant Motion Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "The task of motion forecasting is critical for self- driving vehicles (SDV s) to be able to plan a safe maneuver. Towards this goal, modern approaches reason about the map, the agents' past trajectories and their interactions in order to produce accurate forecasts. The predominant approach has been to encode the map and other agents in the reference frame of each target agent. However, this approach is computationally expensive for multi-agent prediction as inference needs to be run for each agent. To tackle the scaling challenge, the solution thus far has been to encode all agents and the map in a shared coordinate frame (e.g., the SDV frame). However, this is sample inefficient and vulnerable to domain shift (e.g., when the SDV visits uncommon states). In contrast, in this paper, we propose an efficient shared encoding for all agents and the map without sacrificing accuracy or generalization. Towards this goal, we leverage pair-wise relative positional encodings to represent geometric relationships between the agents and the map elements in a heterogeneous spatial graph. This parameterization allows us to be invariant to scene viewpoint, and save online computation by re-using map embeddings computed offline. Our decoder is also viewpoint agnostic, predicting agent goals on the lane graph to enable diverse and context-aware multimodal prediction. We demonstrate the effectiveness of our approach on the urban Argoverse 2 bench-mark as well as a novel highway dataset. For more information, visit the project website: https://waabi.ailresearch/go-relative-for-viewpoint-invariant-motion-forecasting",
        "primary_area": "",
        "author": "Alexander Cui;Sergio Casas;Kelvin Wong;Simon Suo;Raquel Urtasun;Alexander Cui;Sergio Casas;Kelvin Wong;Simon Suo;Raquel Urtasun",
        "authorids": "/37089316979;/37086821588;/37088459336;/37086567697;/37269502900;/37089316979;/37086821588;/37088459336;/37086567697;/37269502900",
        "aff": "Waabi, University of Toronto; Waabi, University of Toronto; Waabi, University of Toronto; Waabi, University of Toronto; Waabi, University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160984/",
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13667218931436917762&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161541",
        "title": "Goal-Conditioned Action Space Reduction for Deformable Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning for deformable object manipulation has been a challenge for a long time in robotics due to its high computational cost. In this work, we propose to reduce this cost by reducing the number of pick points on a deformable object in the action space. We do this by identifying a small number of key particles that are sufficient as pick points to reach a given goal state. We find these key particles through a geometric model simplification process, which finds the minimal geometric model that still enables a good approximation of the original model at the goal state. We present an implementation of this general approach for 1-D linear deformable objects (e.g., ropes) that uses a piece-wise line fitted model, and for 2-D flat deformable objects (e.g., cloth) that uses a mesh simplified model. We conducted simulation experiments on ropes and cloths, which demonstrate the effectiveness of the proposed method. Finally, the planned paths are executed in a real-world setting for two cloth folding tasks.",
        "primary_area": "",
        "author": "Shengyin Wang;Rafael Papallas;Matteo Leonetti;Mehmet Dogar;Shengyin Wang;Rafael Papallas;Matteo Leonetti;Mehmet Dogar",
        "authorids": "/37089894490;/37086603559;/37593250400;/37591140400;/37089894490;/37086603559;/37593250400;/37591140400",
        "aff": "School of Computing, University of Leeds, UK; School of Computing, University of Leeds, UK; Dept. of Informatics, King's College London, UK; School of Computing, University of Leeds, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161541/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1766841238147680486&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Leeds;King's College London",
        "aff_unique_dep": "School of Computing;Dept. of Informatics",
        "aff_unique_url": "https://www.leeds.ac.uk;https://www.kcl.ac.uk",
        "aff_unique_abbr": "Leeds;KCL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160884",
        "title": "Goal-Image Conditioned Dynamic Cable Manipulation through Bayesian Inference and Multi-Objective Black-Box Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "To perform dynamic cable manipulation to realize the configuration specified by a target image, we formulate dynamic cable manipulation as a stochastic forward model. Then, we propose a method to handle uncertainty by maximizing the expectation, which also considers estimation errors of the trained model. To avoid issues like multiple local minima and requirement of differentiability by gradient-based methods, we propose using a black-box optimization (BBO) to optimize joint angles to realize a goal image. Among BBO, we use the Tree-structured Parzen Estimator (TPE), a type of Bayesian optimization. By incorporating constraints into the TPE, the optimized joint angles are constrained within the range of motion. Since TPE is population-based, it is better able to detect multiple feasible configurations using the estimated inverse model. We evaluated image similarity between the target and cable images captured by executing the robot using optimal transport distance. The results show that the proposed method improves accuracy compared to conventional gradient-based approaches and methods that use deterministic models that do not consider uncertainty.",
        "primary_area": "",
        "author": "Kuniyuki Takahashi;Tadahiro Taniguchi;Kuniyuki Takahashi;Tadahiro Taniguchi",
        "authorids": "/37086937050;/37273806600;/37086937050;/37273806600",
        "aff": "Preferred Networks, Inc.; Ritsumeikan University, College of Information Science and Engineering",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160884/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:48--9CaJkCIJ:scholar.google.com/&scioq=Goal-Image+Conditioned+Dynamic+Cable+Manipulation+through+Bayesian+Inference+and+Multi-Objective+Black-Box+Optimization&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Preferred Networks, Inc.;Ritsumeikan University",
        "aff_unique_dep": ";College of Information Science and Engineering",
        "aff_unique_url": "https://www.preferred-networks.com;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "PFN;Ritsumeikan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161574",
        "title": "Gradient-Based Trajectory Optimization With Learned Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory optimization methods have achieved an exceptional level of performance on real-world robots in recent years. These methods heavily rely on accurate analytical models of the dynamics, yet some aspects of the physical world can only be captured to a limited extent. An alternative approach is to leverage machine learning techniques to learn a differentiable dynamics model of the system from data. In this work, we use trajectory optimization and model learning for performing highly dynamic and complex tasks with robotic systems in absence of accurate analytical models of the dynamics. We show that a neural network can model highly nonlinear behaviors accurately for large time horizons, from data collected in only 25 minutes of interactions on two distinct robots: (i) the Boston Dynamics Spot and an (ii) RC car. Furthermore, we use the gradients of the neural network to perform gradient-based trajectory optimization. In our hardware experiments, we demonstrate that our learned model can represent complex dynamics for both the Spot and Radio-controlled (RC) car, and gives good performance in combination with trajectory optimization methods.",
        "primary_area": "",
        "author": "Bhavya Sukhija;Nathanael K\u00f6hler;Miguel Zamora;Simon Zimmermann;Sebastian Curi;Andreas Krause;Stelian Coros;Bhavya Sukhija;Nathanael K\u00f6hler;Miguel Zamora;Simon Zimmermann;Sebastian Curi;Andreas Krause;Stelian Coros",
        "authorids": "/37089895598;/37089891867;/37088230941;/37088231270;/37086332837;/37542827400;/37077396200;/37089895598;/37089891867;/37088230941;/37088231270;/37086332837;/37542827400;/37077396200",
        "aff": "Department of Computer Science, ETH, Z\u00fcrich, Switzerland; Department of Computer Science, ETH, Z\u00fcrich, Switzerland; Department of Computer Science, ETH, Z\u00fcrich, Switzerland; Department of Computer Science, ETH, Z\u00fcrich, Switzerland; Department of Computer Science, ETH, Z\u00fcrich, Switzerland; Department of Computer Science, ETH, Z\u00fcrich, Switzerland; Department of Computer Science, ETH, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161574/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17279460482915231865&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10160723",
        "title": "Graph Neural Networks for Multi-Robot Active Information Acquisition",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the Multi-Robot Active In-formation Acquisition (AIA) problem, where a team of mobile robots, communicating through an underlying graph, estimates a hidden state expressing a phenomenon of interest. Applications like target tracking, coverage and SLAM can be expressed in this framework. Existing approaches, though, are either not scalable, unable to handle dynamic phenomena or not robust to changes in the communication graph. To counter these shortcomings, we propose an Information-aware Graph Block Network (I-GBNet), an AIA adaptation of Graph Neural Networks, that aggregates information over the graph represen-tation and provides sequential-decision making in a distributed manner. The I-GBNet, trained via imitation learning with a centralized sampling-based expert solver, exhibits permutation equivariance and time invariance, while harnessing the superior scalability, robustness and generalizability to previously unseen environments and robot configurations. Numerical simulations on significantly larger graphs and dimensionality of the hidden state and more complex environments than those seen in training validate the properties of the proposed architecture and its efficacy in the application of localization and tracking of dynamic targets.",
        "primary_area": "",
        "author": "Mariliza Tzes;Nikolaos Bousias;Evangelos Chatzipantazis;George J. Pappas;Mariliza Tzes;Nikolaos Bousias;Evangelos Chatzipantazis;George J. Pappas",
        "authorids": "/37086395388;/37086942034;/37089892862;/37281547100;/37086395388;/37086942034;/37089892862;/37281547100",
        "aff": "GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160723/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13482026511485180270&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160287",
        "title": "Graph-based Pose Estimation of Texture-less Surgical Tools for Autonomous Robot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In Robot-assisted Minimally Invasive Surgery (RMIS), the estimation of the pose of surgical tools is crucial for applications such as surgical navigation, visual servoing, autonomous robotic task execution and augmented reality. A plethora of hardware-based and vision-based methods have been proposed in the literature. However, direct application of these methods to RMIS has significant limitations due to partial tool visibility, occlusions and changes in the surgical scene. In this work, a novel keypoint-graph-based network is proposed to estimate the pose of texture-less cylindrical surgical tools of small diameter. To deal with the challenges in RMIS, keypoint object representation is used and for the first time, temporal information is combined with spatial information in keypoint graph representation, for keypoint refinement. Finally, stable and accurate tool pose is computed using a PnP solver. Our performance evaluation study has shown that the proposed method is able to accurately predict the pose of a textureless robotic shaft with an ADD-S score of over 98%. The method outperforms state-of-the-art pose estimation models under challenging conditions such as object occlusion and changes in the lighting of the scene.",
        "primary_area": "",
        "author": "Haozheng Xu;Mark Runciman;Jo\u00e3o Cartucho;Chi Xu;Stamatia Giannarou;Haozheng Xu;Mark Runciman;Jo\u00e3o Cartucho;Chi Xu;Stamatia Giannarou",
        "authorids": "/37089894990;/37086937762;/37086579198;/37089384142;/37891118000;/37089894990;/37086937762;/37086579198;/37089384142;/37891118000",
        "aff": "Department of Surgery and Cancer, Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; Department of Surgery and Cancer, Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; Department of Surgery and Cancer, Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; Department of Surgery and Cancer, Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; Department of Surgery and Cancer, Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160287/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18018111817504803021&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Department of Surgery and Cancer",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161562",
        "title": "Grasp Planning with CNN for Log-loading Forestry Machine",
        "track": "main",
        "status": "Poster",
        "abstract": "Log loading constitutes a key operation in timber harvesting, and despite the recent spike of interest in introducing automation to the forestry sector, efficient and intelligent grasping of logs remains unresolved. This paper presents a grasp planning pipeline that relies on the identification of logs' characteristics and pose in the environment of a log-loading machine, to generate high quality grasps. The proposed pipeline involves replicating identified logs in a virtual environment where grasp planning is carried out by using a convolutional neural network and a virtual depth camera. The network relies solely on depth information and the virtual camera can be positioned at a strategically selected location or to follow a certain trajectory to enhance exposure of the logs, all this without having to move the log-loader's crane. The grasp planning pipeline is evaluated through simulated grasping trials and experiments on a large-scale log-loading test-bed with several configurations of wood logs ranging from a single to multiple logs. The grasp planning pipeline proved to be successful with a grasping rate of 98.33 % in the simulated trials and 96.67 % in the experimental trials. The grasp planner was able to overcome log characterization and localization uncertainties, thus allowing the log-loader to pick individual logs, and multiple logs at once when possible.",
        "primary_area": "",
        "author": "Elie Ayoub;Patrick Levesque;Inna Sharf;Elie Ayoub;Patrick Levesque;Inna Sharf",
        "authorids": "/37085473205;/37089894881;/37283633500;/37085473205;/37089894881;/37283633500",
        "aff": "Department of Mechanical Engineering, McGill University, Montreal, QC, Canada; Software Developer with Software Electronic Applications, FPInnovations, Pointe-Claire, QC, Canada; Lead Researcher at FPInnovations, Pointe-Claire, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161562/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9438596704040954746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "McGill University;FPInnovations",
        "aff_unique_dep": "Department of Mechanical Engineering;Software Electronic Applications",
        "aff_unique_url": "https://www.mcgill.ca;https://www.fpinnovations.ca",
        "aff_unique_abbr": "McGill;",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Montreal;;Pointe-Claire",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160213",
        "title": "GraspAda: Deep Grasp Adaptation through Domain Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based methods for robotic grasping have been shown to yield high performance. However, they rely on expensive-to-acquire and well-labeled datasets. In addition, how to generalize the learned grasping ability across different scenarios is still unsolved. In this paper, we present a novel grasp adaptation strategy to transfer the learned grasping ability to new domains based on visual data using a new grasp feature representation. We present a conditional generative model for visual data transformation. By leveraging the deep feature representational capacity from the well-trained grasp synthesis model, our approach utilizes feature-level contrastive representation learning and adopts adversarial learning on output space. This way we bridge the domain gap between the new domain and the training domain while keeping consistency during the adaptation process. Based on transformed input grasp data via the generator, our trained model can generalize to new domains without any fine-tuning. The proposed method is evaluated on benchmark datasets and based on real robot experiments. The results show that our approach leads to high performance in new scenarios.",
        "primary_area": "",
        "author": "Yiting Chen;Junnan Jiang;Ruiqi Lei;Yasemin Bekiroglu;Fei Chen;Miao Li;Yiting Chen;Junnan Jiang;Ruiqi Lei;Yasemin Bekiroglu;Fei Chen;Miao Li",
        "authorids": "/37088959898;/37089895037;/37088993211;/37947356700;/37085388569;/37086045835;/37088959898;/37089895037;/37088993211;/37947356700;/37085388569;/37086045835",
        "aff": "Institute of Technological Sciences, Wuhan University, Wuhan, China; Institute of Technological Sciences, Wuhan University, Wuhan, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Computer Science, University College, London, UK; Department of Mechanical and Automation Engineering, T-Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong, China; Institute of Technological Sciences, Wuhan University, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160213/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6187635620665724657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;3;0",
        "aff_unique_norm": "Wuhan University;Tsinghua University;University College London;The Chinese University of Hong Kong",
        "aff_unique_dep": "Institute of Technological Sciences;International Graduate School;Department of Computer Science;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "http://www.whu.edu.cn;https://www.tsinghua.edu.cn;https://www.ucl.ac.uk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "WHU;THU;UCL;CUHK",
        "aff_campus_unique_index": "0;0;1;2;3;0",
        "aff_campus_unique": "Wuhan;Shenzhen;London;Hong Kong",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10160842",
        "title": "GraspNeRF: Multiview-based 6-DoF Grasp Detection for Transparent and Specular Objects Using Generalizable NeRF",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we tackle 6-DoF grasp detection for transparent and specular objects, which is an important yet challenging problem in vision-based robotic systems, due to the failure of depth cameras in sensing their geometry. We, for the first time, propose a multiview RGB-based 6-DoF grasp detection network, GraspNeRF, that leverages the generalizable neural radiance field (NeRF) to achieve material-agnostic object grasping in clutter. Compared to the existing NeRF-based 3-DoF grasp detection methods that rely on densely captured input images and time-consuming per-scene optimization, our system can perform zero-shot NeRF construction with sparse RGB inputs and reliably detect 6-DoF grasps, both in real-time. The proposed framework jointly learns generalizable NeRF and grasp detection in an end-to-end manner, optimizing the scene representation construction for the grasping. For training data, we generate a large-scale photorealistic domain-randomized synthetic dataset of grasping in cluttered tabletop scenes that enables direct transfer to the real world. Our extensive experiments in synthetic and real-world environments demonstrate that our method significantly outperforms all the baselines in all the experiments while remaining in real-time. Project page can be found at https://pku-epic.github.io/GraspNeRF.",
        "primary_area": "",
        "author": "Qiyu Dai;Yan Zhu;Yiran Geng;Ciyu Ruan;Jiazhao Zhang;He Wang;Qiyu Dai;Yan Zhu;Yiran Geng;Ciyu Ruan;Jiazhao Zhang;He Wang",
        "authorids": "/37089895869;/37089892326;/37089895146;/37089891921;/37088456456;/37087234128;/37089895869;/37089892326;/37089895146;/37089891921;/37088456456;/37087234128",
        "aff": "Beijing Academy of Artificial Intelligence; Center on Frontiers of Computing Studies, Peking University; Center on Frontiers of Computing Studies, Peking University; College of Intelligence Science and Technology, National University of Defense Technology; Beijing Academy of Artificial Intelligence; Beijing Academy of Artificial Intelligence",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160842/",
        "gs_citation": 111,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9136965344726893963&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;0;0",
        "aff_unique_norm": "Beijing Academy of Artificial Intelligence;Peking University;National University of Defense Technology",
        "aff_unique_dep": ";Center on Frontiers of Computing Studies;College of Intelligence Science and Technology",
        "aff_unique_url": "https://www.baaic.cn;http://www.pku.edu.cn;http://www.nudt.edu.cn/",
        "aff_unique_abbr": "BAAI;Peking U;NUDT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161077",
        "title": "Grey-Box Learning of Adaptive Manipulation Primitives for Robotic Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous learning of robotic manipulation tasks is a promising approach to reduce manual engineering effort and increase flexibility in the future of industrial manufacturing. Although a lot of research has been done especially robotic assembly tasks requiring contact-rich compliant interaction remain a challenge for learning-based methods, since large amounts of interaction data are required. Incorporation of prior knowledge has long been seen as a possibility to make learning-based approaches tractable. The question is how can we enable process experts to encode their prior knowledge in grey-box models so that it can be used for learning robotic manipulation tasks? For that reason we propose a new grey-box learning approach, \u201cAdaptive Manipulation Primitives\u201d (AMP), introduced in this paper. AMPs combine compliant manipulation task specifications based on Manipulation Primitives Nets with Policy Gradient Reinforcement Learning. Our framework is evaluated in a real-world robotic assembly task. It is shown that learning to assemble industrial connector modules is possible with comparatively few real-world trials.",
        "primary_area": "",
        "author": "Marco Braun;Sebastian Wrede;Marco Braun;Sebastian Wrede",
        "authorids": "/37089404621;/37269166200;/37089404621;/37269166200",
        "aff": "CoR-Lab, Technical Faculty, Bielefeld University, Germany; CoR-Lab, Technical Faculty, Bielefeld University, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161077/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=387679401529811822&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Bielefeld University",
        "aff_unique_dep": "Technical Faculty",
        "aff_unique_url": "https://www.uni-bielefeld.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160614",
        "title": "Ground then Navigate: Language-guided Navigation in Dynamic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the Vision-and-Language Navigation (VLN) problem in the context of autonomous driving in outdoor settings. We solve the problem by explicitly grounding the navigable regions corresponding to the textual command. At each timestamp, the model predicts a segmentation mask corresponding to the intermediate or the final navigable region. Our work contrasts with existing efforts in VLN, which pose this task as a node selection problem, given a discrete connected graph corresponding to the environment. We do not assume the availability of such a discretised map. Our work moves towards continuity in action space, provides interpretability through visual feedback and allows VLN on commands requiring finer manoeuvres like \u201cpark between the two cars\u201d. Furthermore, we propose a novel meta-dataset CARLA-NAV to allow efficient training and validation. The dataset comprises pre-recorded training sequences and a live environment for validation and testing. We provide extensive qualitative and quantitative em-pirical results to validate the efficacy of the proposed approach. Code is available at https://github.com/kanji95/carla_nav.",
        "primary_area": "",
        "author": "Kanishk Jain;Varun Chhangani;Amogh Tiwari;K. Madhava Krishna;Vineet Gandhi;Kanishk Jain;Varun Chhangani;Amogh Tiwari;K. Madhava Krishna;Vineet Gandhi",
        "authorids": "/37089194367;/37088511695;/37089895949;/38201465600;/37075471000;/37089194367;/37088511695;/37089895949;/38201465600;/37075471000",
        "aff": "Kohli Center on Intelligent Systems, International Institute of Information Technology, Hyderabad, India; Kohli Center on Intelligent Systems, International Institute of Information Technology, Hyderabad, India; Kohli Center on Intelligent Systems, International Institute of Information Technology, Hyderabad, India; Kohli Center on Intelligent Systems, International Institute of Information Technology, Hyderabad, India; Kohli Center on Intelligent Systems, International Institute of Information Technology, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160614/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14494153149272543871&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "International Institute of Information Technology",
        "aff_unique_dep": "Kohli Center on Intelligent Systems",
        "aff_unique_url": "https://iiit Hyderabad.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "10160396",
        "title": "Grounding Language with Visual Affordances over Unstructured Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent works have shown that Large Language Models (LLMs) can be applied to ground natural language to a wide variety of robot skills. However, in practice, learning multi-task, language-conditioned robotic skills typically requires large-scale data collection and frequent human intervention to reset the environment or help correcting the current policies. In this work, we propose a novel approach to efficiently learn general-purpose language-conditioned robot skills from unstructured, offline and reset-free data in the real world by exploiting a self-supervised visuo-lingual affordance model, which requires annotating as little as 1% of the total data with language. We evaluate our method in extensive experiments both in simulated and real-world robotic tasks, achieving state-of-the-art performance on the challenging CALVIN benchmark and learning over 25 distinct visuomotor manipulation tasks with a single policy in the real world. We find that when paired with LLMs to break down abstract natural language instructions into subgoals via few-shot prompting, our method is capable of completing long-horizon, multi-tier tasks in the real world, while requiring an order of magnitude less data than previous approaches. Code and videos are available at http://hulc2.cs.uni-freiburg.de.",
        "primary_area": "",
        "author": "Oier Mees;Jessica Borja-Diaz;Wolfram Burgard;Oier Mees;Jessica Borja-Diaz;Wolfram Burgard",
        "authorids": "/37086205346;/37089450198;/37270485300;/37086205346;/37089450198;/37270485300",
        "aff": "University of Freiburg, Germany; University of Freiburg, Germany; University of Technology, Nuremberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160396/",
        "gs_citation": 122,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8388582617948964160&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Freiburg;University of Technology, Nuremberg",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-freiburg.de;",
        "aff_unique_abbr": "UoF;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161028",
        "title": "GuILD: Guided Incremental Local Densification for Accelerated Sampling-based Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based motion planners rely on incre-mental densification to discover progressively shorter paths. After computing feasible path \\xi\\xi between start x_{s}x_{s} and goal x_{t}x_{t}, the Informed Set (IS) prunes the configuration space \\mathcal{X}\\mathcal{X} by conservatively eliminating points that cannot yield shorter paths. Densification via sampling from this Informed Set retains asymptotic optimality of sampling from the entire configuration space. For path length c(\\xi)c(\\xi) and Euclidean heuristic h, IS= \\{x\\vert x\\in \\mathcal{X},\\ h(x_{s},\\ x)+h(x,\\ x_{t})\\leq c(\\xi)\\}h, IS= \\{x\\vert x\\in \\mathcal{X},\\ h(x_{s},\\ x)+h(x,\\ x_{t})\\leq c(\\xi)\\}. Relying on the heuristic can render the IS especially conservative in high dimensions or complex environments. Furthermore, the IS only shrinks when shorter paths are discovered. Thus, the computational effort from each iteration of densification and planning is wasted if it fails to yield a shorter path, despite improving the cost-to-come for vertices in the search tree. Our key insight is that even in such a failure, shorter paths to vertices in the search tree (rather than just the goal) can immediately improve the planner's sampling strategy. Guided Incremental Local Densification (GuILD) leverages this information to sample from Local Subsets of the IS. We show that GuILD significantly outperforms uniform sampling of the Informed Set in simulated \\mathbb{R}^{2}, SE(2)\\mathbb{R}^{2}, SE(2) environments and manipulation tasks in \\mathbb{R}^{7}\\mathbb{R}^{7}.",
        "primary_area": "",
        "author": "Rosario Scalise;Aditya Mandalika;Brian Hou;Sanjiban Choudhury;Siddhartha S. Srinivasa;Rosario Scalise;Aditya Mandalika;Brian Hou;Sanjiban Choudhury;Siddhartha S. Srinivasa",
        "authorids": "/37085901034;/37087323492;/37088506431;/37077381500;/37339877600;/37085901034;/37087323492;/37088506431;/37077381500;/37339877600",
        "aff": "Paul G. Allen School of Computer Science and Engineering, University of Washington; Aurora Innovation Inc.; Paul G. Allen School of Computer Science and Engineering, University of Washington; Cornell University; Paul G. Allen School of Computer Science and Engineering, University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161028/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5433143191865282060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "University of Washington;Aurora Innovation Inc.;Cornell University",
        "aff_unique_dep": "Paul G. Allen School of Computer Science and Engineering;;",
        "aff_unique_url": "https://www.washington.edu;https://aurora.tech;https://www.cornell.edu",
        "aff_unique_abbr": "UW;Aurora;Cornell",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seattle;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161463",
        "title": "Guided Conditional Diffusion for Controllable Traffic Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Controllable and realistic traffic simulation is critical for developing and verifying autonomous vehicles. Typical heuristic-based traffic models offer flexible control to make vehicles follow specific trajectories and traffic rules. On the other hand, data-driven approaches generate realistic and human-like behaviors, improving transfer from simulated to real-world traffic. However, to the best of our knowledge, no traffic model offers both controllability and realism. In this work, we develop a conditional diffusion model for controllable traffic generation (CTG) that allows users to control desired properties of trajectories at test time (e.g., reach a goal or follow a speed limit) while maintaining realism and physical feasibility through enforced dynamics. The key technical idea is to leverage recent advances from diffusion modeling and differentiable logic to guide generated trajectories to meet rules defined using signal temporal logic (STL). We further extend guidance to multi-agent settings and enable interaction-based rules like collision avoidance. CTG is extensively evaluated on the nuScenes dataset for diverse and composite rules, demonstrating improvement over strong baselines in terms of the controllability-realism tradeoff. Demo videos can be found at https://aiasd.github.io/ctg.github.io",
        "primary_area": "",
        "author": "Ziyuan Zhong;Davis Rempe;Danfei Xu;Yuxiao Chen;Sushant Veer;Tong Che;Baishakhi Ray;Marco Pavone;Ziyuan Zhong;Davis Rempe;Danfei Xu;Yuxiao Chen;Sushant Veer;Tong Che;Baishakhi Ray;Marco Pavone",
        "authorids": "/37088568991;/37086049369;/37086228189;/37088427220;/37085702725;/37089895956;/37085347631;/37307912900;/37088568991;/37086049369;/37086228189;/37088427220;/37085702725;/37089895956;/37085347631;/37307912900",
        "aff": "NVIDIA; NVIDIA; NVIDIA Research; NVIDIA Research; NVIDIA Research; NVIDIA Research; Columbia University; Georgia Tech",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161463/",
        "gs_citation": 167,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14886783754102589285&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;2",
        "aff_unique_norm": "NVIDIA Corporation;Columbia University;Georgia Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nvidia.com;https://www.columbia.edu;https://www.gatech.edu",
        "aff_unique_abbr": "NVIDIA;Columbia;Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160291",
        "title": "Guided Learning from Demonstration for Robust Transferability",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from demonstration (LfD) has the potential to greatly increase the applicability of robotic manipulators in modern industrial applications. Recent progress in LfD methods have put more emphasis in learning robustness than in guiding the demonstration itself in order to improve robustness. The latter is particularly important to consider when the target system reproducing the motion is structurally different to the demonstration system, as some demonstrated motions may not be reproducible. In light of this, this paper introduces a new guided learning from demonstration paradigm where an interactive graphical user interface (GUI) guides the user during demonstration, preventing them from demonstrating non-reproducible motions. The key aspect of our approach is determining the space of reproducible motions based on a motion planning framework which finds regions in the task space where trajectories are guaranteed to be of bounded length. We evaluate our method on two different setups with a six-degree-of-freedom (DOF) UR5 as the target system. First our method is validated using a seven-DOF Sawyer as the demonstration system. Then an extensive user study is carried out where several participants are asked to demonstrate, with and without guidance, a mock weld task using a hand held tool tracked by a VICON system. With guidance users were able to always carry out the task successfully in comparison to only 44% of the time without guidance.",
        "primary_area": "",
        "author": "Fouad Sukkar;Victor Hernandez Moreno;Teresa Vidal-Calleja;Jochen Deuse;Fouad Sukkar;Victor Hernandez Moreno;Teresa Vidal-Calleja;Jochen Deuse",
        "authorids": "/37086937310;/37089893971;/37085384801;/37287790300;/37086937310;/37089893971;/37085384801;/37287790300",
        "aff": "Australian Cobotics Centre (ITTC for Collaborative Robotics in Advanced Manufacturing); Australian Cobotics Centre (ITTC for Collaborative Robotics in Advanced Manufacturing); Australian Cobotics Centre (ITTC for Collaborative Robotics in Advanced Manufacturing); Australian Cobotics Centre (ITTC for Collaborative Robotics in Advanced Manufacturing)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160291/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=243933749237989012&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Australian Cobotics Centre",
        "aff_unique_dep": "ITTC for Collaborative Robotics in Advanced Manufacturing",
        "aff_unique_url": "",
        "aff_unique_abbr": "ACC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10161058",
        "title": "Guiding Reinforcement Learning with Shared Control Templates",
        "track": "main",
        "status": "Poster",
        "abstract": "Purposeful interaction with objects usually requires certain constraints to be respected, e.g. keeping a bottle upright to avoid spilling. In reinforcement learning, such constraints are typically encoded in the reward function. As a consequence, constraints can only be learned by violating them. This often precludes learning on the physical robot, as it may take many trials to learn the constraints, and the necessity to violate them during the trial-and-error learning may be unsafe. We have serendipitously discovered that constraint representations for shared control - in particular Shared Control Templates (SCTs) - are ideally suited for safely guiding RL. Representing constraints explicitly, rather than implicitly in the reward function, also simplifies the design of the reward function. The main advantage of the approach is safer, faster learning without constraint violations (even with sparse reward functions). We demonstrate this in a pouring task in simulation and on a real robot, where learning the task requires only 65 episodes in 16 minutes.",
        "primary_area": "",
        "author": "Abhishek Padalkar;Gabriel Quere;Franz Steinmetz;Antonin Raffin;Matthias Nieuwenhuisen;Jo\u00e3o Silv\u00e9rio;Freek Stulp;Abhishek Padalkar;Gabriel Quere;Franz Steinmetz;Antonin Raffin;Matthias Nieuwenhuisen;Jo\u00e3o Silv\u00e9rio;Freek Stulp",
        "authorids": "/37085822232;/37086933696;/37085752163;/37086936003;/37402749300;/37085736048;/37681682200;/37085822232;/37086933696;/37085752163;/37086936003;/37402749300;/37085736048;/37681682200",
        "aff": "German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany; Fraunhofer Institute for Communication, Information Processing and Ergonomics FKIE, Wachtberg; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161058/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6064093215635215337&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "German Aerospace Center;Fraunhofer Institute for Communication, Information Processing and Ergonomics FKIE",
        "aff_unique_dep": "Robotics and Mechatronics Center;",
        "aff_unique_url": "https://www.dlr.de;https://www.fkie.fraunhofer.de/",
        "aff_unique_abbr": "DLR;FKIE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Wachtberg",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160575",
        "title": "H-SAUR: Hypothesize, Simulate, Act, Update, and Repeat for Understanding Object Articulations from Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "The world is filled with articulated objects that are difficult to determine how to use from vision alone, e.g., a door might open inwards or outwards. Humans handle these objects with strategic trial-and-error: first pushing a door then pulling if that doesn't work. We enable these capabilities in autonomous agents by proposing \u201cHypothesize, Simulate, Act, Update, and Repeat\u201d (H-SAUR), a probabilistic generative framework that simultaneously generates a distribution of hypotheses about how objects articulate given input observations, captures certainty over hypotheses over time, and infer plausible actions for exploration and goal-conditioned manipulation. We compare our model with existing work in manipulating objects after a handful of exploration actions, on the PartNet-Mobility dataset. We further propose a novel PuzzleBoxes benchmark that contains locked boxes that require multiple steps to solve. We show that the proposed model significantly outperforms the current state-of-the-art articulated object manipulation framework, despite using zero training data. We further improve the test-time efficiency of H-SAUR by integrating a learned prior from learning-based vision models.",
        "primary_area": "",
        "author": "Kei Ota;Hsiao-Yu Tung;Kevin A. Smith;Anoop Cherian;Tim K. Marks;Alan Sullivan;Asako Kanezaki;Joshua B. Tenenbaum;Kei Ota;Hsiao-Yu Tung;Kevin A. Smith;Anoop Cherian;Tim K. Marks;Alan Sullivan;Asako Kanezaki;Joshua B. Tenenbaum",
        "authorids": "/37087323962;/37089895344;/37088836844;/37546001600;/37542341500;/37086700005;/37546453800;/37622583000;/37087323962;/37089895344;/37088836844;/37546001600;/37542341500;/37086700005;/37546453800;/37622583000",
        "aff": "Tokyo Institute of Technology, Japan; Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA, USA; Mitsubishi Electric Research Labs, Cambridge, MA, USA; Mitsubishi Electric Research Labs, Cambridge, MA, USA; Mitsubishi Electric Research Labs, Cambridge, MA, USA; Tokyo Institute of Technology, Japan; Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160575/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11209505389570595334&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;2;2;2;0;1",
        "aff_unique_norm": "Tokyo Institute of Technology;Massachusetts Institute of Technology;Mitsubishi Electric Research Labs",
        "aff_unique_dep": ";Department of Brain and Cognitive Sciences;",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.mit.edu;https://www.merl.com",
        "aff_unique_abbr": "Titech;MIT;MERL",
        "aff_campus_unique_index": "1;1;1;1;1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;1;1;1;1;1;0;1",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "10160655",
        "title": "HALO: Hazard-Aware Landing Optimization for Autonomous Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "With autonomous aerial vehicles enacting safety-critical missions, such as the Mars Science Laboratory Curiosity rover's landing on Mars, the tasks of automatically identifying and reasoning about potentially hazardous landing sites is paramount. This paper presents a coupled perception-planning solution which addresses the hazard detection, optimal landing trajectory generation, and contingency planning challenges encountered when landing in uncertain environments. Specifically, we develop and combine two novel algorithms, Hazard-Aware Landing Site Selection (HALSS) and Adaptive Deferred-Decision Trajectory Optimization (Adaptive-DDTO), to address the perception and planning challenges, respectively. The HALSS framework processes point cloud information to identify feasible safe landing zones, while Adaptive-DDTO is a multi-target contingency planner that adaptively replans as new perception information is received. We demonstrate the efficacy of our approach using a simulated Martian environment and show that our coupled perception-planning method achieves greater landing success whilst being more fuel efficient compared to a non-adaptive DDTO approach.",
        "primary_area": "",
        "author": "Christopher R. Hayner;Samuel C. Buckner;Daniel Broyles;Evelyn Madewell;Karen Leung;Beh\u00e7et A\u00e7ikme\u015fe;Christopher R. Hayner;Samuel C. Buckner;Daniel Broyles;Evelyn Madewell;Karen Leung;Beh\u00e7et A\u00e7ikme\u015fe",
        "authorids": "/37089662745;/37089896072;/37089663618;/37089893919;/37086453267;/38556527000;/37089662745;/37089896072;/37089663618;/37089893919;/37086453267;/38556527000",
        "aff": "Dept. of Aeronautics and Astronautics, University of Washington, USA; Dept. of Aeronautics and Astronautics, University of Washington, USA; Dept. of Aeronautics and Astronautics, University of Washington, USA; Dept. of Aeronautics and Astronautics, University of Washington, USA; Dept. of Aeronautics and Astronautics, University of Washington, USA; Dept. of Aeronautics and Astronautics, University of Washington, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160655/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5622003998161822648&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Dept. of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160431",
        "title": "HAT: Head-Worn Assistive Teleoperation of Mobile Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile manipulators in the home can provide increased autonomy to individuals with severe motor impairments, who often cannot complete activities of daily living (ADLs) without the help of a caregiver. Teleoperation of an assistive mobile manipulator could enable an individual with motor impairments to independently perform self-care and household tasks, yet limited motor function can impede one's ability to interface with a robot. In this work, we present a unique inertial-based wearable assistive interface, embedded in a familiar head-worn garment, for individuals with severe motor impairments to teleoperate and perform physical tasks with a mobile manipulator. We evaluate this wearable interface with both able-bodied (\\mathrm{N}=16\\mathrm{N}=16) and individuals with motor impairments (\\mathrm{N}=2\\mathrm{N}=2) for performing ADLs and everyday household tasks. Our results show that the wearable interface enabled participants to complete physical tasks with low error rates, high perceived ease of use, and low workload measures. Overall, this inertial-based wearable serves as a new assistive interface option for control of mobile manipulators in the home.",
        "primary_area": "",
        "author": "Akhil Padmanabha;Qin Wang;Daphne Han;Jashkumar Diyora;Kriti Kacker;Hamza Khalid;Liang-Jung Chen;Carmel Majidi;Zackory Erickson;Akhil Padmanabha;Qin Wang;Daphne Han;Jashkumar Diyora;Kriti Kacker;Hamza Khalid;Liang-Jung Chen;Carmel Majidi;Zackory Erickson",
        "authorids": "/37088507364;/37089894576;/37089894945;/37089893811;/37089895847;/37089895737;/37089892813;/37589572800;/37085785366;/37088507364;/37089894576;/37089894945;/37089893811;/37089895847;/37089895737;/37089892813;/37589572800;/37085785366",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160431/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9198390483270830767&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161214",
        "title": "HFT: Lifting Perspective Representations via Hybrid Feature Transformation for BEV Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Restoring an accurate Bird's Eye View (BEV) map plays a crucial role in the perception of autonomous driving. The existing works of lifting representations from frontal view to BEV can be classified into two categories, i.e., Camera model-Based Feature Transformation (CBFT) and Camera model-Free Feature Transformation (CFFT). We empirically analyze the significant differences between CBFT and CFFT. The former method lift perspective features based on the flat- world assumption, which often causes distortion of regions lying above the ground plane. The latter method is limited in the perception performance due to the absence of geometric priors and time-consuming computing. In this paper, we propose a novel framework with a Hybrid Feature Transformation module (HFT) to lift perspective representations. Furthermore, we design a mutual learning scheme to augment hybrid transformation. The deformable attention mechanism enables the model to pay more attention to relevant regions and capture features with more semantics. We illustrate the effectiveness of HFT in BEV perception tasks, such as segmentation and object detection. Notably, in the task of semantic segmentation, extensive experiments demonstrate that HFT outperforms the previous state-of-the-art method by relatively 17.9% on the Argoverse and 22.0% on the KITTI 3D Object dataset. With negligible computing budget, HFT outperforms existing image- based methods on 3D object detection. The code will be released soon.",
        "primary_area": "",
        "author": "Jiayu Zou;Zheng Zhu;Junjie Huang;Tian Yang;Guan Huang;Xingang Wang;Jiayu Zou;Zheng Zhu;Junjie Huang;Tian Yang;Guan Huang;Xingang Wang",
        "authorids": "/37089527204;/37085640794;/37089892495;/37089015795;/37087235182;/37407464000;/37089527204;/37085640794;/37089892495;/37089015795;/37087235182;/37407464000",
        "aff": "Institute of Automation, Chinese Academy of Sciences;, School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; PhiGent Robotics, Beijing, China; PhiGent Robotics, Beijing, China; PhiGent Robotics, Beijing, China; PhiGent Robotics, Beijing, China; Institute of Automation, Chinese Academy of Sciences;, School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161214/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15445878866777684056&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;2;2;0;1",
        "aff_unique_norm": "Chinese Academy of Sciences;University of Chinese Academy of Sciences;PhiGent Robotics",
        "aff_unique_dep": "Institute of Automation;School of Artificial Intelligence;",
        "aff_unique_url": "http://www.ia.cas.cn;http://www.ucas.ac.cn;",
        "aff_unique_abbr": "CAS;UCAS;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161019",
        "title": "HMAAC: Hierarchical Multi-Agent Actor-Critic for Aerial Search with Explicit Coordination Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned Aerial Vehicles (UAVs) have become prevalent in Search-And-Rescue (SAR) missions. However, existing solutions to the control and coordination of UAV s are mostly limited to specific environments and are not robust to handle unreliable/unstable communications. To deal with these challenges, Hierarchical Multi-Agent Actor-Critic (HMAAC) framework is proposed where a high-level policy is placed on top of individual low-level actor-critic policies to relax the inter-dependency among the agents. The low-level policies are considered conditionally independent given the coordination action, which is generated by the high-level policy. A Central-ized Training Decentralized Execution (CTDE) would not work because it cannot be assumed that communication is always perfect during training and that the whole system can rely on stable communications during deployment. The proposed framework is evaluated in AirSim, a realistic multi-UAV simula-tor, and is compared against two existing algorithms, i.e., Multi- Agent Actor-Critic (MAAC) and decentralized REINFORCE, in two scenarios, (a) when packet drop is modeled as a Bernoulli process and (b) when shadow zones are created in the search space and communication will be lost if the agents are in these zones. Results show that HMAAC is scalable and robust to unreliable communication and outperforms the other algorithms in terms of exploration and coordination when the number of agents is large and communications are not stable.",
        "primary_area": "",
        "author": "Chuanneng Sun;Songjun Huang;Dario Pompili;Chuanneng Sun;Songjun Huang;Dario Pompili",
        "authorids": "/37088760450;/37088965249;/37269715300;/37088760450;/37088965249;/37269715300",
        "aff": "Dept. of Electrical and Computer Engineering, Rutgers University, New Brunswick, NJ, USA; Dept. of Electrical and Computer Engineering, Rutgers University, New Brunswick, NJ, USA; Dept. of Electrical and Computer Engineering, Rutgers University, New Brunswick, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161019/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14133450339576906388&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161179",
        "title": "HREyes: Design, Development, and Evaluation of a Novel Method for AUVs to Communicate Information and Gaze Direction*",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the design, development, and evaluation of HREyes: biomimetic communication devices which use light to communicate information and, for the first time, gaze direction from AUVs to humans. First, we introduce two types of information displays using the HREye devices: active lucemes and ocular lucemes. Active lucemes communicate information explicitly through animations, while ocular lucemes communicate gaze direction implicitly by mimicking human eyes. We present a human study in which our system is compared to the use of an embedded digital display that explicitly communicates information to a diver by displaying text. Our results demonstrate accurate recognition of active lucemes for trained interactants, limited intuitive understanding of these lucemes for untrained interactants, and relatively accurate perception of gaze direction for all interactants. The results on active luceme recognition demonstrate more accurate recognition than previous light-based communication systems for AUVs (albeit with different phrase sets). Additionally, the ocular lucemes we introduce in this work represent the first method for communicating gaze direction from an AUV, a critical aspect of nonverbal communication used in collabo-rative work. With readily available hardware as well as open-source and easily re-configurable programming, HREyes can be easily integrated into any AUV with the physical space for the devices and used to communicate effectively with divers in any underwater environment with appropriate visibility.",
        "primary_area": "",
        "author": "Michael Fulton;Aditya Prabhu;Junaed Sattar;Michael Fulton;Aditya Prabhu;Junaed Sattar",
        "authorids": "/37086541498;/37089896081;/37546394500;/37086541498;/37089896081;/37546394500",
        "aff": "Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161179/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13438228137220487642&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota Twin Cities",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160648",
        "title": "HaPPArray: Haptic Pneumatic Pouch Array for Feedback in handheld Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Haptic feedback can provide operators of hand-held robots with active guidance during challenging tasks and with critical information on environment interactions. Yet for such haptic feedback to be effective, it must be lightweight, capable of integration into a hand-held form factor, and capable of displaying easily discernible cues. We present the design and evaluation of HaPPArray - a haptic pneumatic pouch array - where the pneumatic pouches can be actuated alone or in sequence to provide information to the user. A 3x3 array of pouches was integrated into a handle, representative of an interface for a hand-held robot. When actuated individually, users were able to correctly identify the pouch being actuated with 86% accuracy, and when actuated in sequence, users were able to correctly identify the associated direction cue with 89 % accuracy. These results, along with a demonstration of how the direction cues can be used for haptic guidance of a medical robot, suggest that HaPPArray can be an effective approach for providing haptic feedback for hand-held robots.",
        "primary_area": "",
        "author": "Xiaolei Luo;Jui-Te Lin;Tania K. Morimoto;Xiaolei Luo;Jui-Te Lin;Tania K. Morimoto",
        "authorids": "/37089894003;/37089629599;/37085803241;/37089894003;/37089629599;/37085803241",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering and the Department of Surgery, University of California, San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160648/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3877678087267695678&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161492",
        "title": "Handling Sparse Rewards in Reinforcement Learning Using Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) has recently proven great success in various domains. Yet, the design of the reward function requires detailed domain expertise and tedious fine-tuning to ensure that agents are able to learn the desired behaviour. Using a sparse reward conveniently mitigates these challenges. However, the sparse reward represents a challenge on its own, often resulting in unsuccessful training of the agent. In this paper, we therefore address the sparse reward problem in RL. Our goal is to find an effective alternative to reward shaping, without using costly human demonstrations, that would also be applicable to a wide range of domains. Hence, we propose to use model predictive control (MPC) as an experience source for training RL agents in sparse reward environments. Without the need for reward shaping, we successfully apply our approach in the field of mobile robot navigation both in simulation and real-world experiments with a Kuboki Turtlebot 2. We furthermore demonstrate great improvement over pure RL algorithms in terms of success rate as well as number of collisions and timeouts. Our experiments show that MPC as an experience source improves the agent's learning process for a given task in the case of sparse rewards.",
        "primary_area": "",
        "author": "Murad Dawood;Nils Dengler;Jorge de Heuvel;Maren Bennewitz;Murad Dawood;Nils Dengler;Jorge de Heuvel;Maren Bennewitz",
        "authorids": "/37088350104;/37087049550;/37089550708;/37324765000;/37088350104;/37087049550;/37089550708;/37324765000",
        "aff": "Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Humanoid Robots Lab., University of Bonn, Germany; Humanoid Robots Lab., University of Bonn, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161492/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16512617534620490711&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Lamarr Institute for Machine Learning and Artificial Intelligence;University of Bonn",
        "aff_unique_dep": ";Humanoid Robots Lab.",
        "aff_unique_url": ";https://www.uni-bonn.de",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161499",
        "title": "Hardware-in-the-Loop Simulator with Low-Thrust Actuator for Free-Flying Robot's Omni-Directional Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Small free-flying robots to assist astronauts and perform experiments need a propulsion system to move freely in microgravity. Hardware-in-the-loop (HIL) simulators can simultaneously verify guidance, navigation, and control (GNC) systems, including flight hardware and software, in three dimensions. However, it is difficult to incorporate a small free-flying robot into the HIL simulator because of the low propulsive force and gravity compensation associated with its attitude changes. This paper proposes a HIL simulator with a propulsion subsystem mounted on a statically fixed force/torque sensor and a GNC subsystem mounted on a dynamically movable robotic arm. This simulator allows us to verify the GNC algorithms comprehensively using actual navigation sensors and propulsive actuators in an emulated flight environment. The actual capabilities of this simulator were successfully demonstrated in motion verifications of a free-flying robot, the Int-Ball2.",
        "primary_area": "",
        "author": "Daichi Hirano;Shinji Mitani;Taisei Nishishita;Tatsuhiko Saito;Daichi Hirano;Shinji Mitani;Taisei Nishishita;Tatsuhiko Saito",
        "authorids": "/37860658100;/37085425149;/37089894439;/37086578997;/37860658100;/37085425149;/37089894439;/37086578997",
        "aff": "Research and Development Directorate, Japan Aerospace Exploration Agency (JAXA), Ibaraki, Japan; Research and Development Directorate, Japan Aerospace Exploration Agency (JAXA), Ibaraki, Japan; Research and Development Directorate, Japan Aerospace Exploration Agency (JAXA), Ibaraki, Japan; System Development Department, Systems Engineering Consultants Co., Ltd., Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161499/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7768706217924994791&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Japan Aerospace Exploration Agency;Systems Engineering Consultants Co., Ltd.",
        "aff_unique_dep": "Research and Development Directorate;System Development Department",
        "aff_unique_url": "https://www.jaxa.jp;",
        "aff_unique_abbr": "JAXA;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ibaraki;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161338",
        "title": "Hazard Analysis of Collaborative Automation Systems: A Two-layer Approach based on Supervisory Control and Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety critical systems are typically subjected to hazard analysis before commissioning to identify and analyse potentially hazardous system states that may arise during operation. Currently, hazard analysis is mainly based on human reasoning, past experiences, and simple tools such as checklists and spreadsheets. Increasing system complexity makes such approaches decreasingly suitable. Furthermore, testing-based hazard analysis is often not suitable due to high costs or dangers of physical faults. A remedy for this are model-based hazard analysis methods, which either rely on formal models or on simulation models, each with their own benefits and drawbacks. This paper proposes a two-layer approach that combines the benefits of exhaustive analysis using formal methods with detailed analysis using simulation. Unsafe behaviours that lead to unsafe states are first synthesised from a formal model of the system using Supervisory Control Theory. The result is then input to the simulation where detailed analyses using domain-specific risk metrics are performed. Though the presented approach is generally applicable, this paper demonstrates the benefits of the approach on an industrial human-robot collaboration system.",
        "primary_area": "",
        "author": "Tom P. Huck;Yuvaraj Selvaraj;Constantin Cronrath;Christoph Ledermann;Martin Fabian;Bengt Lennartson;Torsten Kr\u00f6ger;Tom P. Huck;Yuvaraj Selvaraj;Constantin Cronrath;Christoph Ledermann;Martin Fabian;Bengt Lennartson;Torsten Kr\u00f6ger",
        "authorids": "/37088590233;/37086350791;/37085898261;/38468554800;/37282468500;/37300996400;/37283223400;/37088590233;/37086350791;/37085898261;/38468554800;/37282468500;/37300996400;/37283223400",
        "aff": "Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology, India; Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Gothenburg, Sweden; Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Gothenburg, Sweden; Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology, India; Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Gothenburg, Sweden; Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Gothenburg, Sweden; Torsten Kr\u00f6ger",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161338/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14909366638132315110&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;1;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Chalmers University of Technology;",
        "aff_unique_dep": "Institute of Anthropomatics and Robotics;Department of Electrical Engineering, Division of Systems and Control;",
        "aff_unique_url": "https://www.kit.edu;https://www.chalmers.se;",
        "aff_unique_abbr": "KIT;Chalmers;",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Gothenburg",
        "aff_country_unique_index": "0;1;1;0;1;1",
        "aff_country_unique": "Germany;Sweden;"
    },
    {
        "id": "10161547",
        "title": "Heading Control of a Long-Endurance Insect-Scale Aerial Robot Powered by Soft Artificial Muscles",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial insects demonstrate fast and precise heading control when they perform body saccades and rapid escape maneuvers. While insect-scale micro-aerial-vehicles (IMAVs) have demonstrated early results on heading control, their flight endurance and heading angle tracking accuracy remain far inferior to that of natural fliers. In this work, we present a long endurance sub-gram aerial robot that can demonstrate effective heading control during hovering flight. Through using a tilted wing stroke-plane design, our robot demonstrates a 10-second flight where it tracks a desired yaw trajectory with maximum and root-mean-square (RMS) error of \\boldsymbol{14.2^{\\circ}}\\boldsymbol{14.2^{\\circ}} and \\boldsymbol{5.8}^{\\mathrm{o}}\\boldsymbol{5.8}^{\\mathrm{o}}. The new robot design requires 7% higher lift forces for enabling heading angle control, which creates higher stress on wing hinges and adversely influences robot endurance. To address this challenge, we developed novel 3-layered wing hinges that exhibit 1.82 times improvement of lifetime. With the new wing hinges, our robot demonstrates a 40-second hovering flight - the longest among existing sub-gram IMAVs. These results represent substantial improvement of flight capabilities in soft-actuated IMAVs, showing the potential of operating these insect-like fliers in cluttered natural environments.",
        "primary_area": "",
        "author": "Yi-Hsuan Hsiao;Suhan Kim;Zhijian Ren;YuFeng Chen;Yi-Hsuan Hsiao;Suhan Kim;Zhijian Ren;YuFeng Chen",
        "authorids": "/37086580197;/37087323805;/37088488889;/37085417667;/37086580197;/37087323805;/37088488889;/37085417667",
        "aff": "Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Electrical Engineering and Computer Science, Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161547/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15749222529007368714&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160347",
        "title": "Heading for the Abyss: Control Strategies for Exploiting Swinging of a Descending Tethered Aerial Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of aerial vehicles for exploration and data collection has the potential to significantly aid environmental monitoring in environments which are dangerous and hard to navigate. However, within these environments navigation can often be restricted by overhangs which are challenging to navigate, particularly so with the high payloads required for environmental monitoring. We propose utilizing a tethered bicopter with horizontal propellers. This spherical pendulum like system can exploit the tether, not only as a means of powering and recovering the robot, but also to assist its motion, i.e. by swinging to increase the workspace of the robot. Using PD-based control, we demonstrate how the system can be stabilized and bang-bang control to excite the system to achieve large amplitude swinging. By combining these controllers, we show how the system can be used to navigate in a glacial-inspired scenario where there are overhangs and obstacles through which the robot must navigate.",
        "primary_area": "",
        "author": "Max Polzin;Frank Centamori;Josie Hughes;Max Polzin;Frank Centamori;Josie Hughes",
        "authorids": "/37086182380;/37089891863;/37085816016;/37086182380;/37089891863;/37085816016",
        "aff": "Faculty of Mechanical Engineering, Swiss Federal Institute of Technology Lausanne, Lausanne, Switzerland; Faculty of Mechanical Engineering, Swiss Federal Institute of Technology Lausanne, Lausanne, Switzerland; Faculty of Mechanical Engineering, Swiss Federal Institute of Technology Lausanne, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160347/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11590229690585551935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Swiss Federal Institute of Technology Lausanne",
        "aff_unique_dep": "Faculty of Mechanical Engineering",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10160414",
        "title": "Heterogeneous Coverage and Multi-Resource Allocation in Supply-Constrained Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider a team of heterogeneous robots, each equipped with various types and quantities of resources, and tasked with supplying these resources to multiple areas of demand. We propose a Voronoi-based coverage control approach to deploy robots to areas of demand by defining a position- and time-varying density function to represent the quality at which demand is being met in the environment. This approach allows robots to prioritize the various demand locations in a continuous, distributed fashion. We present analyses to show that our controls drive the robots to critical points in the environment, along with simulations and hardware-in-the-loop experiments to demonstrate our approach.",
        "primary_area": "",
        "author": "Mela Coffey;Alyssa Pierson;Mela Coffey;Alyssa Pierson",
        "authorids": "/37088336178;/37085345711;/37088336178;/37085345711",
        "aff": "Department of Mechanical Engineering, Boston University, Boston, MA, USA; Department of Mechanical Engineering, Boston University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160414/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=574132998374203936&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160523",
        "title": "Hierarchical Adaptive Loco-manipulation Control for Quadruped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots have shown remarkable advantages in navigating uneven terrain. However, realizing effective loco-motion and manipulation tasks on quadruped robots is still challenging. In addition, object and terrain parameters are generally unknown to the robot in these problems. Therefore, this paper proposes a hierarchical adaptive control framework that enables legged robots to perform loco-manipulation tasks without any given assumption on the object's mass, the friction coefficient, or the slope of the terrain. In our approach, we first present an adaptive manipulation control to regulate the contact force to manipulate an unknown object on unknown terrain. We then introduce a unified model predictive control (MPC) for loco-manipulation that takes into account the manipulation force in our robot dynamics. The proposed MPC framework thus can effectively regulate the interaction force between the robot and the object while keeping the robot balance. Experimental validation of our proposed approach is successfully conducted on a Unitree A1 robot, allowing it to manipulate an unknown time-varying load up to 7 kg (60% of the robot's weight). Moreover, our framework enables fast adaptation to unknown slopes or different surfaces with different friction coefficients.",
        "primary_area": "",
        "author": "Mohsen Sombolestan;Quan Nguyen;Mohsen Sombolestan;Quan Nguyen",
        "authorids": "/37089195082;/37085362091;/37089195082;/37085362091",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160523/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12329191772012527732&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160918",
        "title": "Hierarchical Approach for Joint Semantic, Plant Instance, and Leaf Instance Segmentation in the Agricultural Domain",
        "track": "main",
        "status": "Poster",
        "abstract": "Plant phenotyping is a central task in agriculture, as it describes plants' growth stage, development, and other relevant quantities. Robots can help automate this process by accurately estimating plant traits such as the number of leaves, leaf area, and the plant size. In this paper, we address the problem of joint semantic, plant instance, and leaf instance segmentation of crop fields from RGB data. We propose a single convolutional neural network that addresses the three tasks simultaneously, exploiting their underlying hierarchical structure. We introduce task-specific skip connections, which our experimental evaluation proves to be more beneficial than the usual schemes. We also propose a novel automatic post-processing, which explicitly addresses the problem of spatially close instances, common in the agricultural domain because of overlapping leaves. Our architecture simultaneously tackles these problems jointly in the agricultural context. Previous works either focus on plant or leaf segmentation, or do not optimise for semantic segmentation. Results show that our system has superior performance compared to state-of-the-art approaches, while having a reduced number of parameters and is operating at camera frame rate.",
        "primary_area": "",
        "author": "Gianmarco Roggiolani;Matteo Sodano;Tiziano Guadagnino;Federico Magistri;Jens Behley;Cyrill Stachniss;Gianmarco Roggiolani;Matteo Sodano;Tiziano Guadagnino;Federico Magistri;Jens Behley;Cyrill Stachniss",
        "authorids": "/37089894689;/37089432308;/37087324270;/37086805350;/37593243900;/37329668600;/37089894689;/37089432308;/37087324270;/37086805350;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; La Sapienza University of Rome, Italy; University of Bonn, Germany; University of Bonn, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160918/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11849638086187346443&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;2",
        "aff_unique_norm": "University of Bonn;La Sapienza University of Rome;Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.uniroma1.it;",
        "aff_unique_abbr": "UBonn;Sapienza;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "Germany;Italy"
    },
    {
        "id": "10161264",
        "title": "Hierarchical Graph Neural Networks for Proprioceptive 6D Pose Estimation of In-hand Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulation, in particular in-hand object manipulation, often requires an accurate estimate of the object's 6D pose. To improve the accuracy of the estimated pose, state-of-the-art approaches in 6D object pose estimation use observational data from one or more modalities, e.g., RGB images, depth, and tactile readings. However, existing approaches make limited use of the underlying geometric structure of the object captured by these modalities, thereby, increasing their reliance on visual features. This results in poor performance when presented with objects that lack such visual features or when visual features are simply occluded. Furthermore, current approaches do not take advantage of the proprioceptive information embedded in the position of the fingers. To address these limitations, in this paper: (1) we introduce a hierarchical graph neural network architecture for combining multimodal (vision and touch) data that allows for a geometrically informed 6D object pose estimation, (2) we introduce a hierarchical message passing operation that flows the information within and across modalities to learn a graph-based object representation, and (3) we introduce a method that accounts for the proprioceptive information for in-hand object representation. We evaluate our model on a diverse subset of objects from the YCB Object and Model Set, and show that our method substantially outperforms existing state-of-the-art work in accuracy and robustness to occlusion. We also deploy our proposed framework on a real robot and qualitatively demonstrate successful transfer to real settings.",
        "primary_area": "",
        "author": "Alireza Rezazadeh;Snehal Dikhale;Soshi Iba;Nawid Jamali;Alireza Rezazadeh;Snehal Dikhale;Soshi Iba;Nawid Jamali",
        "authorids": "/37089894065;/37089255431;/37329555300;/37546207800;/37089894065;/37089255431;/37329555300;/37546207800",
        "aff": "Department of Electrical and Computer Engineering, University of Minnesota; Honda Research Institute USA, Inc.; Honda Research Institute USA, Inc.; Honda Research Institute USA, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161264/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8870514345149619655&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Minnesota;Honda Research Institute USA",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Research Institute",
        "aff_unique_url": "https://www.umn.edu;https://honda-ri.com",
        "aff_unique_abbr": "UMN;HRI USA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160515",
        "title": "Hierarchical Intention Tracking for Robust Human-Robot Collaboration in Industrial Assembly Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots require effective human intention estimation to safely and smoothly work with humans in less structured tasks such as industrial assembly, where human intention continuously changes. We propose the concept of intention tracking and introduce a collaborative robot system that concurrently tracks intentions at hierarchical levels. The high-level intention is tracked to estimate human's interaction pattern and enable robot to (1) avoid collision with human to minimize interruption and (2) assist human to correct failure. The low-level intention estimate provides robot with task-related information. We implement the system on a UR5e robot and demonstrate robust, seamless and ergonomic human-robot collaboration in an ablative pilot study of an assembly use case.",
        "primary_area": "",
        "author": "Zhe Huang;Ye-Ji Mun;Xiang Li;Yiqing Xie;Ninghan Zhong;Weihang Liang;Junyi Geng;Tan Chen;Katherine Driggs-Campbell;Zhe Huang;Ye-Ji Mun;Xiang Li;Yiqing Xie;Ninghan Zhong;Weihang Liang;Junyi Geng;Tan Chen;Katherine Driggs-Campbell",
        "authorids": "/37087885165;/37089449010;/37089892204;/37089895055;/37089892832;/37089001263;/37089251620;/37086128468;/37085509519;/37087885165;/37089449010;/37089892204;/37089895055;/37089892832;/37089001263;/37089251620;/37086128468;/37085509519",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Computer Science, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Aerospace Engineering, Pennsylvania State University; Department of Electrical and Computer Engineering, Michigan Technological University; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160515/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13840372744967220864&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;1;2;0",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign;Pennsylvania State University;Michigan Technological University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Aerospace Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu;https://www.psu.edu;https://www.mtu.edu",
        "aff_unique_abbr": "UIUC;PSU;MTU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161374",
        "title": "Hierarchical Policy Blending as Inference for Reactive Robot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion generation in cluttered, dense, and dynamic environments is a central topic in robotics, rendered as a multi-objective decision-making problem. Current approaches trade-off between safety and performance. On the one hand, reactive policies guarantee a fast response to environmental changes at the risk of suboptimal behavior. On the other hand, planning-based motion generation provides feasible trajectories, but the high computational cost may limit the control frequency and, thus, safety. To combine the benefits of reactive policies and planning, we propose a hierarchical motion generation method. Moreover, we employ probabilistic inference methods to formalize the hierarchical model and stochastic optimization. We realize this approach as a weighted product of stochastic, reactive expert policies, where planning is used to adaptively compute the optimal weights over the task horizon. This stochastic optimization avoids local optima and proposes feasible reactive plans that find paths in cluttered and dense environments. Our extensive experimental study in planar navigation and 7DoF manipulation shows that our proposed hierarchical motion generation method outperforms both myopic reactive controllers and online re-planning methods. Additional material available at https://sites.google.com/view/hipbi.",
        "primary_area": "",
        "author": "Kay Hansel;Julen Urain;Jan Peters;Georgia Chalvatzaki;Kay Hansel;Julen Urain;Jan Peters;Georgia Chalvatzaki",
        "authorids": "/37089831837;/37086435541;/37533077600;/37085353493;/37089831837;/37086435541;/37533077600;/37085353493",
        "aff": "Computer Science Department, Technische Universit\u00e4t Darmstadt, Germany; Computer Science Department, Technische Universit\u00e4t Darmstadt, Germany; Centre for Cognitive Science; Hessian.AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161374/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12907925505220968412&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;Centre for Cognitive Science;Hessian.AI",
        "aff_unique_dep": "Computer Science Department;Cognitive Science;",
        "aff_unique_url": "https://www.tu-darmstadt.de;;https://www.hessian.ai",
        "aff_unique_abbr": "TUD;;Hessian.AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;2",
        "aff_country_unique": "Germany;;China"
    },
    {
        "id": "10160718",
        "title": "Hierarchical Whole-body Control of the cable-Suspended Aerial Manipulator endowed with Winch-based Actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "During operation, aerial manipulation systems are affected by various disturbances. Among them is a gravitational torque caused by the weight of the robotic arm. Common propeller-based actuation is ineffective against such disturbances because of possible overheating and high power consumption. To overcome this issue, in this paper we propose a winch-based actuation for the crane-stationed cable-suspended aerial manipulator. Three winch-controlled suspension rigging cables produce a desired cable tension distribution to generate a wrench that reduces the effect of gravitational torque. In order to coordinate the robotic arm and the winch-based actuation, a model-based hierarchical whole-body controller is adapted. It resolves two tasks: keeping the robotic arm end-effector at the desired pose and shifting the system center of mass in the location with zero gravitational torque. The performance of the introduced actuation system as well as control strategy is validated through experimental studies.",
        "primary_area": "",
        "author": "Yuri S. Sarkisov;Andre Coelho;Maihara G. Santos;Min Jun Kim;Dzmitry Tsetserukou;Christian Ott;Konstantin Kondak;Yuri S. Sarkisov;Andre Coelho;Maihara G. Santos;Min Jun Kim;Dzmitry Tsetserukou;Christian Ott;Konstantin Kondak",
        "authorids": "/37086345232;/37086573823;/37089892903;/38239144100;/37548023000;/37282440400;/37427143400;/37086345232;/37086573823;/37089892903;/38239144100;/37548023000;/37282440400;/37427143400",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Dextrous Robotics Inc., Memphis, United States; Instituto Tecnol\u00f3gico de Aeron\u00e1utica, S\u00e3o Jos\u00e9 dos Campos, Brazil; Intelligent Robotic Systems Lab, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea; Dzmitry Tsetserukou; Automation and Control Institute, TU Wien, Vienna, Austria; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160718/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2596409602856008294&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;5;0",
        "aff_unique_norm": "German Aerospace Center (DLR);Dextrous Robotics Inc.;Instituto Tecnol\u00f3gico de Aeron\u00e1utica;Korea Advanced Institute of Science and Technology;;TU Wien",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;;;Intelligent Robotic Systems Lab;;Automation and Control Institute",
        "aff_unique_url": "https://www.dlr.de;;http://www.ita.br;https://www.kaist.ac.kr;;https://www.tuwien.ac.at",
        "aff_unique_abbr": "DLR;;ITA;KAIST;;TU Wien",
        "aff_campus_unique_index": "0;2;3;4;0",
        "aff_campus_unique": "Wessling;;S\u00e3o Jos\u00e9 dos Campos;Daejeon;Vienna",
        "aff_country_unique_index": "0;1;2;3;5;0",
        "aff_country_unique": "Germany;United States;Brazil;South Korea;;Austria"
    },
    {
        "id": "10161429",
        "title": "High Resolution Point Clouds from mmWave Radar",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores a machine learning approach on data from a single-chip mmWave radar for generating high resolution point clouds \u2013 a key sensing primitive for robotic applications such as mapping, odometry and localization. Unlike lidar and vision-based systems, mmWave radar can operate in harsh environments and see through occlusions like smoke, fog, and dust. Unfortunately, current mmWave processing techniques offer poor spatial resolution compared to lidar point clouds. This paper presents RadarHD, an end-to-end neural network that constructs lidar-like point clouds from low resolution radar input. Enhancing radar images is challenging due to the presence of specular and spurious reflections. Radar data also doesn't map well to traditional image processing techniques due to the signal's sinc-like spreading pattern. We overcome these challenges by training RadarHD on a large volume of raw I/Q radar data paired with lidar point clouds across diverse indoor settings. Our experiments show the ability to generate rich point clouds even in scenes unobserved during training and in the presence of heavy smoke occlusion. Further, RadarHD's point clouds are high-quality enough to work with existing lidar odometry and mapping workflows.",
        "primary_area": "",
        "author": "Akarsh Prabhakara;Tao Jin;Arnav Das;Gantavya Bhatt;Lilly Kumari;Elahe Soltanaghai;Jeff Bilmes;Swarun Kumar;Anthony Rowe;Akarsh Prabhakara;Tao Jin;Arnav Das;Gantavya Bhatt;Lilly Kumari;Elahe Soltanaghai;Jeff Bilmes;Swarun Kumar;Anthony Rowe",
        "authorids": "/37089644683;/37089894827;/37089895960;/37088968753;/37089895003;/37089237693;/37271129500;/37085847897;/37324658900;/37089644683;/37089894827;/37089895960;/37088968753;/37089895003;/37089237693;/37271129500;/37085847897;/37324658900",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; University of Washington; University of Washington; University of Washington; University of Illinois, Urbana-Champaign; University of Washington; Carnegie Mellon University; Bosch Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161429/",
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3044362906815674504&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;1;1;2;1;0;3",
        "aff_unique_norm": "Carnegie Mellon University;University of Washington;University of Illinois;Bosch Research",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.cmu.edu;https://www.washington.edu;https://illinois.edu;https://research.bosch.com",
        "aff_unique_abbr": "CMU;UW;UIUC;Bosch",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;1",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "10161022",
        "title": "High-Speed High-Accuracy Spatial Curve Tracking Using Motion Primitives in Industrial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial robots are increasingly deployed in applications requiring an end effector tool to closely track a specified path, such as in spraying and welding. Performance and productivity present possibly conflicting objectives: tracking accuracy, path speed, and motion uniformity. Industrial robots are programmed through motion primitives consisting of waypoints connected by pre-defined motion segments, with specified parameters such as path speed and blending zone. The actual executed robot motion depends on the robot joint servo controller and joint motion constraints (e.g., velocity, acceleration limits) which are largely unknown to the users. Programming a robot to achieve the desired performance today is time-consuming and mostly manual, requiring tuning a large number of coupled parameters in the motion primitives. The performance also depends on the choice of additional param-eters: possible redundant degrees of freedom, location of the target curve, and the robot configuration. This paper presents a systematic approach to optimize robot motion parameters. The approach first selects the static parameters, then chooses the motion primitives, and finally iteratively updates the waypoints to minimize the tracking error. The ultimate performance objective is to maximize the path speed subject to the tracking accuracy and speed uniformity constraints over the entire path. We have demonstrated the effectiveness of this approach both in simulation and on physical systems for ABB and FANUC robots applied to two challenging example curves. Comparing with the baseline using the current industry practice, the optimized performance shows over 100% performance improvement.",
        "primary_area": "",
        "author": "Honglu He;Chen-lung Lu;Yunshi Wen;Glenn Saunders;Pinghai Yang;Jeffrey Schoonover;John Wason;Agung Julius;John T. Wen;Honglu He;Chen-lung Lu;Yunshi Wen;Glenn Saunders;Pinghai Yang;Jeffrey Schoonover;John Wason;Agung Julius;John T. Wen",
        "authorids": "/37089579683;/37089893103;/37089895062;/38099159300;/37089893245;/37089894323;/37396209400;/37301262900;/37278935000;/37089579683;/37089893103;/37089895062;/38099159300;/37089893245;/37089894323;/37396209400;/37301262900;/37278935000",
        "aff": "Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute; Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute; Manufacturing Innovations Center, Rensselaer Polytechnic Institute; Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute; GE Research, US; GE Research, US; Wason Technology, LLC; Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute; Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161022/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8412108965727805926&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;1;1;2;0;0",
        "aff_unique_norm": "Rensselaer Polytechnic Institute;GE Research;Wason Technology",
        "aff_unique_dep": "Electrical, Computer, and Systems Engineering;;",
        "aff_unique_url": "https://www.rpi.edu;https://www.ge.com/research;",
        "aff_unique_abbr": "RPI;GER;Wason Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160263",
        "title": "High-Speed Scooping: An Implementation through Stiffness Control and Direct-Drive Actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "This study presents the technique of robotic high-speed scooping: rapidly picking an object lying on a support surface by making contact with the object's open top face and the bottom face that is hidden in contact with the support surface. Essential to high-speed scooping is thus to make suitable dynamic, impactful interaction happen among the robot, object, and environment under errors and uncertainties. We propose a solution to this challenge based on stiffness control, an approach for indirect force control using the robot that is arranged to behave like a desired mechanical system. An implementation of the solution is then presented using a custom-built two-fingered direct-drive gripper. Our experiments verify that high-speed scooping operation is achievable, with the duration of dynamic interaction less than 0.3 s, and effective to various scooping situations featuring objects durable and fragile.",
        "primary_area": "",
        "author": "Ka Hei Mak;Pu Xu;Jungwon Seo;Ka Hei Mak;Pu Xu;Jungwon Seo",
        "authorids": "/37089255332;/37089477095;/38252779400;/37089255332;/37089477095;/38252779400",
        "aff": "Ka Hei Mak; Pu Xu; Pusan National University, Rep. of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160263/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5660729488617334228&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Pusan National University",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.pnu.ac.kr",
        "aff_unique_abbr": ";PNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";South Korea"
    },
    {
        "id": "10161468",
        "title": "Holistic Graph-based Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion prediction for automated vehicles in complex environments is a difficult task that is to be mastered when automated vehicles are to be used in arbitrary situations. Many factors influence the future motion of traffic participants starting with traffic rules and reaching from the interaction between each other to personal habits of human drivers. Therefore, we present a novel approach for a graph-based prediction based on a heterogeneous holistic graph representation that combines temporal information, properties and relations between traffic participants as well as relations with static elements such as the road network. The information is encoded through different types of nodes and edges that both are enriched with arbitrary features. We evaluated the approach on the INTERACTION and the Argoverse dataset and conducted an informative ablation study to demonstrate the benefit of different types of information for the motion prediction quality.",
        "primary_area": "",
        "author": "Daniel Grimm;Philip Sch\u00f6rner;Moritz Dre\u00dfler;J.-Marius Z\u00f6llner;Daniel Grimm;Philip Sch\u00f6rner;Moritz Dre\u00dfler;J.-Marius Z\u00f6llner",
        "authorids": "/37090059463;/37086963019;/37089892833;/38558111200;/37090059463;/37086963019;/37089892833;/38558111200",
        "aff": "FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Germany; Karlsruhe Institute of Technology (KIT), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161468/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18249029243069794168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "FZI Research Center for Information Technology;Karlsruhe Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.fzi.de;https://www.kit.edu",
        "aff_unique_abbr": "FZI;KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Karlsruhe;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161163",
        "title": "Holistic view of Inverse Optimal Control by introducing projections on singularity curves",
        "track": "main",
        "status": "Poster",
        "abstract": "Inverse optimal control (IOC) is a framework used in many fields, especially in robotics and human motion analysis. In this context, various methods of resolution have been proposed in the literature. This article presents Projected Inverse Optimal Control (PIOC), an approach that offers a simple and comprehensive view of IOC methods. Especially, we explain how uncertainties can be properly addressed in our view. Thus, this article highlights how classical methods can be understood as projections of trajectories in the solution space of the underlying Direct Optimal Control (DOC) problem. This perspective allows for an examination of projections other than the classical methods, which can be fruitful for researchers in the field. As an example, we propose a projection that allows us to choose the underlying cost functions of an IOC problem from a set. The IOC's sub-problems are also addressed, such as modelling observed trajectories, noise measurement and the reliability of solutions obtained by IOC. Our proposal is supported by a simple and canonical example throughout the document.",
        "primary_area": "",
        "author": "Jessica Colombel;David Daney;Fran\u00e7ois Charpillet;Jessica Colombel;David Daney;Fran\u00e7ois Charpillet",
        "authorids": "/37089449428;/37273442100;/37284255200;/37089449428;/37273442100;/37284255200",
        "aff": "Jessica Colombel; David Daney; Fran\u00e7ois Charpillet",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161163/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8500723066272419045&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10160547",
        "title": "Holo-Dex: Teaching Dexterity with Immersive Mixed Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "A fundamental challenge in teaching robots is to provide an effective interface for human teachers to demonstrate useful skills to a robot. This challenge is exacerbated in dexterous manipulation, where teaching high-dimensional, contact-rich behaviors often require esoteric teleoperation tools. In this work, we present Holo \u2212 Dex, a framework for dexter-ous manipulation that places a teacher in an immersive mixed reality through commodity VR headsets. The high-fidelity hand pose estimator onboard the headset is used to teleoperate the robot and collect demonstrations for a variety of general-purpose dexterous tasks. Given these demonstrations, we use powerful feature learning combined with non-parametric imi-tation to train dexterous skills. Our experiments on six common dexterous tasks, including in-hand rotation, spinning, and bottle opening, indicate that HOLO-DEX can both collect high-quality demonstration data and train skills in a matter of hours. Finally, we find that our trained skills can exhibit generalization on objects not seen in training. Videos of HOLO \u2212 DEX are available on {https://holo-dex.github.io/.}",
        "primary_area": "",
        "author": "Sridhar Pandian Arunachalam;Irmak G\u00fczey;Soumith Chintala;Lerrel Pinto;Sridhar Pandian Arunachalam;Irmak G\u00fczey;Soumith Chintala;Lerrel Pinto",
        "authorids": "/37089892054;/37089893908;/38547691300;/37085796211;/37089892054;/37089893908;/38547691300;/37085796211",
        "aff": "New York University; New York University; Meta AI Research; New York University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160547/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16739392439072261748&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "New York University;Meta Platforms, Inc.",
        "aff_unique_dep": ";Meta AI Research",
        "aff_unique_url": "https://www.nyu.edu;https://meta.com",
        "aff_unique_abbr": "NYU;Meta AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161398",
        "title": "Household Clothing Set and Benchmarks for Characterising End-Effector Cloth Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The highly varied and deformable structure of clothing presents a challenging task in the area of robot manipulation. Recent literature has shown an increasing interest in this field, however limited information exists on the influence of end-effector selection, instead focusing on the perception, modelling, and methodology in handling fabrics. Here, we present a benchmark set of household clothing items, along with a framework for defining textile features in relation to how the objects can be grasped and manipulated. Alongside these, we present four example benchmarks for evaluating the performance of a robot end-effector in relation to the grasping and manipulation of common pieces of clothing: Edge drag accuracy, edge grasp resilience, grasp encapsulation, and grasp fold generation. We perform these benchmarks on several common robot end-effectors (Franka Emika (FE) Hand with standard and Fin Ray\u00ae style fingers (Flex), Robotiq 2F-140, and the Openhand Model T42) and present and discuss their respective performances. Results show that the Robotiq scored highest across most benchmarks, closely followed by the FE hand. The T42 showed excellent encapsulation of items, while the FE (Flex) was particularly successful picking up flat edges.",
        "primary_area": "",
        "author": "Angus B. Clark;Luke Cramphorn-Neal;Michal Rachowiecki;Austin Gregg-Smith;Angus B. Clark;Luke Cramphorn-Neal;Michal Rachowiecki;Austin Gregg-Smith",
        "authorids": "/37086808936;/37089895509;/37089893008;/37085544175;/37086808936;/37089895509;/37089893008;/37085544175",
        "aff": "Robotics Research Team, Dyson Technology Ltd, Hullavington, UK; Robotics Research Team, Dyson Technology Ltd, Hullavington, UK; Robotics Research Team, Dyson Technology Ltd, Hullavington, UK; Robotics Research Team, Dyson Technology Ltd, Hullavington, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161398/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3992957411765830703&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Dyson Technology Ltd",
        "aff_unique_dep": "Robotics Research Team",
        "aff_unique_url": "https://www.dyson.com",
        "aff_unique_abbr": "Dyson",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hullavington",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160856",
        "title": "How Does It Feel? Self-Supervised Costmap Learning for Off-Road Vehicle Traversability",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating terrain traversability in off-road environments requires reasoning about complex interaction dynamics between the robot and these terrains. However, it is challenging to create informative labels to learn a model in a supervised manner for these interactions. We propose a method that learns to predict traversability costmaps by combining exteroceptive environmental information with proprioceptive terrain interaction feedback in a self-supervised manner. Additionally, we propose a novel way of incorporating robot velocity into the costmap prediction pipeline. We validate our method in multiple short and large-scale navigation tasks on challenging off-road terrains using two different large, all-terrain robots. Our short-scale navigation results show that using our learned costmaps leads to overall smoother navigation, and provides the robot with a more fine-grained understanding of the robot-terrain interactions. Our large-scale navigation trials show that we can reduce the number of interventions by up to 57% compared to an occupancy-based navigation baseline in challenging off-road courses ranging from 400 m to 3150 m. Appendix and full experiment videos can be found in our website: https://mateoguaman.github.io/hdif.",
        "primary_area": "",
        "author": "Mateo Guaman Castro;Samuel Triest;Wenshan Wang;Jason M. Gregory;Felix Sanchez;John G. Rogers;Sebastian Scherer;Mateo Guaman Castro;Samuel Triest;Wenshan Wang;Jason M. Gregory;Felix Sanchez;John G. Rogers;Sebastian Scherer",
        "authorids": "/37089895926;/37088642042;/37087322184;/37086090183;/37089450762;/37533731800;/37584159000;/37089895926;/37088642042;/37087322184;/37086090183;/37089450762;/37533731800;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; DEVCOM Army Research Laboratory, Adelphi, MD, USA; Booz Allen Hamilton, McLean, VA, USA; DEVCOM Army Research Laboratory, Adelphi, MD, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160856/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15521271024252791118&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;2;1;0",
        "aff_unique_norm": "Carnegie Mellon University;DEVCOM Army Research Laboratory;Booz Allen Hamilton",
        "aff_unique_dep": "Robotics Institute;;",
        "aff_unique_url": "https://www.cmu.edu;;https://www.boozallen.com",
        "aff_unique_abbr": "CMU;;",
        "aff_campus_unique_index": "0;0;0;1;2;1;0",
        "aff_campus_unique": "Pittsburgh;Adelphi;McLean",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161277",
        "title": "Human Non-Compliance with Robot Spatial Ownership Communicated via Augmented Reality: Implications for Human-Robot Teaming Safety",
        "track": "main",
        "status": "Poster",
        "abstract": "Ensuring the safety and efficiency of human workers in environments shared with autonomous robots is of paramount importance. In this work we examine the behavior and attitudes of participants performing tasks in a noisy environment collocated with an autonomous quadcopter robot. Visual communication of spatial ownership and nonverbal (deictic gesture) requests for changes in spatial ownership are facilitated using an augmented reality (AR) head-mounted device that renders a color-keyed grid on the floor. After a request, the robot can alter floor ownership to provide participants with a safe path to complete their work. Participants (n=20n=20) in a between-subjects study took part in either a shared space condition (concurrently occupying the work floor with the robot, with obvious rationale for floor ownership) or a turn-taking condition (alternating excursions onto the grid with the robot, without apparent rationale for the floor grid colors). We find consistent evidence of potentially dangerous over-trust in the system that led to non-compliance; notably, 25% of participants intentionally walked across forbidden floor regions during the experiment. We identify design considerations and a variety of user-borne rationale for committing safety violations that designers will need to explicitly take measures to remedy in production AR safety systems.",
        "primary_area": "",
        "author": "Christine T. Chang;Matthew B. Luebbers;Mitchell Hebert;Bradley Hayes;Christine T. Chang;Matthew B. Luebbers;Mitchell Hebert;Bradley Hayes",
        "authorids": "/37089341304;/37088999556;/37085681025;/38573944100;/37089341304;/37088999556;/37085681025;/38573944100",
        "aff": "Charles Stark Draper Laboratory, Inc.; University of Colorado Boulder; Charles Stark Draper Laboratory, Inc.; University of Colorado Boulder",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161277/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17454842988491295953&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Charles Stark Draper Laboratory;University of Colorado",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.draper.com;https://www.colorado.edu",
        "aff_unique_abbr": "Draper Lab;CU Boulder",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Boulder",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161130",
        "title": "Human-Guided Planning for Complex Manipulation Tasks Using the Screw Geometry of Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel method of motion planning for performing complex manipulation tasks by using human demonstration and exploiting the screw geometry of motion. We consider complex manipulation tasks where there are constraints on the motion of the end effector of the robot. Examples of such tasks include opening a door, opening a drawer, transferring granular material from one container to another with a spoon, and loading dishes to a dishwasher. Our approach consists of two steps: First, using the fact that a motion in the task space of the robot can be approximated by using a sequence of constant screw motions, we segment a human demonstration into a sequence of constant screw motions. Second, we use the segmented screws to generate motion plans via screw-linear interpolation for other instances of the same task. The use of screw segmentation allows us to capture the invariants of the demonstrations in a coordinate-free fashion, thus allowing us to plan for different task instances from just one example. We present extensive experimental results on a variety of manipulation scenarios showing that our method can be used across a wide range of manipulation tasks.",
        "primary_area": "",
        "author": "Dasharadhan Mahalingam;Nilanjan Chakraborty;Dasharadhan Mahalingam;Nilanjan Chakraborty",
        "authorids": "/37089448262;/37314871600;/37089448262;/37314871600",
        "aff": "Department of Mechanical Engineering, Brook University (SBU), Stony Brook, NY, USA; Department of Mechanical Engineering, Brook University (SBU), Stony Brook, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161130/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3907434288672751102&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Brook University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.brook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161075",
        "title": "Humans Need Augmented Feedback to Physically Track Non-Biological Robot Movements",
        "track": "main",
        "status": "Poster",
        "abstract": "An important component for the effective collaboration of humans with robots is the compatibility of their movements, especially when humans physically collaborate with a robot partner. Following previous findings that humans interact more seamlessly with a robot that moves with human-like or biological velocity profiles, this study examined whether humans can adapt to a robot that violates human signatures. The specific focus was on the role of extensive practice and real-time augmented feedback. Six groups of participants physically tracked a robot tracing an ellipse with profiles where velocity scaled with the curvature of the path in biological and non-biological ways, while instructed to minimize the interaction force with the robot. Three of the 6 groups received real-time visual feedback about their force error. Results showed that with 3 daily practice sessions, when given feedback about their force errors, humans could decrease their interaction forces when the robot's trajectory violated human-like velocity patterns. Conversely, when augmented feedback was not provided, there were no improvements despite this extensive practice. The biological profile showed no improvements, even with feedback, indicating that the (non-zero) force had already reached a floor level. These findings highlight the importance of biological robot trajectories and augmented feedback to guide humans to adapt to non-biological movements in physical human-robot interaction. These results have implications on various fields of robotics, such as surgical applications and collaborative robots for industry.",
        "primary_area": "",
        "author": "Mahdiar Edraki;Pauline Maurice;Dagmar Sternad;Mahdiar Edraki;Pauline Maurice;Dagmar Sternad",
        "authorids": "/37089893891;/37086197298;/38469397700;/37089893891;/37086197298;/38469397700",
        "aff": "Department of Mechanical and Industrial Engineering, Northeastern University, USA; CNRS, Inria, LORIA, Universite de Lorraine, Nancy, France; Department of Biology, Electrical and Computer Engineering, and Physics, Institute for Experiential Robotics, Northeastern University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161075/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4286380279373952624&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Northeastern University;CNRS",
        "aff_unique_dep": "Department of Mechanical and Industrial Engineering;",
        "aff_unique_url": "https://www.northeastern.edu;https://www.cnrs.fr",
        "aff_unique_abbr": "NU;CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "10160819",
        "title": "Hummingbird-bat hybrid wing by 3-D printing*",
        "track": "main",
        "status": "Poster",
        "abstract": "Hovering hummingbirds have inspired small flapping-wing aerial robots. Natural flyers, including hummingbirds and bats, undergo torsional wing deformation during flapping flight owing to complex wing structure, while previous artificial wings were relatively simple and difficult to design the torsional flexibility. In this paper, we proposed a hummingbird-bat hybrid (HBH) wing in which torsional flexibility was implemented by an available fabrication technology. The HBH wing had a torsional arm at the leading edge inspired by a torsional wrist of a hummingbird. A bat-like stretchable wing membrane was also employed not to constrain the wing torsion. The membrane was supported by wing shafts of which bending stiffness was designed based on that of the feather shaft of a hummingbird. The three-dimensional (3-D) shape of the torsional arm and wing shafts was created by 3-D printing. The effect of the torsional arm and stretchable membrane on lift generation and deformation was evaluated using an electric flapping mechanism. It was confirmed that the torsional arm actually enhanced the passive wing torsion. The stretchable wing membrane further promoted the torsion effect of the torsional arm. Consequently, the HBH wing did not increase lift, but efficacy, defined as lift per input power, was greatly improved by 14% at most compared with the wing without a torsional arm.",
        "primary_area": "",
        "author": "Tomoya Fujii;Jinqiang Dang;Hiroto Tanaka;Tomoya Fujii;Jinqiang Dang;Hiroto Tanaka",
        "authorids": "/37086194506;/37089893608;/37558784400;/37086194506;/37089893608;/37558784400",
        "aff": "Tokyo Institute of Technology, Tokyo, Japan; Tokyo Institute of Technology, Tokyo, Japan; Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160819/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1959557057637948484&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161349",
        "title": "Hybrid SUSD-Based Task Allocation for Heterogeneous Multi-Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "Effective task allocation is an essential component to the coordination of heterogeneous robots. This paper proposes a hybrid task allocation algorithm that improves upon given initial solutions, for example from the popular decentralized market-based allocation algorithm, via a derivative-free optimization strategy called Speeding-Up and Slowing-Down (SUSD). Based on the initial solutions, SUSD performs a search to find an improved task assignment. Unique to our strategy is the ability to apply a gradient-like search to solve a classical integer-programming problem. The proposed strategy outperforms other state-of-the-art algorithms in terms of total task utility and can achieve near optimal solutions in simulation. Experimental results using the Robotarium are also provided.",
        "primary_area": "",
        "author": "Shengkang Chen;Tony X. Lin;Said Al-Abri;Ronald C. Arkin;Fumin Zhang;Shengkang Chen;Tony X. Lin;Said Al-Abri;Ronald C. Arkin;Fumin Zhang",
        "authorids": "/37088863907;/37088439582;/37086332221;/37278162600;/37406187900;/37088863907;/37088439582;/37086332221;/37278162600;/37406187900",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Sultan Qaboos University, Alkhod, Oman; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161349/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11130328791106722113&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Georgia Institute of Technology;Sultan Qaboos University",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu;",
        "aff_unique_abbr": "Georgia Tech;",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Atlanta;Alkhod",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;Oman"
    },
    {
        "id": "10160248",
        "title": "Identification of a Generalized Base Inertial Parameter Set of Robotic Manipulators Considering Mounting Configurations",
        "track": "main",
        "status": "Poster",
        "abstract": "Identifying the inertial parameters of real robotic manipulators is a fundamental step towards realistic modeling and better controller performances, which is crucial for safe human-robot interaction. Our work introduces a novel framework for identifying a generalized set of base inertial parameters of a serial link manipulator. This framework is designed to be adaptable to accommodate any new mounting configuration of the robot. Our theoretical analysis highlights the influence of the robot's mounting configuration on the emergence of new parameters that cannot be identified through the conventional vertical base-axis mounting approach studied previously. To validate our proposed framework, we carried out two main experiments: the first involved simulation to establish the feasibility of our concept, and in the second, our framework was employed on a Franka Emika Robot in a real-world scenario to demonstrate and validate our approach. Our simulation results confirmed the feasibility of our proposed framework, while our real-world experiment successfully identified the generalized base inertial parameter set and validated its applicability to a new robot mounting configuration.",
        "primary_area": "",
        "author": "Mario Tr\u00f6binger;Abdeldjallil Naceri;Xiao Chen;Hamid Sadeghian;Sami Haddadin;Mario Tr\u00f6binger;Abdeldjallil Naceri;Xiao Chen;Hamid Sadeghian;Sami Haddadin",
        "authorids": "/37088863248;/37546043900;/37088992427;/38539589600;/37542865300;/37088863248;/37546043900;/37088992427;/38539589600;/37542865300",
        "aff": "Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Faculty of Engineering, University of Isfahan, Isfahan, Iran; Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160248/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3391044254560739437&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;University of Isfahan",
        "aff_unique_dep": "Munich School of Robotics and Machine Intelligence;Faculty of Engineering",
        "aff_unique_url": "https://www.tum.de;http://www.ui.ac.ir",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Munich;Isfahan",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;Iran"
    },
    {
        "id": "10160408",
        "title": "Identifying Contact Distance Uncertainty in Whisker Sensing with Tapered, Flexible Whiskers",
        "track": "main",
        "status": "Poster",
        "abstract": "Whisker-based tactile sensors have the potential to perform fast and accurate 3D mappings of the environment, complementing vision-based methods under conditions of glare, reflection, proximity, and occlusion. However, current algorithms for mapping with whiskers make assumptions about the conditions of contact, and these assumptions are not always valid and can cause significant sensing errors. Here we introduce a new whisker sensing system with a tapered, flexible whisker. The system provides inputs to two separate algorithms for estimating radial contact distance on a whisker. Using a Gradient-Moment (GM) algorithm, we correctly detect contact distance in most cases (within 4% of the whisker length). We introduce the Z-Dissimilarity score as a new metric that quantifies uncertainty in the radial contact distance estimate using both the GM algorithm and a Moment-Force (MF) algorithm that exploits the tapered whisker design. Combining the two algorithms ultimately results in contact distance estimates more robust than either algorithm alone.",
        "primary_area": "",
        "author": "Teresa A. Kent;Hannah Emnett;Mahnoush Babaei;Mitra J. Z. Hartmann;Sarah Bergbreiter;Teresa A. Kent;Hannah Emnett;Mahnoush Babaei;Mitra J. Z. Hartmann;Sarah Bergbreiter",
        "authorids": "/37089133664;/37089892014;/37088359355;/37566629100;/37542605000;/37089133664;/37089892014;/37088359355;/37566629100;/37542605000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Mechanical Engineering, Northwestern University, Evanston, IL, USA; University of Texas Austin, Austin, TX, USA; Biomedical Engineering and Mechanical Engineering, Northwestern University, Evanston, IL, USA; Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160408/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2616042958361549415&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Northwestern University;University of Texas at Austin",
        "aff_unique_dep": "Robotics Institute;Mechanical Engineering;",
        "aff_unique_url": "https://www.cmu.edu;https://www.northwestern.edu;https://www.utexas.edu",
        "aff_unique_abbr": "CMU;NU;UT Austin",
        "aff_campus_unique_index": "0;1;2;1;0",
        "aff_campus_unique": "Pittsburgh;Evanston;Austin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161373",
        "title": "Image Masking for Robust Self-Supervised Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised monocular depth estimation is a salient task for 3D scene understanding. Learned jointly with monocular ego-motion estimation, several methods have been proposed to predict accurate pixel-wise depth without using labeled data. Nevertheless, these methods focus on improving performance under ideal conditions without natural or digital corruptions. The general absence of occlusions is assumed even for object-specific depth estimation. These methods are also vulnerable to adversarial attacks, which is a pertinent concern for their reliable deployment in robots and autonomous driving systems. We propose MIMDepth, a method that adapts masked image modeling (MIM) for self-supervised monocular depth estimation. While MIM has been used to learn generalizable features during pre-training, we show how it could be adapted for direct training of monocular depth estimation. Our experiments show that MIMDepth is more robust to noise, blur, weather conditions, digital artifacts, occlusions, as well as untargeted and targeted adversarial attacks.",
        "primary_area": "",
        "author": "Hemang Chawla;Kishaan Jeeveswaran;Elahe Arani;Bahram Zonooz;Hemang Chawla;Kishaan Jeeveswaran;Elahe Arani;Bahram Zonooz",
        "authorids": "/37088595013;/37089891879;/37088597781;/37088596827;/37088595013;/37089891879;/37088597781;/37088596827",
        "aff": "Advanced Research Lab, NavInfo Europe, The Netherlands; Advanced Research Lab, NavInfo Europe, The Netherlands; Department of Mathematics and Computer Science, Eindhoven University of Technology, The Netherlands; Department of Mathematics and Computer Science, Eindhoven University of Technology, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161373/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17232134775138546983&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "NavInfo Europe;Eindhoven University of Technology",
        "aff_unique_dep": "Advanced Research Lab;Department of Mathematics and Computer Science",
        "aff_unique_url": "https://www.navinfo.com;https://www.tue.nl",
        "aff_unique_abbr": "NavInfo;TU/e",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10161229",
        "title": "Image Segmentation for Continuum Robots from a Kinematic Prior",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we address the problem of robust segmentation of a continuum robot from images without the need for training data or markers. We present a method that leverages information about the kinematics of these robots to produce an estimate of the robot shape, which is refined through optimization over global image statistics. Our approach can be straightforwardly applied to any continuum robot design and is able to handle partial occlusions of the robot body, as well as challenging background conditions. We validate our method experimentally for a concentric tube robot in a simulated surgical environment and show that our method significantly outperforms a naive projection of the robot shape and color thresholding, which is commonly used in current vision-based estimation algorithms for these robots. Overall, this work has the potential to improve the viability of vision-based state estimation for continuum robots in real-world settings.",
        "primary_area": "",
        "author": "Connor M. Watson;Anna B. Nguyen;Tania K. Morimoto;Connor M. Watson;Anna B. Nguyen;Tania K. Morimoto",
        "authorids": "/37088215479;/37089894728;/37085803241;/37088215479;/37089894728;/37085803241",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering and the Department of Surgery, University of California, San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161229/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16448325121413404927&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160853",
        "title": "Image-Based Visual Servoing Switchable Leader-follower Control of Heterogeneous Multi-agent Underwater Robot System",
        "track": "main",
        "status": "Poster",
        "abstract": "Confined and cluttered aquatic environments present a number of significant challenges with respect to inspection by robotic platforms, including localisation and communications. Some of these can be mitigated by using collaborative heterogeneous multi-robot teams. An important element of such a system is collaborative control. This paper addresses this challenge by presenting an Image-Based Visual Servoing (IBVS), leader-follower control system for heterogeneous aquatic robots. Experiments were conducted in an uncluttered pond to demonstrate the capabilities of the system. The results show robots can maintain tracking each other with maximum xx and yy displacements of 0.42 m and 0.41 m, the maximum projection distance in the xy-plane of maintaining formation is 0.45 m, showing the stability and feasibility of deploying such system on underwater platforms.",
        "primary_area": "",
        "author": "Kanzhong Yao;Nathalie Bauschmann;Thies L Alff;Wei Cheah;Daniel A Duecker;Keir Groves;Ognjen Marjanovic;Simon Watson;Kanzhong Yao;Nathalie Bauschmann;Thies L Alff;Wei Cheah;Daniel A Duecker;Keir Groves;Ognjen Marjanovic;Simon Watson",
        "authorids": "/37089895617;/37088566120;/37089891929;/37086576110;/37086262227;/37086497192;/37415789000;/38185385000;/37089895617;/37088566120;/37089891929;/37086576110;/37086262227;/37086497192;/37415789000;/38185385000",
        "aff": "Department of Electrical and Electronic Engineering, Manchester Centre for Robotics and AI, University of Manchester, UK; Institute of Mechanics and Ocean Engineering, Hamburg University of Technology, Germany; Institute of Mechanics and Ocean Engineering, Hamburg University of Technology, Germany; Department of Electrical and Electronic Engineering, Manchester Centre for Robotics and AI, University of Manchester, UK; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Department of Electrical and Electronic Engineering, Manchester Centre for Robotics and AI, University of Manchester, UK; Department of Electrical and Electronic Engineering, Manchester Centre for Robotics and AI, University of Manchester, UK; Department of Electrical and Electronic Engineering, Manchester Centre for Robotics and AI, University of Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160853/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4477047865481493837&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;0;2;0;0;0",
        "aff_unique_norm": "University of Manchester;Hamburg University of Technology;Technical University of Munich",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering;Institute of Mechanics and Ocean Engineering;Munich Institute of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.manchester.ac.uk;https://www.tuhh.de/;https://www.tum.de",
        "aff_unique_abbr": "UoM;TUHH;TUM",
        "aff_campus_unique_index": "0;1;1;0;2;0;0;0",
        "aff_campus_unique": "Manchester;Hamburg;Munich",
        "aff_country_unique_index": "0;1;1;0;1;0;0;0",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "10161066",
        "title": "Image-based Pose Estimation and Shape Reconstruction for Robot Manipulators and Soft, Continuum Robots via Differentiable Rendering",
        "track": "main",
        "status": "Poster",
        "abstract": "State estimation from measured data is crucial for robotic applications as autonomous systems rely on sensors to capture the motion and localize in the 3D world. Among sensors that are designed for measuring a robot's pose, or for soft robots, their shape, vision sensors are favorable because they are information-rich, easy to set up, and cost-effective. With recent advancements in computer vision, deep learning-based methods no longer require markers for identifying feature points on the robot. However, learning-based methods are data-hungry and hence not suitable for soft and prototyping robots, as building such bench-marking datasets is usually infeasible. In this work, we achieve image-based robot pose estimation and shape reconstruction from camera images. Our method requires no precise robot meshes, but rather utilizes a differentiable renderer and primitive shapes. It hence can be applied to robots for which CAD models might not be available or are crude. Our parameter estimation pipeline is fully differentiable. The robot shape and pose are estimated iteratively by back-propagating the image loss to update the parameters. We demonstrate that our method of using geometrical shape primitives can achieve high accuracy in shape reconstruction for a soft continuum robot and pose estimation for a robot manipulator.",
        "primary_area": "",
        "author": "Jingpei Lu;Fei Liu;C\u00e9dric Girerd;Michael C. Yip;Jingpei Lu;Fei Liu;C\u00e9dric Girerd;Michael C. Yip",
        "authorids": "/37088071646;/37088689503;/37086316227;/37085382768;/37088071646;/37088689503;/37086316227;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; LIRMM, Univ Montpellier, CNRS, Montpellier, France; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161066/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17357501852425907904&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California San Diego;Laboratoire d'Informatique, de Robotique et de Micro\u00e9lectronique de Montpellier",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.ucsd.edu;https://www.lirmm.fr",
        "aff_unique_abbr": "UCSD;LIRMM",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "La Jolla;Montpellier",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "10160815",
        "title": "Image-to-Image Translation for Autonomous Driving from Coarsely-Aligned Image Pairs",
        "track": "main",
        "status": "Poster",
        "abstract": "A self-driving car must be able to reliably handle adverse weather conditions (e.g., snowy) to operate safely. In this paper, we investigate the idea of turning sensor inputs (i.e., images) captured in an adverse condition into a benign one (i.e., sunny), upon which the downstream tasks (e.g., semantic segmentation) can attain high accuracy. Prior work primarily formulates this as an unpaired image-to-image translation problem due to the lack of paired images captured under the exact same camera poses and semantic layouts. While perfectly-aligned images are not available, one can easily obtain coarsely-paired images. For instance, many people drive the same routes daily in both good and adverse weather; thus, images captured at close-by GPS locations can form a pair. Though data from repeated traversals are unlikely to capture the same foreground objects, we posit that they provide rich contextual information to supervise the image translation model. To this end, we propose a novel training objective leveraging coarsely-aligned image pairs. We show that our coarsely-aligned training scheme leads to a better image translation quality and improved downstream tasks, such as semantic segmentation, monocular depth estimation, and visual localization.",
        "primary_area": "",
        "author": "Youya Xia;Josephine Monica;Wei-Lun Chao;Bharath Hariharan;Kilian Q Weinberger;Mark Campbell;Youya Xia;Josephine Monica;Wei-Lun Chao;Bharath Hariharan;Kilian Q Weinberger;Mark Campbell",
        "authorids": "/37089539200;/37086939060;/37086876034;/38232046900;/37282690200;/37272971700;/37089539200;/37086939060;/37086876034;/38232046900;/37282690200;/37272971700",
        "aff": "Computer Science Department, Cornell University, United States; Mechanical and Aerospace Engineering Department, Cornell University, United States; Department of Computer Science and Engineering, Ohio State University, USA; Computer Science Department, Cornell University, United States; Computer Science Department, Cornell University, United States; Mechanical and Aerospace Engineering Department, Cornell University, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160815/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3130545040954278591&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Cornell University;Ohio State University",
        "aff_unique_dep": "Computer Science Department;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.cornell.edu;https://www.osu.edu",
        "aff_unique_abbr": "Cornell;OSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161428",
        "title": "ImmFusion: Robust mmWave-RGB Fusion for 3D Human Body Reconstruction in All Weather Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "3D human reconstruction from RGB images achieves decent results in good weather conditions but degrades dramatically in rough weather. Complementary, mmWave radars have been employed to reconstruct 3D human joints and meshes in rough weather. However, combining RGB and mmWave signals for robust all-weather 3D human reconstruction is still an open challenge, given the sparse nature of mmWave and the vulnerability of RGB images. In this paper, we present ImmFusion, the first mmWave-RGB fusion solution to reconstruct 3D human bodies in all weather conditions robustly. Specifically, our ImmFusion consists of image and point backbones for token feature extraction and a Transformer module for token fusion. The image and point backbones refine global and local features from original data, and the Fusion Transformer Module aims for effective information fusion of two modalities by dynamically selecting informative tokens. Extensive experiments on a large-scale dataset, mmBody, captured in various environments demonstrate that ImmFusion can efficiently utilize the information of two modalities to achieve a robust 3D human body reconstruction in all weather conditions. In addition, our method's accuracy is significantly superior to that of state-of-the-art Transformer-based LiDAR-camera fusion methods.",
        "primary_area": "",
        "author": "Anjun Chen;Xiangyu Wang;Kun Shi;Shaohao Zhu;Bin Fang;Yingfeng Chen;Jiming Chen;Yuchi Huo;Qi Ye;Anjun Chen;Xiangyu Wang;Kun Shi;Shaohao Zhu;Bin Fang;Yingfeng Chen;Jiming Chen;Yuchi Huo;Qi Ye",
        "authorids": "/37088983859;/37089894099;/37088985296;/37089895685;/37089577630;/37087231086;/37280686900;/37088456476;/37086235936;/37088983859;/37089894099;/37088985296;/37089895685;/37089577630;/37087231086;/37280686900;/37088456476;/37086235936",
        "aff": "State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; Tsinghua University, Beijing, China; Fuxi AI Lab, NetEase, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; State Key Lab of CAD&CG, Zhejiang Lab, Zhejiang University, Hangzhou, China; Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems of Zhejiang Province",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161428/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1638752511974865659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;1;2;0;0;3",
        "aff_unique_norm": "Zhejiang University;Tsinghua University;NetEase;Zhejiang Province Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology;;Fuxi AI Lab;Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.tsinghua.edu.cn;https://www.163.com;",
        "aff_unique_abbr": "ZJU;THU;NetEase;",
        "aff_campus_unique_index": "0;0;0;0;1;0;0;0",
        "aff_campus_unique": "Hangzhou;Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160560",
        "title": "Immersive Demonstrations are the Key to Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Achieving successful robotic manipulation is an essential step towards robots being widely used in industry and home settings. Recently, many learning-based methods have been proposed to tackle this challenge, with imitation learning showing great promise. However, imperfect demonstrations and a lack of feedback from teleoperation systems may lead to poor or even unsafe results. In this work we explore the effect of demonstrator force feedback on imitation learning, using a feedback glove and a robot arm to render fingertip-level and palm-level forces, respectively. 10 participants recorded 5 demonstrations of a pick-and-place task with 3 grippers, under conditions with no force feedback, fingertip force feedback, and fingertip and palm force feedback. Results show that force feedback significantly reduces demonstrator fingertip and palm forces, leads to a lower variation in demonstrator forces, and recorded trajectories that are quicker to execute. Using behavioral cloning, we find that agents trained to imitate these trajectories mirror these benefits, even though agents have no force data shown to them during training. We conclude that immersive demonstrations, achieved with force feedback, may be the key to unlocking safer, quicker-to-execute dexterous manipulation policies.",
        "primary_area": "",
        "author": "Kelin Li;Digby Chappell;Nicolas Rojas;Kelin Li;Digby Chappell;Nicolas Rojas",
        "authorids": "/37086355530;/37088691283;/37990657400;/37086355530;/37088691283;/37990657400",
        "aff": "REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160560/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10041644756679645228&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dyson School of Design Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161249",
        "title": "Implementation and Optimization of Grasping Learning with Dual-modal Soft Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust and efficient grasping of different objects is still an open problem due to the difficulty of integrating multidisciplinary knowledge such as gripper ontology design, perception, control, and learning. In recent years, learning-based methods have achieved excellent results in grasping various novel objects. However, current methods are usually limited to a single grasping mode or rely on different end effectors to grasp objects of different shapes. For human beings, our hands are capable of grasping various objects with changes in grasping methods and form of hands. In light of this, developing a gripper with similar performance could possibly improve the robot's gripping ability. In this paper, we design a dual-modal soft gripper (DSG) and propose a deep reinforcement learning (DRL) framework to implement the operations. Both of our grasping modes, namely enveloping and pinching, are achieved through the tendon drive system and the deformation of the spring steel plate, which enables the gripper to switch between the two grasping modes in real time. We also combined the cutting-edge achievements of deep learning and reinforcement learning to design an autonomous grasping algorithm based on Q-learning and a deep Q network. Moreover, to fully utilize the visual input from the sensor, we added semantic embeddings of target objects to facilitate the learning, which is especially useful in deciding the grasping method for objects previously unseen. We also evaluate our DRL framework in different scenarios, offering a detailed comparison of each grasping mode and the mixed method (with or without semantic information). Our design has proved efficient in reducing the number of failing grasping actions and improving the success rate when facing novel and tricky objects.",
        "primary_area": "",
        "author": "Lei Zhao;Haoyue Liu;Feihan Li;Xingyu Ding;Yuhao Sun;Fuchun Sun;Jianhua Shan;Qi Ye;Lincheng Li;Bin Fang;Lei Zhao;Haoyue Liu;Feihan Li;Xingyu Ding;Yuhao Sun;Fuchun Sun;Jianhua Shan;Qi Ye;Lincheng Li;Bin Fang",
        "authorids": "/37089894538;/37089893326;/37089893431;/37089894389;/37089892405;/37279269000;/37087007113;/37086235936;/37088489974;/37089577630;/37089894538;/37089893326;/37089893431;/37089894389;/37089892405;/37279269000;/37087007113;/37086235936;/37088489974;/37089577630",
        "aff": "School of Mechanical Engineering, Anhui University of Technology, Ma'an Shan, China; Department of computer science and technology, Department of foreign languages and literatures, Tsinghua University, Beijing, China; Department of computer science and technology, Department of foreign languages and literatures, Tsinghua University, Beijing, China; School of Mechanical Engineering, Anhui University of Technology, Ma'an Shan, China; School of Mechanical Engineering, Anhui University of Technology, Ma'an Shan, China; Department of computer science and technology, Department of foreign languages and literatures, Tsinghua University, Beijing, China; School of Mechanical Engineering, Anhui University of Technology, Ma'an Shan, China; Zhejiang University, China; NetEase Fuxi AI Lab, China; Department of computer science and technology, Department of foreign languages and literatures, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161249/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=318473422613572285&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;1;0;0;1;0;2;3;1",
        "aff_unique_norm": "Anhui University of Technology;Tsinghua University;Zhejiang University;NetEase Fuxi AI Lab",
        "aff_unique_dep": "School of Mechanical Engineering;Department of Computer Science and Technology;;AI Lab",
        "aff_unique_url": ";https://www.tsinghua.edu.cn;http://www.zju.edu.cn;https://www.netease.com",
        "aff_unique_abbr": ";THU;ZJU;NetEase Fuxi",
        "aff_campus_unique_index": "0;1;1;0;0;1;0;1",
        "aff_campus_unique": "Ma'an Shan;Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160475",
        "title": "Implicit Neural Field Guidance for Teleoperated Robot-assisted Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperated techniques enable remote human-robot interaction and have been widely accepted in robot-assisted surgeries. However, it is still hard to guarantee the safety of teleoperated surgery due to the imperfect input commands limited by remote perception, preventing teleoperated surgery from being widely used. We propose a new framework to avoid the collision of surgery robots and human tissue caused by inaccurate inputs. We directly take the medical volume data and propose to use the implicit neural field to guide teleoperated robot-assisted surgery. With guidance, the trajectory of the robot manipulator is optimized to safely work inside a narrow workspace. We evaluated our method in several aspects and conducted a real-world experiment on a head phantom. Experimental results show that our proposed method can effectively avoid the collision between the surgical tool and the human tissue during teleoperation.",
        "primary_area": "",
        "author": "Heng Zhang;Lifeng Zhu;Jiangwei Shen;Aiguo Song;Heng Zhang;Lifeng Zhu;Jiangwei Shen;Aiguo Song",
        "authorids": "/37089571653;/37086246211;/37089564679;/37276033000;/37089571653;/37086246211;/37089564679;/37276033000",
        "aff": "State Key Laboratory of Bioelectronics Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, P.R.China; State Key Laboratory of Bioelectronics Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, P.R.China; State Key Laboratory of Bioelectronics Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, P.R.China; State Key Laboratory of Bioelectronics Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, P.R.China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160475/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13023593374270148030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southeast University",
        "aff_unique_dep": "School of Instrument Science and Engineering",
        "aff_unique_url": "https://www.seu.edu.cn/",
        "aff_unique_abbr": "SEU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160255",
        "title": "Improved Benthic Classification using Resolution Scaling and SymmNet Unsupervised Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous Underwater Vehicles (AUVs) conduct regular visual surveys of marine environments to characterise and monitor the composition and diversity of the benthos. The use of machine learning classifiers for this task is limited by the low numbers of annotations available and the many fine-grained classes involved. In addition to these challenges, there are domain shifts between image sets acquired during different AUV surveys due to changes in camera systems, imaging altitude, illumination and water column properties leading to a drop in classification performance for images from a different survey where some or all these elements may have changed. This paper proposes a framework to improve the performance of a benthic morphospecies classifier when used to classify images from a different survey compared to the training data. We adapt the SymmNet state-of-the-art Unsupervised Domain Adaptation method with an efficient bilinear pooling layer and image scaling to normalise spatial resolution, and show improved classification accuracy. We test our approach on two datasets with images from AUV surveys with different imaging payloads and locations. The results show that generic domain adaptation can be enhanced to produce a significant increase in accuracy for images from an AUV survey that differs from the training images.",
        "primary_area": "",
        "author": "Heather Doig;Oscar Pizarro;Stefan B. Williams;Heather Doig;Oscar Pizarro;Stefan B. Williams",
        "authorids": "/37089892898;/37265974600;/37275821600;/37089892898;/37265974600;/37275821600",
        "aff": "Australian Centre for Field Robotics, University of Sydney, NSW, Australia; Marine Technology Department, Norwegian University of Science and Technology, Trondheim, Norway; Australian Centre for Field Robotics, University of Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160255/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18327964534026997913&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Sydney;Norwegian University of Science and Technology",
        "aff_unique_dep": "Australian Centre for Field Robotics;Marine Technology Department",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.ntnu.edu",
        "aff_unique_abbr": "USYD;NTNU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Sydney;Trondheim",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Australia;Norway"
    },
    {
        "id": "10160605",
        "title": "Improved Event-Based Dense Depth Estimation via Optical Flow Compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "Event cameras have the potential to overcome the limitations of classical computer vision in real-world applications. Depth estimation is a crucial step for high-level robotics tasks and has attracted much attention from the community. In this paper, we propose an event-based dense depth estimation architecture, Mixed-EF2DNet, which firstly predicts inter-grid optical flow to compensate for lost temporal information, and then estimates multiple contextual depth maps that are fused to generate a robust depth estimation map. To supervise the network training, we further design a smoothing loss function used to smooth local depth estimates and facilitate estimating reasonable depth for pixels without events. In addition, we introduce SE-resblocks in the depth network to enhance the network representation by selecting feature channels. Experimental evaluations on both real-world and synthetic datasets show that our method performs better in terms of accuracy when compared to state-of-the-art algorithms, especially in scene detail estimation. Besides, our method demonstrates excellent generalization in cross-dataset tasks.",
        "primary_area": "",
        "author": "Dianxi Shi;Luoxi Jing;Ruihao Li;Zhe Liu;Lin Wang;Huachi Xu;Yi Zhang;Dianxi Shi;Luoxi Jing;Ruihao Li;Zhe Liu;Lin Wang;Huachi Xu;Yi Zhang",
        "authorids": "/37401070600;/37088971992;/38468746700;/37089500669;/37089611316;/37088969079;/37089921571;/37401070600;/37088971992;/38468746700;/37089500669;/37089611316;/37088969079;/37089921571",
        "aff": "Artificial Intelligence Research Center (AIRC), Defense Innovation Institute, Beijing, China; School of Computer Science, Peking University, Beijing, China; Artificial Intelligence Research Center (AIRC), Defense Innovation Institute, Beijing, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; Artificial Intelligence Research Center (AIRC), Defense Innovation Institute, Beijing, China; Artificial Intelligence Research Center (AIRC), Defense Innovation Institute, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160605/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8082856329222880449&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;2;0;0",
        "aff_unique_norm": "Defense Innovation Institute;Peking University;National University of Defense Technology",
        "aff_unique_dep": "Artificial Intelligence Research Center (AIRC);School of Computer Science;College of Computer",
        "aff_unique_url": ";http://www.pku.edu.cn;http://www.nudt.edu.cn",
        "aff_unique_abbr": ";PKU;NUDT",
        "aff_campus_unique_index": "0;0;0;1;1;0;0",
        "aff_campus_unique": "Beijing;Changsha",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160844",
        "title": "Improving Video Super-Resolution with Long-Term Self-Exemplars",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing video super-resolution methods often utilize a few neighboring frames to generate a higher-resolution image for each frame. However, the abundant information in distant frames has not been fully exploited in these methods: corresponding patches of the same instance appear across distant frames at different scales. Based on this observation, we propose to improve the video super-resolution quality with long-term cross-scale aggregation that leverages similar patches (self-exemplars) across distant frames. Our method can be implemented as post-processing for any super-resolution methods to improve performance. Our model consists of a multi-reference alignment module to fuse the features derived from similar patches: we fuse the features of distant references to perform high-quality super-resolution. We also propose a novel and practical training strategy for reference-based super-resolution. To evaluate the performance of our proposed method, we conduct extensive experiments on our collected CarCam dataset, the Waymo Open dataset, and the REDS dataset, and the results demonstrate our method outperforms state-of-the-art methods.",
        "primary_area": "",
        "author": "Guotao Meng;Yue Wu;Qifeng Chen;Guotao Meng;Yue Wu;Qifeng Chen",
        "authorids": "/37089629712;/37088457572;/37087230927;/37089629712;/37088457572;/37087230927",
        "aff": "Department of Electronic and Computer Engineering, HKUST; Department of Computer Science and Engineering, HKUST; Department of Computer Science and Engineering, HKUST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160844/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18177308287906631606&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.hkust.edu.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160876",
        "title": "Improving robot navigation in crowded environments using intrinsic rewards",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation in crowded environments is an open problem with many applications, essential for the coexistence of robots and humans in the smart cities of the future. In recent years, deep reinforcement learning approaches have proven to outperform model-based algorithms. Nevertheless, even though the results provided are promising, the works are not able to take advantage of the capabilities that their models offer. They usually get trapped in local optima in the training process, that prevent them from learning the optimal policy. They are not able to visit and interact with every possible state appropriately, such as with the states near the goal or near the dynamic obstacles. In this work, we propose using intrinsic rewards to balance between exploration and exploitation and explore depending on the uncertainty of the states instead of on the time the agent has been trained, encouraging the agent to get more curious about unknown states. We explain the benefits of the approach and compare it with other exploration algorithms that may be used for crowd navigation. Many simulation experiments are performed modifying several algorithms of the state-of-the-art, showing that the use of intrinsic rewards makes the robot learn faster and reach higher rewards and success rates (fewer collisions) in shorter navigation times, outperforming the state-of-the-art.",
        "primary_area": "",
        "author": "Diego Martinez-Baselga;Luis Riazuelo;Luis Montano;Diego Martinez-Baselga;Luis Riazuelo;Luis Montano",
        "authorids": "/37089891906;/37871660700;/37278575700;/37089891906;/37871660700;/37278575700",
        "aff": "Robotics, Perception and Real Time Group, Aragon Institute of Engineering Research (I3A), Universidad de Zaragoza, Zaragoza, Spain; Robotics, Perception and Real Time Group, Aragon Institute of Engineering Research (I3A), Universidad de Zaragoza, Zaragoza, Spain; Robotics, Perception and Real Time Group, Aragon Institute of Engineering Research (I3A), Universidad de Zaragoza, Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160876/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=635179729423997389&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Robotics, Perception and Real Time Group, Aragon Institute of Engineering Research (I3A)",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zaragoza",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10160788",
        "title": "Improving the Generalizability of Trajectory Prediction Models with Fren\u00e9t-Based Domain Normalization",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the future trajectories of robots' nearby objects plays a pivotal role in applications such as autonomous driving. While learning-based trajectory prediction methods have achieved remarkable performance on public benchmarks, the generalization ability of these approaches remains questionable. The poor generalizability on unseen domains, a well-recognized defect of data-driven approaches, can potentially harm the real-world performance of trajectory prediction models. We are thus motivated to improve models' generalization ability instead of merely pursuing high accuracy on average. Due to the lack of benchmarks for quantifying the generalization ability of trajectory predictors, we first construct a new benchmark called argoverse-shift, where the data distributions of domains are significantly different. Using this benchmark for evaluation, we identify that the domain shift problem seriously hinders the generalization of trajectory predictors since state-of-the-art approaches suffer from severe performance degradation when facing those out-of-distribution scenes. To enhance the robustness of models against domain shift problem, we propose a plug-and-play strategy for domain normalization in trajectory prediction. Our strategy utilizes the Fren\u00e9t coordinate frame for modeling and can effectively narrow the domain gap of different scenes caused by the variety of road geometry and topology. Experiments show that our strategy noticeably boosts the prediction performance of the state-of-the-art in domains that were previously unseen to the models, thereby improving the generalization ability of data-driven trajectory prediction methods.",
        "primary_area": "",
        "author": "Luyao Ye;Zikang Zhou;Jianping Wang;Luyao Ye;Zikang Zhou;Jianping Wang",
        "authorids": "/37088760247;/37089539477;/37406463900;/37088760247;/37089539477;/37406463900",
        "aff": "Department of Computer Science, City University of Hong Kong, Hong Kong SAR, City University of Hong Kong Shenzhen Research Institute, Shenzhen, China; Department of Computer Science, City University of Hong Kong, Hong Kong SAR, City University of Hong Kong Shenzhen Research Institute, Shenzhen, China; Department of Computer Science, City University of Hong Kong, Hong Kong SAR, City University of Hong Kong Shenzhen Research Institute, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160788/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7897696589553560998&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "City University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.cityu.edu.hk",
        "aff_unique_abbr": "CityU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160499",
        "title": "Improving the Performance of Local Bundle Adjustment for Visual-Inertial SLAM with Efficient Use of GPU Resources",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present our approach to efficiently leveraging GPU resources to improve the performance of local bundle adjustment for visual-inertial SLAM. We observe that for local bundle adjustment (i) the Schur complement method, a technique often used to speed up bundle adjustment, has the largest overhead when solving for the parameter update, and (ii) the workload consists of operations on small- to medium-sized matrices. Based on these observations, we develop and combine several techniques that efficiently handle small- to medium-sized matrices. We then implement these techniques as a drop-in replacement block solver for g2o, a library frequently used for bundle adjustment, and integrate it with ORB-SLAM3, a well-known open-source visual-inertial SLAM system. Our evaluation done with two popular datasets, EuRoC and TUM-VI, shows that we can reduce the time taken by local bundle adjustment by 13.81%-33.79% with our techniques across an embedded device and a desktop machine.",
        "primary_area": "",
        "author": "Shishir Gopinath;Karthik Dantu;Steven Y. Ko;Shishir Gopinath;Karthik Dantu;Steven Y. Ko",
        "authorids": "/37088550284;/37328608800;/38548765100;/37088550284;/37328608800;/38548765100",
        "aff": "Simon Fraser University, Canada; University at Buffalo, USA; Simon Fraser University, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160499/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4390697236345643576&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Simon Fraser University;University at Buffalo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sfu.ca;https://www.buffalo.edu",
        "aff_unique_abbr": "SFU;UB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "10161516",
        "title": "In-Hand Manipulation in Power Grasp: Design of an Adaptive Robot Hand with Active Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the development of BACH (Belt-Augmented Compliant Hand), a compliant robotic hand equipped with active surfaces. The hand can securely grasp an object using power grasp and simultaneously manipulate the grasped object. The hand consists of three identical fingers, each with an actuated timing belt wrapped around a Fin Ray based compliant finger backbone. Each finger is mounted on a compliant pivot joint allowing for further adaptability. The combination of compliant mechanisms and active surfaces allows the hand to perform dexterous in-hand manipulation with great robustness. Multiple analyses were conducted to optimize and validate the design of BACH. The hand was experimentally tested for grasping and manipulating objects of various geometries and sizes, and it demonstrated highly robust and efficient in-hand manipulation capabilities.",
        "primary_area": "",
        "author": "Yilin Cai;Shenli Yuan;Yilin Cai;Shenli Yuan",
        "authorids": "/37089366342;/37088506196;/37089366342;/37088506196",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; SRI International, Menlo Park, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161516/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15116199607380968961&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Carnegie Mellon University;SRI International",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.sri.com",
        "aff_unique_abbr": "CMU;SRI",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Pittsburgh;Menlo Park",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160467",
        "title": "In-Mouth Robotic Bite Transfer with Visual and Haptic Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Assistance during eating is essential for those with severe mobility issues or eating risks. However, dependence on traditional human caregivers is linked to malnutrition, weight loss, and low self-esteem. For those who require eating assistance, a semi-autonomous robotic platform can provide independence and a healthier lifestyle. We demonstrate an essential capability of this platform: safe, comfortable, and effective transfer of a bite-sized food item from a utensil directly to the inside of a person's mouth. Our system uses a force-reactive controller to safely accommodate the user's motions throughout the transfer, allowing full reactivity until bite detection then reducing reactivity in the direction of exit. Additionally, we introduce a novel dexterous wrist-like end effector capable of small, unimposing movements to reduce user discomfort. We conduct a user study with 11 participants covering 8 diverse food categories to evaluate our system end-to-end, and we find that users strongly prefer our method to a wide range of baselines. Appendices and videos are available at our website: https://tinyurl.com/btICRA.",
        "primary_area": "",
        "author": "Lorenzo Shaikewitz;Yilin Wu;Suneel Belkhale;Jennifer Grannen;Priya Sundaresan;Dorsa Sadigh;Lorenzo Shaikewitz;Yilin Wu;Suneel Belkhale;Jennifer Grannen;Priya Sundaresan;Dorsa Sadigh",
        "authorids": "/37089895463;/37089894374;/37086933683;/37088507002;/37087011905;/38234464200;/37089895463;/37089894374;/37086933683;/37088507002;/37087011905;/38234464200",
        "aff": "California Institute of Technology; Stanford University; Stanford University; Stanford University; Stanford University; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160467/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15203013429199887972&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "California Institute of Technology;Stanford University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.caltech.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Caltech;Stanford",
        "aff_campus_unique_index": "0;1;1;1;1;1",
        "aff_campus_unique": "Pasadena;Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161153",
        "title": "In-situ Mechanical Calibration for Vision-based Tactile Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel approach to conduct routine calibration for the changing mechanical parameters over time of a vision-based tactile sensor, without disassembling its overall structure, i.e., in-situ mechanical calibration. Calibration for mechanical parameters, Young's modulus and Poisson's ratio, of a tactile sensor's sensing elastomer, is crucial for its force perception capabilities. However, there are few methods that can retrieve values of these parameters both accurately and conveniently. To address this problem, we propose an in-situ approach to calibrate mechanical parameters other than the verbose traditional evaluation process. This method incorporates the deformation sensing capability of the sensor, the accurate force sensing capability of a force/torque sensor, and most importantly, the deformation-force relation-ship for an indentation with embedded mechanical parameters of the elastomers. We also present the indentation test setup and the complete pipeline to extract Young's modulus and Poisson's ratio from experimental results. We validate the method by comparing the indentation depths simulated through finite element analysis (FEA) using the cali-brated parameters with the indentation depths measured in real experiments. Furthermore, superior contact force distribution can be achieved with the accurate mechanical parameters. The proposed method provides the theoretical basis for accurate, lifelong routine calibration, whether weekly or even daily, which can enhance the applications of tactile sensors in real manipulation scenarios.",
        "primary_area": "",
        "author": "Can Zhao;Jieji Ren;Hexi Yu;Daolin Ma;Can Zhao;Jieji Ren;Hexi Yu;Daolin Ma",
        "authorids": "/37089894158;/37088549788;/37089893094;/37086410541;/37089894158;/37088549788;/37089893094;/37086410541",
        "aff": "School of Naval Architecture, Ocean & Civil Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Naval Architecture, Ocean & Civil Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Naval Architecture, Ocean & Civil Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161153/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9326571271332819627&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Naval Architecture, Ocean & Civil Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161035",
        "title": "Increasing Admittance of Industrial Robots By Velocity Feedback Inner-Loop Shaping",
        "track": "main",
        "status": "Poster",
        "abstract": "Admittance and impedance controllers are often purely feedforward, using measured external force or motion, respectively, to generate a reference for an inner-loop controller. In this case, the range of dynamics which can be rendered is limited by the inner-loop, which causes, e.g. contact stability issues for low admittance industrial robots in stiff contact. When both position and force are measured, feedback control can be added to more flexibly reshape the rendered dynamics. This paper uses velocity feedback to increase the admittance of motion-controlled industrial robots in force control applications. This allows an industrial robot with a lower intrinsic admittance, which may be needed for payload, speed, or accuracy, to realize a higher admittance by control, allowing lighter manual guidance and safer contact. This is achieved by a modified disturbance observer, where an inverse dynamic model estimates external forces and amplifies them with positive feedback. This approach is compared with using positive velocity feedback with a shaping filter. Here, velocity reference calculated by the virtual admittance model is modified by the DOB (Dist-Add) or the positive velocity feedback (Vel-Add). When combined with an outer-loop admittance controller, these methods can render a higher admittance while maintaining contact stability compared to standard feedforward admittance control.",
        "primary_area": "",
        "author": "Kangwagye Samuel;Kevin Haninger;Sehoon Oh;Kangwagye Samuel;Kevin Haninger;Sehoon Oh",
        "authorids": "/37086293662;/38468165500;/37279132500;/37086293662;/38468165500;/37279132500",
        "aff": "Department of Automation, Fraunhofer IPK, Berlin, Germany; Department of Automation, Fraunhofer IPK, Berlin, Germany; Department of Robotics and Mechatronics Engineering, DGIST, Daegu, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161035/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11438406718313482212&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Fraunhofer IPK;Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": "Department of Automation;Department of Robotics and Mechatronics Engineering",
        "aff_unique_url": "https://www.ipk.fraunhofer.de;https://www.dgist.ac.kr",
        "aff_unique_abbr": "Fraunhofer IPK;DGIST",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Berlin;Daegu",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;South Korea"
    },
    {
        "id": "10160283",
        "title": "Incremental Few-Shot Object Detection via Simple Fine-Tuning Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we explore incremental few-shot object detection (iFSD), which incrementally learns novel classes using only a few examples without revisiting base classes. Previous iFSD works achieved the desired results by applying metalearning. However, meta-learning approaches show insufficient performance that is difficult to apply to practical problems. In this light, we propose a simple fine-tuning-based approach, the Incremental Two-stage Fine-tuning Approach (iTFA) for iFSD, which contains three steps: 1) base training using abundant base classes with the class-agnostic box regressor, 2) separation of the RoI feature extractor and classifier into the base and novel class branches for preserving base knowledge, and 3) fine-tuning the novel branch using only a few novel class examples. We evaluate our iTFA on the real-world datasets PASCAL VOC, COCO, and LVIS. iTFA achieves competitive performance in COCO and shows a 30% higher AP accuracy than meta-learning methods in the LVIS dataset. Experimental results show the effectiveness and applicability of our proposed method11Code is available at https://github.com/TMIU/iTFA.",
        "primary_area": "",
        "author": "Tae-Min Choi;Jong-Hwan Kim;Tae-Min Choi;Jong-Hwan Kim",
        "authorids": "/37089715773;/37281186400;/37089715773;/37281186400",
        "aff": "School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160283/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16825922990242856895&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161512",
        "title": "Induced Vertex Motion As a Performance Measure for Surgery in Confined Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "While in the design phase of a robotic system for the procedures performed in surgical confined spaces or hard-to-reach-deep surgical fields, designers can leverage a systematic method to compare the design alternatives for tele-surgical manipulators quantitatively. Unlike most of the work in the literature, we propose an approach for comparing design alternatives by considering the spurious motions along the length of the manipulator in lieu of existing approaches looking at only the end-effector dexterity measures. We propose a performance measure quantifying these spurious motions while the end-effector executes the application-critical tasks such as suturing and tying a knot. A good manipulator design should yield minimal swept volume along its length portions within the confined space. If informed about these spurious motions, that design would lead to reduced force on the internal organs, reducing the pain and discomfort as well as occurrences of extracorporeal inter-manipulator collisions. To validate the proposed approach, we present two illustrative simulation case studies: (1) two planar rigid link serial robots performing the task of following a desired trajectory and (2) two different architectures of tele-surgical manipulators performing the task of passing a circular suture needle under the fulcrum constraints. The results show the applicability of the proposed performance measure in determining the suitability of a particular design alternative for a given task. Although results are promising, using this measure alone for design optimization may compromise overall device dexterity. Therefore, this measure needs to be incorporated into a weighted optimization framework for robot design.",
        "primary_area": "",
        "author": "Neel Shihora;Nabil Simaan;Neel Shihora;Nabil Simaan",
        "authorids": "/37089194036;/37282380300;/37089194036;/37282380300",
        "aff": "Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161512/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15031756979284672925&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160838",
        "title": "Informable Multi-Objective and Multi-Directional RRT* System for Robot Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-objective or multi-destination path planning is crucial for mobile robotics applications such as mobility as a service, robotics inspection, and electric vehicle charging for long trips. This work proposes an anytime iterative system to concurrently solve the multi-objective path planning problem and determine the visiting order of destinations. The system is comprised of an anytime informable multi-objective and multi-directional RRT* algorithm to form a simple connected graph, and a solver that consists of an enhanced cheapest insertion algorithm and a genetic algorithm to solve approximately the relaxed traveling salesman problem in polynomial time. Moreover, a list of waypoints is often provided for robotics inspection and vehicle routing so that the robot can preferentially visit certain equipment or areas of interest. We show that the proposed system can inherently incorporate such knowledge to navigate challenging topology. The proposed anytime system is evaluated on large and complex graphs built for real-world driving applications. C++ implementations are available at: https://github.com/UMich-BipedLab/IMOMD-RRTStar.",
        "primary_area": "",
        "author": "Jiunn-Kai Huang;Yingwen Tan;Dongmyeong Lee;Vishnu R. Desaraju;Jessy W. Grizzle;Jiunn-Kai Huang;Yingwen Tan;Dongmyeong Lee;Vishnu R. Desaraju;Jessy W. Grizzle",
        "authorids": "/37086581500;/37089895668;/37089892688;/37568756100;/37277141500;/37086581500;/37089895668;/37089892688;/37568756100;/37277141500",
        "aff": "Jiunn-Kai Huang; Yingwen Tan; Dongmyeong Lee; Vishnu R. Desaraju; Jessy W. Grizzle",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160838/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9307359111050837871&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10160407",
        "title": "Information-theoretic Abstraction of Semantic Octree Models for Integrated Perception and Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we develop an approach that enables autonomous robots to build and compress semantic environment representations from point-cloud data. Our approach builds a three-dimensional, semantic tree representation of the environment from raw sensor data which is then compressed by a novel information-theoretic tree-pruning approach. The proposed approach is probabilistic and incorporates the uncertainty in semantic classification inherent in real-world environments. Moreover, our approach allows robots to prioritize individual semantic classes when generating the compressed trees, so as to design multi-resolution representations that retain the relevant semantic information while simultaneously discarding unwanted semantic categories. We demonstrate the approach by compressing semantic octree models of a large outdoor, semantically rich, real-world environment. In addition, we show how the octree abstractions can be used to create semantically-informed graphs for motion planning, and provide a comparison of our approach with uninformed graph construction methods such as Halton sequences.",
        "primary_area": "",
        "author": "Daniel T. Larsson;Arash Asgharivaskasi;Jaein Lim;Nikolay Atanasov;Panagiotis Tsiotras;Daniel T. Larsson;Arash Asgharivaskasi;Jaein Lim;Nikolay Atanasov;Panagiotis Tsiotras",
        "authorids": "/37086287195;/37088997086;/37088506597;/37670511000;/37330609800;/37086287195;/37088997086;/37088506597;/37670511000;/37330609800",
        "aff": "D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, University of California San Diego, San Diego, CA, USA; D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, University of California San Diego, San Diego, CA, USA; D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160407/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1227960867695992972&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;University of California San Diego",
        "aff_unique_dep": "School of Aerospace Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "Georgia Tech;UCSD",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Atlanta;San Diego",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160809",
        "title": "Infrared Image Captioning with Wearable Device",
        "track": "main",
        "status": "Poster",
        "abstract": "Wearable devices have garnered widespread attention as a mobile solution, and various intelligent modules based on wearable devices are increasingly being integrated. Additionally, image captioning is an important task in computer vision that maps images to text. Existing image captioning achievements are based on high-quality visible images. However, higher target complexity and insufficient light can lead to reduced captioning performance and mistakes. In this paper, we present an infrared image captioning framework designed to solve the problem of invalid visible image captioning in special conditions. Remarkably, we integrate the infrared image captioning model into the wearable device. Volunteers perform offline and real-time environmental analysis tasks in the real world to evaluate the framework's effectiveness in multiple scenarios. The results indicate that both the accuracy of infrared image captioning and the feedback from wearable device users are promising.",
        "primary_area": "",
        "author": "Chenjun Gao;Yanzhi Dong;Xiaohu Yuan;Yifei Han;Huaping Liu;Chenjun Gao;Yanzhi Dong;Xiaohu Yuan;Yifei Han;Huaping Liu",
        "authorids": "/37089601233;/37089597515;/37085824271;/37089892710;/37310126400;/37089601233;/37089597515;/37085824271;/37089892710;/37310126400",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Mathematical Sciences, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160809/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12308562953292116274&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161536",
        "title": "Infrastructure-based End-to-End Learning and Prevention of Driver Failure",
        "track": "main",
        "status": "Poster",
        "abstract": "Intelligent intersection managers can improve safety by detecting dangerous drivers or failure modes in autonomous vehicles, warning oncoming vehicles as they approach an intersection. In this work, we present FailureNet, a recurrent neural network trained end-to-end on trajectories of both nominal and reckless drivers in a scaled miniature city. FailureNet observes the poses of vehicles as they approach an intersection and detects whether a failure is present in the autonomy stack, warning cross-traffic of potentially dangerous drivers. FailureNet can accurately identify control failures, upstream perception errors, and speeding drivers, distinguishing them from nominal driving. The network is trained and deployed with autonomous vehicles in the MiniCity. Compared to speed or frequency-based predictors, FailureNet's recurrent neural network structure provides improved predictive power, yielding upwards of 84% accuracy when deployed on hardware.",
        "primary_area": "",
        "author": "Noam Buckman;Shiva Sreeram;Mathias Lechner;Yutong Ban;Ramin Hasani;Sertac Karaman;Daniela Rus;Noam Buckman;Shiva Sreeram;Mathias Lechner;Yutong Ban;Ramin Hasani;Sertac Karaman;Daniela Rus",
        "authorids": "/37087324071;/37089895020;/37086937501;/37086284172;/37085814419;/37304113000;/37279652300;/37087324071;/37089895020;/37086937501;/37086284172;/37085814419;/37304113000;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; California Institute of Technology, Pasadena, CA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory of Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161536/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16143696419861380213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;California Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://www.mit.edu;https://www.caltech.edu",
        "aff_unique_abbr": "MIT;Caltech",
        "aff_campus_unique_index": "0;1;0;0;0;0;0",
        "aff_campus_unique": "Cambridge;Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160556",
        "title": "Input-Output Boundedness of a Magnetically-Actuated Helical Device",
        "track": "main",
        "status": "Poster",
        "abstract": "To date, all previous research in the wireless magnetic actuation of untethered helical devices has achieved motion stability using feedback control in vitro. However, feedback control systems are likely to be affected by the increased sensory uncertainty during in vivo trials. In this study we investigate the input-output boundedness of an interconnection between a helical device and a single rotating magnet actuator in low-Reynolds-number regime. Using the resistive-force theory, the interconnection is expressed in terms of all possible input-output pairs. Inputs representing the actuation frequency, pitch angle, lateral speed, and field strength are analyzed numerically and experimentally. We demonstrate input-output boundedness of the states of the helical device during circular and straight runs in open-loop, and we demonstrate bounded input-output propulsion without orienting the angle of attack (the often used input to swim horizontally without vertical drift) of the helical device to counteract gravity. Our results are important for a number of minimally invasive applications and tasks requiring improved control authority for stable runs of helical devices without drift due to gravity and without feedback control and restricted configuration imposed on the helical device's motion.",
        "primary_area": "",
        "author": "Leendert-Jan W. Ligtenberg;Islam S. M. Khalil;Leendert-Jan W. Ligtenberg;Islam S. M. Khalil",
        "authorids": "/37089894771;/37409115400;/37089894771;/37409115400",
        "aff": "Department of Biomechanical Engineering, University of Twente, AE Enschede, The Netherlands; Department of Biomechanical Engineering, University of Twente, AE Enschede, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160556/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6978173412177897861&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Twente",
        "aff_unique_dep": "Department of Biomechanical Engineering",
        "aff_unique_url": "https://www.utwente.nl",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Enschede",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10161149",
        "title": "Instance-wise Grasp Synthesis for Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating high-quality instance-wise grasp con-figurations provides critical information of how to grasp specific objects in a multi-object environment and is of high importance for robot manipulation tasks. This work proposed a novel Single-Stage Grasp (SSG) synthesis network, which performs high-quality instance-wise grasp synthesis in a single stage: instance mask and grasp configurations are generated for each object simultaneously. Our method outperforms state-of-the-art on robotic grasp prediction based on the OCID-Grasp dataset, and performs competitively on the JACQUARD dataset. The benchmarking results showed significant improvements compared to the baseline on the accuracy of generated grasp configurations. The performance of the proposed method has been validated through both extensive simulations and real robot experiments for three tasks including single object pick-and-place, grasp synthesis in cluttered environments and table cleaning task.",
        "primary_area": "",
        "author": "Yucheng Xu;Mohammadreza Kasaei;Hamidreza Kasaei;Zhibin Li;Yucheng Xu;Mohammadreza Kasaei;Hamidreza Kasaei;Zhibin Li",
        "authorids": "/37089892484;/37089894512;/37088515518;/37857029500;/37089892484;/37089894512;/37088515518;/37857029500",
        "aff": "School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; Department of Artificial Intelligence, Faculty of Science and Engineering, Bernoulli Institute, University of Groningen, The Netherlands; Department of Computer Science, University College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161149/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4942948944240679980&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "University of Edinburgh;University of Groningen;University College London",
        "aff_unique_dep": "School of Informatics;Department of Artificial Intelligence;Department of Computer Science",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.rug.nl;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Edinburgh;RUG;UCL",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Edinburgh;;London",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;Netherlands"
    },
    {
        "id": "10160824",
        "title": "Integrated vector field and backstepping control for quadcopters",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present an Integrated Guidance and Controller (IGC) scheme to drive quadcopters in path-following tasks with obstacle avoidance and constant uncertainty rejection. This scheme is based on the combination of a time-varying artificial vector field and Backstepping with integral action control. The vector field switches between two behaviors: (i) path-following; and (ii) obstacle circumnavigation to allow collision avoidance. This vector field is then integrated into a nonlinear controller designed via Backstepping with Integral Action to deal with the quadcopter vehicle dynamics and reject constant uncertainties. The considered vehicle model is based on quaternion algebra. The control inputs are considered to be the total thrust and torques. Stability is proved by using Lyapunov's Theory and Matrosov's Theorem.",
        "primary_area": "",
        "author": "Arthur H. D. Nunes;Guilherme V. Raffo;Luciano C. A. Pimenta;Arthur H. D. Nunes;Guilherme V. Raffo;Luciano C. A. Pimenta",
        "authorids": "/37088504019;/37590643600;/37297110600;/37088504019;/37590643600;/37297110600",
        "aff": "Graduate Program in Electrical Engineering (PPGEE), Universidade Federal de Minas Gerais (UFMG), Belo Horizonte, MG, Brazil; Graduate Program in Electrical Engineering (PPGEE), Universidade Federal de Minas Gerais (UFMG), Belo Horizonte, MG, Brazil; Graduate Program in Electrical Engineering (PPGEE), Universidade Federal de Minas Gerais (UFMG), Belo Horizonte, MG, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160824/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15650616253593518467&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidade Federal de Minas Gerais",
        "aff_unique_dep": "Graduate Program in Electrical Engineering",
        "aff_unique_url": "https://www.ufmg.br",
        "aff_unique_abbr": "UFMG",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Belo Horizonte",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "10160660",
        "title": "Intention Aware Robot Crowd Navigation with Attention-Based Interaction Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of safe and intention-aware robot navigation in dense and interactive crowds. Most previous reinforcement learning (RL) based methods fail to consider different types of interactions among all agents or ignore the intentions of people, which results in performance degradation. In this paper, we propose a novel recurrent graph neural network with attention mechanisms to capture heterogeneous interactions among agents through space and time. To encourage longsighted robot behaviors, we infer the intentions of dynamic agents by predicting their future trajectories for several timesteps. The predictions are incorporated into a model-free RL framework to prevent the robot from intruding into the intended paths of other agents. We demonstrate that our method enables the robot to achieve good navigation performance and non-invasiveness in challenging crowd navigation scenarios. We successfully transfer the policy learned in simulation to a real-world TurtleBot 2i. Our code and videos are available at https://sites.google.com/view/intention-aware-crowdnav/home.",
        "primary_area": "",
        "author": "Shuijing Liu;Peixin Chang;Zhe Huang;Neeloy Chakraborty;Kaiwen Hong;Weihang Liang;D. Livingston McPherson;Junyi Geng;Katherine Driggs-Campbell;Shuijing Liu;Peixin Chang;Zhe Huang;Neeloy Chakraborty;Kaiwen Hong;Weihang Liang;D. Livingston McPherson;Junyi Geng;Katherine Driggs-Campbell",
        "authorids": "/37088687174;/37088688639;/37087885165;/37088996927;/37089892500;/37089001263;/37085370314;/37089251620;/37085509519;/37088687174;/37088688639;/37087885165;/37088996927;/37089892500;/37089001263;/37085370314;/37089251620;/37085509519",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Aerospace Engineering, Pennsylvania State University; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160660/",
        "gs_citation": 92,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13008810435359911280&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Illinois, Urbana-Champaign;Pennsylvania State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Aerospace Engineering",
        "aff_unique_url": "https://illinois.edu;https://www.psu.edu",
        "aff_unique_abbr": "UIUC;PSU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161412",
        "title": "Interacting with Multi-Robot Systems via Mixed Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots are becoming safer and more affordable, and their presence in the workspace is increasing. However, many tasks that involve reasoning, long-term planning or human preferences are still hard to automate. While some solutions in specialised areas slowly emerge, an alternative to full autonomy can be to actively leverage intuition and experience of human operators. To do this, suitable interfaces and modes of interaction have to be explored. Inspired by Real-Time Strategy games, we implement a Mixed Reality interface that can be used with either a Microsoft HoloLens 2 headset or a tablet. The interface allows users to interact with multiple mobile robots simultaneously. We conduct a user study to compare the headset and tablet versions of the interface in different scenarios inspired by a real-world construction setting. We show that, while performance and preference of interface are dependent on the task and the complexity of the required interaction, users are able to solve non-trivial tasks on both platforms using our system.",
        "primary_area": "",
        "author": "Florian Kennel-Maushart;Roi Poranne;Stelian Coros;Florian Kennel-Maushart;Roi Poranne;Stelian Coros",
        "authorids": "/37088998456;/37085580542;/37077396200;/37088998456;/37085580542;/37077396200",
        "aff": "Department of Computer Science, ETH Zurich, Zurich, Switzerland; Department of Computer Science, University of Haifa, Haifa, Israel; Department of Computer Science, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161412/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5272973659201692395&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "ETH Zurich;University of Haifa",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch;https://www.haifa.ac.il",
        "aff_unique_abbr": "ETHZ;UoH",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Zurich;Haifa",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Switzerland;Israel"
    },
    {
        "id": "10160890",
        "title": "Interaction-Aware Trajectory Planning for Autonomous Vehicles with Analytic Integration of Neural Networks into Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles (AVs) must share the driving space with other drivers and often employ conservative motion planning strategies to ensure safety. These conservative strategies can negatively impact AV's performance and significantly slow traffic throughput. Therefore, to avoid conservatism, we design an interaction-aware motion planner for the ego vehicle (AV) that interacts with surrounding vehicles to perform complex maneuvers in a locally optimal manner. Our planner uses a neural network-based interactive trajectory predictor and analytically integrates it with model predictive control (MPC). We solve the MPC optimization using the alternating direction method of multipliers (ADMM) and prove the algorithm's convergence. We provide an empirical study and compare our method with a baseline heuristic method.",
        "primary_area": "",
        "author": "Piyush Gupta;David Isele;Donggun Lee;Sangjae Bae;Piyush Gupta;David Isele;Donggun Lee;Sangjae Bae",
        "authorids": "/37275299700;/37086124264;/37086933984;/37086173533;/37275299700;/37086124264;/37086933984;/37086173533",
        "aff": "Honda Research Institute, San Jose, CA, USA; Honda Research Institute, San Jose, CA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Honda Research Institute, San Jose, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160890/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15344120842035434830&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Honda Research Institute;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://honda-ri.com;https://www.mit.edu",
        "aff_unique_abbr": "HRI;MIT",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "San Jose;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160904",
        "title": "Interactive Object Segmentation in 3D Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an interactive approach for 3D instance segmentation, where users can iteratively collaborate with a deep learning model to segment objects directly in a 3D point cloud. Current methods for 3D instance segmentation are generally trained in a fully-supervised fashion, which requires large amounts of costly training labels, and does not generalize well to classes unseen during training. Few works have attempted to obtain 3D segmentation masks using human interactions. Existing methods rely on user feedback in the 2D image domain. As a consequence, users are required to constantly switch between 2D images and 3D representations, and custom architectures are employed to combine multiple input modalities. Therefore, integration with existing standard 3D models is not straightforward. The core idea of this work is to enable users to interact directly with 3D point clouds by clicking on desired 3D objects of interest (or their background) to interactively segment the scene in an open-world setting. Specifically, our method does not require training data from any target domain and can adapt to new environments where no appropriate training sets are available. Our system continuously adjusts the object segmentation based on the user feedback and achieves accurate dense 3D segmentation masks with minimal human effort (few clicks per object). Besides its potential for efficient labeling of large-scale and varied 3D datasets, our approach, where the user directly interacts with the 3D environment, enables new AR/VR and human-robot interaction applications.",
        "primary_area": "",
        "author": "Theodora Kontogianni;Ekin Celikkan;Siyu Tang;Konrad Schindler;Theodora Kontogianni;Ekin Celikkan;Siyu Tang;Konrad Schindler",
        "authorids": "/37086119807;/37089892392;/37087233283;/37267277500;/37086119807;/37089892392;/37087233283;/37267277500",
        "aff": "ETH AI Center; Computer Vision Group, RWTH Aachen University, Germany; ETH Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160904/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10063131673374258372&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "ETH Zurich;RWTH Aachen University;ETH Z\u00fcrich",
        "aff_unique_dep": "AI Center;Computer Vision Group;",
        "aff_unique_url": "https://www.ethz.ch;https://www.rwth-aachen.de;https://www.ethz.ch",
        "aff_unique_abbr": "ETH;RWTH;ETHZ",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Zurich;Aachen;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "10161324",
        "title": "Intermittent diffusion-based path planning for heterogeneous groups of mobile sensors in cluttered environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for task-oriented path planning and collision avoidance for a group of heterogeneous holonomic mobile sensors. It is a generalization of the authors' prior work on diffusion-based path planning. The proposed variant allows one to plan paths in environments cluttered with obstacles. The agents follow flow dynamics, i.e., the negative gradient of a function that is the sum of two functions: the first minimizes the distance from desired target regions and the second captures distance from other agents within a field of view. When it becomes necessary to steer around an obstacle, this function is augmented by a projection term that is carefully designed in terms of obstacle boundaries. More importantly, a diffusion term is added intermittently so that agents can exit local minima. In addition, the new approach skips the offline planning phase in the prior approach to improve computational performance and handle collision avoidance with a completely decentralized method. This approach also provably finds collision-free paths under certain conditions. Numerical simulations of three deployment missions further support the performance of ID-based diffusion.",
        "primary_area": "",
        "author": "Christina Frederick;Haomin Zhou;Frank Crosby;Christina Frederick;Haomin Zhou;Frank Crosby",
        "authorids": "/37089892123;/37834718900;/37088403702;/37089892123;/37834718900;/37088403702",
        "aff": "Department of Mathematical Sciences, NJIT, Newark, NJ, USA; Department of Mathematics, Georgia Tech, Atlanta, GA, USA; NSWC PC, Florida, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161324/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7399739737586428280&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "New Jersey Institute of Technology;Georgia Tech;Naval Surface Warfare Center Panama City Division",
        "aff_unique_dep": "Department of Mathematical Sciences;Department of Mathematics;",
        "aff_unique_url": "https://www.njit.edu;https://www.gatech.edu;https://www.navsea.navy.mil/Home/NSWC-Panama-City-Division/",
        "aff_unique_abbr": "NJIT;GT;NSWC PC",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Newark;Atlanta;Panama City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160913",
        "title": "Interpretable and Flexible Target-Conditioned Neural Planners For Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based approaches to autonomous vehicle planners have the potential to scale to many complicated real-world driving scenarios by leveraging huge amounts of driver demonstrations. However, prior work only learns to estimate a single planning trajectory, while there may be multiple acceptable plans in real-world scenarios. To solve the problem, we propose an interpretable neural planner to regress a heatmap, which effectively represents multiple potential goals in the bird's-eye view for an autonomous vehicle. The planner employs an adaptive Gaussian kernel and relaxed hourglass loss to better capture the uncertainty of planning problems. We also use a negative Gaussian kernel to add supervision to the heatmap regression, enabling the model to learn collision avoidance effectively. Our systematic evaluation on the Lyft Open Dataset across a diverse range of real-world driving scenarios shows that our model achieves a safer and more flexible driving performance than prior works.",
        "primary_area": "",
        "author": "Haolan Liu;Jishen Zhao;Liangjun Zhang;Haolan Liu;Jishen Zhao;Liangjun Zhang",
        "authorids": "/37089893300;/37085443152;/37088642847;/37089893300;/37085443152;/37088642847",
        "aff": "University of California San Diego; University of California San Diego; Baidu Research, Sunnyvale, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160913/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4502793138560258928&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of California, San Diego;Baidu Research",
        "aff_unique_dep": ";Research",
        "aff_unique_url": "https://ucsd.edu;https://research.baidu.com",
        "aff_unique_abbr": "UCSD;Baidu Res.",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "San Diego;Sunnyvale",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160699",
        "title": "Intuitive Robot Integration via Virtual Reality Workspaces",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots become increasingly prominent in di-verse industrial settings, the desire for an accessible and reliable system has correspondingly increased. Yet, the task of meaningfully assessing the feasibility of introducing a new robotic component, or adding more robots into an existing infrastructure, remains a challenge. This is due to both the logistics of acquiring a robot and the need for expert knowledge in setting it up. In this paper, we address these concerns by developing a purely virtual simulation of a robotic system. Our proposed framework enables natural human-robot interaction through a visually immersive representation of the workspace. The main advantages of our approach are the following: (i) independence from a physical system, (ii) flexibility in defining the workspace and robotic tasks, and (iii) an intuitive interaction between the operator and the simulated environment. Not only does our system provide an enhanced understanding of 3D space to the operator, but it also encourages a hands-on way to perform robot programming. We evaluate the effectiveness of our method in applying novel automation assignments by training a robot in virtual reality and then executing the task on a real robot.",
        "primary_area": "",
        "author": "Minh Q. Tram;Joseph M. Cloud;William J. Beksi;Minh Q. Tram;Joseph M. Cloud;William J. Beksi",
        "authorids": "/37089894725;/37086945000;/37085463379;/37089894725;/37086945000;/37085463379",
        "aff": "Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA; Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA; Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160699/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15057019165862243410&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Texas at Arlington",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.uta.edu",
        "aff_unique_abbr": "UT Arlington",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Arlington",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161124",
        "title": "Intuitive Telemanipulation of Hyper-Redundant Snake Robots within Locomotion and Reorientation using Task-Priority Inverse Kinematics",
        "track": "main",
        "status": "Poster",
        "abstract": "Snake robots offer considerable potential for endoscopic interventions due to their ability to follow curvilinear paths. Telemanipulation is an open problem due to hyper-redundancy, as input devices only allow a specification of six degrees of freedom. Our work addresses this by presenting a unified telemanipulation strategy which enables follow-the-leader locomotion and reorientation keeping the shape change as small as possible. The basis for this is a novel shape-fitting approach for solving the inverse kinematics in only a few milliseconds. Shape fitting is performed by maximizing the similarity of two curves using Fr\u00e9chet distance while simultaneously specifying the position and orientation of the end effector. Telemanipulation performance is investigated in a study in which 14 participants controlled a simulated snake robot to locomote into the target area. In a final validation, pivot reorientation within the target area is addressed.",
        "primary_area": "",
        "author": "Tim-Lukas Habich;Melvin Hueter;Moritz Schappler;Svenja Spindeldreier;Tim-Lukas Habich;Melvin Hueter;Moritz Schappler;Svenja Spindeldreier",
        "authorids": "/37086963048;/37089892543;/37086131932;/37088940377;/37086963048;/37089892543;/37086131932;/37088940377",
        "aff": "Leibniz University Hannover, Institute of Mechatronic Systems, Garbsen, Germany; Leibniz University Hannover, Institute of Mechatronic Systems, Garbsen, Germany; Leibniz University Hannover, Institute of Mechatronic Systems, Garbsen, Germany; Leibniz University Hannover, Institute of Mechatronic Systems, Garbsen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161124/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8687887884397320341&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Leibniz University Hannover",
        "aff_unique_dep": "Institute of Mechatronic Systems",
        "aff_unique_url": "https://www.uni-hannover.de",
        "aff_unique_abbr": "LUH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Garbsen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160849",
        "title": "Inverse Perspective Mapping-Based Neural Occupancy Grid Map for Visual Parking",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensing environmental obstacles and establishing an occupancy map of surroundings are critical to achieving automated parking for autonomous vehicles. This paper presents a method to obtain surrounding occupancy information from inverse perspective mapping (IPM) images. This method uses the easily-accessed pseudo-labels from LiDAR to supervise a visual network, which can detect occupied boundaries of obstacles. Fusing this visual occupancy with ego-motion information, we develop a multi-frame fusion approach to build a local OGM to realize online environment mapping. Compared with other learning-based occupancy approaches, our method does not require time-consuming and labor-intensive labeling for the environment due to the ground truth of surrounding occupancy coming from LiDAR easily. The proposed method achieves LiDAR-like performance with pure visual inputs, which greatly decreases the cost of real products. Experiments on driving and parking environments prove that our method can accurately sense surrounding occupancy information and build a robust occupancy map of the environment.",
        "primary_area": "",
        "author": "Xiangru Mu;Haoyang Ye;Daojun Zhu;Tongqing Chen;Tong Qin;Xiangru Mu;Haoyang Ye;Daojun Zhu;Tongqing Chen;Tong Qin",
        "authorids": "/37089895616;/37086022108;/37089895232;/37088688037;/37086218149;/37089895616;/37086022108;/37089895232;/37088688037;/37086218149",
        "aff": "IAS BU, Huawei Technologies, Shanghai, China; IAS BU, Huawei Technologies, Shanghai, China; IAS BU, Huawei Technologies, Shanghai, China; IAS BU, Huawei Technologies, Shanghai, China; IAS BU, Huawei Technologies, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160849/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11331230963929403428&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Huawei Technologies",
        "aff_unique_dep": "IAS BU",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160687",
        "title": "Inverse Reinforcement Learning Framework for Transferring Task Sequencing Policies from Humans to Robots in Manufacturing Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present an inverse reinforcement learning approach for solving the problem of task sequencing for robots in complex manufacturing processes. Our proposed framework is adaptable to variations in process and can perform sequencing for entirely new parts. We prescribe an approach to capture feature interactions in a demonstration dataset based on a metric that computes feature interaction coverage. We then actively learn the expert's policy by keeping the expert in the loop. Our training and testing results reveal that our model can successfully learn the expert's policy. We demonstrate the performance of our method on a real-world manufacturing application where we transfer the policy for task sequencing to a manipulator. Our experiments show that the robot can perform these tasks to produce human-competitive performance. Code and video can be found at: https://sites.google.com/usc.edu/irlfortasksequencing",
        "primary_area": "",
        "author": "Omey M. Manyar;Zachary McNulty;Stefanos Nikolaidis;Satyandra K. Gupta;Omey M. Manyar;Zachary McNulty;Stefanos Nikolaidis;Satyandra K. Gupta",
        "authorids": "/37088999526;/37086012577;/37643766400;/37878971100;/37088999526;/37086012577;/37643766400;/37878971100",
        "aff": "Realization of Robotic Systems Lab, University of Southern California, Los Angeles, CA, USA; Realization of Robotic Systems Lab, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Realization of Robotic Systems Lab, University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160687/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13834020032542396185&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Realization of Robotic Systems Lab",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160376",
        "title": "Inverted Landing in a Small Aerial Robot via Deep Reinforcement Learning for Triggering and Control of Rotational Maneuvers",
        "track": "main",
        "status": "Poster",
        "abstract": "Inverted landing in a rapid and robust manner is a challenging feat for aerial robots, especially while depending entirely on onboard sensing and computation. In spite of this, this feat is routinely performed by biological fliers such as bats, flies, and bees. Our previous work has identified a direct causal connection between a series of onboard visual cues and kinematic actions that allow for reliable execution of this challenging aerobatic maneuver in small aerial robots. In this work, we utilized Deep Reinforcement Learning and a physics-based simulation to obtain a general, optimal control policy for robust inverted landing starting from any arbitrary approach condition. This optimized control policy provides a computationally-efficient mapping from the system's emulated observational space to its motor command action space, including both triggering and control of rotational maneuvers. This was accomplished by training the system over a large range of approach flight velocities that varied with magnitude and direction. Next, we performed a sim-to-real transfer and experimental validation of the learned policy via domain randomization, by varying the robot's inertial parameters in the simulation. Through experimental trials, we identified several dominant factors which greatly improved landing robustness and the primary mechanisms that determined inverted landing success. We expect the reinforcement learning framework developed in this study can be generalized to solve more challenging tasks, such as utilizing noisy onboard sensory data, landing on surfaces of various orientations, or landing on dynamically-moving surfaces.",
        "primary_area": "",
        "author": "Bryan Habas;Jack W. Langelaan;Bo Cheng;Bryan Habas;Jack W. Langelaan;Bo Cheng",
        "authorids": "/37089447550;/37546827400;/37536373700;/37089447550;/37546827400;/37536373700",
        "aff": "Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA; Department of Aerospace Engineering, Air Vehicle Intelligence and Autonomy Lab, The Pennsylvania State University, PA, USA; Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160376/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15527044423074065578&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The Pennsylvania State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "University Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161386",
        "title": "It Takes Two: Learning to Plan for Human-Robot Cooperative Carrying",
        "track": "main",
        "status": "Poster",
        "abstract": "Cooperative table-carrying is a complex task due to the continuous nature of the action and state-spaces, multimodality of strategies, and the need for instantaneous adaptation to other agents. In this work, we present a method for predicting realistic motion plans for cooperative human-robot teams on the task. Using a Variational Recurrent Neural Network (VRNN) to model the variation in the trajectory of a human-robot team across time, we are able to capture the distribution over the team's future states while leveraging information from interaction history. The key to our approach is leveraging human demonstration data to generate trajectories that synergize well with humans during test time in a receding horizon fashion. Comparison between a baseline, sampling-based planner RRT (Rapidly-exploring Random Trees) and the VRNN planner in centralized planning shows that the VRNN generates motion more similar to the distribution of human-human demonstrations than the RRT. Results in a human-in-the-loop user study show that the VRNN planner outperforms decentralized RRT on task-related metrics, and is significantly more likely to be perceived as human than the RRT planner. Finally, we demonstrate the VRNN planner on a real robot paired with a human teleoperating another robot.",
        "primary_area": "",
        "author": "Eley Ng;Ziang Liu;Monroe Kennedy;Eley Ng;Ziang Liu;Monroe Kennedy",
        "authorids": "/37088455115;/37088505106;/37089500447;/37088455115;/37088505106;/37089500447",
        "aff": "Department of Mechanical Engineering, ARMLab, Stanford University, Stanford, CA, USA; Department of Computer Science, ARMLab, Stanford University, Stanford, CA, USA; Department of Computer Science, ARMLab, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161386/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17975628459088937528&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160542",
        "title": "Joint Camera Intrinsic and LiDAR-Camera Extrinsic Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensor-based environmental perception is a crucial step for autonomous driving systems, for which an accurate calibration between multiple sensors plays a critical role. For the calibration of LiDAR and camera, the existing method is generally to calibrate the intrinsic of the camera first and then calibrate the extrinsic of the LiDAR and camera. If the camera's intrinsic is not calibrated correctly in the first stage, it is not easy to calibrate the LiDAR-camera extrinsic accurately. Due to the complex internal structure of the camera and the lack of an effective quantitative evaluation method for the camera's intrinsic calibration, in the actual calibration, the accuracy of extrinsic parameter calibration is often reduced due to the tiny error of the camera's intrinsic parameters. To this end, we propose a novel target-based joint calibration method of the camera intrinsic and LiDAR-camera extrinsic parameters. Firstly, we design a novel calibration board pattern, adding four circular holes around the checkerboard for locating the LiDAR pose. Subsequently, a cost function defined under the reprojection constraints of the checkerboard and circular holes features is designed to solve the camera's intrinsic parameters, distortion factor, and LiDAR-camera extrinsic parameter. In the end, quantitative and qualitative experiments are conducted in actual and simulated environments, and the result shows the proposed method can achieve accuracy and robust performance. The open-source code is available at https://github.com/OpenCalib/JointCalib.",
        "primary_area": "",
        "author": "Guohang Yan;Feiyu He;Chunlei Shi;Pengjin Wei;Xinyu Cai;Yikang Li;Guohang Yan;Feiyu He;Chunlei Shi;Pengjin Wei;Xinyu Cai;Yikang Li",
        "authorids": "/37089659382;/37089895573;/37089892493;/37089659959;/37089661769;/37089161200;/37089659382;/37089895573;/37089892493;/37089659959;/37089661769;/37089161200",
        "aff": "Shanghai AI Laboratory, Autonomous Driving Group, China; Shanghai AI Laboratory, Autonomous Driving Group, China; Shanghai AI Laboratory, Autonomous Driving Group, China; Shanghai AI Laboratory, Autonomous Driving Group, China; Shanghai AI Laboratory, Autonomous Driving Group, China; Shanghai AI Laboratory, Autonomous Driving Group, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160542/",
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3140598811720751330&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Shanghai AI Laboratory",
        "aff_unique_dep": "Autonomous Driving Group",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160253",
        "title": "Joint Segmentation and Grasp Pose Detection with Multi-Modal Feature Fusion Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient grasp pose detection is essential for robotic manipulation in cluttered scenes. However, most methods only utilize point clouds or images for prediction, ignoring the advantages of different features. In this paper, we present a multi-modal fusion network for joint segmentation and grasp pose detection. We design a point cloud and image co-guided feature fusion module that can be used to fuse features and adaptively estimate the importance of the point-pixel feature pairs. Moreover, we develop a seed point sampling algorithm that simultaneously considers the distance, semantics and attention scores. For selected seed points, we adopt a local feature aggregation module to fully utilize the local spatial features in the grasp region. Experimental results on the GraspNet-lBillion Dataset show that our network outperforms several state-of-the-art methods. We also conduct real robot grasping experiments to demonstrate the effectiveness of our approach.",
        "primary_area": "",
        "author": "Xiaozheng Liu;Yunzhou Zhang;He Cao;Dexing Shan;Jiaqi Zhao;Xiaozheng Liu;Yunzhou Zhang;He Cao;Dexing Shan;Jiaqi Zhao",
        "authorids": "/37089633935;/37310459100;/37089892159;/37089633109;/37089895210;/37089633935;/37310459100;/37089892159;/37089633109;/37089895210",
        "aff": "College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160253/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=939386945461532509&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "College of Information Science and Engineering",
        "aff_unique_url": "http://www.neu.edu.cn/",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenyang",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160433",
        "title": "Joint Semi-Supervised and Active Learning via 3D Consistency for 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous driving powered by deep learning requires large-scale, high-quality training data from diverse driving environments to operate effectively worldwide. However, collecting and annotating such data is costly and time-consuming. To address this challenge, active learning methods have been explored to select the most informative data samples for training. Nevertheless, most existing methods focus on 2D tasks and do not fully exploit the value of unlabeled data. In this paper, we propose a semi-supervised active learning approach for 3D object detection tasks that leverages the potential of collected data and reduces annotation costs. Our method considers the 3D consistency of bounding box predictions in both semi-supervised and active learning processes, thereby improving the performance of point cloud-based 3D object detection models. Our framework specifically utilizes self-supervision to decrease bounding box uncertainties. Moreover, it selects objects that are either occluded or distant and still exhibit high uncertainty for annotation even after semi-supervised training has decreased their uncertainty. Experiments on the KITTI dataset demonstrate that our semi-supervised active learning approach selects objects with high measurement uncertainties and enhances the model's ability to detect occluded objects. Our approach improves the baseline by more than 60% (+17.12 mAP) when using only 1500 annotated frames.",
        "primary_area": "",
        "author": "Sihwan Hwang;Sanmin Kim;Youngseok Kim;Dongsuk Kum;Sihwan Hwang;Sanmin Kim;Youngseok Kim;Dongsuk Kum",
        "authorids": "/37089894154;/37088594659;/37086964519;/37967151300;/37089894154;/37088594659;/37086964519;/37967151300",
        "aff": "Cho Chun Shik Graduate School of Mobility, KAIST, Daejeon, Republic of Korea; Cho Chun Shik Graduate School of Mobility, KAIST, Daejeon, Republic of Korea; Cho Chun Shik Graduate School of Mobility, KAIST, Daejeon, Republic of Korea; Cho Chun Shik Graduate School of Mobility, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160433/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2348939446448845457&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "Cho Chun Shik Graduate School of Mobility",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160293",
        "title": "Just Round: Quantized Observation Spaces Enable Memory Efficient Learning of Dynamic Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (DRL) is one of the most powerful tools for synthesizing complex robotic behaviors. But training DRL models is incredibly compute and memory intensive, requiring large training datasets and replay buffers to achieve performant results. This poses a challenge for the next generation of field robots that will need to learn on the edge to adapt to their environment. In this paper, we begin to address this issue through observation space quantization. We evaluate our approach using four simulated robot locomotion tasks and two state-of-the-art DRL algorithms, the on-policy Proximal Policy Optimization (PPO) and off-policy Soft Actor-Critic (SAC) and find that observation space quantization reduces overall memory costs by as much as 4.2\\times4.2\\times without impacting learning performance.",
        "primary_area": "",
        "author": "Lev Grossman;Brian Plancher;Lev Grossman;Brian Plancher",
        "authorids": "/37087323750;/37086069939;/37087323750;/37086069939",
        "aff": "Berkshire Grey, Bedford, MA, USA; Barnard College, Columbia University, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160293/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4841570357938632107&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Berkshire Grey;Columbia University",
        "aff_unique_dep": ";Barnard College",
        "aff_unique_url": ";https://www.columbia.edu",
        "aff_unique_abbr": ";Columbia",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160349",
        "title": "KGNet: Knowledge-Guided Networks for Category-Level 6D Object Pose and Size Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the giant leap made in object 6D pose estimation and robotic grasping under structured scenarios, most approaches depend heavily on the exact CAD models of target objects beforehand, thereby limiting their wide applications. To address this, we propose a novel knowledge-guided network - KGNet to estimate the pose and size of category-level unseen objects. This network includes three primary innovations: knowledge-guided categorical model generation, pointwise deformation probability matrix and synergetic RGBD feature fusion, with the former two leveraging categorical object knowledge for unseen object reconstruction and the latter one facilitating pose-sensitive feature extraction. Exten-sive experiments on CAMERA25 and REAL275 verify their effectiveness, and KGNet achieves the SOTA performance on these two acknowledged benchmarks. Additionally, a real-world robotic grasping experiment is conducted, and its results further qualitatively prove the practicability and robustness of KGNet.",
        "primary_area": "",
        "author": "Qiwei Meng;Jason Gu;Shiqiang Zhu;Jianfeng Liao;Tianlei Jin;Fangtai Guo;Wen Wang;Wei Song;Qiwei Meng;Jason Gu;Shiqiang Zhu;Jianfeng Liao;Tianlei Jin;Fangtai Guo;Wen Wang;Wei Song",
        "authorids": "/37089686524;/37276928500;/37281408900;/37086048853;/37089236029;/37087407242;/37089232953;/37852830600;/37089686524;/37276928500;/37281408900;/37086048853;/37089236029;/37087407242;/37089232953;/37852830600",
        "aff": "Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Department of Electrical and Computer Engineering, Dalhousie University, Halifax, NS, Canada; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160349/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14754631070690601070&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang Engineering Research Center for Intelligent Robotics;Dalhousie University",
        "aff_unique_dep": ";Department of Electrical and Computer Engineering",
        "aff_unique_url": ";https://www.dal.ca",
        "aff_unique_abbr": ";Dal",
        "aff_campus_unique_index": "0;1;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou;Halifax",
        "aff_country_unique_index": "0;1;0;0;0;0;0;0",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "10160504",
        "title": "KRIS: A Novel Device for Kinesthetic Corrective Feedback during Robot Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel device that can be used to perform kinesthetic corrective feedback for robotic systems. KRIS (Kinesthetic Robotic Interaction System) is a device that can be mounted on the end-effector of an articulated robot. From here it can be manipulated by a human to give corrective feedback to the robot system during execution and in an intuitive way. The device can provide feedback in six degrees of freedom while giving passive haptic feedback to the user about both the position, rotation, and movement of the robot. We evaluated KRIS in a user study with respect to a baseline based on keyboard feedback in the areas of usability, intuitiveness, accuracy of corrections, and user task load. KRIS outperformed our baseline on the first three metrics and performed similar on task load. We believe that KRIS can enable a wide variety of robots to be taught interactively by non-expert humans in diverse collaborative settings.",
        "primary_area": "",
        "author": "Jorn Verheggen;Kim Baraka;Jorn Verheggen;Kim Baraka",
        "authorids": "/37089895294;/37072368800;/37089895294;/37072368800",
        "aff": "Computer Science Department, Vrije Universiteit, Amsterdam, The Netherlands; Computer Science Department, Vrije Universiteit, Amsterdam, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160504/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1500824631442494967&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vrije Universiteit Amsterdam",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.vu.nl",
        "aff_unique_abbr": "VU Amsterdam",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Amsterdam",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10161284",
        "title": "Keypoint-GraspNet: Keypoint-based 6-DoF Grasp Generation from the Monocular RGB-D input",
        "track": "main",
        "status": "Poster",
        "abstract": "The success of 6-DoF grasp learning with point cloud input is tempered by the computational costs resulting from their unordered nature and pre-processing needs for reducing the point cloud to a manageable size. These properties lead to failure on small objects with low point cloud cardinality. Instead of point clouds, this manuscript explores grasp generation directly from the RGB-D image input. The approach, called Keypoint-GraspNet (KGN), operates in perception space by detecting projected gripper keypoints in the image, then recovering their SE(3) poses with a \\mathrm{P}n\\mathrm{P}\\mathrm{P}n\\mathrm{P} algorithm. Training of the network involves a synthetic dataset derived from primitive shape objects with known continuous grasp families. Trained with only single-object synthetic data, Keypoint-GraspNet achieves superior result on our single-object dataset, comparable performance with state-of-art baselines on a multi-object test set, and outperforms the most competitive baseline on small objects. Keypoint-GraspNet is more than 3x faster than tested point cloud methods. Robot experiments show high success rate, demonstrating KGN's practical potential.",
        "primary_area": "",
        "author": "Yiye Chen;Yunzhi Lin;Ruinian Xu;Patricio A. Vela;Yiye Chen;Yunzhi Lin;Ruinian Xu;Patricio A. Vela",
        "authorids": "/37089001985;/37088506366;/37086419762;/37329553400;/37089001985;/37088506366;/37086419762;/37329553400",
        "aff": "School of Electrical and Computer Engineering, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA; School of Electrical and Computer Engineering, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA; School of Electrical and Computer Engineering, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA; School of Electrical and Computer Engineering, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161284/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4075682023565863579&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160533",
        "title": "Kinematic Analysis and Design of a Novel (6+3)-DoF Parallel Robot with Fixed Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel kinematically redundant (6+36+3) -DoF parallel robot is presented in this paper. Three identical 3-DoF RU/2-RUS legs are attached to a configurable platform through spherical joints. With the selected leg mechanism, the motors are mounted at the base, reducing the reflected inertia. The robot is intended to be actuated with direct-drive motors in order to perform intuitive physical human-robot interaction. The design of the leg mechanism maximizes the workspace in which the end-effector of the leg can have a 2g acceleration in all directions. All singularities of the leg mechanism are identified under a simplifying assumption. A CAD model of the (6+3)-DoF robot is presented in order to illustrate the preliminary design of the robot.",
        "primary_area": "",
        "author": "Arda Yi\u011fit;David Breton;Zhou Zhou;Thierry Lalibert\u00e9;Cl\u00e9ment Gosselin;Arda Yi\u011fit;David Breton;Zhou Zhou;Thierry Lalibert\u00e9;Cl\u00e9ment Gosselin",
        "authorids": "/37088507420;/37089895942;/37089895186;/37442629800;/37293911800;/37088507420;/37089895942;/37089895186;/37442629800;/37293911800",
        "aff": "Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, Qc, Canada; Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, Qc, Canada; Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, Qc, Canada; Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, Qc, Canada; Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, Qc, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160533/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2487796294021963425&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Laval",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ulaval.ca",
        "aff_unique_abbr": "ULaval",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Qu\u00e9bec",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161560",
        "title": "Kinodynamic Rapidly-exploring Random Forest for Rearrangement-Based Nonprehensile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Rearrangement-based nonprehensile manipulation still remains as a challenging problem due to the high-dimensional problem space and the complex physical uncertainties it entails. We formulate this class of problems as a coupled problem of local rearrangement and global action optimization by incorporating free-space transit motions between constrained rearranging actions. We propose a forest-based kinodynamic planning framework to concurrently search in multiple problem regions, so as to enable global exploration of the most task-relevant subspaces, while facilitating effective switches between local rearranging actions. By interleaving dynamic horizon planning and action execution, our framework can adaptively handle real-world uncertainties. With extensive experiments, we show that our framework significantly improves the planning efficiency and manipulation effectiveness while being robust against various uncertainties.",
        "primary_area": "",
        "author": "Kejia Ren;Podshara Chanrungmaneekul;Lydia E. Kavraki;Kaiyu Hang;Kejia Ren;Podshara Chanrungmaneekul;Lydia E. Kavraki;Kaiyu Hang",
        "authorids": "/37089696201;/37089894385;/37279015600;/37085393148;/37089696201;/37089894385;/37279015600;/37085393148",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161560/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3063479499144105820&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161047",
        "title": "Knowledge Distillation for Feature Extraction in Underwater VSLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, learning-based feature detection and matching have outperformed manually-designed methods in in-air cases. However, it is challenging to learn the features in the underwater scenario due to the absence of annotated underwater datasets. This paper proposes a cross-modal knowl-edge distillation framework for training an underwater feature detection and matching network (UFEN). In particular, we use in-air RGBD data to generate synthetic underwater images based on a physical underwater imaging formation model and employ these as the medium to distil knowledge from a teacher model SuperPoint pretrained on in-air images. We embed UFEN into the ORB-SLAM3 framework to replace the ORB feature by introducing an additional binarization layer. To test the effectiveness of our method, we built a new underwater dataset with groundtruth measurements named EASI (https://github.com/Jinghe-mel/UFEN-SLAM), recorded in an indoor water tank for different turbidity levels. The experimental results on the existing dataset and our new dataset demonstrate the effectiveness of our method.",
        "primary_area": "",
        "author": "Jinghe Yang;Mingming Gong;Girish Nair;Jung Hoon Lee;Jason Monty;Ye Pu;Jinghe Yang;Mingming Gong;Girish Nair;Jung Hoon Lee;Jason Monty;Ye Pu",
        "authorids": "/37089895257;/37086582272;/37265817400;/37089896123;/37089894497;/37089894630;/37089895257;/37086582272;/37265817400;/37089896123;/37089894497;/37089894630",
        "aff": "the Department of Electrical and Electronic Engineering, The University of Melbourne; School of Mathematics and Statistics, The University of Melbourne; the Department of Electrical and Electronic Engineering, The University of Melbourne; the Department of Mechanical Engineering, The University of Melbourne; the Department of Mechanical Engineering, The University of Melbourne; the Department of Electrical and Electronic Engineering, The University of Melbourne",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161047/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16589870322905342333&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "The University of Melbourne",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.unimelb.edu.au",
        "aff_unique_abbr": "UniMelb",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Melbourne",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160632",
        "title": "KubeROS: A Unified Platform for Automated and Scalable Deployment of ROS2-based Multi-Robot Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "As advanced algorithms enable robots to handle more challenging tasks and operate more autonomously, the on-board computer cannot meet the increased demands regarding computing power and memory storage in an efficient way. Leveraging the massive computing power of the cloud and low-latency connectivity to the edge can compensate for this lack of computing resources. However, this introduces a new challenge related to the deployment of complex robotic software across multiple devices, especially in a large-scale system. This paper presents KubeROS, a unified and fully managed platform for automated deployment of robotic applications developed on top of Robot Operating System 2 (ROS2), in a hybrid computing infrastructure with robots, edge and cloud. KubeROS uses Kubernetes from Cloud Native Computing as its underlying software orchestration framework. It aims to help researchers and developers with no prior cloud computing knowledge deploy their ROS2-based robotic applications at any scale. KubeROS eliminates the need for system configuration and network setup. We demonstrate the applicability of KubeROS by deploying a fleet of simulated mobile manipulators in a clas-sical pick-and-place application. The experiments demonstrate the effects of different deployment strategies for vision-based motion planning under different fleet sizes and workloads. In addition, KubeROS improves task performance by using high-performance computing at the edge and in the cloud, and achieves high resource efficiency when using the shared deployment strategy.",
        "primary_area": "",
        "author": "Yongzhou Zhang;Christian Wurll;Bj\u00f6rn Hein;Yongzhou Zhang;Christian Wurll;Bj\u00f6rn Hein",
        "authorids": "/37089894886;/37370368500;/37604448500;/37089894886;/37370368500;/37604448500",
        "aff": "Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe University of Applied Sciences, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160632/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6837223233849433097&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Karlsruhe University of Applied Sciences",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kit.edu;https://www.hs-karlsruhe.de",
        "aff_unique_abbr": "KIT;HsKA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161443",
        "title": "L-C*: Visual-inertial Loose Coupling for Resilient and Lightweight Direct Visual Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "This study presents a framework, L-C*, for resilient and lightweight direct visual localization, employing a loosely coupled fusion of visual and inertial data. Unlike indirect methods, direct visual localization facilitates accurate pose estimation on general color three-dimensional maps that are not tailored for visual localization. However, it suffers from temporal localization failures and high computational costs for real-time applications. For long-term and real-time visual localization, we developed an L-C* that incorporates direct visual localization C* in a visual-inertial loose coupling. By capturing ego-motion via visual-inertial odometry to interpolate global pose estimates, the framework allows for a significant reduction in the frequency of demanding global localization, thereby facilitating lightweight but reliable visual localization. In addition, forming a closed loop that feeds the latest pose estimate to the visual localization component as an initial guess for the next pose inference renders the system highly robust. A quantitative evaluation of a simulation dataset demonstrated the accuracy and efficiency of the proposed framework. Experiments using smartphone sensors also demonstrated the robustness and resiliency of L-C* in real-world situations.",
        "primary_area": "",
        "author": "Shuji Oishi;Kenji Koide;Masashi Yokozuka;Atsuhiko Banno;Shuji Oishi;Kenji Koide;Masashi Yokozuka;Atsuhiko Banno",
        "authorids": "/37085895378;/37086179385;/38230409400;/37391486400;/37085895378;/37086179385;/38230409400;/37391486400",
        "aff": "Smart Mobility Research Team, National Institute of Advanced Industrial Science and Technology (AIST), Ibaraki, Japan; Smart Mobility Research Team, National Institute of Advanced Industrial Science and Technology (AIST), Ibaraki, Japan; Smart Mobility Research Team, National Institute of Advanced Industrial Science and Technology (AIST), Ibaraki, Japan; Smart Mobility Research Team, National Institute of Advanced Industrial Science and Technology (AIST), Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161443/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10122953369671727127&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Smart Mobility Research Team",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ibaraki",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161220",
        "title": "L2E: Lasers to Events for 6-DoF Extrinsic Calibration of Lidars and Event Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "As neuromorphic technology is maturing, its application to robotics and autonomous vehicle systems has become an area of active research. In particular, event cameras have emerged as a compelling alternative to frame-based cameras in low-power and latency-demanding applications. To enable event cameras to operate alongside staple sensors like lidar in perception tasks, we propose a direct, temporally-decoupled extrinsic calibration method between event cameras and lidars. The high dynamic range, high temporal resolution, and low-latency operation of event cameras are exploited to directly register lidar laser returns, allowing information-based correlation methods to optimize for the 6- DoF extrinsic calibration between the two sensors. This paper presents the first direct calibration method between event cameras and lidars, removing dependencies on frame-based camera intermediaries and/or highly-accurate hand measurements. Code: https://github.com/kev-in-ta/12e",
        "primary_area": "",
        "author": "Kevin Ta;David Bruggemann;Tim Br\u00f6dermann;Christos Sakaridis;Luc Van Gool;Kevin Ta;David Bruggemann;Tim Br\u00f6dermann;Christos Sakaridis;Luc Van Gool",
        "authorids": "/37088476210;/37089314488;/37088745295;/37086579921;/37277167600;/37088476210;/37089314488;/37088745295;/37086579921;/37277167600",
        "aff": "Computer Vision Lab, ETH Zurich, Zurich, Switzerland; Computer Vision Lab, ETH Zurich, Zurich, Switzerland; Computer Vision Lab, ETH Zurich, Zurich, Switzerland; Computer Vision Lab, ETH Zurich, Zurich, Switzerland; Department of Electrical Engineering, KU Leuven, Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161220/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6462021760440596323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "ETH Zurich;KU Leuven",
        "aff_unique_dep": "Computer Vision Lab;Department of Electrical Engineering",
        "aff_unique_url": "https://www.ethz.ch;https://www.kuleuven.be",
        "aff_unique_abbr": "ETHZ;KU Leuven",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Zurich;Leuven",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Switzerland;Belgium"
    },
    {
        "id": "10160757",
        "title": "LAPTNet-FPN: Multi-Scale LiDAR-Aided Projective Transform Network for Real Time Semantic Grid Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic grids can be useful representations of the scene around an autonomous system. By having information about the layout of the space around itself, a robot can leverage this type of representation for crucial tasks such as navigation or tracking. By fusing information from multiple sensors, robustness can be increased and the computational load for the task can be lowered, achieving real time performance. Our multi-scale LiDAR-Aided Perspective Transform network uses information available in point clouds to guide the projection of image features to a top-view representation, resulting in a relative improvement in the state of the art for semantic grid generation for human (+8.67%) and movable object (+49.07%) classes in the nuScenes dataset, as well as achieving results close to the state of the art for the vehicle, drivable area and walkway classes, while performing inference at 25 FPS.",
        "primary_area": "",
        "author": "Manuel Diaz-Zapata;David Sierra-Gonzalez;\u00d6zg\u00fcr Erkent;Christian Laugier;Jilles Dibangoye;Manuel Diaz-Zapata;David Sierra-Gonzalez;\u00d6zg\u00fcr Erkent;Christian Laugier;Jilles Dibangoye",
        "authorids": "/37088637298;/37088636930;/38132645500;/37273327000;/37086163536;/37088637298;/37088636930;/38132645500;/37273327000;/37086163536",
        "aff": "CHROMA team, Inria, Univ. Grenoble Alpes, Grenoble, France; CHROMA team, Inria, Univ. Grenoble Alpes, Grenoble, France; Hacettepe University, Ankara, Turkey; CHROMA team, Inria, Univ. Grenoble Alpes, Grenoble, France; CHROMA team, Inria, Univ. Grenoble Alpes, Grenoble, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160757/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1052316659580627935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Inria;Hacettepe University",
        "aff_unique_dep": "CHROMA team;",
        "aff_unique_url": "https://www.inria.fr;https://www.hacettepe.edu.tr",
        "aff_unique_abbr": "Inria;Hacettepe",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Grenoble;Ankara",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "France;Turkey"
    },
    {
        "id": "10161570",
        "title": "LATITUDE: Robotic Global Localization with Truncated Dynamic Low-pass Filter in City-scale NeRF",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural Radiance Fields (NeRFs) have made great success in representing complex 3D scenes with high-resolution details and efficient memory. Nevertheless, current NeRF - based pose estimators have no initial pose prediction and are prone to local optima during optimization. In this paper, we present LATITUDE: Global Localization with Truncated Dynamic Low-pass Filter, which introduces a two-stage localization mechanism in city-scale NeRF. In place recognition stage, we train a regressor through images generated from trained NeRFs, which provides an initial value for global localization. In pose optimization stage, we minimize the residual between the observed image and rendered image by directly optimizing the pose on the tangent plane. To avoid falling into local optimum, we introduce a Truncated Dynamic Low-pass Filter (TDLF) for coarse-to-fine pose registration. We evaluate our method on both synthetic and real-world data and show its potential applications for high-precision navigation in large-scale city scenes. Codes and dataset will be publicly available at https://github.com/jike5/LATITUDE.",
        "primary_area": "",
        "author": "Zhenxin Zhu;Yuantao Chen;Zirui Wu;Chao Hou;Yongliang Shi;Chuxuan Li;Pengfei Li;Hao Zhao;Guyue Zhou;Zhenxin Zhu;Yuantao Chen;Zirui Wu;Chao Hou;Yongliang Shi;Chuxuan Li;Pengfei Li;Hao Zhao;Guyue Zhou",
        "authorids": "/37089892902;/37089895317;/37089894989;/37089893448;/37086798123;/37089893290;/37089893178;/37086217629;/37085489402;/37089892902;/37089895317;/37089894989;/37089893448;/37086798123;/37089893290;/37089893178;/37086217629;/37085489402",
        "aff": "Beihang University, China; Xi'an University of architecture and technology, China; Beijing Institute of Technology, China; The University of Hong Kong, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161570/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11433437713498949300&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;2;3;4;4;4;4;4",
        "aff_unique_norm": "Beihang University;Xi'an University of Architecture and Technology;Beijing Institute of Technology;The University of Hong Kong;Tsinghua University",
        "aff_unique_dep": ";;;;Institute for AI Industry Research (AIR)",
        "aff_unique_url": "http://www.buaa.edu.cn/;http://www.xauat.edu.cn/;http://www.bit.edu.cn/;https://www.hku.hk;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "BUAA;XAUAT;BIT;HKU;Tsinghua",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161068",
        "title": "LATTE: LAnguage Trajectory TransformEr",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural language is one of the most intuitive ways to express human intent. However, translating instructions and commands towards robotic motion generation and deployment in the real world is far from being an easy task. The challenge of combining a robot's inherent low-level geometric and kinodynamic constraints with a human's high-level semantic instructions traditionally is solved using task-specific solutions with little generalizability between hardware platforms, often with the use of static sets of target actions and commands. This work instead proposes a flexible language-based framework that allows a user to modify generic robotic trajectories. Our method leverages pre-trained language models (BERT and CLIP) to encode the user's intent and target objects directly from a free-form text input and scene images, fuses geometrical features generated by a transformer encoder network, and finally outputs trajectories using a transformer decoder, without the need of priors related to the task or robot information. We significantly extend our own previous work presented in [1] by expanding the trajectory parametrization space to 3D and velocity as opposed to just XY movements. In addition, we now train the model to use actual images of the objects in the scene for context (as opposed to textual descriptions), and we evaluate the system in a diverse set of scenarios beyond manipulation, such as aerial and legged robots. Our simulated and real-life experiments demonstrate that our transformer model can successfully follow human intent, modifying the shape and speed of trajectories within multiple environments. Codebase avail-able at: https://github.com/arthurfenderbucker/LaTTe-Language-Trajectory-TransformEr.git.",
        "primary_area": "",
        "author": "Arthur Bucker;Luis Figueredo;Sami Haddadin;Ashish Kapoor;Shuang Ma;Sai Vemprala;Rogerio Bonatti;Arthur Bucker;Luis Figueredo;Sami Haddadin;Ashish Kapoor;Shuang Ma;Sai Vemprala;Rogerio Bonatti",
        "authorids": "/37089000770;/37063909900;/37542865300;/37397699500;/37086565371;/37085796013;/37086934741;/37089000770;/37063909900;/37542865300;/37397699500;/37086565371;/37085796013;/37086934741",
        "aff": "Technische Universit\u00e4t, M\u00fcnchen; Technische Universit\u00e4t, M\u00fcnchen; Technische Universit\u00e4t, M\u00fcnchen; Microsoft; Microsoft; Microsoft; Microsoft",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161068/",
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14211024456241696372&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;1",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Microsoft Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tum.de;https://www.microsoft.com",
        "aff_unique_abbr": "TUM;Microsoft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "M\u00fcnchen;",
        "aff_country_unique_index": "0;0;0;1;1;1;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "10161211",
        "title": "LEARNEST: LEARNing Enhanced Model-based State ESTimation for Robots using Knowledge-based Neural Ordinary Differential Equations",
        "track": "main",
        "status": "Poster",
        "abstract": "State estimation is an important aspect in many robotics applications. In this work, we consider the task of obtaining accurate state estimates for robotic systems by enhancing the dynamics model used in state estimation algorithms. Existing frameworks such as moving horizon estimation (MHE) and the unscented Kalman filter (UKF) provide the flexibility to incorporate nonlinear dynamics and measurement models. However, this implies that the dynamics model within these algorithms has to be sufficiently accurate in order to warrant the accuracy of the state estimates. To enhance the dynamics models and improve the estimation accuracy, we utilize a deep learning framework known as knowledge-based neural ordinary differential equations (KNODEs). The KNODE framework embeds prior knowledge into the training procedure and synthesizes an accurate hybrid model by fusing a prior first-principles model with a neural ordinary differential equation (NODE) model. In our proposed LEARNEST framework, we integrate the data-driven model into two novel model-based state estimation algorithms, which are denoted as KNODE-MHE and KNODE-UKF. These two algorithms are compared against their conventional counterparts across a number of robotic applications; state estimation for a cartpole system using partial measurements, localization for a ground robot, as well as state estimation for a quadrotor. Through simulations and tests using real-world experimental data, we demonstrate the versatility and efficacy of the proposed learning-enhanced state estimation framework.",
        "primary_area": "",
        "author": "Kong Yao Chee;M. Ani Hsieh;Kong Yao Chee;M. Ani Hsieh",
        "authorids": "/37088602790;/38238444800;/37088602790;/38238444800",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161211/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7912712967705091096&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161328",
        "title": "LEMURS: Learning Distributed Multi-Robot Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents LEMURS, an algorithm for learning scalable multi-robot control policies from cooperative task demonstrations. We propose a port-Hamiltonian description of the multi-robot system to exploit universal physical constraints in interconnected systems and achieve closed-loop stability. We represent a multi-robot control policy using an architecture that combines self-attention mechanisms and neural ordinary differential equations. The former handles time-varying communication in the robot team, while the latter respects the continuous-time robot dynamics. Our representation is distributed by construction, enabling the learned control policies to be deployed in robot teams of different sizes. We demonstrate that LEMURS can learn interactions and cooperative behaviors from demonstrations of multi-agent navigation and flocking tasks.",
        "primary_area": "",
        "author": "Eduardo Sebasti\u00e1n;Thai Duong;Nikolay Atanasov;Eduardo Montijano;Carlos Sag\u00fc\u00e9s;Eduardo Sebasti\u00e1n;Thai Duong;Nikolay Atanasov;Eduardo Montijano;Carlos Sag\u00fc\u00e9s",
        "authorids": "/37086025534;/37088507510;/37670511000;/37681715400;/37542881000;/37086025534;/37088507510;/37670511000;/37681715400;/37542881000",
        "aff": "RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain; RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161328/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=546385705322317957&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Universidad de Zaragoza;University of California San Diego",
        "aff_unique_dep": "DIIS - I3A;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.unizar.es;https://www.ucsd.edu",
        "aff_unique_abbr": ";UCSD",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";La Jolla",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "Spain;United States"
    },
    {
        "id": "10160279",
        "title": "LES: Locally Exploitative Sampling for Robot Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based algorithms solve the path planning problem by generating random samples in the searchspace and incrementally growing a connectivity graph or a tree. Conventionally, the sampling strategy used in these algorithms is biased towards exploration to acquire information about the search-space. In contrast, this work proposes an optimization-based procedure that generates new samples so as to improve the cost-to-come value of vertices in a given neighborhood. The application of the proposed algorithm adds an exploitativebias to sampling and results in a faster convergence to the optimal solution compared to other state-of-the-art sampling techniques. This is demonstrated using benchmarking experiments performed for 7 DOF Panda and 14 DOF Baxter robots.",
        "primary_area": "",
        "author": "Sagar Suhas Joshi;Seth Hutchinson;Panagiotis Tsiotras;Sagar Suhas Joshi;Seth Hutchinson;Panagiotis Tsiotras",
        "authorids": "/37088691385;/37282386200;/37330609800;/37088691385;/37282386200;/37330609800",
        "aff": "Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160279/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3483530619952833837&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160290",
        "title": "LGCNet: Feature Enhancement and Consistency Learning Based on Local and Global Coherence Network for Correspondence Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "Correspondence selection, a crucial step in many computer vision tasks, aims to distinguish between inliers and outliers from putative correspondences. The coherence of correspondences is often used for predicting inlier probability, but it is difficult for neural networks to extract coherence contexts based only on quadruple coordinates. To overcome this difficulty, we propose enhancing the preliminary features using local and global handcrafted coherent characteristics before model learning, which strengthens the discrimination of each correspondence and guides the model to prune obvious outliers. Furthermore, to fully utilize local information, neighbors are searched in coordinate space as well as feature space. These two kinds of neighbors provide complementary and plentiful contexts for inlier probability prediction. Finally, a novel neighbor representation and a fusion architecture are proposed to retain detailed features. Experiments demonstrate that our method achieves state-of-the-art performance on relative camera pose estimation and correspondence selection metrics on the outdoor YFCC100M [1] and the indoor SUN3D [2] datasets.",
        "primary_area": "",
        "author": "Tzu-Han Wu;Kuan-Wen Chen;Tzu-Han Wu;Kuan-Wen Chen",
        "authorids": "/37089892566;/37089893887;/37089892566;/37089893887",
        "aff": "Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160290/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7035779694286239356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Yang Ming Chiao Tung University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NYCU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160552",
        "title": "LODE: Locally Conditioned Eikonal Implicit Scene Completion from Sparse LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "Scene completion refers to obtaining dense scene representation from an incomplete perception of complex 3D scenes. This helps robots detect multi-scale obstacles and analyse object occlusions in scenarios such as autonomous driving. Recent advances show that implicit representation learning can be leveraged for continuous scene completion and achieved through physical constraints like Eikonal equations. However, former Eikonal completion methods only demonstrate results on watertight meshes at a scale of tens of meshes. None of them are successfully done for non-watertight LiDAR point clouds of open large scenes at a scale of thousands of scenes. In this paper, we propose a novel Eikonal formulation that conditions the implicit representation on localized shape priors which function as dense boundary value constraints, and demonstrate it works on SemanticKITTI and SemanticPOSS. It can also be extended to semantic Eikonal scene completion with only small modifications to the network architecture. With extensive quantitative and qualitative results, we demonstrate the benefits and drawbacks of existing Eikonal methods, which naturally leads to the new locally conditioned formulation. Notably, we improve IoU from 31.7% to 51.2% on SemanticKITTI and from 40.5% to 48.7% on SemanticPOSS. We extensively ablate our methods and demonstrate that the proposed formulation is robust to a wide spectrum of implementation hyper-parameters. Codes and models are publicly available at https://github.com/AIR-DISCOVER/LODE",
        "primary_area": "",
        "author": "Pengfei Li;Ruowen Zhao;Yongliang Shi;Hao Zhao;Jirui Yuan;Guyue Zhou;Ya-Qin Zhang;Pengfei Li;Ruowen Zhao;Yongliang Shi;Hao Zhao;Jirui Yuan;Guyue Zhou;Ya-Qin Zhang",
        "authorids": "/37089893178;/37089892616;/37086798123;/37086217629;/37089538852;/37085489402;/37089274960;/37089893178;/37089892616;/37086798123;/37086217629;/37089538852;/37085489402;/37089274960",
        "aff": "Department of Computer Science and Technology, Tsinghua University, China; University of Chinese Academy of Sciences, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160552/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12459033194258004784&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University;University of Chinese Academy of Sciences",
        "aff_unique_dep": "Department of Computer Science and Technology;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://www.ucas.ac.cn",
        "aff_unique_abbr": "THU;UCAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160730",
        "title": "Large-Scale Radar Localization using Online Public Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose using online public maps, e.g., OpenStreetMap (OSM), for large-scale radar-based localization without needing a prior sensing map. This can potentially extend the localization system to anywhere worldwide without building, saving, or maintaining a sensing map, as long as an online public map covers the operating area. Existing methods using OSM only use route network or semantics information. These two sources of information are not combined in the previous works, while our proposed system fuses them to improve localization accuracy. Our experiments, on three open datasets collected from three different continents, show that the proposed system outperforms the state-of-the-art localization methods, reducing up to 50% of position errors. We release an open-source implementation for the community.",
        "primary_area": "",
        "author": "Ziyang Hong;Yvan Petillot;Kaicheng Zhang;Shida Xu;Sen Wang;Ziyang Hong;Yvan Petillot;Kaicheng Zhang;Shida Xu;Sen Wang",
        "authorids": "/37088217691;/37282015500;/37089195030;/37089197042;/37086278300;/37088217691;/37282015500;/37089195030;/37089197042;/37086278300",
        "aff": "Heriot-Watt University, UK; Heriot-Watt University, UK; Heriot-Watt University, UK; Heriot-Watt University, UK; Department of Electrical and Electronic Engineering, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160730/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3063413901177134370&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Heriot-Watt University;Imperial College London",
        "aff_unique_dep": ";Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.hw.ac.uk;https://www.imperial.ac.uk",
        "aff_unique_abbr": "HWU;ICL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160571",
        "title": "Learnable Tegotae-based Feedback in CPGs with Sparse Observation Produces Efficient and Adaptive Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Central Pattern generators (CPG) are a biologically inspired, decentralized control architecture that enables model-free, but yet adaptively stable and computational lightweight locomotion capabilities on complex robots. Nevertheless, no unified design guidelines for closed-loop CPG controllers are available in the literature. Therefore, we propose a task-distributed, end-to-end trainable, closed-loop CPG control policy by generalizing and extending Tegotae control. The Tegotae approach modulates CPG activity by quantifying the discrepancy between internal belief states and environmental reactions. Spontaneous and adaptive gait formation towards situationally efficient locomotion patterns are intrinsic properties of Tegotae control. The Tegotae control policy is trained and benchmarked in simulation on a 1D hopping robot. We found that our approach can learn efficient and adaptive locomotion on minimal feedback information, while out-performing unstructured, classic reinforcement learning policies of equal complexity. To the best of our knowledge, this is the first study to fully generalize the Tegotae approach and construct unimpeded, end-to-end trainable Tegotae control policies.",
        "primary_area": "",
        "author": "Christopher Herneth;Mitsuhiro Hayashibe;Dai Owaki;Christopher Herneth;Mitsuhiro Hayashibe;Dai Owaki",
        "authorids": "/37085882956;/37586645600;/37294593400;/37085882956;/37586645600;/37294593400",
        "aff": "Department of Robotics, Neuro-Robotics Lab, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Robotics, Neuro-Robotics Lab, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Robotics, Neuro-Robotics Lab, Graduate School of Engineering, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160571/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8697533769017370476&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160680",
        "title": "Learned Risk Metric Maps for Kinodynamic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Learned Risk Metric Maps (LRMM) for real-time estimation of coherent risk metrics of high-dimensional dynamical systems operating in unstructured, partially observed environments. LRMM models are simple to design and train-requiring only procedural generation of obstacle sets, state and control sampling, and supervised training of a function approximator-which makes them broadly applicable to arbitrary system dynamics and obstacle sets. In a parallel autonomy setting, we demonstrate the model's ability to rapidly infer collision probabilities of a fast-moving car-like robot driving recklessly in an obstructed environment; allowing the LRMM agent to intervene, take control of the vehicle, and avoid collisions. In this time-critical scenario, we show that LRMMs can evaluate risk metrics 20-100x times faster than alternative safety algorithms based on control barrier functions (CBFs) and Hamilton-Jacobi reachability (HJ-reach), leading to 5\u201315 % fewer obstacle collisions by the LRMM agent than CBFs and HJ-reach. This performance improvement comes in spite of the fact that the LRMM model only has access to local/partial observation of obstacles, whereas the CBF and HJ-reach agents are granted privileged/global information. We also show that our model can be equally well trained on a 12-dimensional quadrotor system operating in an obstructed indoor environment. The LRMM codebase is provided at https://github.com/mit-drl/pyrmm.",
        "primary_area": "",
        "author": "Ross E. Allen;Wei Xiao;Daniela Rus;Ross E. Allen;Wei Xiao;Daniela Rus",
        "authorids": "/37088470952;/37086963559;/37279652300;/37088470952;/37086963559;/37279652300",
        "aff": "Massachusetts Institute of Technology, Lincoln Laboratory, Lexington, MA, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160680/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1343965714018230295&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Lincoln Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Lexington;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160747",
        "title": "Learning Agent-Aware Affordances for Closed-Loop Interaction with Articulated Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Interactions with articulated objects are a challenging but important task for mobile robots. To tackle this challenge, we propose a novel closed-loop control pipeline, which integrates manipulation priors from affordance estimation with sampling-based whole-body control. We introduce the concept of agent-aware affordances which fully reflect the agent's capabilities and embodiment and we show that they outperform their state-of-the-art counterparts which are only conditioned on the end-effector geometry. Additionally, closed-loop affordance inference is found to allow the agent to divide a task into multiple non-continuous motions and recover from failure and unexpected states. Finally, the pipeline is able to perform long-horizon mobile manipulation tasks, i.e. opening and closing an oven, in the real world with high success rates (opening: 71%, closing: 72%).",
        "primary_area": "",
        "author": "Giulio Schiavi;Paula Wulkop;Giuseppe Rizzi;Lionel Ott;Roland Siegwart;Jen Jen Chung;Giulio Schiavi;Paula Wulkop;Giuseppe Rizzi;Lionel Ott;Roland Siegwart;Jen Jen Chung",
        "authorids": "/37089891964;/37086550781;/37086934960;/38251784400;/37281398300;/37085668354;/37089891964;/37086550781;/37086934960;/38251784400;/37281398300;/37085668354",
        "aff": "Autonomous Systems Lab, ETH, Zurich, Switzerland; Autonomous Systems Lab, ETH, Zurich, Switzerland; Autonomous Systems Lab, ETH, Zurich, Switzerland; Autonomous Systems Lab, ETH, Zurich, Switzerland; Autonomous Systems Lab, ETH, Zurich, Switzerland; School of ITEE, The University of Queensland, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160747/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13332802457666581614&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "ETH Zurich;The University of Queensland",
        "aff_unique_dep": "Autonomous Systems Lab;School of ITEE",
        "aff_unique_url": "https://www.ethz.ch;https://www.uq.edu.au",
        "aff_unique_abbr": "ETH;UQ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich;",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "Switzerland;Australia"
    },
    {
        "id": "10160712",
        "title": "Learning Agile Flight Maneuvers: Deep SE(3) Motion Planning and Control for Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "Agile flights of autonomous quadrotors in clut-tered environments require constrained motion planning and control subject to translational and rotational dynamics. Tra-ditional model-based methods typically demand complicated design and heavy computation. In this paper, we develop a novel deep reinforcement learning-based method that tackles the challenging task of flying through a dynamic narrow gate. We design a model predictive controller with its adaptive tracking references parameterized by a deep neural network (DNN). These references include the traversal time and the quadrotor SE(3) traversal pose that encourage the robot to fly through the gate with maximum safety margins from various initial conditions. To cope with the difficulty of training in highly dynamic environments, we develop a reinforce-imitate learning framework to train the DNN efficiently that generalizes well to diverse settings. Furthermore, we propose a binary search algorithm that allows online adaption of the SE(3) references to dynamic gates in real-time. Finally, through extensive high-fidelity simulations, we show that our approach is adaptive to different gate trajectories, velocities, and orientations.",
        "primary_area": "",
        "author": "Yixiao Wang;Bingheng Wang;Shenning Zhang;Han Wei Sia;Lin Zhao;Yixiao Wang;Bingheng Wang;Shenning Zhang;Han Wei Sia;Lin Zhao",
        "authorids": "/37089894776;/37085686177;/37089893149;/37089892829;/37089024309;/37089894776;/37085686177;/37089893149;/37089892829;/37089024309",
        "aff": "Department of Electrical and Computer Engineering, National University of Singapore, Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore, Singapore; ST Engineering, Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160712/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4430498562155065383&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "National University of Singapore;ST Engineering",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.stengg.com",
        "aff_unique_abbr": "NUS;ST Engg",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160582",
        "title": "Learning Arm-Assisted Fall Damage Reduction and Recovery for Legged Mobile Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Adaptive falling and recovery skills greatly extend the applicability of robot deployments. In the case of legged mobile manipulators, the robot arm could adaptively stop the fall and assist the recovery. Prior works on falling and recovery strategies for legged mobile manipulators usually rely on assumptions such as inelastic collisions and falling in defined directions to enable real-time computation. This paper presents a learning-based approach to reducing fall damage and recovery. An asymmetric actor-critic training structure is used to train a time-invariant policy with time-varying reward functions. In simulated experiments, the policy recovers from 98.9% of initial falling configurations. It reduces base contact impulse, peak joint internal forces, and base acceleration during the fall compared to the baseline methods. The trained control policy is deployed and extensively tested on the ALMA robot hardware. A video summarizing the proposed method and the hardware tests is available at https://youtu.be/avwg2HqGi8s",
        "primary_area": "",
        "author": "Yuntao Ma;Farbod Farshidian;Marco Hutter;Yuntao Ma;Farbod Farshidian;Marco Hutter",
        "authorids": "/37088998578;/37085428006;/37545251000;/37088998578;/37085428006;/37545251000",
        "aff": "Robotic Systems Lab, ETH Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160582/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9479510711594766243&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161476",
        "title": "Learning Augmented, Multi-Robot Long-Horizon Navigation in Partially Mapped Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel approach for efficient and reliable goal-directed long-horizon navigation for a multi-robot team in a structured, unknown environment by predicting statistics of unknown space. Building on recent work in learning-augmented model based planning under uncertainty, we introduce a high-level state and action abstraction that lets us approximate the challenging Dec-POMDP into a tractable stochastic MDP. Our Multi-Robot Learning over Subgoals Planner (MR-LSP) guides agents towards coordinated exploration of regions more likely to reach the unseen goal. We demonstrate improvement in cost against other multi-robot strategies; in simulated office-like environments, we show that our approach saves 13.29% (2 robot) and 4.6% (3 robot) average cost versus standard non-learned optimistic planning and a learning-informed baseline.",
        "primary_area": "",
        "author": "Abhish Khanal;Gregory J. Stein;Abhish Khanal;Gregory J. Stein",
        "authorids": "/37089892398;/37085348859;/37089892398;/37085348859",
        "aff": "Department of Computer Science, George Mason University, Fairfax, VA, USA; Department of Computer Science, George Mason University, Fairfax, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161476/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3814740105448845455&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "George Mason University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.gmu.edu",
        "aff_unique_abbr": "GMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Fairfax",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160820",
        "title": "Learning Category-Level Manipulation Tasks from Point Clouds with Dynamic Graph CNNs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new technique for learning category-level manipulation from raw RGB-D videos of task demonstrations, with no manual labels or annotations. Category-level learning aims to acquire skills that can be generalized to new objects, with geometries and textures that are different from the ones of the objects used in the demonstrations. We address this problem by first viewing both grasping and manipulation as special cases of tool use, where a tool object is moved to a sequence of key-poses defined in a frame of reference of a target object. Tool and target objects, along with their key-poses, are predicted using a dynamic graph convolutional neural network that takes as input an automatically segmented depth and color image of the entire scene. Empirical results on object manipulation tasks with a real robotic arm show that the proposed network can efficiently learn from real visual demonstrations to perform the tasks on novel objects within the same category, and outperforms alternative approaches.",
        "primary_area": "",
        "author": "Junchi Liang;Abdeslam Boularias;Junchi Liang;Abdeslam Boularias",
        "authorids": "/37088689223;/37542596800;/37088689223;/37542596800",
        "aff": "Department of Computer Science of Rutgers University, Piscataway, New Jersey, USA; Department of Computer Science of Rutgers University, Piscataway, New Jersey, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160820/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11804452779286797810&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160455",
        "title": "Learning Continuous Control Policies for Information-Theoretic Active Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a method for learning continuous control policies for exploration and active landmark localization. We consider a mobile robot detecting landmarks within a limited sensing range, and tackle the problem of learning a control policy that maximizes the mutual information between the landmark states and the sensor observations. We employ a Kalman filter to convert the partially observable problem in the landmark states to a Markov decision process (MDP), a differentiable field of view to shape the reward function, and an attention-based neural network to represent the control policy. The approach is combined with active volumetric mapping to promote environment exploration in addition to landmark localization. The performance is demonstrated in several simulated landmark localization tasks in comparison with benchmark methods.",
        "primary_area": "",
        "author": "Pengzhi Yang;Yuhan Liu;Shumon Koga;Arash Asgharivaskasi;Nikolay Atanasov;Pengzhi Yang;Yuhan Liu;Shumon Koga;Arash Asgharivaskasi;Nikolay Atanasov",
        "authorids": "/37089893210;/37089893188;/37085850367;/37088997086;/37670511000;/37089893210;/37089893188;/37085850367;/37088997086;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, UC San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, UC San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, UC San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, UC San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, UC San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160455/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10576371181914624849&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160961",
        "title": "Learning Decoupled Multi-touch Force Estimation, Localization and Stretch for Soft Capacitive E-skin",
        "track": "main",
        "status": "Poster",
        "abstract": "Distributed sensor arrays capable of detecting multiple spatially distributed stimuli are considered an important element in the realisation of exteroceptive and proprioceptive soft robots. This paper expands upon the previously presented idea of decoupling the measurements of pressure and location of a local indentation from global deformation, using the overall stretch experienced by a soft capacitive e-skin. We employed machine learning methods to decouple and predict these highly coupled deformation stimuli, collecting data from a soft sensor e-skin which was then fed to a machine learning system comprising of linear regressor, gaussian process regressor, SVM and random forest classifier for stretch, force, detection and localisation respectively. We also studied how the localisation and forces are affected when two forces are applied simultaneously. Soft sensor arrays aided by appropriately chosen machine learning techniques can pave the way to e-skins capable of deciphering multi-modal stimuli in soft robots.",
        "primary_area": "",
        "author": "Abu Bakar Dawood;Claudio Coppola;Kaspar Althoefer;Abu Bakar Dawood;Claudio Coppola;Kaspar Althoefer",
        "authorids": "/37088686052;/37086087991;/37265264700;/37088686052;/37086087991;/37265264700",
        "aff": "School of Engineering and Materials Science, Queen Mary University of London, London, UK; School of Electronics Engineering and Computer Science, Queen Mary University of London, London, UK; School of Engineering and Materials Science, Queen Mary University of London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160961/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11038740854960062566&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "School of Engineering and Materials Science",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160465",
        "title": "Learning Deposition Policies for Fused Multi-Material 3D Printing",
        "track": "main",
        "status": "Poster",
        "abstract": "3D printing based on continuous deposition of materials, such as filament-based 3D printing, has seen widespread adoption thanks to its versatility in working with a wide range of materials. An important shortcoming of this type of technology is its limited multi-material capabilities. While there are simple hardware designs that enable multi-material printing in principle, the required software is heavily underdeveloped. A typical hardware design fuses together individual materials fed into a single chamber from multiple inlets before they are deposited. This design, however, introduces a time delay between the intended material mixture and its actual deposition. In this work, inspired by diverse path planning research in robotics, we show that this mechanical challenge can be addressed via improved printer control. We propose to formulate the search for optimal multi-material printing policies in a reinforcement learning setup. We put forward a simple numerical deposition model that takes into account the non-linear material mixing and delayed material deposition. To validate our system we focus on color fabrication, a problem known for its strict requirements for varying material mixtures at a high spatial frequency. We demonstrate that our learned control policy outperforms state-of-the-art hand-crafted algorithms.",
        "primary_area": "",
        "author": "Kang Liao;Thibault Tricard;Michal Piovar\u010di;Hans-Peter Seidel;Vahid Babaei;Kang Liao;Thibault Tricard;Michal Piovar\u010di;Hans-Peter Seidel;Vahid Babaei",
        "authorids": "/37087404115;/37089892916;/37089891859;/37271851300;/37085790191;/37087404115;/37089892916;/37089891859;/37271851300;/37085790191",
        "aff": "Beijing Jiaotong University; Max Planck Institute for Informatics; Institute of Science and Technology, Austria; Max Planck Institute for Informatics; Max Planck Institute for Informatics",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160465/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3915587136495650446&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;1",
        "aff_unique_norm": "Beijing Jiaotong University;Max Planck Institute for Informatics;Institute of Science and Technology Austria",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.njtu.edu.cn/en;https://mpi-inf.mpg.de;https://www.ist.ac.at",
        "aff_unique_abbr": "BJTU;MPII;IST Austria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;1;1",
        "aff_country_unique": "China;Germany;Austria"
    },
    {
        "id": "10160619",
        "title": "Learning Depth Completion of Transparent Objects using Augmented Unpaired Data",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a technique for depth completion of transparent objects using augmented data captured directly from real environments with complicated geometry. Using cyclic adversarial learning we train translators to convert between painted versions of the objects and their real transparent counterpart. The translators are trained on unpaired data, hence datasets can be created rapidly and without any manual labeling. Our technique does not make any assumptions about the geometry of the environment, unlike SOTA systems that assume easily observable occlusion and contact edges, such as ClearGrasp. We show how our technique outperforms ClearGrasp in a dishwasher environment, in which occlusion and contact edges are difficult to observe. We also show how the technique can be used to create an object manipulation application with a humanoid robot. Supplementary URI: https://ftorise.github.io/faking_depth_web/.",
        "primary_area": "",
        "author": "Floris Erich;Bruno Leme;Noriaki Ando;Ryo Hanai;Yukiyasu Domae;Floris Erich;Bruno Leme;Noriaki Ando;Ryo Hanai;Yukiyasu Domae",
        "authorids": "/37086823894;/37086262431;/37265745200;/37601275900;/37840048000;/37086823894;/37086262431;/37265745200;/37601275900;/37840048000",
        "aff": "Industrial CPS Research Center, National Institute of Advanced Industrial Science and Technology, Japan; Horticultural Sciences Department, University of Florida, USA; Industrial CPS Research Center, National Institute of Advanced Industrial Science and Technology, Japan; Industrial CPS Research Center, National Institute of Advanced Industrial Science and Technology, Japan; Industrial CPS Research Center, National Institute of Advanced Industrial Science and Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160619/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11287788843986571409&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;University of Florida",
        "aff_unique_dep": "Industrial CPS Research Center;Horticultural Sciences Department",
        "aff_unique_url": "https://www.aist.go.jp;https://www.ufl.edu",
        "aff_unique_abbr": "AIST;UF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "10161147",
        "title": "Learning Dexterous Manipulation from Exemplar Object Trajectories and Pre-Grasps",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning diverse dexterous manipulation behaviors with assorted objects remains an open grand challenge. While policy learning methods offer a powerful avenue to attack this problem, these approaches require extensive per-task engineering and algorithmic tuning. This paper seeks to escape these constraints, by developing a Pre-Grasp informed Dexterous Manipulation (PGDM) framework that generates diverse dexter-ous manipulation behaviors, without any task-specific reasoning or hyper-parameter tuning. At the core of PGDM is a well known robotics construct, pre-grasps (i.e. the hand-pose preparing for object interaction). This simple primitive is enough to induce efficient exploration strategies for acquiring complex dexterous manipulation behaviors. To exhaustively verify these claims, we introduce TCDM, a benchmark of 50 diverse manipulation tasks defined over multiple objects and dexterous manipulators. Tasks for TCDM are defined automatically using exemplar object trajectories from diverse sources (animators, human behaviors, etc.), without any per-task engineering and/or supervision. Our experiments validate that PGDM's exploration strategy, induced by a surprisingly simple ingredient (single pre-grasp pose), matches the performance of prior methods, which require expensive per-task feature/reward engineering, expert supervision, and hyper-parameter tuning. For animated visualizations, trained policies, and project code, please refer to https://pregrasps.github.io/.",
        "primary_area": "",
        "author": "Sudeep Dasari;Abhinav Gupta;Vikash Kumar;Sudeep Dasari;Abhinav Gupta;Vikash Kumar",
        "authorids": "/37089893020;/37291130800;/37077886400;/37089893020;/37291130800;/37077886400",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Meta AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161147/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2693982589728093928&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Carnegie Mellon University;Meta Platforms, Inc.",
        "aff_unique_dep": "Robotics Institute;Meta AI Research",
        "aff_unique_url": "https://www.cmu.edu;https://meta.com",
        "aff_unique_abbr": "CMU;Meta AI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160759",
        "title": "Learning Exploration Strategies to Solve Real-World Marble Runs",
        "track": "main",
        "status": "Poster",
        "abstract": "Tasks involving locally unstable or discontinuous dynamics (such as bifurcations and collisions) remain challenging in robotics, because small variations in the environment can have a significant impact on task outcomes. For such tasks, learning a robust deterministic policy is difficult. We focus on structuring exploration with multiple stochastic policies based on a mixture of experts (MoE) policy representation that can be efficiently adapted. The MoE policy is composed of stochastic sub-policies that allow exploration of multiple distinct regions of the action space (or strategies) and a high-level selection policy to guide exploration towards the most promising regions. We develop a robot system to evaluate our approach in a real-world physical problem solving domain. After training the MoE policy in simulation, online learning in the real world demonstrates efficient adaptation within just a few dozen attempts, with a minimal sim2real gap. Our results confirm that representing multiple strategies promotes efficient adaptation in new environments and strategies learned under different dynamics can still provide useful information about where to look for good strategies.",
        "primary_area": "",
        "author": "Alisa Allaire;Christopher G. Atkeson;Alisa Allaire;Christopher G. Atkeson",
        "authorids": "/37089450215;/37277593800;/37089450215;/37277593800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160759/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:m0u_c8QYVZkJ:scholar.google.com/&scioq=Learning+Exploration+Strategies+to+Solve+Real-World+Marble+Runs&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160887",
        "title": "Learning Feasibility of Factored Nonlinear Programs in Robotic Manipulation Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "A factored Nonlinear Program (Factored-NLP) explicitly models the dependencies between a set of continuous variables and nonlinear constraints, providing an expressive formulation for relevant robotics problems such as manipulation planning or simultaneous localization and mapping. When the problem is over-constrained or infeasible, a fundamental issue is to detect a minimal subset of variables and constraints that are infeasible. Previous approaches require solving several nonlinear programs, incrementally adding and removing constraints, and are thus computationally expensive. In this paper, we propose a graph neural architecture that predicts which variables and constraints are jointly infeasible. The model is trained with a dataset of labeled subgraphs of Factored-NLPs, and importantly, can make useful predictions on larger factored nonlinear programs than the ones seen during training. We evaluate our approach in robotic manipulation planning, where our model is able to generalize to longer manipulation sequences involving more objects and robots, and different geometric environments. The experiments show that the learned model accelerates general algorithms for conflict extraction (by a factor of 50) and heuristic algorithms that exploit expert knowledge (by a factor of 4).",
        "primary_area": "",
        "author": "Joaquim Ortiz-Haro;Jung-Su Ha;Danny Driess;Erez Karpas;Marc Toussaint;Joaquim Ortiz-Haro;Jung-Su Ha;Danny Driess;Erez Karpas;Marc Toussaint",
        "authorids": "/37088998356;/38543013300;/37085994159;/37086941114;/37528418600;/37088998356;/38543013300;/37085994159;/37086941114;/37528418600",
        "aff": "TU Berlin, Germany; TU Berlin, Germany; TU Berlin, Germany; Technion, Israel; TU Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160887/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13307764259113325332&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Technical University of Berlin;Technion - Israel Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tu-berlin.de;https://www.technion.ac.il/en/",
        "aff_unique_abbr": "TU Berlin;Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;Israel"
    },
    {
        "id": "10160405",
        "title": "Learning Food Picking without Food: Fracture Anticipation by Breaking Reusable Fragile Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Food picking is trivial for humans but not for robots, as foods are fragile. Presetting foods' physical properties does not help robots much due to the objects' inter- and intra-category diversity. A recent study proved that learning-based fracture anticipation with tactile sensors could overcome this problem; however, the method trains the model for each food to deal with intra-category differences, and tuning robots for each food leads to an undesirable amount of food consumption. This study proposes a novel framework for learning food-picking tasks without consuming foods. The key idea is to leverage the object-breaking experiences of several reusable fragile objects instead of consuming real foods while making the picking ability object-invariant with domain generalization (DG). In real-robot experiments, we trained a model with reusable objects (toy blocks, ping-pong balls, and jellies), selected based on the three common fracture types (crack, rupture, and crush). We then tested the model with four real food objects (tofu, bananas, potato chips, and tomatoes). The results showed that the proposed combination of reusable objects' breaking experiences and DG is effective for the food-picking task.",
        "primary_area": "",
        "author": "Rinto Yagawa;Reina Ishikawa;Masashi Hamaya;Kazutoshi Tanaka;Atsushi Hashimoto;Hideo Saito;Rinto Yagawa;Reina Ishikawa;Masashi Hamaya;Kazutoshi Tanaka;Atsushi Hashimoto;Hideo Saito",
        "authorids": "/37089893242;/37088852535;/37085532024;/37088507484;/38235720900;/37273875600;/37089893242;/37088852535;/37085532024;/37088507484;/38235720900;/37273875600",
        "aff": "Keio University, Yokohama, Japan; Keio University, Yokohama, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; Keio University, Yokohama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160405/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2893940503848891192&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Keio University;OMRON SINIC X Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.keio.ac.jp;",
        "aff_unique_abbr": "Keio;",
        "aff_campus_unique_index": "0;0;1;1;1;0",
        "aff_campus_unique": "Yokohama;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161271",
        "title": "Learning Generalizable Pivoting Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "The skill of pivoting an object with a robotic system is challenging for the external forces that act on the system, mainly given by contact interaction. The complexity increases when the same skills are required to generalize across different objects. This paper proposes a framework for learning robust and generalizable pivoting skills, which consists of three steps. First, we learn a pivoting policy on an \u201cunitary\u201d object using Reinforcement Learning (RL). Then, we obtain the object's feature space by supervised learning to encode the kinematic properties of arbitrary objects. Finally, to adapt the unitary policy to multiple objects, we learn data-driven projections based on the object features to adjust the state and action space of the new pivoting task. The proposed approach is entirely trained in simulation. It requires only one depth image of the object and can zero-shot transfer to real-world objects. We demonstrate robustness to sim-to-real transfer and generalization to multiple objects.",
        "primary_area": "",
        "author": "Xiang Zhang;Siddarth Jain;Baichuan Huang;Masayoshi Tomizuka;Diego Romeres;Xiang Zhang;Siddarth Jain;Baichuan Huang;Masayoshi Tomizuka;Diego Romeres",
        "authorids": "/37089612990;/37088688017;/37088981654;/37281933000;/37086098761;/37089612990;/37088688017;/37088981654;/37281933000;/37086098761",
        "aff": "Mechanical Systems Control Lab, UC Berkeley, Berkeley, CA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Department of Computer Science, Rutgers University, Piscataway, NJ, USA; Mechanical Systems Control Lab, UC Berkeley, Berkeley, CA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161271/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16606699566821861928&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;1",
        "aff_unique_norm": "University of California, Berkeley;Mitsubishi Electric Research Laboratories;Rutgers University",
        "aff_unique_dep": "Mechanical Systems Control Lab;;Department of Computer Science",
        "aff_unique_url": "https://www.berkeley.edu;https://www.merl.com;https://www.rutgers.edu",
        "aff_unique_abbr": "UC Berkeley;MERL;Rutgers",
        "aff_campus_unique_index": "0;1;2;0;1",
        "aff_campus_unique": "Berkeley;Cambridge;Piscataway",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160955",
        "title": "Learning Height for Top-Down Grasps with the DIGIT Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of grasping unknown objects identified from top-down images with a parallel gripper. When no object 3D model is available, the state-of-the-art grasp generators identify the best candidate locations for planar grasps using the RGBD image. However, while they generate the Cartesian location and orientation of the gripper, the height of the grasp center is often determined by heuristics based on the highest point in the depth map, which leads to unsuccessful grasps when the objects are not thick, or have transparencies or curved shapes. In this paper, we propose to learn a regressor that predicts the best grasp height based from the image. We train this regressor with a dataset that is automatically acquired thanks to the DIGIT optical tactile sensors, which can evaluate grasp success and stability. Using our predictor, the grasping success is improved by 6% for all objects, by 16% on average on difficult objects, and by 40% for objects that are notably very difficult to grasp (e.g., transparent, curved, thin).",
        "primary_area": "",
        "author": "Thais Bernardi;Yoann Fleytoux;Jean-Baptiste Mouret;Serena Ivaldi;Thais Bernardi;Yoann Fleytoux;Jean-Baptiste Mouret;Serena Ivaldi",
        "authorids": "/37089892660;/37089450100;/37586421200;/38534379600;/37089892660;/37089450100;/37586421200;/38534379600",
        "aff": "Federal University of Technology - Paran\u00e1 (UTFPR), Brazil; CNRS, Inria, University of Lorraine, Loria, France; CNRS, Inria, University of Lorraine, Loria, France; CNRS, Inria, University of Lorraine, Loria, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160955/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=651119646906769485&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Federal University of Technology - Paran\u00e1;CNRS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utfpr.edu.br;https://www.cnrs.fr",
        "aff_unique_abbr": "UTFPR;CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Brazil;France"
    },
    {
        "id": "10160357",
        "title": "Learning Low-Frequency Motion Control for Robust and Dynamic Robot Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic locomotion is often approached with the goal of maximizing robustness and reactivity by increasing motion control frequency. We challenge this intuitive notion by demonstrating robust and dynamic locomotion with a learned motion controller executing at as low as 8 Hz on a real ANYmal C quadruped. The robot is able to robustly and repeatably achieve a high heading velocity of 1.5 ms-1, traverse uneven terrain, and resist unexpected external perturbations. We further present a comparative analysis of deep reinforcement learning (RL) based motion control policies trained and executed at frequencies ranging from 5 Hz to 200 Hz. We show that low-frequency policies are less sensitive to actuation latencies and variations in system dynamics. This is to the extent that a successful sim- to-real transfer can be performed even without any dynamics randomization or actuation modeling. We support this claim through a set of rigorous empirical evaluations. Moreover, to assist reproducibility, we provide the training and deployment code along with an extended analysis at https://ori-drs.github.io/lfmc/.",
        "primary_area": "",
        "author": "Siddhant Gangapurwala;Luigi Campanaro;Ioannis Havoutis;Siddhant Gangapurwala;Luigi Campanaro;Ioannis Havoutis",
        "authorids": "/37088356748;/37089893500;/37542879900;/37088356748;/37089893500;/37542879900",
        "aff": "Dynamic Robots Systems (DRS) group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) group, Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160357/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11417616921910348587&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160845",
        "title": "Learning Modular Robot Visual-motor Locomotion Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Control policy learning for modular robot locomotion has previously been limited to proprioceptive feedback and flat terrain. This paper develops policies for modular systems with vision traversing more challenging environments. These modular robots can be reconfigured to form many different designs, where each design needs a controller to function. Though one could create a policy for individual designs and environments, such an approach is not scalable given the wide range of potential designs and environments. To address this challenge, we create a visual-motor policy that can generalize to both new designs and environments. The policy itself is modular, in that it is divided into components, each of which corresponds to a type of module (e.g., a leg, wheel, or body). The policy components can be recombined during training to learn to control multiple designs. We develop a deep reinforcement learning algorithm where visual observations are input to a modular policy interacting with multiple environments at once. We apply this algorithm to train robots with combinations of legs and wheels, then demonstrate the policy controlling real robots climbing stairs and curbs.",
        "primary_area": "",
        "author": "Julian Whitman;Howie Choset;Julian Whitman;Howie Choset",
        "authorids": "/37086038296;/37281322200;/37086038296;/37281322200",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160845/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:KcJ56kx-38YJ:scholar.google.com/&scioq=Learning+Modular+Robot+Visual-motor+Locomotion+Policies&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160545",
        "title": "Learning Neuro-symbolic Programs for Language Guided Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Given a natural language instruction and an input scene, our goal is to train a model to output a manipulation program that can be executed by the robot. Prior approaches for this task possess one of the following limitations: (i) rely on hand-coded symbols for concepts limiting generalization beyond those seen during training [1] (ii) infer action sequences from instructions but require dense sub-goal supervision [2] or (iii) lack semantics required for deeper object-centric reasoning inherent in interpreting complex instructions [3]. In contrast, our approach can handle linguistic as well as perceptual variations, end-to-end trainable and requires no intermediate supervision. The proposed model uses symbolic reasoning constructs that operate on a latent neural object-centric representation, allowing for deeper reasoning over the input scene. Central to our approach is a modular structure consisting of a hierarchical instruction parser and an action simulator to learn disentangled action representations. Our experiments on a simulated environment with a 7-DOF manipulator, consisting of instructions with varying number of steps and scenes with different number of objects, demonstrate that our model is robust to such variations and significantly outperforms baselines, particularly in the generalization settings. The code, dataset and experiment videos are available at https://nsrmp.github.io",
        "primary_area": "",
        "author": "Namasivayam K;Himanshu Singh;Vishal Bindal;Arnav Tuli;Vishwajeet Agrawal;Rahul Jain;Parag Singla;Rohan Paul;Namasivayam K;Himanshu Singh;Vishal Bindal;Arnav Tuli;Vishwajeet Agrawal;Rahul Jain;Parag Singla;Rohan Paul",
        "authorids": "/37089892728;/392419433484591;/37089893913;/37089895504;/37089891876;/37089894453;/37838098100;/37089892880;/37089892728;/392419433484591;/37089893913;/37089895504;/37089891876;/37089894453;/37838098100;/37089892880",
        "aff": "IIT Delhi.; IIT Delhi.; IIT Delhi.; IIT Delhi.; IIT Delhi.; IIT Delhi.; IIT Delhi.; IIT Delhi.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160545/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2562782705540011037&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Indian Institute of Technology Delhi",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iitd.ac.in",
        "aff_unique_abbr": "IITD",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Delhi",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "10160563",
        "title": "Learning Perception-Aware Agile Flight in Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, neural control policies have outperformed existing model-based planning-and-control methods for autonomously navigating quadrotors through cluttered environments in minimum time. However, they are not perception aware, a crucial requirement in vision-based navigation due to the camera's limited field of view and the underactuated nature of a quadrotor. We propose a learning-based system that achieves perception-aware, agile flight in cluttered environments. Our method combines imitation learning with reinforcement learning (RL) by leveraging a privileged learning-by-cheating framework. Using RL, we first train a perception-aware teacher policy with full-state information to fly in minimum time through cluttered environments. Then, we use imitation learning to distill its knowledge into a vision-based student policy that only perceives the environment via a camera. Our approach tightly couples perception and control, showing a significant advantage in computation speed (10\u00d7faster) and success rate. We demonstrate the closed-loop control performance using hardware-in-the-loop simulation. Video: https://youtu.be/9q059CFGcVA",
        "primary_area": "",
        "author": "Yunlong Song;Kexin Shi;Robert Penicka;Davide Scaramuzza;Yunlong Song;Kexin Shi;Robert Penicka;Davide Scaramuzza",
        "authorids": "/37088688858;/37089892627;/37085674700;/37397688400;/37088688858;/37089892627;/37085674700;/37397688400",
        "aff": "Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Dep. of Informatics, Robotics and Perception Group, University of Zurich, Switzerland; Multi-robot Systems Group, Czech Technical University in Prague, Czech Republic; Dep. of Informatics, Robotics and Perception Group, University of Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160563/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2200153669496161243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Zurich;Czech Technical University in Prague",
        "aff_unique_dep": "Department of Neuroinformatics;Multi-robot Systems Group",
        "aff_unique_url": "https://www.unizh.ch;https://www.cvut.cz",
        "aff_unique_abbr": "UZH;CTU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Prague",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Switzerland;Czech Republic"
    },
    {
        "id": "10161327",
        "title": "Learning Perceptual Hallucination for Multi-Robot Navigation in Narrow Hallways",
        "track": "main",
        "status": "Poster",
        "abstract": "While current systems for autonomous robot navigation can produce safe and efficient motion plans in static environments, they usually generate suboptimal behaviors when multiple robots must navigate together in confined spaces. For example, when two robots meet each other in a narrow hallway, they may either turn around to find an alternative route or collide with each other. This paper presents a new approach to navigation that allows two robots to pass each other in a narrow hallway without colliding, stopping, or waiting. Our approach, Perceptual Hallucination for Hallway Passing (PHHP), learns to synthetically generate virtual obstacles (i.e., perceptual hallucination) to facilitate passing in narrow hallways by multiple robots that utilize otherwise standard autonomous navigation systems. Our experiments on physical robots in a variety of hallways show improved performance compared to multiple baselines.",
        "primary_area": "",
        "author": "Jin-Soo Park;Xuesu Xiao;Garrett Warnell;Harel Yedidsion;Peter Stone;Jin-Soo Park;Xuesu Xiao;Garrett Warnell;Harel Yedidsion;Peter Stone",
        "authorids": "/37089892769;/37086258082;/37079072000;/37086064503;/37269574900;/37089892769;/37086258082;/37079072000;/37086064503;/37269574900",
        "aff": "Department of Electrical and Computer Engineering, The University of Texas at Austin, United States; Everyday Robots, United States; Army Research Laboratory, United States; Department of Computer Science, The University of Texas at Austin, United States; Sony AI, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161327/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10774663153352809861&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;3",
        "aff_unique_norm": "The University of Texas at Austin;Everyday Robots;Army Research Laboratory;Sony AI",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;;;",
        "aff_unique_url": "https://www.utexas.edu;;https://www.arl.army.mil;https://ai.sony",
        "aff_unique_abbr": "UT Austin;;ARL;Sony AI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "10160411",
        "title": "Learning Personalised Human Sit-to-Stand Motion Strategies via Inverse Musculoskeletal Optimal Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Physically assistive robots and exoskeletons have great potential to help humans with a wide variety of collaborative tasks. However, a challenging aspect of the control of such devices is to accurately model or predict human behaviour, which can be highly individual and personalised. In this work, we implement a framework for learning subject-specific models of underlying human motion strategies using inverse musculoskeletal optimal control. We apply this framework to a specific motion task: the sit-to-stand transition. By collecting sit-to-stand data from 4 subjects with and without perturbations, we show that humans modulate their sit-to-stand strategy in the presence of instability, and learn the corresponding models of these strategies. In the future, the personalised motion strategies resulting from this framework could be used to inform the design of real-time assistance strategies for human-robot collaboration problems.",
        "primary_area": "",
        "author": "Daniel F. N. Gordon;Andreas Christou;Theodoros Stouraitis;Michael Gienger;Sethu Vijayakumar;Daniel F. N. Gordon;Andreas Christou;Theodoros Stouraitis;Michael Gienger;Sethu Vijayakumar",
        "authorids": "/37086356722;/37089417244;/37086314988;/37277233400;/37295595500;/37086356722;/37089417244;/37086314988;/37277233400;/37295595500",
        "aff": "Alan Turing Institute, London, UK; School of Informatics, The University of Edinburgh, Edinburgh, UK; Honda Research Institute Europe GmbH, Offenbach am Main, Germany; Honda Research Institute Europe GmbH, Offenbach am Main, Germany; Alan Turing Institute, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160411/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4072433959245631297&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;0",
        "aff_unique_norm": "Alan Turing Institute;The University of Edinburgh;Honda Research Institute Europe GmbH",
        "aff_unique_dep": ";School of Informatics;",
        "aff_unique_url": "https://www.turing.ac.uk;https://www.ed.ac.uk;https://honda-ri.de",
        "aff_unique_abbr": "ATI;Edinburgh;HRI-Europe",
        "aff_campus_unique_index": "0;1;2;2;0",
        "aff_campus_unique": "London;Edinburgh;Offenbach am Main",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "10160869",
        "title": "Learning Pre-Grasp Manipulation of Flat Objects in Cluttered Environments using Sliding Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Flat objects with negligible thicknesses like books and disks are challenging to be grasped by the robot because of the width limit of the robot's gripper, especially when they are in cluttered environments. Pre-grasp manipulation is conducive to rearranging objects on the table and moving the flat objects to the table edge, making them graspable. In this paper, we formulate this task as Parameterized Action Markov Decision Process, and a novel method based on deep reinforcement learning is proposed to address this problem by introducing sliding primitives as actions. A weight-sharing policy network is utilized to predict the sliding primitive's parameters for each object, and a Q-network is adopted to select the acted object among all the candidates on the table. Meanwhile, via integrating a curriculum learning scheme, our method can be scaled to cluttered environments with more objects. In both simulation and real-world experiments, our method surpasses the existing methods and achieves pre-grasp manipulation with higher task success rates and fewer action steps. Without fine-tuning, it can be generalized to novel shapes and household objects with more than 85% success rates in the real world. Videos and supplementary materials are available at https://sites.google.com/view/pre-grasp-sliding.",
        "primary_area": "",
        "author": "Jiaxi Wu;Haoran Wu;Shanlin Zhong;Quqin Sun;Yinlin Li;Jiaxi Wu;Haoran Wu;Shanlin Zhong;Quqin Sun;Yinlin Li",
        "authorids": "/37088964822;/37086337320;/37086387702;/37089894252;/37085616329;/37088964822;/37086337320;/37086387702;/37089894252;/37085616329",
        "aff": "State Key Laboratory of Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; Department of Automation, University of Science and Technology of China, Heifei, China; State Key Laboratory of Management and Control for Complex System, Institute of Automation, Chinese Academy of Science, Beijing, China; Science and Technology on Thermal Energy and Power Laboratory, Wuhan, China; State Key Laboratory of Management and Control for Complex System, Institute of Automation, Chinese Academy of Science, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160869/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13031931389996202435&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;2",
        "aff_unique_norm": "Peking University;University of Science and Technology of China;Chinese Academy of Sciences;Science and Technology on Thermal Energy and Power Laboratory",
        "aff_unique_dep": "College of Engineering;Department of Automation;Institute of Automation;",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.ustc.edu.cn;http://www.ia.cas.cn;",
        "aff_unique_abbr": "PKU;USTC;CAS;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Beijing;Heifei;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161112",
        "title": "Learning Responsibility Allocations for Safe Human-Robot Interaction with Applications to Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Drivers have a responsibility to exercise reasonable care to avoid collision with other road users. This assumed responsibility allows interacting agents to maintain safety without explicit coordination. Thus to enable safe autonomous vehicle (AV) interactions, AVs must understand what their responsibilities are to maintain safety and how they affect the safety of nearby agents. In this work we seek to understand how responsibility is shared in multi-agent settings where an autonomous agent is interacting with human counterparts. We introduce Responsibility-Aware Control Barrier Functions (RA-CBFs) and present a method to learn responsibility allocations from data. By combining safety-critical control and learning- based techniques, RA-CBFs allow us to account for scene- dependent responsibility allocations and synthesize safe and efficient driving behaviors without making worst-case assumptions that typically result in overly-conservative behaviors. We test our framework using real-world driving data and demonstrate its efficacy as a tool for both safe control and forensic analysis of unsafe driving.",
        "primary_area": "",
        "author": "Ryan K. Cosner;Yuxiao Chen;Karen Leung;Marco Pavone;Ryan K. Cosner;Yuxiao Chen;Karen Leung;Marco Pavone",
        "authorids": "/37088901068;/37088427220;/37086453267;/37307912900;/37088901068;/37088427220;/37086453267;/37307912900",
        "aff": "California Institute of Technology; NVIDIA; University of Washington and NVIDIA; Stanford University and NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161112/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7349536997018039291&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "California Institute of Technology;NVIDIA Corporation;University of Washington;Stanford University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.caltech.edu;https://www.nvidia.com;https://www.washington.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Caltech;NVIDIA;UW;Stanford",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Pasadena;;Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161178",
        "title": "Learning Reward Functions for Robotic Manipulation by Observing Humans",
        "track": "main",
        "status": "Poster",
        "abstract": "Observing a human demonstrator manipulate objects provides a rich, scalable and inexpensive source of data for learning robotic policies. However, transferring skills from human videos to a robotic manipulator poses several challenges, not least a difference in action and observation spaces. In this work, we use unlabeled videos of humans solving a wide range of manipulation tasks to learn a task-agnostic reward function for robotic manipulation policies. Thanks to the diversity of this training data, the learned reward function sufficiently generalizes to image observations from a previously unseen robot embodiment and environment to provide a meaningful prior for directed exploration in reinforcement learning. We propose two methods for scoring states relative to a goal image: through direct temporal regression, and through distances in an embedding space obtained with time-contrastive learning. By conditioning the function on a goal image, we are able to reuse one model across a variety of tasks. Unlike prior work on leveraging human videos to teach robots, our method, Human Offline Learned Distances (HOLD) requires neither a priori data from the robot environment, nor a set of task-specific human demonstrations, nor a predefined notion of correspondence across morphologies, yet it is able to accelerate training of several manipulation tasks on a simulated robot arm compared to using only a sparse reward obtained from task completion.",
        "primary_area": "",
        "author": "Minttu Alakuijala;Gabriel Dulac-Arnold;Julien Mairal;Jean Ponce;Cordelia Schmid;Minttu Alakuijala;Gabriel Dulac-Arnold;Julien Mairal;Jean Ponce;Cordelia Schmid",
        "authorids": "/37089893200;/37088836294;/37298504700;/37282647000;/37282990700;/37089893200;/37088836294;/37298504700;/37282647000;/37282990700",
        "aff": "CNRS, Grenoble INP, LJK, Univ. Grenoble Alpes, Inria, Grenoble, France; Google Research; CNRS, Grenoble INP, LJK, Univ. Grenoble Alpes, Inria, Grenoble, France; Center for Data Science, Courant Institute of Mathematical Sciences, New York University; Google Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161178/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17930435044400883729&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;1",
        "aff_unique_norm": "CNRS;Google;New York University",
        "aff_unique_dep": ";Google Research;Center for Data Science, Courant Institute of Mathematical Sciences",
        "aff_unique_url": "https://www.cnrs.fr;https://research.google;https://www.nyu.edu",
        "aff_unique_abbr": "CNRS;Google Research;NYU",
        "aff_campus_unique_index": "0;1;0;2;1",
        "aff_campus_unique": "Grenoble;Mountain View;New York",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "10161268",
        "title": "Learning Risk-Aware Costmaps via Inverse Reinforcement Learning for Off-Road Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "The process of designing costmaps for off-road driving tasks is often a challenging and engineering-intensive task. Recent work in costmap design for off-road driving focuses on training deep neural networks to predict costmaps from sensory observations using corpora of expert driving data. However, such approaches are generally subject to over-confident mis-predictions and are rarely evaluated in-the-loop on physical hardware. We present an inverse reinforcement learning-based method of efficiently training deep cost functions that are uncertainty-aware. We do so by leveraging recent advances in highly parallel model-predictive control and robotic risk estimation. In addition to demonstrating improvement at reproducing expert trajectories, we also evaluate the efficacy of these methods in challenging off-road navigation scenarios. We observe that our method significantly outperforms a geometric baseline, resulting in 44% improvement in expert path reconstruction and 57% fewer interventions in practice. We also observe that varying the risk tolerance of the vehicle results in qualitatively different navigation behaviors, especially with respect to higher-risk scenarios such as slopes and tall grass.33More detailed algorithms and additional visualizations are provided in the appendix Appendix (appendix link: tinyurl.com/mtkj63e8)",
        "primary_area": "",
        "author": "Samuel Triest;Mateo Guaman Castro;Parv Maheshwari;Matthew Sivaprakasam;Wenshan Wang;Sebastian Scherer;Samuel Triest;Mateo Guaman Castro;Parv Maheshwari;Matthew Sivaprakasam;Wenshan Wang;Sebastian Scherer",
        "authorids": "/37088642042;/37089895926;/37089750058;/37088996836;/37087322184;/37584159000;/37088642042;/37089895926;/37089750058;/37088996836;/37087322184;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mathematics, Indian Institute of Technology Kharagpur; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161268/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15423094525332143067&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Indian Institute of Technology Kharagpur",
        "aff_unique_dep": "Robotics Institute;Department of Mathematics",
        "aff_unique_url": "https://www.cmu.edu;https://www.iitkgp.ac.in",
        "aff_unique_abbr": "CMU;IIT Kharagpur",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Pittsburgh;Kharagpur",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "10160917",
        "title": "Learning Robotic Cutting from Demonstration: Non-Holonomic DMPs using the Udwadia-Kalaba Method",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic Movement Primitives (DMPs) offer great versatility for encoding, generating and adapting complex end-effector trajectories. DMPs are also very well suited to learning manipulation skills from human demonstration. However, the reactive nature of DMPs restricts their applicability for tool use and object manipulation tasks involving non-holonomic constraints, such as scalpel cutting or catheter steering. In this work, we extend the Cartesian space DMP formulation by adding a coupling term that enforces a pre-defined set of non-holonomic constraints. We obtain the closed-form expression for the constraint forcing term using the Udwadia-Kalaba method. This approach offers a clean and practical solution for guaranteed constraint satisfaction at run-time. Further, the proposed analytical form of the constraint forcing term enables efficient trajectory optimization subject to constraints. We demonstrate the usefulness of this approach by showing how we can learn robotic cutting skills from human demonstration.",
        "primary_area": "",
        "author": "Art\u016bras Strai\u017eys;Michael Burke;Subramanian Ramamoorthy;Art\u016bras Strai\u017eys;Michael Burke;Subramanian Ramamoorthy",
        "authorids": "/37088506804;/38252303400;/37529920500;/37088506804;/38252303400;/37529920500",
        "aff": "School of Informatics, University of Edinburgh; Department of Electrical and Computer Systems Engineering, Monash University; School of Informatics, University of Edinburgh",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160917/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5853532494923660818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Edinburgh;Monash University",
        "aff_unique_dep": "School of Informatics;Department of Electrical and Computer Systems Engineering",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.monash.edu",
        "aff_unique_abbr": "Edinburgh;Monash",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Australia"
    },
    {
        "id": "10161477",
        "title": "Learning Sim-to-Real Dense Object Descriptors for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "It is crucial to address the following issues for ubiquitous robotics manipulation applications: (a) vision-based manipulation tasks require the robot to visually learn and understand the object with rich information like dense object descriptors; and (b) sim-to-real transfer in robotics aims to close the gap between simulated and real data. In this paper, we present Sim-to-Real Dense Object Nets (SRDONs), a dense object descriptors that not only understands the object via appropriate representation but also maps simulated and real data to a unified feature space with pixel consistency. We proposed an object-to-object matching method for image pairs from different scenes and different domains. This method helps reduce the effort of training data from real-world by taking advantage of public datasets, such as GraspNet. With sim-to-real object representation consistency, our SRDONs can serve as a building block for a variety of sim-to-real manipulation tasks. We demonstrate in experiments that pre-trained SRDONs significantly improve performances on unseen objects and unseen visual environments for various robotic tasks with zero real-world training.",
        "primary_area": "",
        "author": "Hoang-Giang Cao;Weihao Zeng;I-Chen Wu;Hoang-Giang Cao;Weihao Zeng;I-Chen Wu",
        "authorids": "/37089449331;/37089449340;/37089448023;/37089449331;/37089449340;/37089448023",
        "aff": "Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan; School of Computer Science, Carnegie Mellon University, United States; Research Center for IT Innovation, Academia Sinica, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161477/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1359621408069861118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "National Yang Ming Chiao Tung University;Carnegie Mellon University;Academia Sinica",
        "aff_unique_dep": "Department of Computer Science;School of Computer Science;Research Center for IT Innovation",
        "aff_unique_url": "https://www.nctu.edu.tw;https://www.cmu.edu;https://www.sinica.edu.tw",
        "aff_unique_abbr": "NYCU;CMU;AS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160928",
        "title": "Learning Stabilization Control from Observations by Learning Lyapunov-like Proxy Models",
        "track": "main",
        "status": "Poster",
        "abstract": "The deployment of Reinforcement Learning to robotics applications faces the difficulty of reward engineering. Therefore, approaches have focused on creating reward functions by Learning from Observations (LfO) which is the task of learning policies from expert trajectories that only contain state sequences. We propose new methods for LfO for the important class of continuous control problems of learning to stabilize, by introducing intermediate proxy models acting as reward functions between the expert and the agent policy based on Lyapunov stability theory. Our LfO training process consists of two steps. The first step attempts to learn a Lyapunov-like landscape proxy model from expert state sequences without access to any kinematics model, and the second step uses the learned landscape model to guide in training the learner's policy. We formulate novel learning objectives for the two steps that are important for overall training success. We evaluate our methods in real automobile robot environments and other simulated stabilization control problems in model-free settings, like Quadrotor control and maintaining upright positions of Hopper in MuJoCo. We compare with state-of-the-art approaches and show the proposed methods can learn efficiently with less expert observations.",
        "primary_area": "",
        "author": "Milan Ganai;Chiaki Hirayama;Ya-Chien Chang;Sicun Gao;Milan Ganai;Chiaki Hirayama;Ya-Chien Chang;Sicun Gao",
        "authorids": "/37089892764;/37086334453;/37089000572;/37088349203;/37089892764;/37086334453;/37089000572;/37088349203",
        "aff": "Department of Computer Science and Engineering, UC San Diego, USA; Department of Computer Science and Engineering, UC San Diego, USA; Department of Computer Science and Engineering, UC San Diego, USA; Department of Computer Science and Engineering, UC San Diego, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160928/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3208955406059212073&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161237",
        "title": "Learning Stable Dynamics via Iterative Quadratic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel autonomous dynamic system (ADS) based controller for trajectory learning from demonstration (LfD). We call our method Learning Stable Dynamics via Iterative Quadratic Programming (LSD-IQP). LSD-IQP learns an energy function and an ADS from demonstrations via semi-infinite quadratic programming. Energy function constraints are imposed on the learned ADS to ensure convergence to a single goal position. Unlike other energy-based methods, LSD-IQP allows the energy function to have both local maximums and saddle points. This flexibility enables LSD-IQP to learn a broader class of motions compared to other ADS-based controllers. We demonstrate the capabilities of LSD-IQP via several experiments, including: 1) learning handwritten symbols and comparing the swept error area to several other ADS methods 2) learning a pick-and-place task with novel goal positions for a robot, and 3) learning a point to point motion in the presence of a non-convex obstacle for a robot.",
        "primary_area": "",
        "author": "Paul Gesel;Momotaz Begum;Paul Gesel;Momotaz Begum",
        "authorids": "/37086936045;/37293898900;/37086936045;/37293898900",
        "aff": "Department of Computer Science, University of New Hampshire, USA; Department of Computer Science, University of New Hampshire, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161237/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2682636445328280501&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of New Hampshire",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unh.edu",
        "aff_unique_abbr": "UNH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160585",
        "title": "Learning State Conditioned Linear Mappings for Low-Dimensional Control of Robotic Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Identifying an appropriate task space can simplify solving robotic manipulation problems. One solution is deploying control algorithms in a learned low-dimensional action space. Linear and nonlinear action mapping methods have trade-offs between simplicity and the ability to express motor commands outside of a single low-dimensional subspace. We propose that learning local linear action representations can achieve both of these benefits. Our state-conditioned linear maps ensure that for any given state, the high-dimensional robotic actuation is linear in the low-dimensional actions. As the robot state evolves, so do the action mappings, so that necessary motions can be performed during a task. These local linear representations guarantee desirable theoretical properties by design. We validate these findings empirically through two user studies. Results suggest state-conditioned linear maps outperform conditional autoencoder and PCA baselines on a pick-and-place task and perform comparably to mode switching in a more complex pouring task.",
        "primary_area": "",
        "author": "Michael Przystupa;Kerrick Johnstonbaugh;Zichen Zhang;Laura Petrich;Masood Dehghan;Faezeh Haghverd;Martin Jagersand;Michael Przystupa;Kerrick Johnstonbaugh;Zichen Zhang;Laura Petrich;Masood Dehghan;Faezeh Haghverd;Martin Jagersand",
        "authorids": "/37088998333;/37088562063;/37086377227;/37086934069;/37951137300;/37089893147;/37269568300;/37088998333;/37088562063;/37086377227;/37086934069;/37951137300;/37089893147;/37269568300",
        "aff": "Department of Computing Science, University of Alberta, Edmonton AB, Canada; Department of Computing Science, University of Alberta, Edmonton AB, Canada; Department of Computing Science, University of Alberta, Edmonton AB, Canada; Department of Computing Science, University of Alberta, Edmonton AB, Canada; Department of Computing Science, University of Alberta, Edmonton AB, Canada; Department of Computing Science, University of Alberta, Edmonton AB, Canada; Department of Computing Science, University of Alberta, Edmonton AB, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160585/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7520684923247107055&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Computing Science",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161135",
        "title": "Learning Tethered Perching for Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial robots have a wide range of applications, such as collecting data in hard-to-reach areas. This requires the longest possible operation time. However, because currently available commercial batteries have limited specific energy of roughly 300 W h kg-1, a drone's flight time is a bottleneck for sustainable long-term data collection. Inspired by birds in nature, a possible approach to tackle this challenge is to perch drones on trees, and environmental or man-made structures, to save energy whilst in operation. In this paper, we propose an algorithm to automatically generate trajectories for a drone to perch on a tree branch, using the proposed tethered perching mechanism with a pendulum-like structure. This enables a drone to perform an energy-optimised, controlled 180\u00b0 flip to safely disarm upside down. To fine-tune a set of reachable trajectories, a soft actor critic-based reinforcement algorithm is used. Our experimental results show the feasibility of the set of trajectories with successful perching. Our findings demonstrate that the proposed approach enables energy-efficient landing for long-term data collection tasks.",
        "primary_area": "",
        "author": "Fabian Hauf;Basaran Bahadir Kocer;Alan Slatter;Hai-Nguyen Nguyen;Oscar Pang;Ronald Clark;Edward Johns;Mirko Kovac;Fabian Hauf;Basaran Bahadir Kocer;Alan Slatter;Hai-Nguyen Nguyen;Oscar Pang;Ronald Clark;Edward Johns;Mirko Kovac",
        "authorids": "/37089895569;/37072753900;/37089895444;/37085630997;/37089887631;/37086184882;/37602799000;/37085542534;/37089895569;/37072753900;/37089895444;/37085630997;/37089887631;/37086184882;/37602799000;/37085542534",
        "aff": "Aerial Robotics Laboratory, Imperial College London, London, UK; Department of Aerospace Engineering, University of Bristol, Bristol, UK; Aerial Robotics Laboratory, Imperial College London, London, UK; LAAS-CNRS, Universit\u00e9 de Toulouse, Toulouse, France; Aerial Robotics Laboratory, Imperial College London, London, UK; Department of Computer Science, University of Oxford, U.K; Department of Computing, Imperial College London, London, U.K; Laboratory of Sustainability Robotics at the Swiss Federal Laboratories for Materials Science and Technology, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161135/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12449462945488874102&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;2;0;3;0;4",
        "aff_unique_norm": "Imperial College London;University of Bristol;Universit\u00e9 de Toulouse;University of Oxford;Swiss Federal Laboratories for Materials Science and Technology",
        "aff_unique_dep": "Aerial Robotics Laboratory;Department of Aerospace Engineering;LAAS-CNRS;Department of Computer Science;Laboratory of Sustainability Robotics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.bristol.ac.uk;https://www.univ-toulouse.fr;https://www.ox.ac.uk;https://www.empa.ch",
        "aff_unique_abbr": "ICL;UoB;UT;Oxford;EMPA",
        "aff_campus_unique_index": "0;1;0;2;0;0",
        "aff_campus_unique": "London;Bristol;Toulouse;",
        "aff_country_unique_index": "0;0;0;1;0;0;0;2",
        "aff_country_unique": "United Kingdom;France;Switzerland"
    },
    {
        "id": "10161453",
        "title": "Learning Tool Morphology for Contact-Rich Manipulation Tasks with Differentiable Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "When humans perform contact-rich manipulation tasks, customized tools are often necessary to simplify the task. For instance, we use various utensils for handling food, such as knives, forks and spoons. Similarly, robots may benefit from specialized tools that enable them to more easily complete a variety of tasks. We present an end-to-end framework to automatically learn tool morphology for contact-rich manipulation tasks by leveraging differentiable physics simulators. Previous work relied on manually constructed priors requiring detailed specification of a 3D object model, grasp pose and task description to facilitate the search or optimization process. Our approach only requires defining the objective with respect to task performance and enables learning a robust morphology through randomizing variations of the task. We make this optimization tractable by casting it as a continual learning problem. We demonstrate the effectiveness of our method for designing new tools in several scenarios, such as winding ropes, flipping a box and pushing peas onto a scoop in simulation. Additionally, experiments with real robots show that the tool shapes discovered by our method help them succeed in these scenarios.",
        "primary_area": "",
        "author": "Mengxi Li;Rika Antonova;Dorsa Sadigh;Jeannette Bohg;Mengxi Li;Rika Antonova;Dorsa Sadigh;Jeannette Bohg",
        "authorids": "/37088689162;/37085991913;/38234464200;/37591153900;/37088689162;/37085991913;/38234464200;/37591153900",
        "aff": "Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161453/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7948327628278737075&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161336",
        "title": "Learning Video-Conditioned Policies for Unseen Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to specify robot commands by a non-expert user is critical for building generalist agents capable of solving a large variety of tasks. One convenient way to specify the intended robot goal is by a video of a person demonstrating the target task. While prior work typically aims to imitate human demonstrations performed in robot environments, here we focus on a more realistic and challenging setup with demonstrations recorded in natural and diverse human environments. We propose Video-conditioned Policy learning (ViP), a data-driven approach that maps human demonstrations of previously unseen tasks to robot manipulation skills. To this end, we learn our policy to generate appropriate actions given current scene observations and a video of the target task. To encourage generalization to new tasks, we avoid particular tasks during training and learn our policy from unlabelled robot trajectories and corresponding robot videos. Both robot and human videos in our framework are represented by video embeddings pre-trained for human action recognition. At test time we first translate human videos to robot videos in the common video embedding space, and then use resulting embeddings to condition our policies. Notably, our approach enables robot control by human demonstrations in a zero-shot manner, i.e., without using robot trajectories paired with human instructions during training. We validate our approach on a set of challenging multi-task robot manipulation environments and outperform state of the art. Our method also demonstrates excellent performance in a new challenging zero-shot setup where no paired data is used during training.",
        "primary_area": "",
        "author": "Elliot Chane-Sane;Cordelia Schmid;Ivan Laptev;Elliot Chane-Sane;Cordelia Schmid;Ivan Laptev",
        "authorids": "/37089892194;/37282990700;/37270740700;/37089892194;/37282990700;/37270740700",
        "aff": "Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France; Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France; Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161336/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8177760905438973774&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Inria",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160760",
        "title": "Learning Visual Locomotion with Cross-Modal Supervision",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we show how to learn a visual walking policy that only uses a monocular RGB camera and proprioception. Since simulating RGB is hard, we necessarily have to learn vision in the real world. We start with a blind walking policy trained in simulation. This policy can traverse some terrains in the real world but often struggles since it lacks knowledge of the upcoming geometry. This can be resolved with the use of vision. We train a visual module in the real world to predict the upcoming terrain with our proposed algorithm Cross-Modal Supervision (CMS). CMS uses time-shifted proprioception to supervise vision and allows the policy to continually improve with more real-world experience. We evaluate our vision-based walking policy over a diverse set of terrains including stairs (up to 19cm high), slippery slopes (inclination of 35\u00b0), curbs and tall steps (up to 20cm), and complex discrete terrains. We achieve this performance with less than 30 minutes of real-world data. Finally, we show that our policy can adapt to shifts in the visual field with a limited amount of real-world experience.",
        "primary_area": "",
        "author": "Antonio Loquercio;Ashish Kumar;Jitendra Malik;Antonio Loquercio;Ashish Kumar;Jitendra Malik",
        "authorids": "/37086299855;/37089497753;/37282929000;/37086299855;/37089497753;/37282929000",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160760/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1494445752227552578&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161461",
        "title": "Learning Visual-Audio Representations for Voice-Controlled Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Based on the recent advancements in representation learning, we propose a novel pipeline for task-oriented voice-controlled robots with raw sensor inputs. Previous methods rely on a large number of labels and task-specific reward functions. Not only can such an approach hardly be improved after the deployment, but also has limited generalization across robotic platforms and tasks. To address these problems, our pipeline first learns a visual-audio representation (VAR) that associates images and sound commands. Then the robot learns to fulfill the sound command via reinforcement learning using the reward generated by the VAR. We demonstrate our approach with various sound types, robots, and tasks. We show that our method outperforms previous work with much fewer labels. We show in both the simulated and real-world experiments that the system can self-improve in previously unseen scenarios given a reasonable number of newly labeled data.",
        "primary_area": "",
        "author": "Peixin Chang;Shuijing Liu;D. Livingston McPherson;Katherine Driggs-Campbell;Peixin Chang;Shuijing Liu;D. Livingston McPherson;Katherine Driggs-Campbell",
        "authorids": "/37088688639;/37088687174;/37085370314;/37085509519;/37088688639;/37088687174;/37085370314;/37085509519",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161461/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8955153105302915009&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160836",
        "title": "Learning a Single Near-hover Position Controller for Vastly Different Quadcopters",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an adaptive near-hover position controller for quadcopters, which can be deployed to quadcopters of very different mass, size and motor constants, and also shows rapid adaptation to unknown disturbances during runtime. The core algorithmic idea is to learn a single policy that can adapt online at test time not only to the disturbances applied to the drone, but also to the robot dynamics and hardware in the same framework. We achieve this by training a neural network to estimate a latent representation of the robot and environment parameters, which is used to condition the behaviour of the controller, also represented as a neural network. We train both networks exclusively in simulation with the goal of flying the quadcopters to goal positions and avoiding crashes to the ground. We directly deploy the same controller trained in the simulation without any modifications on two quadcopters in the real world with differences in mass, size, motors, and propellers with mass differing by 4.5 times. In addition, we show rapid adaptation to sudden and large disturbances up to one-third of the mass of the quadcopters. We perform an extensive evaluation in both simulation and the physical world, where we outperform a state-of-the-art learning-based adaptive controller and a traditional PID controller specifically tuned to each platform individually. Video results can be found at https://youtu.be/U-c-LbTfvoA.",
        "primary_area": "",
        "author": "Dingqi Zhang;Antonio Loquercio;Xiangyu Wu;Ashish Kumar;Jitendra Malik;Mark W. Mueller;Dingqi Zhang;Antonio Loquercio;Xiangyu Wu;Ashish Kumar;Jitendra Malik;Mark W. Mueller",
        "authorids": "/37089895469;/37086299855;/37086448421;/37089497753;/37282929000;/37086448968;/37089895469;/37086299855;/37086448421;/37089497753;/37282929000;/37086448968",
        "aff": "Dept. of Mechanical Engineering, High Performance Robotics Lab; Dept. of Electrical Engineering and Computer Science, University of California Berkeley; Dept. of Mechanical Engineering, High Performance Robotics Lab; Dept. of Electrical Engineering and Computer Science, University of California Berkeley; Dept. of Electrical Engineering and Computer Science, University of California Berkeley; Dept. of Mechanical Engineering, High Performance Robotics Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160836/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18001623262979942118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;1;0",
        "aff_unique_norm": "High Performance Robotics Lab;University of California, Berkeley",
        "aff_unique_dep": "Dept. of Mechanical Engineering;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": ";https://www.berkeley.edu",
        "aff_unique_abbr": ";UC Berkeley",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "1;1;1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "10160340",
        "title": "Learning an Efficient Terrain Representation for Haptic Localization of a Legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Although haptic sensing has recently been used for legged robot localization in extreme environments where a camera or LiDAR might fail, the problem of efficiently representing the haptic signatures in a learned prior map is still open. This paper introduces an approach to terrain representation for haptic localization inspired by recent trends in machine learning. It combines this approach with the proven Monte Carlo algorithm to obtain an accurate, computation-efficient, and practical method for localizing legged robots under adversarial environmental conditions. We apply the triplet loss concept to learn highly descriptive embeddings in a transformer-based neural network. As the training haptic data are not labeled, the positive and negative examples are discriminated by their geometric locations discovered while training. We demonstrate experimentally that the proposed approach outperforms by a large margin the previous solutions to haptic localization of legged robots concerning the accuracy, inference time, and the amount of data stored in the map. As far as we know, this is the first approach that completely removes the need to use a dense terrain map for accurate haptic localization, thus paving the way to practical applications.",
        "primary_area": "",
        "author": "Damian S\u00f3jka;Micha\u0142 R. Nowicki;Piotr Skrzypczy\u0144ski;Damian S\u00f3jka;Micha\u0142 R. Nowicki;Piotr Skrzypczy\u0144ski",
        "authorids": "/37089894319;/37085439474;/37611911500;/37089894319;/37085439474;/37611911500",
        "aff": "Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160340/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13349993897319695252&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Poznan University of Technology",
        "aff_unique_dep": "Institute of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.put.poznan.pl/",
        "aff_unique_abbr": "PUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Poznan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Poland"
    },
    {
        "id": "10160587",
        "title": "Learning and Blending Robot Hugging Behaviors in Time and Space",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce an imitation learning-based physical human-robot interaction algorithm capable of predicting appropriate robot responses in complex interactions involving a superposition of multiple interactions. Our proposed algorithm, Blending Bayesian Interaction Primitives (B-BIP) allows us to achieve responsive interactions in complex hugging scenarios, capable of reciprocating and adapting to a hug's motion and timing. We show that this algorithm is a generalization of prior work, for which the original formulation reduces to the particular case of a single interaction, and evaluate our method through both an extensive user study and empirical experiments. Our algorithm yields significantly better quantitative prediction error and more-favorable participant responses with respect to accuracy, responsiveness, and timing, when compared to existing state-of-the-art methods.",
        "primary_area": "",
        "author": "Michael Drolet;Joseph Campbell;Heni Ben Amor;Michael Drolet;Joseph Campbell;Heni Ben Amor",
        "authorids": "/37088505031;/37085810305;/37293927700;/37088505031;/37085810305;/37293927700",
        "aff": "School of Computing and Augmented Intelligence at Arizona State University, USA; Robotics Institute at Carnegie Mellon University, USA; School of Computing and Augmented Intelligence at Arizona State University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160587/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5705291343079814669&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Arizona State University;Carnegie Mellon University",
        "aff_unique_dep": "School of Computing and Augmented Intelligence;Robotics Institute",
        "aff_unique_url": "https://asu.edu;https://www.cmu.edu",
        "aff_unique_abbr": "ASU;CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tempe;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161416",
        "title": "Learning from Physical Human Feedback: An Object-Centric One-Shot Adaptation Method",
        "track": "main",
        "status": "Poster",
        "abstract": "For robots to be effectively deployed in novel environments and tasks, they must be able to understand the feedback expressed by humans during intervention. This can either correct undesirable behavior or indicate additional preferences. Existing methods either require repeated episodes of interactions or assume prior known reward features, which is data-inefficient and can hardly transfer to new tasks. We relax these assumptions by describing human tasks in terms of object-centric sub-tasks and interpreting physical interventions in relation to specific objects. Our method, Object Preference Adaptation (OPA), is composed of two key stages: 1) pre-training a base policy to produce a wide variety of behaviors, and 2) online-updating according to human feedback. The key to our fast, yet simple adaptation is that general interaction dynamics between agents and objects are fixed, and only object-specific preferences are updated. Our adaptation occurs online, requires only one human intervention (one-shot), and produces new behaviors never seen during training. Trained on cheap synthetic data instead of expensive human demonstrations, our policy correctly adapts to human perturbations on realistic tasks on a physical 7DOF robot. Videos, code, and supplementary material: https://alvinosaur.github.io/AboutMe/projects/opa.",
        "primary_area": "",
        "author": "Alvin Shek;Bo Ying Su;Rui Chen;Changliu Liu;Alvin Shek;Bo Ying Su;Rui Chen;Changliu Liu",
        "authorids": "/37089822667;/37089892406;/37088952173;/37085543217;/37089822667;/37089892406;/37088952173;/37085543217",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, United States; Carnegie Mellon University, Pittsburgh, PA, United States; Carnegie Mellon University, Pittsburgh, PA, United States; Carnegie Mellon University, Pittsburgh, PA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161416/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1016593599461176939&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161491",
        "title": "Learning on the Job: Self-Rewarding Offline-to-Online Finetuning for Industrial Insertion of Novel Connectors from Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based methods in robotics hold the promise of generalization, but what can be done if a learned policy does not generalize to a new situation? In principle, if an agent can at least evaluate its own success (i.e., with a reward classifier that generalizes well even when the policy does not), it could actively practice the task and finetune the policy in this situation. We study this problem in the setting of industrial insertion tasks, such as inserting connectors in sockets and setting screws. Existing algorithms rely on precise localization of the connector or socket and carefully managed physical setups, such as assembly lines, to succeed at the task. But in unstructured environments such as homes or even some industrial settings, robots cannot rely on precise localization and may be tasked with previously unseen connectors. Offline reinforcement learning on a variety of connector insertion tasks is a potential solution, but what if the robot is tasked with inserting previously unseen connector? In such a scenario, we will still need methods that can robustly solve such tasks with online practice. One of the main observations we make in this work is that, with a suitable representation learning and domain generalization approach, it can be significantly easier for the reward function to generalize to a new but structurally similar task (e.g., inserting a new type of connector) than for the policy. This means that a learned reward function can be used to facilitate the finetuning of the robot's policy in situations where the policy fails to generalize in zero shot, but the reward function generalizes successfully. We show that such an approach can be instantiated in the real world, pretrained on 50 different connectors, and successfully finetuned to new connectors via the learned reward function. Videos and visualizations can be viewed at sites.google.com/view/learningonthejob",
        "primary_area": "",
        "author": "Ashvin Nair;Brian Zhu;Gokul Narayanan;Eugen Solowjow;Sergey Levine;Ashvin Nair;Brian Zhu;Gokul Narayanan;Eugen Solowjow;Sergey Levine",
        "authorids": "/37086106243;/37089893432;/37089892637;/37947855300;/37085481973;/37086106243;/37089893432;/37089892637;/37947855300;/37085481973",
        "aff": "University of California, Berkeley; Siemens Corporation; Siemens Corporation; Siemens Corporation; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161491/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14532760939645603988&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;Siemens AG",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.siemens.com",
        "aff_unique_abbr": "UC Berkeley;Siemens",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "10160784",
        "title": "Learning to Estimate 3-D States of Deformable Linear Objects from Single-Frame Occluded Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately and robustly estimating the state of deformable linear objects (DLOs), such as ropes and wires, is crucial for DLO manipulation and other applications. However, it remains a challenging open issue due to the high dimensionality of the state space, frequent occlusions, and noises. This paper focuses on learning to robustly estimate the states of DLOs from single-frame point clouds in the presence of occlusions using a data-driven method. We propose a novel two-branch network architecture to exploit global and local information of input point cloud respectively and design a fusion module to effectively leverage the advantages of both methods. Simulation and real-world experimental results demonstrate that our method can generate globally smooth and locally precise DLO state estimation results even with heavily occluded point clouds, which can be directly applied to real-world robotic manipulation of DLOs in 3-D space.",
        "primary_area": "",
        "author": "Kangchen Lv;Mingrui Yu;Yifan Pu;Xin Jiang;Gao Huang;Xiang Li;Kangchen Lv;Mingrui Yu;Yifan Pu;Xin Jiang;Gao Huang;Xiang Li",
        "authorids": "/37089717220;/37089448870;/37089894628;/37089892529;/37274328900;/37280877200;/37089717220;/37089448870;/37089894628;/37089892529;/37274328900;/37280877200",
        "aff": "Department of Automation, Tsinghua University, China; Department of Automation, Tsinghua University, China; Department of Automation, Tsinghua University, China; Beijing Academy of Artificial Intelligence, Beijing, China; Department of Automation, Tsinghua University, China; Department of Automation, Tsinghua University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160784/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10375784234204811705&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Tsinghua University;Beijing Academy of Artificial Intelligence",
        "aff_unique_dep": "Department of Automation;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.baaic.cn",
        "aff_unique_abbr": "Tsinghua;BAAI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160951",
        "title": "Learning to Explore Informative Trajectories and Samples for Embodied Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "We are witnessing significant progress on perception models, specifically those trained on large-scale internet images. However, efficiently generalizing these perception models to unseen embodied tasks is insufficiently studied, which will help various relevant applications (e.g., home robots). Unlike static perception methods trained on pre-collected images, the embodied agent can move around in the environment and obtain images of objects from any viewpoints. Therefore, efficiently learning the exploration policy and collection method to gather informative training samples is the key to this task. To do this, we first build a 3D semantic distribution map to train the exploration policy self-supervised by introducing the semantic distribution disagreement and the semantic distribution uncertainty rewards. Note that the map is generated from multi-view observations and can weaken the impact of misidentification from an unfamiliar viewpoint. Our agent is then encouraged to explore the objects with different semantic distributions across viewpoints, or uncertain semantic distributions. With the explored informative trajectories, we propose to select hard samples on trajectories based on the semantic distribution uncertainty to reduce unnecessary observations that can be correctly identified. Experiments show that the perception model fine-tuned with our method outperforms the baselines trained with other exploration policies. Further, we demonstrate the robustness of our method in real-robot experiments.",
        "primary_area": "",
        "author": "Ya Jing;Tao Kong;Ya Jing;Tao Kong",
        "authorids": "/37089892917;/37085802024;/37089892917;/37085802024",
        "aff": "ByteDance AI Lab; ByteDance AI Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160951/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6040325203591031644&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ByteDance",
        "aff_unique_dep": "AI Lab",
        "aff_unique_url": "https://www.bytedance.com",
        "aff_unique_abbr": "ByteDance",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160766",
        "title": "Learning to Forecast Aleatoric and Epistemic Uncertainties over Long Horizon Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "Giving autonomous agents the ability to forecast their own outcomes and uncertainty will allow them to communicate their competencies and be used more safely. We accomplish this by using a learned world model of the agent system to forecast full agent trajectories over long time horizons. Real world systems involve significant sources of both aleatoric and epistemic uncertainty that compound and interact over time in the trajectory forecasts. We develop a deep generative world model that quantifies aleatoric uncertainty while incorporating the effects of epistemic uncertainty during the learning process. We show on two reinforcement learning problems that our uncertainty model produces calibrated outcome uncertainty estimates over the full trajectory horizon.",
        "primary_area": "",
        "author": "Aastha Acharya;Rebecca Russell;Nisar R. Ahmed;Aastha Acharya;Rebecca Russell;Nisar R. Ahmed",
        "authorids": "/37089662584;/37087682958;/37533152500;/37089662584;/37087682958;/37533152500",
        "aff": "The Charles Stark Draper Laboratory, Inc., Cambridge, Massachusetts; The Charles Stark Draper Laboratory, Inc., Cambridge, Massachusetts; Ann and H.J. Smead Department of Aerospace Engineering Sciences, University of Colorado Boulder, Boulder, Colorado",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160766/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4954318813548018356&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "The Charles Stark Draper Laboratory, Inc.;University of Colorado Boulder",
        "aff_unique_dep": ";Ann and H.J. Smead Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.draper.com;https://www.colorado.edu",
        "aff_unique_abbr": "Draper Lab;CU Boulder",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Cambridge;Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160717",
        "title": "Learning to Influence Vehicles' Routing in Mixed-Autonomy Networks by Dynamically Controlling the Headway of Autonomous Cars",
        "track": "main",
        "status": "Poster",
        "abstract": "It is known that autonomous cars can increase road capacities by maintaining a smaller headway through vehicle platooning. Recent works have shown that these capacity increases can influence vehicles' route choices in unexpected ways similar to the well-known Braess's paradox, such that the network congestion might increase. In this paper, we propose that in mixed-autonomy networks, i.e., networks where roads are shared between human-driven and autonomous cars, the headway of autonomous cars can be directly controlled to influence vehicles' routing and reduce congestion. We argue that the headway of autonomous cars - and consequently the capacity of link segments - is not just a fixed design choice; but rather, it can be leveraged as an infrastructure control strategy to dynamically regulate capacities. Imagine that similar to variable speed limits which regulate the maximum speed of vehicles on a road segment, a control policy regulates the headway of autonomous cars along each road segment. We seek to influence vehicles' route choices by directly controlling the headway of autonomous cars to prevent Braess-like unexpected outcomes and increase network efficiency. We model the dynamics of mixed-autonomy traffic networks while accounting for the vehicles' route choice dynamics. We train an RL policy that learns to regulate the headway of autonomous cars such that the total travel time in the network is minimized. We will show empirically that our trained policy can not only prevent Braess-like inefficiencies but also decrease total travel time11The code is available at: https://github.com/labicon/RL-Traffic-Dynamics.",
        "primary_area": "",
        "author": "Xiaoyu Ma;Negar Mehr;Xiaoyu Ma;Negar Mehr",
        "authorids": "/37089895041;/37085844571;/37089895041;/37085844571",
        "aff": "Department of Electrical and Computer Engineering, UIUC, Urbana, IL, USA; Department of Aerospace Engineering, UIUC, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160717/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9675478141928416280&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.uiuc.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161114",
        "title": "Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In Task and motion planning (TAMP), symbolic search is combined with continuous geometric planning. A task planner finds an action sequence while a motion planner checks its feasibility and plans the corresponding sequence of motions. However, due to the high combinatorial complexity of discrete search, the number of calls to the geometric planner can be very large. Previous works [1] [2] leverage learning methods to efficiently predict the feasibility of actions, much like humans do, on tabletop scenarios. This way, the time spent on motion planning can be greatly reduced. In this work, we generalize these methods to 3D environments, thus covering the whole workspace of the robot. We propose an efficient method for 3D scene representation, along with a deep neural network capable of predicting the probability of feasibility of an action. We develop a simple TAMP algorithm that integrates the trained classifier, and demonstrate the performance gain of using our approach on multiple problem domains. On complex problems, our method can reduce the time spent on geometric planning by up to 90%.",
        "primary_area": "",
        "author": "Smail Ait Bouhsain;Rachid Alami;Thierry Sim\u00e9on;Smail Ait Bouhsain;Rachid Alami;Thierry Sim\u00e9on",
        "authorids": "/37089895072;/37278643600;/37325350600;/37089895072;/37278643600;/37325350600",
        "aff": "LAAS-CNRS, Toulouse, France; LAAS-CNRS, Toulouse, France; LAAS-CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161114/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5537820689461628105&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "LAAS-CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.laas.fr/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160946",
        "title": "Learning to View: Decision Transformers for Active Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Active perception describes a broad class of techniques that couple planning and perception systems to move the robot in a way to give the robot more information about the environment. In most robotic systems, perception is typically independent of motion planning. For example, traditional object detection is passive: it operates only on the images it receives. However, we have a chance to improve the results if we allow planning to consume detection signals and move the robot to collect views that maximize the quality of the results. In this paper, we use reinforcement learning (RL) methods to control the robot in order to obtain images that maximize the detection quality. Specifically, we propose using a Decision Transformer with online fine-tuning, which first optimizes the policy with a pre-collected expert dataset and then improves the learned policy by exploring better solutions in the environment. We evaluate the performance of proposed method on an interactive dataset collected from an indoor scenario simulator. Experimental results demonstrate that our method outperforms all baselines, including expert policy and pure offline RL methods. We also provide exhaustive analyses of the reward distribution and observation space.",
        "primary_area": "",
        "author": "Wenhao Ding;Nathalie Majcherczyk;Mohit Deshpande;Xuewei Qi;Ding Zhao;Rajasimman Madhivanan;Arnie Sen;Wenhao Ding;Nathalie Majcherczyk;Mohit Deshpande;Xuewei Qi;Ding Zhao;Rajasimman Madhivanan;Arnie Sen",
        "authorids": "/37088505922;/37086582203;/37089892156;/37089894692;/37085680141;/37089894141;/37089833053;/37088505922;/37086582203;/37089892156;/37089894692;/37085680141;/37089894141;/37089833053",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Amazon Lab126, Sunnyvale, CA, USA; Amazon Lab126, Sunnyvale, CA, USA; Amazon Lab126, Sunnyvale, CA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Amazon Lab126, Sunnyvale, CA, USA; Amazon Lab126, Sunnyvale, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160946/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3852603600653701484&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;0;1;1",
        "aff_unique_norm": "Carnegie Mellon University;Amazon Lab126",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.amazon.com",
        "aff_unique_abbr": "CMU;",
        "aff_campus_unique_index": "0;1;1;1;0;1;1",
        "aff_campus_unique": "Pittsburgh;Sunnyvale",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161302",
        "title": "Learning to Walk by Steering: Perceptive Quadrupedal Locomotion in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We tackle the problem of perceptive locomotion in dynamic environments. In this problem, a quadrupedal robot must exhibit robust and agile walking behaviors in response to environmental clutter and moving obstacles. We present a hierarchical learning framework, named PRELUDE, which decomposes the problem of perceptive locomotion into high-level decision-making to predict navigation commands and low-level gait generation to realize the target commands. In this framework, we train the high-level navigation controller with imitation learning on human demonstrations collected on a steerable cart and the low-level gait controller with reinforcement learning (RL). Therefore, our method can acquire complex navigation behaviors from human supervision and discover versatile gaits from trial and error. We demonstrate the effectiveness of our approach in simulation and with hardware experiments. Videos and code can be found at the project page: https://ut-austin-rpl.github.io/PRELUDE.",
        "primary_area": "",
        "author": "Mingyo Seo;Ryan Gupta;Yifeng Zhu;Alexy Skoutnev;Luis Sentis;Yuke Zhu;Mingyo Seo;Ryan Gupta;Yifeng Zhu;Alexy Skoutnev;Luis Sentis;Yuke Zhu",
        "authorids": "/37086119481;/37088506542;/37088690974;/37089895516;/37426747500;/37086080772;/37086119481;/37088506542;/37088690974;/37089895516;/37426747500;/37086080772",
        "aff": "The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin; Vanderbilt University; The University of Texas at Austin; The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161302/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10925580329972639192&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of Texas at Austin;Vanderbilt University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.vanderbilt.edu",
        "aff_unique_abbr": "UT Austin;Vanderbilt",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161381",
        "title": "Learning-Based Dimensionality Reduction for Computing Compact and Effective Local Feature Descriptors",
        "track": "main",
        "status": "Poster",
        "abstract": "A distinctive representation of image patches in form of features is a key component of many computer vision and robotics tasks, such as image matching, image retrieval, and visual localization. State-of-the-art descriptors, from hand-crafted descriptors such as SIFT to learned ones such as HardNet, are usually high-dimensional; 128 dimensions or even more. The higher the dimensionality, the larger the memory consumption and computational time for approaches using such descriptors. In this paper, we investigate multi-layer perceptrons (MLPs) to extract low-dimensional but high-quality descriptors. We thoroughly analyze our method in unsuper-vised, self-supervised, and supervised settings, and evaluate the dimensionality reduction results on four representative descriptors. We consider different applications, including visual localization, patch verification, image matching and retrieval. The experiments show that our lightweight MLPs trained using supervised method achieve better dimensionality reduction than PCA. The lower-dimensional descriptors generated by our approach outperform the original higher-dimensional descriptors in downstream tasks, especially for the hand-crafted ones. The code is available at https://github.com/PRBonn/descriptor-dr.",
        "primary_area": "",
        "author": "Hao Dong;Xieyuanli Chen;Mihai Dusmanu;Viktor Larsson;Marc Pollefeys;Cyrill Stachniss;Hao Dong;Xieyuanli Chen;Mihai Dusmanu;Viktor Larsson;Marc Pollefeys;Cyrill Stachniss",
        "authorids": "/37089895371;/37086247697;/37087232078;/37085374289;/37271138500;/37329668600;/37089895371;/37086247697;/37087232078;/37085374289;/37271138500;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; ETH Zurich, Switzerland; Lund University, Sweden; Microsoft Research; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161381/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1816773714676357383&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;3;4",
        "aff_unique_norm": "University of Bonn;ETH Zurich;Lund University;Microsoft Corporation;Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": ";;;Microsoft Research;",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.ethz.ch;https://www.lunduniversity.lu.se;https://www.microsoft.com/en-us/research;",
        "aff_unique_abbr": "UBonn;ETHZ;LU;MSR;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;2;3;0",
        "aff_country_unique": "Germany;Switzerland;Sweden;United States"
    },
    {
        "id": "10161426",
        "title": "Learning-based Initialization of Trajectory Optimization for Path-following Problems of Redundant Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory optimization (TO) is an efficient tool to generate a redundant manipulator's joint trajectory following a 6-dimensional Cartesian path. The optimization performance largely depends on the quality of initial trajectories. However, the selection of a high-quality initial trajectory is non-trivial and requires a considerable time budget due to the extremely large space of the solution trajectories and the lack of prior knowledge about task constraints in configuration space. To alleviate the issue, we present a learning-based initial trajectory generation method that generates high-quality initial trajectories in a short time budget by adopting example-guided reinforcement learning. In addition, we suggest a null-space projected imitation reward to consider null-space constraints by efficiently learning kinematically feasible motion captured in expert demonstrations. Our statistical evaluation in simulation shows the improved optimality, efficiency, and applicability of TO when we plug in our method's output, compared with three other baselines. We also show the performance improvement and feasibility via real-world experiments with a seven-degree-of-freedom manipulator.",
        "primary_area": "",
        "author": "Minsung Yoon;Mincheul Kang;Daehyung Park;Sung-Eui Yoon;Minsung Yoon;Mincheul Kang;Daehyung Park;Sung-Eui Yoon",
        "authorids": "/37089447491;/37086439291;/37085429958;/37066068100;/37089447491;/37086439291;/37085429958;/37066068100",
        "aff": "School of Computing, Korea Advanced Institute of Science and Technology, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161426/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7528054207847922928&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161393",
        "title": "Learning-based Relational Object Matching Across Views",
        "track": "main",
        "status": "Poster",
        "abstract": "Intelligent robots require object-level scene understanding to reason about possible tasks and interactions with the environment. Moreover, many perception tasks such as scene reconstruction, image retrieval, or place recognition can benefit from reasoning on the level of objects. While keypoint-based matching can yield strong results for finding correspondences for images with small to medium view point changes, for large view point changes, matching semantically on the object-level becomes advantageous. In this paper, we propose a learning-based approach which combines local keypoints with novel object-level features for matching object detections between RGB images. We train our object-level matching features based on appearance and inter-frame and cross-frame spatial relations between objects in an associative graph neural network. We demonstrate our approach in a large variety of views on realistically rendered synthetic images. Our approach compares favorably to previous state-of-the-art object-level matching approaches and achieves improved performance over a pure keypoint-based approach for large view-point changes.",
        "primary_area": "",
        "author": "Cathrin Elich;Iro Armeni;Martin R. Oswald;Marc Pollefeys;Joerg Stueckler;Cathrin Elich;Iro Armeni;Martin R. Oswald;Marc Pollefeys;Joerg Stueckler",
        "authorids": "/37089894332;/37086168626;/38467098900;/37271138500;/37088215404;/37089894332;/37086168626;/38467098900;/37271138500;/37088215404",
        "aff": "Max Planck ETH Center for Learning Systems; Computer Vision and Geometry Lab, ETH Zurich, Switzerland; University of Amsterdam, Netherlands; Microsoft Mixed Reality and AI Lab, Zurich, Switzerland; Embodied Vision Group, Max Planck Institute for Intelligent Systems, Tuebingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161393/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11427678823331179508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "Max Planck ETH Center for Learning Systems;ETH Zurich;University of Amsterdam;Microsoft Mixed Reality and AI Lab;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Center for Learning Systems;Computer Vision and Geometry Lab;;Mixed Reality and AI;Embodied Vision Group",
        "aff_unique_url": "https://learning-systems.org;https://www.ethz.ch;https://www.uva.nl;https://www.microsoft.com/en-us/research/group/mixed-reality-ai-lab;https://www.mpituebingen.mpg.de",
        "aff_unique_abbr": ";ETHZ;UvA;Microsoft MR&A Lab;MPI-IS",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Zurich;Tuebingen",
        "aff_country_unique_index": "0;0;1;0;2",
        "aff_country_unique": "Switzerland;Netherlands;Germany"
    },
    {
        "id": "10161543",
        "title": "Learning-based Uncertainty-aware Navigation in 3D Off-Road Terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a safe, efficient, and agile ground vehicle navigation algorithm for 3D off-road terrain environments. Off-road navigation is subject to uncertain vehicle-terrain interactions caused by different terrain conditions on top of 3D terrain topology. The existing works are limited to adopt overly simplified vehicle-terrain models. The proposed algorithm learns the terrain-induced uncertainties from driving data and encodes the learned uncertainty distribution into the traversability cost for path evaluation. The navigation path is then designed to optimize the uncertainty-aware traversability cost, resulting in a safe and agile vehicle maneuver. Assuring real-time execution, the algorithm is further implemented within parallel computation architecture running on Graphics Processing Units (GPU).",
        "primary_area": "",
        "author": "Hojin Lee;Junsung Kwon;Cheolhyeon Kwon;Hojin Lee;Junsung Kwon;Cheolhyeon Kwon",
        "authorids": "/37088904226;/37089893838;/37072992300;/37088904226;/37089893838;/37072992300",
        "aff": "Department of Mechanical Engineering, Ulsan National Institute of Science and Technology, Ulsan, Repulic of Korea; Department of Mechanical Engineering, Ulsan National Institute of Science and Technology, Ulsan, Repulic of Korea; Department of Mechanical Engineering, Ulsan National Institute of Science and Technology, Ulsan, Repulic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161543/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14399041061615212674&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.unist.ac.kr",
        "aff_unique_abbr": "UNIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ulsan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161470",
        "title": "Legs as Manipulator: Pushing Quadrupedal Agility Beyond Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Locomotion has seen dramatic progress for walking or running across challenging terrains. However, robotic quadrupeds are still far behind their biological counterparts, such as dogs, which display a variety of agile skills and can use the legs beyond locomotion to perform several basic manipulation tasks like interacting with objects and climbing. In this paper, we take a step towards bridging this gap by training quadruped robots not only to walk but also to use the front legs to climb walls, press buttons, and perform object interaction in the real world. To handle this challenging optimization, we decouple the skill learning broadly into locomotion, which involves anything that involves movement whether via walking or climbing a wall, and manipulation, which involves using one leg to interact while balancing on the other three legs. These skills are trained in simulation using curriculum and transferred to the real world using our proposed sim2real variant that builds upon recent locomotion success. Finally, we combine these skills into a robust long-term plan by learning a behavior tree that encodes a high-level task hierarchy from one clean expert demonstration. We evaluate our method in both simulation and real-world showing successful executions of both short as well as long-range tasks and how robustness helps confront external perturbations. Videos at https://robot-skills.github.io/.",
        "primary_area": "",
        "author": "Xuxin Cheng;Ashish Kumar;Deepak Pathak;Xuxin Cheng;Ashish Kumar;Deepak Pathak",
        "authorids": "/37089260506;/37089497753;/37085372144;/37089260506;/37089497753;/37085372144",
        "aff": "Carnegie Mellon University; UC Berkeley; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161470/",
        "gs_citation": 73,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1940124529181073035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "CMU;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161427",
        "title": "Leveraging Scene Embeddings for Gradient-Based Motion Planning in Latent Space",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning framed as optimisation in structured latent spaces has recently emerged as competitive with traditional methods in terms of planning success while significantly outperforming them in terms of computational speed. However, the real-world applicability of recent work in this domain remains limited by the need to express obstacle information directly in state-space, involving simple geometric primitives. In this work we address this challenge by leveraging learned scene embeddings together with a generative model of the robot manipulator to drive the optimisation process. In addition, we introduce an approach for efficient collision checking which directly regularises the optimisation undertaken for planning. Using simulated as well as real-world experiments, we demonstrate that our approach, AMP-LS, is able to successfully plan in novel, complex scenes while outperforming traditional planning baselines in terms of computation speed by an order of magnitude. We show that the resulting system is fast enough to enable closed-loop planning in real-world dynamic scenes.",
        "primary_area": "",
        "author": "Jun Yamada;Chia-Man Hung;Jack Collins;Ioannis Havoutis;Ingmar Posner;Jun Yamada;Chia-Man Hung;Jack Collins;Ioannis Havoutis;Ingmar Posner",
        "authorids": "/37089892765;/37088998853;/37086935516;/37542879900;/37601368300;/37089892765;/37088998853;/37086935516;/37542879900;/37601368300",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161427/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15046790060602508118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10
    },
    {
        "id": "10160775",
        "title": "LiDAR-SGM: Semi-Global Matching on LiDAR Point Clouds and Their Cost-Based Fusion into Stereo Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Stereo matching can be used to estimate dense but inaccurate depth information for each pixel of a camera image. A LiDAR can provide accurate but sparse depth measurements. The fusion of both can combine their advantages. We propose an efficient method for fusing stereo and LiDAR at the cost level of Semi-Global Matching. It significantly improves density and accuracy of the estimated disparities while remaining real-time capable. Based on a LiDAR point cloud projected into the camera image costs are calculated for each possible disparity. These costs are added to the costs from stereo matching. Our LiDAR-SGM outperforms other real-time capable fusion approaches evaluated on the KITTI Stereo 2015 dataset. In addition to this real data, synthetic datasets are created (and made available) for a detailed analysis of the benefit of stereo LiDAR fusion as well as the evaluation of different sensors.",
        "primary_area": "",
        "author": "Bianca Forkel;Hans-Joachim Wuensche;Bianca Forkel;Hans-Joachim Wuensche",
        "authorids": "/37088402331;/37393701000;/37088402331;/37393701000",
        "aff": "The Institute for Autonomous Systems Technology (TAS) of the Universit\u00e4t der Bundeswehr M\u00fcnchen, Neubiberg, Germany; The Institute for Autonomous Systems Technology (TAS) of the Universit\u00e4t der Bundeswehr M\u00fcnchen, Neubiberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160775/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6238227292046284952&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e4t der Bundeswehr M\u00fcnchen",
        "aff_unique_dep": "Institute for Autonomous Systems Technology (TAS)",
        "aff_unique_url": "https://www.unibw.de",
        "aff_unique_abbr": "UniBW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Neubiberg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160274",
        "title": "LiDAR-based Indoor Localization with Optimal Particle Filters using Surface Normal Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and robust localization systems are often highly desired in autonomous mobile robots. Existing LiDAR-based localization systems generally use standard particle filters which suffer from the well-known particle degeneracy problem. Furthermore, standard particle filters are ill-suited for handling discrepancies between maps and the actual operating environments. In this work, we present an effective LiDAR-based indoor localization system which addresses these two issues. The particle degeneracy problem is tackled with an efficient implementation of an optimal particle filter. Map discrepancies are then handled with the use of a high-fidelity observation model for accurate particle propagation and a separate low-fidelity observation model for robust weight update. Evaluations were carried out against a standard particle filter baseline on both real-world and simulated data from challenging indoor environments. The proposed system was found to show significantly better performance in-terms of accuracy, robustness to ambiguity, and robustness to map discrepancies. These performance gains were observed even with more than ten times smaller particle set sizes than in the baseline, while the increase in the computation time per particle was only around 20%.",
        "primary_area": "",
        "author": "Heruka Andradi;Sebastian Blumenthal;Erwin Prassler;Paul G. Pl\u00f6ger;Heruka Andradi;Sebastian Blumenthal;Erwin Prassler;Paul G. Pl\u00f6ger",
        "authorids": "/37089893970;/37968357600;/37277371000;/37344552000;/37089893970;/37968357600;/37277371000;/37344552000",
        "aff": "Bonn-Rhein-Sieg University of Applied Sciences, Germany; KELO Robotics GmbH, Germany; Bonn-Rhein-Sieg University of Applied Sciences, Germany; Bonn-Rhein-Sieg University of Applied Sciences, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160274/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4943207413578209474&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Bonn-Rhein-Sieg University of Applied Sciences;KELO Robotics GmbH",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.fh-bonn-rhein-sieg.de;",
        "aff_unique_abbr": "UAS Bonn-Rhein-Sieg;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161037",
        "title": "Lidar Augment: Searching for Scalable 3D LiDAR Data Augmentations",
        "track": "main",
        "status": "Poster",
        "abstract": "Data augmentations are important for training high-performance 3D object detectors that use point clouds. Despite recent efforts on designing new data augmentations, perhaps surprisingly, most current state-of-the-art 3D detectors only rely on a few simple data augmentations. In particular, different from 2D image data augmentations, 3D data augmentations need to account for different representations of input data and require being customized for different models, which introduces significant overhead. In this paper, we propose LidarAugment, a practical and effective data augmentation strategy for 3D object detection. Unlike previous methods, which require tuning all augmentation policies in an exponentially large search space, we propose to factorize and align the search space of each data augmentation, which cuts down the 20+ hyperparameters to 2, and significantly reduces the search complexity. We show LidarAugment can be easily adapted to different model architectures with different input representations by a simple 2D grid search, and consistently improve a range of detectors including both convolution-based UPillars/StarNet/RSN and transformer-based SWFormer. Furthermore, Lidar Augment mitigates overfitting and enables 3D detectors to scale up to larger capacities. When combined with the latest 3D detectors, Lidar Augment achieves a new state-of-the-art 74.8 mAPH L2 on the Waymo Open Dataset.",
        "primary_area": "",
        "author": "Zhaoqi Leng;Guowang Li;Chenxi Liu;Ekin Dogus Cubuk;Pei Sun;Tong He;Dragomir Anguelov;Mingxing Tan;Zhaoqi Leng;Guowang Li;Chenxi Liu;Ekin Dogus Cubuk;Pei Sun;Tong He;Dragomir Anguelov;Mingxing Tan",
        "authorids": "/37089447734;/37089892841;/37089895204;/38257528500;/37088454400;/37090020777;/37278026400;/37087230954;/37089447734;/37089892841;/37089895204;/38257528500;/37088454400;/37090020777;/37278026400;/37087230954",
        "aff": "Waymo Research, United States; Waymo Research, United States; Waymo Research, United States; Google Brain, United States; Waymo Research, United States; Waymo Research, United States; Waymo Research, United States; Waymo Research, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161037/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7326761837282288905&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;0;0;0;0",
        "aff_unique_norm": "Waymo;Google",
        "aff_unique_dep": "Waymo Research;Google Brain",
        "aff_unique_url": "https://waymo.com;https://brain.google.com",
        "aff_unique_abbr": "Waymo;Google Brain",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161111",
        "title": "Light-Weight Pointcloud Representation with Sparse Gaussian Process",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a framework to represent high-fidelity pointcloud sensor observations for efficient communication and storage. The proposed approach exploits Sparse Gaussian Process to encode pointcloud into a compact form. Our approach represents both the free space and the occupied space using only one model (one 2D Sparse Gaussian Process) instead of the existing two-model framework (two 3D Gaussian Mixture Models). We achieve this by proposing a variance-based sampling technique that effectively discriminates between the free and occupied space. The new representation requires less memory footprint and can be transmitted across limited-bandwidth communication channels. The framework is extensively evaluated in simulation and it is also demonstrated using a real mobile robot equipped with a 3D LiDAR. Our method results in a 70~100 times reduction in the communication rate compared to sending the raw pointcloud. We have provided a demonstration video11Video: https://youtu.be/BQZzXiCFGrM and open-sourced our code 22Code: https://github.com/mahmoud-a-ali/vsgp_pcl.",
        "primary_area": "",
        "author": "Mahmoud Ali;Lantao Liu;Mahmoud Ali;Lantao Liu",
        "authorids": "/37089892070;/37085785167;/37089892070;/37085785167",
        "aff": "Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161111/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8760926315228021372&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indiana University",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering",
        "aff_unique_url": "https://www.indiana.edu",
        "aff_unique_abbr": "IU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bloomington",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160381",
        "title": "Lighthouses and Global Graph Stabilization: Active SLAM for Low-compute, Narrow-FoV Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous exploration to build a map of an unknown environment is a fundamental robotics problem. However, the quality of the map directly influences the quality of subsequent robot operation. Instability in a simultaneous localization and mapping (SLAM) system can lead to poor-quality maps and subsequent navigation failures during or after exploration. This becomes particularly noticeable in consumer robotics, where compute budget and limited field-of-view are very common. In this work, we propose (i) the concept of lighthouses: panoramic views with high visual information content that can be used to maintain the stability of the map locally in their neighborhoods and (ii) the final stabilization strategy for global pose graph stabilization. We call our novel exploration strategy SLAM-aware exploration (SAE) and evaluate its performance on real-world home environments.",
        "primary_area": "",
        "author": "Mohit Deshpande;Richard Kim;Dhruva Kumar;Jong Jin Park;Jim Zamiska;Mohit Deshpande;Richard Kim;Dhruva Kumar;Jong Jin Park;Jim Zamiska",
        "authorids": "/37089892156;/37089894348;/37089893972;/37089892753;/37089893438;/37089892156;/37089894348;/37089893972;/37089892753;/37089893438",
        "aff": "Amazon Lab126; Amazon Lab126; Amazon Lab126; Amazon Lab126; Amazon Lab126",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160381/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16322332870845462806&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Amazon Lab126",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.amazon.com",
        "aff_unique_abbr": "Amazon Lab126",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160566",
        "title": "Lightweight Monocular Depth Estimation via Token-Sharing Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth estimation is an important task in various robotics systems and applications. In mobile robotics systems, monocular depth estimation is desirable since a single RGB camera can be deployable at a low cost and compact size. Due to its significant and growing needs, many lightweight monocular depth estimation networks have been proposed for mobile robotics systems. While most lightweight monocular depth estimation methods have been developed using convolution neural networks, the Transformer has been gradually utilized in monocular depth estimation recently. However, massive parameters and large computational costs in the Transformer disturb the deployment to embedded devices. In this paper, we present a Token-Sharing Transformer (TST), an architecture using the Transformer for monocular depth estimation, optimized especially in embedded devices. The proposed TST utilizes global token sharing, which enables the model to obtain an accurate depth prediction with high throughput in embedded devices. Experimental results show that TST outperforms the existing lightweight monocular depth estimation methods. On the NYU Depth v2 dataset, TST can deliver depth maps up to 63.4 FPS in NVIDIA Jetson nano and 142.6 FPS in NVIDIA Jetson TX2, with lower errors than the existing methods. Furthermore, TST achieves real-time depth estimation of high-resolution images on Jetson TX2 with competitive results.",
        "primary_area": "",
        "author": "Dong-Jae Lee;Jae Young Lee;Hyunguk Shon;Eojindl Yi;Yeong-Hun Park;Sung-Sik Cho;Junmo Kim;Dong-Jae Lee;Jae Young Lee;Hyunguk Shon;Eojindl Yi;Yeong-Hun Park;Sung-Sik Cho;Junmo Kim",
        "authorids": "/37089892718;/37086014891;/37089017914;/37088689760;/37089647637;/37089893622;/37407301400;/37089892718;/37086014891;/37089017914;/37088689760;/37089647637;/37089893622;/37407301400",
        "aff": "Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea; MOBIS, South Korea; MOBIS, South Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160566/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=986493013178825009&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;MOBIS",
        "aff_unique_dep": "Department of Electrical Engineering;",
        "aff_unique_url": "https://www.kaist.ac.kr;",
        "aff_unique_abbr": "KAIST;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161315",
        "title": "Limit Cycle Generation with Pneumatically Driven Physical Reservoir Computing",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the recent developments in physical reservoir computing, which uses the complex dynamics of a physical system as a computational resource, is the use of a pneumatic pipeline system as a computational resource. This uses the dynamics of air for computation, and because it is lightweight and power-saving, it is used for gait-assist control using a soft exoskeleton with pneumatic rubber artificial muscles. In this study, we verified that by feeding back the estimated information to a pneumatic pipeline system, the pneumatic physical reservoir computing can generate periodic pressure changes as a stable limit cycle, such as those seen in walking. A pneumatic reservoir with feedback loops was modeled to generate limit cycles in the simulation, and it was confirmed that the system could generate limit cycles with high accuracy even from initial positions far from the target limit cycle. This system is expected to be applied to assist walking movements with a soft exoskeleton with a lightweight computational device.",
        "primary_area": "",
        "author": "Hiroaki Shinkawa;Toshihiro Kawase;Tetsuro Miyazaki;Takahiro Kanno;Maina Sogabe;Kenji Kawashima;Hiroaki Shinkawa;Toshihiro Kawase;Tetsuro Miyazaki;Takahiro Kanno;Maina Sogabe;Kenji Kawashima",
        "authorids": "/37089895659;/37086578826;/37086294776;/37085394750;/37088908615;/37280901500;/37089895659;/37086578826;/37086294776;/37085394750;/37088908615;/37280901500",
        "aff": "Department of Information Physics and Computing, The University of Tokyo, Tokyo, Japan; Department of Information and Communicatin Engineering, School of Engineering, Tokyo Denki University, Tokyo, Japan; Department of Information Physics and Computing, The University of Tokyo, Tokyo, Japan; Riverfield Inc., Tokyo, Japan; Department of Information Physics and Computing, The University of Tokyo, Tokyo, Japan; Department of Information Physics and Computing, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161315/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9869265524052128387&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;0",
        "aff_unique_norm": "The University of Tokyo;Tokyo Denki University;Riverfield Inc.",
        "aff_unique_dep": "Department of Information Physics and Computing;Department of Information and Communication Engineering;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.tdu.ac.jp;",
        "aff_unique_abbr": "UTokyo;TDU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161332",
        "title": "Linear Auto-calibration of Pan-Tilt-Zoom Cameras With Rotation Center Offset",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the linear auto-calibration problem of a pan-tilt-zoom (PTZ) camera. Unlike existing methods, we take full advantage of the offset of the camera center from the rotation center, which is usually non-negligible in bullet-type PTZ cameras. Without any prior assumption, we propose a linear method to recover all intrinsic parameters. First, we successively acquired at least four images using the zoom and rotation capabilities of the PTZ camera. Second, using the homography of two images at the same location but different scales, the principal point and zoom scalar can be linearly recovered. Finally, based on the unknown offset of the camera center and rotation center, we propose a linear method to solve the scale factor in the Kruppa equation and recover the remaining camera intrinsic parameters, namely focal lengths and skew. Synthetic and real experiments demonstrate the feasibility of our approach.",
        "primary_area": "",
        "author": "Yu Liu;Hui Zhang;Yu Liu;Hui Zhang",
        "authorids": "/37089893309;/37559772500;/37089893309;/37559772500",
        "aff": "Department of Computer Science, United International College, BNU-HKBU, Zhuhai, China; Department of Computer Science, United International College, Beijing Normal University-Hong Kong Baptist University, Zhuhai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161332/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10351023309625437374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "United International College;United International College, Beijing Normal University-Hong Kong Baptist University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.uic.edu.hk;",
        "aff_unique_abbr": "UIC;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Zhuhai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160578",
        "title": "Linear Delta Arrays for Compliant Dexterous Distributed Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new type of distributed dexterous manipulator: delta arrays. Our delta array setup consists of 64 linearly-actuated delta robots with 3D-printed compliant linkages. Through the design of the individual delta robots, the modular array structure, and distributed communication and control, we study a wide range of in-plane and out-of-plane manipulations, as well as prehensile manipulations among subsets of neighboring delta robots. We also demonstrate dexterous manipulation capabilities of the delta array using reinforcement learning while leveraging compliance. Our evaluations show that the resulting 192 DoF compliant robot is capable of performing various coordinated distributed manipulations of a variety of objects, including translation, alignment, prehensile squeezing, lifting, and grasping.",
        "primary_area": "",
        "author": "Sarvesh Patil;Tony Tao;Tess Hellebrekers;Oliver Kroemer;F. Zeynep Temel;Sarvesh Patil;Tony Tao;Tess Hellebrekers;Oliver Kroemer;F. Zeynep Temel",
        "authorids": "/37089658154;/37089893817;/37085635447;/37593222300;/37944884400;/37089658154;/37089893817;/37085635447;/37593222300;/37944884400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Meta AI Research; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160578/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1388763735008605314&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Meta Platforms, Inc.",
        "aff_unique_dep": "Robotics Institute;Meta AI Research",
        "aff_unique_url": "https://www.cmu.edu;https://meta.com",
        "aff_unique_abbr": "CMU;Meta AI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160782",
        "title": "Loc-NeRF: Monte Carlo Localization using Neural Radiance Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Loc-NeRF, a real-time vision-based robot localization approach that combines Monte Carlo localization and Neural Radiance Fields (NeRF). Our system uses a pre-trained NeRF model as the map of an environment and can localize itself in real-time using an RGB camera as the only exteroceptive sensor onboard the robot. While neural radiance fields have seen significant applications for visual rendering in computer vision and graphics, they have found limited use in robotics. Existing approaches for NeRF-based localization require both a good initial pose guess and significant computation, making them impractical for real-time robotics applications. By using Monte Carlo localization as a workhorse to estimate poses using a NeRF map model, LocNeRF is able to perform localization faster than the state of the art and without relying on an initial pose estimate. In addition to testing on synthetic data, we also run our system using real data collected by a Clearpath Jackal UGV and demonstrate for the first time the ability to perform real-time and global localization (albeit over a small workspace) with neural radiance fields. We make our code publicly available at https://github.com/MIT-SPARK/Loc-NeRF.",
        "primary_area": "",
        "author": "Dominic Maggio;Marcus Abate;Jingnan Shi;Courtney Mario;Luca Carlone;Dominic Maggio;Marcus Abate;Jingnan Shi;Courtney Mario;Luca Carlone",
        "authorids": "/37088883840;/37088503950;/37088823761;/37717347200;/37545784100;/37088883840;/37088503950;/37088823761;/37717347200;/37545784100",
        "aff": "Draper Scholar with the Perception and Embedded ML Group, Draper, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Draper Perception and Embedded ML Group, Draper, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160782/",
        "gs_citation": 114,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10404781851375765906&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Draper;Massachusetts Institute of Technology",
        "aff_unique_dep": "Perception and Embedded ML Group;Laboratory for Information & Decision Systems",
        "aff_unique_url": "https://www.draper.com;https://web.mit.edu",
        "aff_unique_abbr": ";MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161245",
        "title": "Local Layer Splitting: An Additive Manufacturing Method to Define the Mechanical Properties of Soft Pneumatic Actuators During Fabrication",
        "track": "main",
        "status": "Poster",
        "abstract": "Additive manufacturing of silicone is increasingly being explored to complement the traditional molding fabrication technique for Soft Pneumatic Actuators (SPAs). However, the mechanical behavior of SPAs is defined by their 3D form, which leads to prioritizing the SPAs mechanical properties over their aspect. In this paper, we propose a novel SPA fabrication method where the mechanical properties of a silicone part are defined during the fabrication phase rather than the 3D modeling phase, leading to the object's mechanical properties being independent of the object's aspect. This novel SPA fabrication method, named Local Layer Splitting (LLS), consists of local modifications of the printing layer height to integrate stiffness variation, thus generating controlled mechanical deformation when pressured. We discovered that silicone printing layer height impacts the final stiffness of the material, and it could be used to program bending deformation to actuators during printing. We first characterize the effect of the layer height parameters on 3D-printed silicone stiffness with tensile tests. Then, we present a custom slicer we developed to generate G-codes with local layer height variations depending on the x and y positions. We then characterize the bending and force achievable by SPAs made with the LLS process and find that they match those of state-of-the-art SPAs. Finally, we present and discuss how the LLS method impacts the SPAs design by shifting the bending behavior integration from the SPAs 3D conception to their fabrication phase.",
        "primary_area": "",
        "author": "Brice Parilusyan;Marc Teyssier;Zacharie Guillaume;Thibault Charlet;Cl\u00e9ment Duhart;Marcos Serrano;Brice Parilusyan;Marc Teyssier;Zacharie Guillaume;Thibault Charlet;Cl\u00e9ment Duhart;Marcos Serrano",
        "authorids": "/37088995849;/37089001539;/37089894188;/37088435326;/37088876101;/37089893437;/37088995849;/37089001539;/37089894188;/37088435326;/37088876101;/37089893437",
        "aff": "IRIT - Elipse, University of Toulouse 3, France; Research Center, L\u00e9onard de Vinci P\u00f4le Universitaire, France; Research Center, L\u00e9onard de Vinci P\u00f4le Universitaire, France; Research Center, L\u00e9onard de Vinci P\u00f4le Universitaire, France; Research Center, L\u00e9onard de Vinci P\u00f4le Universitaire, France; IRIT - Elipse, University of Toulouse 3, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161245/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13636808453944213749&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "University of Toulouse 3;L\u00e9onard de Vinci P\u00f4le Universitaire",
        "aff_unique_dep": "IRIT - Elipse;Research Center",
        "aff_unique_url": "https://www.univ-toulouse.fr;",
        "aff_unique_abbr": "UT3;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toulouse;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160423",
        "title": "Local Neural Descriptor Fields: Locally Conditioned Object Representations for Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot operating in a household environment will see a wide range of unique and unfamiliar objects. While a system could train on many of these, it is infeasible to predict all the objects a robot will see. In this paper, we present a method to generalize object manipulation skills acquired from a limited number of demonstrations, to novel objects from unseen shape categories. Our approach, Local Neural Descriptor Fields (L-NDF), utilizes neural descriptors defined on the local geometry of the object to effectively transfer manipulation demonstrations to novel objects at test time. In doing so, we leverage the local geometry shared between objects to produce a more general manipulation framework. We illustrate the efficacy of our approach in manipulating novel objects in novel poses - both in simulation and in the real world. Project website, videos, and code: https://elchun.github.io/lndf/.",
        "primary_area": "",
        "author": "Ethan Chun;Yilun Du;Anthony Simeonov;Tomas Lozano-Perez;Leslie Kaelbling;Ethan Chun;Yilun Du;Anthony Simeonov;Tomas Lozano-Perez;Leslie Kaelbling",
        "authorids": "/37089894859;/37089315638;/37086194255;/38273814000;/37269373600;/37089894859;/37089315638;/37086194255;/38273814000;/37269373600",
        "aff": "Computer Science and Artificial Intelligence Laboratory, MIT, USA; Computer Science and Artificial Intelligence Laboratory, MIT, USA; Computer Science and Artificial Intelligence Laboratory, MIT, USA; Computer Science and Artificial Intelligence Laboratory, MIT, USA; Computer Science and Artificial Intelligence Laboratory, MIT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160423/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13198863480505759544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161015",
        "title": "Local_INN: Implicit Map Representation and Localization with Invertible Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot localization is an inverse problem of finding a robot's pose using a map and sensor measurements. In recent years, Invertible Neural Networks (INN s) have successfully solved ambiguous inverse problems in various fields. This paper proposes a framework that approaches the localization problem with INN. We design a network that provides implicit map representation in the forward path and localization in the inverse path. By sampling the latent space in evaluation, Local_INN outputs robot poses with covariance, which can be used to estimate the uncertainty. We show that the localization performance of Local_INN is on par with current methods with much lower latency. We show detailed 2D and 3D map reconstruction from Local_INN using poses exterior to the training set. We also provide a global localization algorithm using Local_INN to tackle the kidnapping problem.",
        "primary_area": "",
        "author": "Zirui Zang;Hongrui Zheng;Johannes Betz;Rahul Mangharam;Zirui Zang;Hongrui Zheng;Johannes Betz;Rahul Mangharam",
        "authorids": "/37089459636;/37088505879;/37085882294;/37296357400;/37089459636;/37088505879;/37085882294;/37296357400",
        "aff": "Department of Electrical and Systems Engineering, the University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering, the University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering, the University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering, the University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161015/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6591703075168452197&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Electrical and Systems Engineering",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160300",
        "title": "Locate before Segment: Topology-guided Retinal Layer Segmentation in Optical Coherence Tomography Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Optical Coherence Tomography (OCT) is a non-invasive imaging technique that is instrumental in retinal disease diagnosis and treatment. Segmentation of retinal layers in OCT is an essential step, but remains challenging for common pixel-wise segmentation methods usually fail to obtain the correct layer topology. To tackle this challenge, we propose a novel Locate-to-Segment (L2S) framework to provide a layer region location guidance for pixel-wise labeling learning so as to obtain better segmentation with the correct topology and smooth boundaries. Specifically, a Structured Boundary Regression Network (SBRNet) is devised to first predict the surface positions. For effective learning on normal-size images, we design two regression branches to regress the top surface and eight layer widths separately in SBRNet to locate each layer region with absolutely correct orderings. Then, we take the prediction of SBRNet as an additional input for a common pixel-wise segmentation network to provide the guidance of correct topology. In this L2S manner, our framework takes merits of regression-based methods and pixel-wise labeling-based methods to obtain accurate segmentation with the correct topology and smooth continuous boundaries. Experimental results on a public retinal OCT dataset demonstrate the effectiveness of our method, outperforming state-of-the-art segmentation methods with the highest average Dice score of 90.29% and the lowest average MAD score of 0.782.",
        "primary_area": "",
        "author": "Ye Lu;Yutian Shen;Xiaohan Xing;Max Q.-H. Meng;Ye Lu;Yutian Shen;Xiaohan Xing;Max Q.-H. Meng",
        "authorids": "/37089345278;/37088955451;/37086496866;/37274117000;/37089345278;/37088955451;/37086496866;/37274117000",
        "aff": "Department of Electrical Engineering, The City University of Hong Kong, Hong Kong SAR, China; Department of Electrical Engineering, The City University of Hong Kong, Hong Kong SAR, China; Department of Electronic and Electrical Engineering, Shenzhen Key Laboratory of Robotics Perception and Intelligence, Southern University of Science and Technology, Shenzhen, China; Shenzhen Research Institute of The Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160300/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:mnLHcIGaxacJ:scholar.google.com/&scioq=Locate+before+Segment:+Topology-guided+Retinal+Layer+Segmentation+in+Optical+Coherence+Tomography+Images&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "The City University of Hong Kong;Southern University of Science and Technology;The Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electrical Engineering;Department of Electronic and Electrical Engineering;Shenzhen Research Institute",
        "aff_unique_url": "https://www.cityu.edu.hk;https://www.sustech.edu.cn;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CityU;SUSTech;CUHK",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160696",
        "title": "Loitering and Trajectory Tracking of Suspended Payloads in Cable-Driven Balloons Using UGVs",
        "track": "main",
        "status": "Poster",
        "abstract": "Investigations of unmanned aerial vehicles (UAV s) for planetary exploration and payload manipulation have become a strong focus of research within space robotics. Among possible solutions, balloon-based systems possess merits that make them extremely attractive, such as their simple operation mechanism and endured operation time. However, there are many hurdles to overcome to achieve robust trajectory tracking performance for balloon-based applications. In this work, in order to facilitate the control and versatile use of balloons for near-surface planetary payload manipulation, a novel robotic platform and control strategy featuring the coordinated servoing of multiple unmanned ground vehicles (UGVs) to actuate a cable-driven balloon and the suspended payload is proposed. An earthbound prototype and dynamic model of this system are designed to allow for the investigation of payload trajectory tracking performance using a tailored Model Predictive Controller in simulation and experiment.",
        "primary_area": "",
        "author": "Julius Wanner;Eric Sihite;Alireza Ramezani;Morteza Gharib;Julius Wanner;Eric Sihite;Alireza Ramezani;Morteza Gharib",
        "authorids": "/37089835737;/37088452718;/37398489300;/37299650900;/37089835737;/37088452718;/37398489300;/37299650900",
        "aff": "Department of Mechanical and Process Engineering, ETH Zurich, Z\u00fcrich, Switzerland; Graduate Aerospace Laboratories of the California Institute of Technology (Caltech GALCIT), Pasadena, CA, USA; Department of Electrical and Computer Engineering, SiliconSynapse Laboratory, Northeastern University, Boston, MA, USA; Graduate Aerospace Laboratories of the California Institute of Technology (Caltech GALCIT), Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160696/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9175160068636577816&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "ETH Zurich;California Institute of Technology;Northeastern University",
        "aff_unique_dep": "Department of Mechanical and Process Engineering;Graduate Aerospace Laboratories;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ethz.ch;https://www.caltech.edu;https://www.northeastern.edu",
        "aff_unique_abbr": "ETHZ;Caltech;NU",
        "aff_campus_unique_index": "0;1;2;1",
        "aff_campus_unique": "Z\u00fcrich;Pasadena;Boston",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "10160567",
        "title": "Loosely-coupled localization fusion system based on track-to-track fusion with bias alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "The localization system is an essential element in robotics, which can provide accurate position information. Multiple localization systems can be integrated for reliable localization operations because there are various methods for measuring the position or processing algorithms. Significantly, the track-to-track (T2T) fusion method can fuse multiple localization systems using each system's estimate without accessing the sensor's low data. However, most T2T fusion-based localization systems ignore slowly varying biases, such as drift errors, odometry errors, and offsets among multiple maps. This can degrade the localization performance because a slowly varying bias is directly reflected in the localization estimate. Therefore, a slowly varying bias must be considered in the fusion process to derive reliable estimates. This study proposes a T2T fusion-based localization system that considers a slowly varying bias. First, the slow-varying bias difference between the systems was estimated. Because each localization system can have a different bias, the estimated bias difference was used to align it with the reference system. Second, a fused estimate can be obtained by T2T fusion using biasaligned estimates. The proposed fusion system can also be used without limiting the number of inputs to the localization system. The proposed system was compared with various T2T-based localization fusion algorithms for verification in a simulation environment, and it exhibited the best performance in RMSE error comparison.",
        "primary_area": "",
        "author": "Soyeong Kim;Jaeyoung Jo;Paulo Resende;Benazouz Bradai;Kichun Jo;Soyeong Kim;Jaeyoung Jo;Paulo Resende;Benazouz Bradai;Kichun Jo",
        "authorids": "/37089854209;/37089895407;/37587390600;/37589898100;/37541109700;/37089854209;/37089895407;/37587390600;/37589898100;/37541109700",
        "aff": "Department of Smart Vehicle Engineering, Konkuk University, Seoul, Republic of Korea; Department of Smart Vehicle Engineering, Konkuk University, Seoul, Republic of Korea; Driving Assistance Research Center, Valeo, CEDEX, Bobigny, France; Driving Assistance Research Center, Valeo, CEDEX, Bobigny, France; Department of Smart Vehicle Engineering, Konkuk University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160567/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13189890280766726917&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Konkuk University;Valeo",
        "aff_unique_dep": "Department of Smart Vehicle Engineering;Driving Assistance Research Center",
        "aff_unique_url": "http://www.konkuk.ac.kr;https://www.valeo.com",
        "aff_unique_abbr": "KU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul;",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "South Korea;France"
    },
    {
        "id": "10160500",
        "title": "Lossless SIMD Compression of LiDAR Range and Attribute Scan Sequences",
        "track": "main",
        "status": "Poster",
        "abstract": "As LiDAR sensors have become ubiquitous, the need for an efficient LiDAR data compression algorithm has increased. Modern LiDARs produce gigabytes of scan data per hour (Fig. 1) and are often used in applications with limited compute, bandwidth, and storage resources. We present a fast, lossless compression algorithm for Li-DAR range and attribute scan sequences including multiple-return range, signal, reflectivity, and ambient infrared. Our algorithm\u2014dubbed \u201cJiffy\u201d\u2014achieves substantial compression by exploiting spatiotemporal redundancy and sparsity. Speed is accomplished by maximizing use of single-instruction-multiple-data (SIMD) instructions. In autonomous driving, infrastructure monitoring, drone inspection, and handheld mapping benchmarks, the Jiffy algorithm consistently outcompresses competing lossless codecs while operating at speeds in excess of 65M points/sec on a single core. In a typical autonomous vehicle use case, single-threaded Jiffy achieves 6x compression of centimeter-precision range scans at 500+ scans per second. To ensure reproducibility and enable adoption, the software is freely available as an open source library33Software is available here: http://github.com/jsford64/jiffy-compression.",
        "primary_area": "",
        "author": "Jeff Ford;Jordan Ford;Jeff Ford;Jordan Ford",
        "authorids": "/37089894847;/37088883033;/37089894847;/37088883033",
        "aff": "ComplexIQ, Atlanta, GA, USA; Department of Electrical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160500/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7591075024519191440&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "ComplexIQ;Carnegie Mellon University",
        "aff_unique_dep": ";Department of Electrical Engineering",
        "aff_unique_url": ";https://www.cmu.edu",
        "aff_unique_abbr": ";CMU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Atlanta;Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160987",
        "title": "Low-level controller in response to changes in quadrotor dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "The dynamics of all real quadrotors inevitably differ even if they are the same product. In particular, the dynamics can change significantly during the flight due to additional device attachments or overheating motors. In this study, we focus on training a low-level controller, which operates in response to dynamics-changes without prior knowledge or fine-tuning of the parameters, using reinforcement learning. We randomize the dynamics of quadrotors in the simulator and train the policy based on dynamics information extracted from the state-action history through recurrent neural networks (RNNs). In addition, our experiment demonstrates the difficulties in applying existing actor-critic structures that extract dynamics information using end-to-end RNNs for unstable quadrotors; hence, we propose a novel structure with better performance. Finally, the excellent performance of the proposed controller is verified by testing experiments that stabilize quadrotors with different dynamics. The experiment videos and the code can be found at https://github.com/jackyoung96/RNN-Quadrotor-controller.",
        "primary_area": "",
        "author": "Jae-Kyung Cho;Chan Kim;Mohamed Khalid M Jaffar;Michael W. Otte;Seong-Woo Kim;Jae-Kyung Cho;Chan Kim;Mohamed Khalid M Jaffar;Michael W. Otte;Seong-Woo Kim",
        "authorids": "/37089358297;/37089001231;/37086836562;/37604381000;/37537386000;/37089358297;/37089001231;/37086836562;/37604381000;/37537386000",
        "aff": "Seoul National University, Seoul, South Korea; Seoul National University, Seoul, South Korea; University of Maryland, Maryland, United States; University of Maryland, Maryland, United States; Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160987/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:fYRqnp58thgJ:scholar.google.com/&scioq=Low-level+controller+in+response+to+changes+in+quadrotor+dynamics&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Seoul National University;University of Maryland",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.snu.ac.kr;https://www/umd.edu",
        "aff_unique_abbr": "SNU;UMD",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Seoul;Maryland",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "10160934",
        "title": "M-EMBER: Tackling Long-Horizon Mobile Manipulation via Factorized Domain Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel method to create visuomotor mobile manipulation solutions to long-horizon activities. We propose to leverage the recent advances in robot simulation to train robust visual solutions in simulation that can transfer to the real world. While previous works have shown success applying this procedure to autonomous visual navigation and stationary manipulation, applying it to long-horizon visuomotor mobile manipulation is still an open challenge that demands both perceptual and compositional generalization of multiple skills. In this work, we develop Mobile-EMBER, or M-EMBER, a factorized method that decomposes a long-horizon mobile manipulation activity into a repertoire of primitive visual skills, reinforcement-learns each skill in simulation, and composes these skills to a long-horizon mobile manipulation activity. On a real mobile manipulation robot, we find that M-EMBER completes a long-horizon mobile manipulation activity, cleaning_kitchen, achieving over 50% success rate. This requires successfully planning and executing five factorized, learned visual skills, in sequences of up to 48 skills long.",
        "primary_area": "",
        "author": "Bohan Wu;Roberto Mart\u00edn-Mart\u00edn;Li Fei-Fei;Bohan Wu;Roberto Mart\u00edn-Mart\u00edn;Li Fei-Fei",
        "authorids": "/37089012576;/37085788640;/38273560700;/37089012576;/37085788640;/38273560700",
        "aff": "Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, The University of Texas at Austin, Austin, TX, USA; Department of Computer Science, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160934/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14462045988035386371&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;The University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Stanford;UT Austin",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stanford;Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161281",
        "title": "METEOR: A Dense, Heterogeneous, and Unstructured Traffic Dataset with Rare Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new traffic dataset, Meteor, which captures traffic patterns and multi-agent driving behaviors in unstructured scenarios. Meteor consists of more than 1000 one-minute videos, over 2 million annotated frames with bounding boxes and GPS trajectories for 16 unique agent categories, and more than 13 million bounding boxes for traffic agents. Meteor is a dataset for rare and interesting, multi-agent driving behaviors that are grouped into traffic violations, atypical interactions, and diverse scenarios. Every video in Meteor is tagged using a diverse range of factors corresponding to weather, time of the day, road conditions, and traffic density. We use Meteor to benchmark perception methods for object detection and multi-agent behavior prediction. Our key finding is that state-of-the-art models for object detection and behavior prediction, which otherwise succeed on existing datasets such as Waymo, fail on the Meteor dataset. Meteor is a step towards developing more sophisticated perception models for dense, heterogeneous, and unstructured scenarios.",
        "primary_area": "",
        "author": "Rohan Chandra;Xijun Wang;Mridul Mahajan;Rahul Kala;Rishitha Palugulla;Chandrababu Naidu;Alok Jain;Dinesh Manocha;Rohan Chandra;Xijun Wang;Mridul Mahajan;Rahul Kala;Rishitha Palugulla;Chandrababu Naidu;Alok Jain;Dinesh Manocha",
        "authorids": "/37086365992;/37089893476;/37088477105;/37545481000;/37088594932;/37089895752;/37089895480;/37267825600;/37086365992;/37089893476;/37088477105;/37545481000;/37088594932;/37089895752;/37089895480;/37267825600",
        "aff": "Department of Computer Science, University of Maryland, College Park, USA; Department of Computer Science, University of Maryland, College Park, USA; Centre for Intelligent Robotics, Indian Institute of Information Technology, Allahabad, India; Centre for Intelligent Robotics, Indian Institute of Information Technology, Allahabad, India; NavAjna Technologies Pvt. Ltd.; NavAjna Technologies Pvt. Ltd.; NavAjna Technologies Pvt. Ltd.; Department of Electrical and Computer Engineering, University of Maryland, College Park, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161281/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11570012642728645543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;1;2;2;2;0",
        "aff_unique_norm": "University of Maryland, College Park;Indian Institute of Information Technology;NavAjna Technologies",
        "aff_unique_dep": "Department of Computer Science;Centre for Intelligent Robotics;",
        "aff_unique_url": "https://www/umd.edu;https://www.iiitallahabad.ac.in;",
        "aff_unique_abbr": "UMD;IIIT Allahabad;",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "College Park;Allahabad;",
        "aff_country_unique_index": "0;0;1;1;1;1;1;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "10161263",
        "title": "MMIC-I: A Robotic Platform for Assembly Integration and Internal Locomotion through Mechanical Meta-Material Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "In-space assembly is crucial to creating large-scale space structures and enabling long term space missions. Natural limitations in the size of transportation vehicles and ISRU production facilities necessitate an additive strategy with the size of the typical structural unit being essentially fixed and inversely proportional to the final assembly size. In prior robotic and space assembly examples, reversible mechanical integration of structural modules is typically achieved with actuated alignment and fastening mechanisms onboard every structural module. Additive assembly or manufacturing planning approaches often feature a \u201cbuild front\u201d that receives new materials or parts and progresses gradually across the target geometry. The system we describe here places much of the alignment and fastener actuation systems onboard a mobile robot that can operate at a build front while companion robots (Scaling Omni-directional Lattice Locomoting Explorer, SOLL-E) provide part or material transportation. The design and evaluation of this Mobile Meta-Material Interior Co-Integrator (MMIC-I), an inchworm-style locomoting robotic assembler, is described here with an emphasis on ease of assembly and a low number of unique parts for a simple design. It is designed to assist in alignment of cuboctahedron structural unit cells with captive fasteners, defining the build front in operation. Adjacent structural unit cells are locked together with specified axial and rotational actuation of the fasteners. Hardware prototypes show that the robot is able to successfully locomote to any indexed location within a lattice structure and bolt together each set of fasteners on any interface.",
        "primary_area": "",
        "author": "Olivia Formoso;Greenfield Trinh;Damiana Catanoso;In-Won Park;Christine Gregg;Kenneth Cheung;Olivia Formoso;Greenfield Trinh;Damiana Catanoso;In-Won Park;Christine Gregg;Kenneth Cheung",
        "authorids": "/37086866094;/37086088366;/37088471339;/37287263800;/37086047057;/37086043647;/37086866094;/37086088366;/37088471339;/37287263800;/37086047057;/37086043647",
        "aff": "Coded Structures Lab, NASA Ames Research Center, Moffett Field, CA; Coded Structures Lab, NASA Ames Research Center, Moffett Field, CA; NASA Ames Research Center, KBR Inc., Moffett Field, CA; NASA Ames Research Center, KBR Inc., Moffett Field, CA; Coded Structures Lab, NASA Ames Research Center, Moffett Field, CA; Coded Structures Lab, NASA Ames Research Center, Moffett Field, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161263/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6228359585916910137&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "NASA Ames Research Center",
        "aff_unique_dep": "Coded Structures Lab",
        "aff_unique_url": "https://ames.nasa.gov",
        "aff_unique_abbr": "NASA Ames",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Moffett Field",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161450",
        "title": "MMRDN: Consistent Representation for Multi-View Manipulation Relationship Detection in Object-Stacked Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation relationship detection (MRD) aims to guide the robot to grasp objects in the right order, which is important to ensure the safety and reliability of grasping in object stacked scenes. Previous works infer manipulation relationship by deep neural network trained with data collected from a predefined view, which has limitation in visual dislocation in unstructured environments. Multi-view data provide more comprehensive information in space, while a challenge of multi-view MRD is domain shift. In this paper, we propose a novel multi-view fusion framework, namely multi-view MRD network (MMRDN), which is trained by 2D and 3D multi-view data. We project the 2D data from different views into a common hidden space and fit the embeddings with a set of Von-Mises-Fisher distributions to learn the consistent representations. Besides, taking advantage of position information within the 3D data, we select a set of KK Maximum Vertical Neighbors (KMVN) points from the point cloud of each object pair, which encodes the relative position of these two objects. Finally, the features of multi-view 2D and 3D data are concatenated to predict the pairwise relationship of objects. Experimental results on the challenging REGRAD dataset show that MMRDN outperforms the state-of-the-art methods in multi-view MRD tasks. The results also demonstrate that our model trained by synthetic data is capable to transfer to real-world scenarios.",
        "primary_area": "",
        "author": "Han Wang;Jiayuan Zhang;Lipeng Wan;Xingyu Chen;Xuguang Lan;Nanning Zheng;Han Wang;Jiayuan Zhang;Lipeng Wan;Xingyu Chen;Xuguang Lan;Nanning Zheng",
        "authorids": "/37089083581;/37089896135;/37087323777;/37085568094;/37270865300;/37271536700;/37089083581;/37089896135;/37087323777;/37085568094;/37270865300;/37271536700",
        "aff": "National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Application, Institute of Artificial Intelligence and Robotics Xi'an Jiaotong University, Xi'an, Shaanxi, China; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Application, Institute of Artificial Intelligence and Robotics Xi'an Jiaotong University, Xi'an, Shaanxi, China; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Application, Institute of Artificial Intelligence and Robotics Xi'an Jiaotong University, Xi'an, Shaanxi, China; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Application, Institute of Artificial Intelligence and Robotics Xi'an Jiaotong University, Xi'an, Shaanxi, China; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Application, Institute of Artificial Intelligence and Robotics Xi'an Jiaotong University, Xi'an, Shaanxi, China; National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Application, Institute of Artificial Intelligence and Robotics Xi'an Jiaotong University, Xi'an, Shaanxi, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161450/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4229373294544631825&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Xi'an Jiaotong University",
        "aff_unique_dep": "Institute of Artificial Intelligence and Robotics",
        "aff_unique_url": "http://www.xjtu.edu.cn",
        "aff_unique_abbr": "XJTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160588",
        "title": "MOFT: Monocular odometry based on deep depth and careful feature selection and tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous localization in unknown environments is a fundamental problem in many emerging fields and the monocular visual approach offers many advantages, due to being a rich source of information and avoiding comparatively more complicated setups and multisensor calibration. Deep learning opened new venues for monocular odometry yielding not only end-to-end approaches but also hybrid methods combining the well studied geometry with specific deep components. In this paper we propose a monocular odometry that leverages deep depth within a feature based geometrical framework yielding a lightweight frame-to-frame approach with metrically scaled trajectories and state-of-the-art accuracy. The front-end is based on a multihypothesis matcher with perspective correction coupled with deep depth predictions that enables careful feature selection and tracking; especially of ground plane features that are suitable for translation estimation. The back-end is based on point-to-epipolar line minimization for rotation and unit translation estimation, followed by deep depth aided reprojection error minimization for metrically correct translation estimation. Furthermore, we also present a domain shift adaptation approach that allows for generalization over different camera intrinsic and extrinsic setups. The proposed approach is evaluated on the KITTI and KITTI-360 datasets, showing competitive results and in most cases outperforming other state-of-the-art stereo and monocular methods.",
        "primary_area": "",
        "author": "Karlo Koledi\u0107;Igor Cvi\u0161i\u0107;Ivan Markovi\u0107;Ivan Petrovi\u0107;Karlo Koledi\u0107;Igor Cvi\u0161i\u0107;Ivan Markovi\u0107;Ivan Petrovi\u0107",
        "authorids": "/37089893641;/37076757900;/37697833300;/37564131900;/37089893641;/37076757900;/37697833300;/37564131900",
        "aff": "University of Zagreb Faculty of Electrical Engineering and Computing, Laboratory for Autonomous, Systems and Mobile Robotics, Zagreb, Croatia; University of Zagreb Faculty of Electrical Engineering and Computing, Laboratory for Autonomous, Systems and Mobile Robotics, Zagreb, Croatia; University of Zagreb Faculty of Electrical Engineering and Computing, Laboratory for Autonomous, Systems and Mobile Robotics, Zagreb, Croatia; University of Zagreb Faculty of Electrical Engineering and Computing, Laboratory for Autonomous, Systems and Mobile Robotics, Zagreb, Croatia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160588/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5441192426122075242&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Zagreb",
        "aff_unique_dep": "Faculty of Electrical Engineering and Computing",
        "aff_unique_url": "https://www.unizg.hr",
        "aff_unique_abbr": "UNIZG",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zagreb",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Croatia"
    },
    {
        "id": "10161280",
        "title": "MPC with Sensor-Based Online Cost Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Model predictive control is a powerful tool to generate complex motions for robots. However, it often requires solving non-convex problems online to produce rich behaviors, which is computationally expensive and not always practical in real time. Additionally, direct integration of high dimensional sensor data (e.g. RGB-D images) in the feedback loop is challenging with current state-space methods. This paper aims to address both issues. It introduces a model predictive control scheme, where a neural network constantly updates the cost function of a quadratic program based on sensory inputs, aiming to minimize a general non-convex task loss without solving a non-convex problem online. By updating the cost, the robot is able to adapt to changes in the environment directly from sensor measurement without requiring a new cost design. Furthermore, since the quadratic program can be solved efficiently with hard constraints, a safe deployment on the robot is ensured. Experiments with a wide variety of reaching tasks on an industrial robot manipulator demonstrate that our method can efficiently solve complex non-convex problems with high-dimensional visual sensory inputs, while still being robust to external disturbances.",
        "primary_area": "",
        "author": "Avadesh Meduri;Huaijiang Zhu;Armand Jordana;Ludovic Righetti;Avadesh Meduri;Huaijiang Zhu;Armand Jordana;Ludovic Righetti",
        "authorids": "/37088355351;/37086330610;/37089432602;/37295828600;/37088355351;/37086330610;/37089432602;/37295828600",
        "aff": "Tandon School of Engineering, New York University, USA; Tandon School of Engineering, New York University, USA; Tandon School of Engineering, New York University, USA; Tandon School of Engineering, New York University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161280/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14671639602014748813&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Tandon School of Engineering",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160342",
        "title": "MPOGames: Efficient Multimodal Partially Observable Dynamic Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Game theoretic methods have become popular for planning and prediction in situations involving rich multi-agent interactions. However, these methods often assume the existence of a single local Nash equilibria and are hence unable to handle uncertainty in the intentions of different agents. While maximum entropy (MaxEnt) dynamic games try to address this issue, practical approaches solve for MaxEnt Nash equilibria using linear-quadratic approximations which are restricted to unimodal responses and unsuitable for scenarios with multiple local Nash equilibria. By reformulating the problem as a POMDP, we propose MPOGames, a method for efficiently solving MaxEnt dynamic games that captures the interactions between local Nash equilibria. We show the importance of uncertainty-aware game theoretic methods via a two-agent merge case study. Finally, we prove the real-time capabilities of our approach with hardware experiments on a 1/10th scale car platform.",
        "primary_area": "",
        "author": "Oswin So;Paul Drews;Thomas Balch;Velin Dimitrov;Guy Rosman;Evangelos A. Theodorou;Oswin So;Paul Drews;Thomas Balch;Velin Dimitrov;Guy Rosman;Evangelos A. Theodorou",
        "authorids": "/37089447383;/37089308631;/37089893860;/37089894744;/37393688300;/37546007800;/37089447383;/37089308631;/37089893860;/37089894744;/37393688300;/37546007800",
        "aff": "Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160342/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15011077210669656322&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Toyota Research Institute;Georgia Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tri.global;https://www.gatech.edu",
        "aff_unique_abbr": "TRI;Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161197",
        "title": "MRI-powered Magnetic Miniature Capsule Robot with HIFU-controlled On-demand Drug Delivery",
        "track": "main",
        "status": "Poster",
        "abstract": "Magnetic resonance imaging (MRI)-guided robotic systems offer great potential for new minimally invasive medical tools, including MRI-powered miniature robots. By re-purposing the imaging hardware of an MRI scanner, the magnetic miniature robot could be navigated into the remote part of the patient's body without needing tethered endoscopic tools. However, state-of-art MRI-powered magnetic miniature robots have limited functionality besides navigation. Here, we propose an MRI-powered magnetic miniature capsule robot benefiting from acoustic streaming forces generated by MRI-guided high-intensity focus ultrasound (HIFU) for controlled drug release. Our design comprises a polymer capsule shell with a submillimeter-diameter drug-release hole that captures an air bubble functioning as a stopper. We use the HIFU pulse to initiate drug release by removing the air bubble once the capsule robot reaches the target location. By controlling acoustic pressure, we also regulate the drug release rate for multiple locations targeting during navigation. We demonstrated that the proposed magnetic capsule robot could travel at high speed, up to 1.13 cm/s in ex vivo porcine small intestine, and release drug to multiple target sites in a single operation, using a combination of MRI-powered actuation and HIFU-controlled release. The proposed MRI-guided microrobotic drug release system will greatly impact minimally invasive medical procedures by allowing on-demand targeted drug delivery.",
        "primary_area": "",
        "author": "Mehmet Efe Tiryaki;Fatih Do\u011fang\u00fcn;Cem Balda Dayan;Paul Wrede;Metin Sitti;Mehmet Efe Tiryaki;Fatih Do\u011fang\u00fcn;Cem Balda Dayan;Paul Wrede;Metin Sitti",
        "authorids": "/37087324110;/37089893214;/37089892439;/37089893054;/37265828200;/37087324110;/37089893214;/37089892439;/37089893054;/37265828200",
        "aff": "ETH Zurich, Institute for Biomedical Engineering, Zurich, Switzerland; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Max Planck and ETH Center for Learning Systems, Stuttgart, Germany; College of Engineering and School of Medicine, Ko\u00e7 University, Istanbul, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161197/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=191200042954955893&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;3",
        "aff_unique_norm": "ETH Zurich;Max Planck Institute for Intelligent Systems;Max Planck Institute;Ko\u00e7 University",
        "aff_unique_dep": "Institute for Biomedical Engineering;Physical Intelligence Department;Center for Learning Systems;College of Engineering",
        "aff_unique_url": "https://www.ethz.ch;https://www.mpi-is.mpg.de;https://cls.mpdl.mpg.de;https://www.koc.edu.tr",
        "aff_unique_abbr": "ETHZ;MPI-IS;MP-ETH CLS;Ko\u00e7",
        "aff_campus_unique_index": "0;1;1;1;2",
        "aff_campus_unique": "Zurich;Stuttgart;Istanbul",
        "aff_country_unique_index": "0;1;1;1;2",
        "aff_country_unique": "Switzerland;Germany;Turkey"
    },
    {
        "id": "10161329",
        "title": "MVFusion: Multi-View 3D Object Detection with Semantic-aligned Radar and Camera Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-view radar-camera fused 3D object detection provides a farther detection range and more helpful features for autonomous driving, especially under adverse weather. The current radar-camera fusion methods deliver kinds of designs to fuse radar information with camera data. However, these fusion approaches usually adopt the straightforward concatenation operation between multi-modal features, which ignores the semantic alignment with radar features and sufficient correlations across modals. In this paper, we present MVFusion, a novel Multi-View radar-camera Fusion method to achieve semantic-aligned radar features and enhance the cross-modal information interaction. To achieve so, we inject the semantic alignment into the radar features via the semantic-aligned radar encoder (SARE) to produce image-guided radar features. Then, we propose the radar-guided fusion transformer (RGFT) to fuse our radar and image features to strengthen the two modals' correlation from the global scope via the cross-attention mechanism. Extensive experiments show that MVFusion achieves state-of-the-art performance (51.7% NDS and 45.3% mAP) on the nuScenes dataset. We shall release our code and trained networks upon publication.",
        "primary_area": "",
        "author": "Zizhang Wu;Guilian Chen;Yuanzhu Gan;Lei Wang;Jian Pu;Zizhang Wu;Guilian Chen;Yuanzhu Gan;Lei Wang;Jian Pu",
        "authorids": "/37088645948;/37089894686;/37089197542;/37089893772;/37086254785;/37088645948;/37089894686;/37089197542;/37089893772;/37086254785",
        "aff": "Zongmu Technology, China; Zongmu Technology, China; Zongmu Technology, China; Zongmu Technology, China; Fudan University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161329/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8483533809036217781&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Zongmu Technology;Fudan University",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.fudan.edu.cn",
        "aff_unique_abbr": ";Fudan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161089",
        "title": "MVTrans: Multi-View Perception of Transparent Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Transparent object perception is a crucial skill for applications such as robot manipulation in household and laboratory settings. Existing methods utilize RGB-D or stereo inputs to handle a subset of perception tasks including depth and pose estimation. However transparent object perception remains to be an open problem. In this paper, we forgo the unreliable depth map from RGB-D sensors and extend the stereo based method. Our proposed method, MVTrans, is an end-to-end multi-view architecture with multiple perception capabilities, including depth estimation, segmentation, and pose estimation. Additionally, we establish a novel procedural photo-realistic dataset generation pipeline and create a large-scale transparent object detection dataset, Syn-TODD, which is suitable for training networks with all three modalities, RGB-D, stereo and multi-view RGB. https://ac-rad.github.io/MVTrans/",
        "primary_area": "",
        "author": "Yi Ru Wang;Yuchi Zhao;Haoping Xu;Sagi Eppel;Al\u00e1n Aspuru-Guzik;Florian Shkurti;Animesh Garg;Yi Ru Wang;Yuchi Zhao;Haoping Xu;Sagi Eppel;Al\u00e1n Aspuru-Guzik;Florian Shkurti;Animesh Garg",
        "authorids": "/37089895545;/37089894419;/37089894983;/37089894485;/38277946300;/37706697200;/37086330576;/37089895545;/37089894419;/37089894983;/37089894485;/38277946300;/37706697200;/37086330576",
        "aff": "University of Washington; University of Waterloo; University of Toronto & Vector Institute; University of Toronto & Vector Institute; University of Toronto & Vector Institute; University of Toronto & Vector Institute; Nvidia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161089/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14007799516469371798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;2;2;3",
        "aff_unique_norm": "University of Washington;University of Waterloo;University of Toronto;NVIDIA Corporation",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.washington.edu;https://uwaterloo.ca;https://www.utoronto.ca;https://www.nvidia.com",
        "aff_unique_abbr": "UW;UW;U of T;NVIDIA",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0;1;1;1;1;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "10161042",
        "title": "MagTac: Magnetic Six-Axis Force/Torque Fingertip Tactile Sensor for Robotic Hand Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a novel hall-effect-based six-axis force/torque (F/T) tactile sensor integrated into the fingertip of robotic hands. When the robotic hands performs the grasping tasks in an unstructured environment, the visual information plays a main role in sensing the external properties of the objects. However, the various intrinsic properties of the objects such as softness, roughness, mass distribution, and weight cannot be measured properly only with the visual information. To detect the various force information in performing diverse tasks, we aim to implement the six-axis F/T fingertip tactile sensor with hall-effect-based principle. The experimental results demonstrate that the proposed sensor can measure the six-axis F/T with average errors of about 3.3%. In addition, it is observed that the effect of stray field can be shielded by applying a soft magnetic shielding film to the sensor.",
        "primary_area": "",
        "author": "Sungwoo Park;Sang-Rok Oh;Donghyun Hwang;Sungwoo Park;Sang-Rok Oh;Donghyun Hwang",
        "authorids": "/37089396469;/37279130300;/38017242900;/37089396469;/37279130300;/38017242900",
        "aff": "School of Electrical Engineering, Korea University, Seoul, South Korea; Center for Robotics Research, KIST, Seoul, South Korea; Center for Robotics Research, KIST, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161042/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4176161771207905393&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Korea University;KIST",
        "aff_unique_dep": "School of Electrical Engineering;Center for Robotics Research",
        "aff_unique_url": "http://www.korea.ac.kr;https://www.kist.re.kr",
        "aff_unique_abbr": "KU;KIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160695",
        "title": "Magnetic Ball Chain Robots for Endoluminal Interventions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a novel class of hyperredun-dant robots comprised of chains of permanently magnetized spheres enclosed in a cylindrical polymer skin. With their shape controlled using an externally-applied magnetic field, the spherical joints of these robots enable them to bend to very small radii of curvature. These robots can be used as steerable tips for endoluminal instruments. A kinematic model is derived based on minimizing magnetic and elastic potential energy. Simulation is used to demonstrate the enhanced steerability of these robots in comparison to magnetic soft continuum robots designed using either distributed or lumped magnetic material. Experiments are included to validate the model and to demonstrate the steering capability of ball chain robots in bifurcating channels.",
        "primary_area": "",
        "author": "Giovanni Pittiglio;Margherita Mencattelli;Pierre E. Dupont;Giovanni Pittiglio;Margherita Mencattelli;Pierre E. Dupont",
        "authorids": "/37086690861;/37085502011;/37268329700;/37086690861;/37085502011;/37268329700",
        "aff": "Department of Cardio-vascular Surgery, Boston Children's Hospital, Harvard Medical School, Boston, MA, USA; Department of Cardio-vascular Surgery, Boston Children's Hospital, Harvard Medical School, Boston, MA, USA; Department of Cardio-vascular Surgery, Boston Children's Hospital, Harvard Medical School, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160695/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17165425039993012400&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard Medical School",
        "aff_unique_dep": "Department of Cardio-vascular Surgery",
        "aff_unique_url": "https://hms.harvard.edu",
        "aff_unique_abbr": "HMS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160568",
        "title": "Mapping Waves with an Uncrewed Surface Vessel via Gaussian Process Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots are well suited for environmental surveys because they can travel to any area of interest and react to observations without the need for pre-existing infrastructure or significant setup time. However, vehicle motion constraints limit where and when measurements occur. This is challenging for a single vehicle observing a time-varying phenomenon, such as coastal waves, but the ability to generate a spatiotemporal map would have immediate scientific and engineering applications. In this paper, an uncrewed surface vessel (USV) was used to measure waves on the coast of Lake Ontario, Canada. Data were collected from a low-cost inertial measurement system onboard the USV and processed in an offline Gaussian process regression (GPR) workflow to create a spatiotemporal wave model. Frequency analysis of raw sensor data was used to best select and design kernel functions, and to initialize hyperparameters. The relative speed of the waves limited the ability to make complete wave reconstructions, but GPR captured the dominant periodic components of the waves despite irregularities in the signals. After optimization, the hyperparameters indicate a dominant signal with a wave period of 0.87 \\mathbf{s}\\mathbf{s}, which concurs with ground truth estimates.",
        "primary_area": "",
        "author": "Thomas M. C. Sears;M. Riley Cooper;Joshua A. Marshall;Thomas M. C. Sears;M. Riley Cooper;Joshua A. Marshall",
        "authorids": "/37089658597;/37089895295;/37269656200;/37089658597;/37089895295;/37269656200",
        "aff": "Department of Electrical & Computer Engineering, Ingenuity Labs Research Institute, Queen's University at Kingston which is situated on the territory of the Haudenosaunee and the Anishinaabek., Ontario, Canada; Department of Electrical & Computer Engineering, Ingenuity Labs Research Institute, Queen's University at Kingston which is situated on the territory of the Haudenosaunee and the Anishinaabek., Ontario, Canada; Department of Electrical & Computer Engineering, Ingenuity Labs Research Institute, Queen's University at Kingston which is situated on the territory of the Haudenosaunee and the Anishinaabek., Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160568/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3500287369369822659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queen's University at Kingston",
        "aff_unique_dep": "Department of Electrical & Computer Engineering",
        "aff_unique_url": "https://www.queensu.ca",
        "aff_unique_abbr": "Queen's U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kingston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160590",
        "title": "Mask3D: Mask Transformer for 3D Semantic Instance Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern 3D semantic instance segmentation approaches predominantly rely on specialized voting mechanisms followed by carefully designed geometric clustering techniques. Building on the successes of recent Transformer-based methods for object detection and image segmentation, we propose the first Transformer-based approach for 3D semantic instance segmentation. We show that we can leverage generic Transformer building blocks to directly predict instance masks from 3D point clouds. In our model - called Mask3D - each object instance is represented as an instance query. Using Transformer decoders, the instance queries are learned by iteratively attending to point cloud features at multiple scales. Combined with point features, the instance queries directly yield all instance masks in parallel. Mask3D has several advantages over current state-of-the-art approaches, since it neither relies on (1) voting schemes which require hand-selected geometric properties (such as centers) nor (2) geometric grouping mechanisms requiring manually-tuned hyper-parameters (e.g. radii) and (3) enables a loss that directly optimizes instance masks. Mask3D sets a new state-of-the-art on ScanNet test (+6.2mAP), S3DIS 6-fold (+10.1 mAP), STPLS3D (+11.2 mAP) and ScanNet200 test (+12.4 mAP).",
        "primary_area": "",
        "author": "Jonas Schult;Francis Engelmann;Alexander Hermans;Or Litany;Siyu Tang;Bastian Leibe;Jonas Schult;Francis Engelmann;Alexander Hermans;Or Litany;Siyu Tang;Bastian Leibe",
        "authorids": "/37088453890;/37085782069;/37085358298;/37085781338;/37087233283;/37298473000;/37088453890;/37085782069;/37085358298;/37085781338;/37087233283;/37298473000",
        "aff": "Computer Vision Group, RWTH Aachen University, Germany; ETH AI Center, Z\u00fcrich, Switzerland; Computer Vision Group, RWTH Aachen University, Germany; NVIDIA, Santa Clara, USA; Computer Vision and Learning Group, ETH Z\u00fcrich, Switzerland; Computer Vision Group, RWTH Aachen University, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160590/",
        "gs_citation": 272,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18164235719100490444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;1;0",
        "aff_unique_norm": "RWTH Aachen University;ETH Z\u00fcrich;NVIDIA",
        "aff_unique_dep": "Computer Vision Group;ETH AI Center;",
        "aff_unique_url": "https://www.rwth-aachen.de;https://www.ethz.ch;https://www.nvidia.com",
        "aff_unique_abbr": "RWTH;ETH;NV",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "Aachen;Z\u00fcrich;Santa Clara;",
        "aff_country_unique_index": "0;1;0;2;1;0",
        "aff_country_unique": "Germany;Switzerland;United States"
    },
    {
        "id": "10161170",
        "title": "Mechanical Intelligence for Prehensile In-Hand Manipulation of Spatial Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "The application of mechanical and other physical properties to the development of robotic systems that can easily adapt to changing external situations is known as mechanical intelligence. Following this concept, many robot hand designs can produce self-adaptive and versatile grasps with simple underactuated fingers and open-loop control, while mechanical- intelligent strategies for dexterous manipulation are still limited. This paper proposes a mechanical-intelligent technique to facilitate dexterous manipulation, in particular prehensile inhand manipulation. The proposed strategy is based on the generation of complex spatial trajectories of the hand-object system, controlled in open loop with the minimum number of actuators and using simple low-level non-position modes. This approach is exemplified by the rigorous analysis and testing of a three-fingered two-actuator underactuated robot hand, called the helical hand, which is capable of generating helical prehensile in-hand manipulation of diversiform objects under error tolerance controlled by constant speed algorithm.",
        "primary_area": "",
        "author": "Qiujie Lu;Zhongxue Gan;Xinran Wang;Guochao Bai;Zhuang Zhang;Nicolas Rojas;Qiujie Lu;Zhongxue Gan;Xinran Wang;Guochao Bai;Zhuang Zhang;Nicolas Rojas",
        "authorids": "/37086808828;/37087467032;/37089372289;/37086601108;/37088364196;/37990657400;/37086808828;/37087467032;/37089372289;/37086601108;/37088364196;/37990657400",
        "aff": "REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; Academy for Engineering and Technology, Fudan University, Shanghai, China; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; ChangingTek Ltd, Wangjing Science & Technology Innovation Park, Beijing, China; School of Engineering, Westlake University, Hangzhou, China; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161170/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12630693771176208002&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;3;0",
        "aff_unique_norm": "Imperial College London;Fudan University;ChangingTek Ltd;Westlake University",
        "aff_unique_dep": "Dyson School of Design Engineering;Academy for Engineering and Technology;;School of Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.fudan.edu.cn;;https://www.westlake.edu.cn",
        "aff_unique_abbr": "ICL;Fudan;;",
        "aff_campus_unique_index": "0;1;0;3;0",
        "aff_campus_unique": "London;Shanghai;;Hangzhou",
        "aff_country_unique_index": "0;1;0;1;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "10160665",
        "title": "Memory-based Exploration-value Evaluation Model for Visual Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a hierarchical visual navigation solution, called Memory-based Exploration-value Evaluation Model (MEEM), to improve the agent's navigation performance. MEEM employs a hierarchical policy to tackle the challenge of sparse rewards, holds an episodic memory to store the historical information of the agent, and applies an Exploration-value Evaluation Model to calculate an exploration-value for action planning at each location in the observable area. We experimentally verify MEEM by navigation performance comparison on two datasets including the grid-map dataset and the 3D scenes Gibson dataset, where our approach achieves state-of-the-art performance on both. Specifically, the overall success rate of MEEM is 95% on the grid-map dataset while the best competitor reaches 68% only. As for the Gibson dataset, the success rate of ours and the best competitor SemExp are 69.8% and 54.4%, respectively. Ablation analysis on the tile-map dataset indicates that all three components of MEEM have positive effects.",
        "primary_area": "",
        "author": "Yongquan Feng;Liyang Xu;Minglong Li;Ruochun Jin;Da Huang;Shaowu Yang;Wenjing Yang;Yongquan Feng;Liyang Xu;Minglong Li;Ruochun Jin;Da Huang;Shaowu Yang;Wenjing Yang",
        "authorids": "/37086113880;/37085736392;/37085814052;/37086478586;/37088855100;/37085409104;/37085869205;/37086113880;/37085736392;/37085814052;/37086478586;/37088855100;/37085409104;/37085869205",
        "aff": "Institute for Quantum Information State Key Laboratory of High Performance Computing, College of Computer Science and Technology, National University of Defense Technology, Changsha, China; Institute for Quantum Information State Key Laboratory of High Performance Computing, College of Computer Science and Technology, National University of Defense Technology, Changsha, China; Institute for Quantum Information State Key Laboratory of High Performance Computing, College of Computer Science and Technology, National University of Defense Technology, Changsha, China; Institute for Quantum Information State Key Laboratory of High Performance Computing, College of Computer Science and Technology, National University of Defense Technology, Changsha, China; Institute for Quantum Information State Key Laboratory of High Performance Computing, College of Computer Science and Technology, National University of Defense Technology, Changsha, China; Institute for Quantum Information State Key Laboratory of High Performance Computing, College of Computer Science and Technology, National University of Defense Technology, Changsha, China; Institute for Quantum Information State Key Laboratory of High Performance Computing, College of Computer Science and Technology, National University of Defense Technology, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160665/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17341704216108834593&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "College of Computer Science and Technology",
        "aff_unique_url": "http://www.nudt.edu.cn",
        "aff_unique_abbr": "NUDT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160513",
        "title": "Meta-Learning-Based Optimal Control for Soft Robotic Manipulators to Interact with Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe and efficient robot-environment interaction is a critical but challenging problem as robots are being increasingly employed to operate in unstructured and unpredictable environments. Soft robots are inherently compliant to safely interact with environments but their high nonlinearity exacerbates control difficulties. Meta-learning provides a powerful tool for fast online model adaptation because it can learn an efficient model from data across different environments. Thus, this work applies the idea of meta-learning for the control of soft robotics. In particular, a target-oriented proactive search strategy is firstly performed to collect environment-specific data efficiently when a new interaction environment occurs. Then meta-learning exploits past experience to train a data-driven probabilistic model prior, and the model prior is online updated to be fast adapted to the new environment. Lastly, a model-based optimal control policy is utilized to drive the robot to desired performance. Our approach controls a soft robotic manipulator to achieve the desired position and contact force simultaneously when interacting with unknown changing environments. Overall, this work provides a viable control approach for soft robots to interact with unknown environments.",
        "primary_area": "",
        "author": "Zhiqiang Tang;Peiyi Wang;Wenci Xin;Zhexin Xie;Longxin Kan;Muralidharan Mohanakrishnan;Cecilia Laschi;Zhiqiang Tang;Peiyi Wang;Wenci Xin;Zhexin Xie;Longxin Kan;Muralidharan Mohanakrishnan;Cecilia Laschi",
        "authorids": "/37086918698;/37088964593;/37088533289;/37085842444;/37089895164;/37089823794;/37283624400;/37086918698;/37088964593;/37088533289;/37085842444;/37089895164;/37089823794;/37283624400",
        "aff": "Department of Mechanical Engineering, National University of Singapore, Singapore; Robotics Research Center, Beijing Jiaotong University, Beijing, China; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160513/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9228640766146739182&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "National University of Singapore;Beijing Jiaotong University",
        "aff_unique_dep": "Department of Mechanical Engineering;Robotics Research Center",
        "aff_unique_url": "https://www.nus.edu.sg;http://www.bjtu.edu.cn",
        "aff_unique_abbr": "NUS;BJTU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Beijing",
        "aff_country_unique_index": "0;1;0;0;0;0;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "10160626",
        "title": "Meta-Reinforcement Learning via Language Instructions",
        "track": "main",
        "status": "Poster",
        "abstract": "Although deep reinforcement learning has recently been very successful at learning complex behaviors, it requires a tremendous amount of data to learn a task. One of the fundamental reasons causing this limitation lies in the nature of the trial-and-error learning paradigm of reinforcement learning, where the agent communicates with the environment and pro-gresses in the learning only relying on the reward signal. This is implicit and rather insufficient to learn a task well. On the con-trary, humans are usually taught new skills via natural language instructions. Utilizing language instructions for robotic motion control to improve the adaptability is a recently emerged topic and challenging. In this paper, we present a meta-RL algorithm that addresses the challenge of learning skills with language instructions in multiple manipulation tasks. On the one hand, our algorithm utilizes the language instructions to shape its in-terpretation of the task, on the other hand, it still learns to solve task in a trial-and-error process. We evaluate our algorithm on the robotic manipulation benchmark (Meta-World) and it significantly outperforms state-of-the-art methods in terms of training and testing task success rates. Codes are available at https://tumi6robot.wixsite.com/million.",
        "primary_area": "",
        "author": "Zhenshan Bing;Alexander Koch;Xiangtong Yao;Kai Huang;Alois Knoll;Zhenshan Bing;Alexander Koch;Xiangtong Yao;Kai Huang;Alois Knoll",
        "authorids": "/37085994830;/38354587100;/37086962477;/37534912900;/37276234100;/37085994830;/38354587100;/37086962477;/37534912900;/37276234100",
        "aff": "Department of Informatics, Technical University of Munich, Germany; Department of Informatics, Technical University of Munich, Germany; Department of Informatics, Technical University of Munich, Germany; School of Data and Computer Science, Sun Yat-sen University, China; Department of Informatics, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160626/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6636524312189861254&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;Sun Yat-sen University",
        "aff_unique_dep": "Department of Informatics;School of Data and Computer Science",
        "aff_unique_url": "https://www.tum.de;http://www.sysu.edu.cn/",
        "aff_unique_abbr": "TUM;SYSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "10160313",
        "title": "Mimicking Real Forces on a Drone Through a Haptic Suit to Enable Cost-Effective Validation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots operate under certain forces that affect their behavior. Consider, a drone meant to deliver packages must hold its pose as long as it operates under its weight and wind limits. Validating that such a drone handles external forces correctly is key to ensuring its safety. Nevertheless, validating the system's behavior under the effect of such forces can be difficult and costly. For example, checking the effects of different wind magnitudes may require waiting for the matching outdoor conditions or requiring wind tunnels. Checking the effects of different package sizes and shapes may require many slow and laborious iterations, and validating the combinations of wind gusts and package configurations is often hard to replicate. This work introduces a framework to overcome such challenges by mimicking external forces exercised on a drone with limited cost, setup, and space. The framework consists of a haptic suit device with directional propellers that can be mounted onto a drone, a synthesizer to transform intended forces into setpoints for the suit's directional propellers, and a controller for the suit to meet those setpoints. We conduct a study to assess the framework's capabilities under multiple scenarios involving various forces. Our findings show that the haptic suit framework can recreate real-world forces on the drone with acceptable precision.",
        "primary_area": "",
        "author": "Carl Hildebrandt;Wen Ying;Seongkook Heo;Sebastian Elbaum;Carl Hildebrandt;Wen Ying;Seongkook Heo;Sebastian Elbaum",
        "authorids": "/37086580389;/37089823159;/37089825879;/37272376100;/37086580389;/37089823159;/37089825879;/37272376100",
        "aff": "University of Virginia, USA; University of Virginia, USA; University of Virginia, USA; University of Virginia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160313/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:lLhfK7WnJuEJ:scholar.google.com/&scioq=Mimicking+Real+Forces+on+a+Drone+Through+a+Haptic+Suit+to+Enable+Cost-Effective+Validation&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161401",
        "title": "Minimally Constrained Multi-Robot Coordination with Line-of-Sight Connectivity Maintenance",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider a team of mobile robots executing simultaneously multiple behaviors by different subgroups, while maintaining global and subgroup line-of-sight (LOS) network connectivity that minimally constrains the original multi-robot behaviors. The LOS connectivity between pairwise robots is preserved when two robots stay within the limited communication range and their LOS remains occlusion-free from static obstacles while moving. By using control barrier functions (CBF) and minimum volume enclosing ellipsoids (MVEE), we first introduce the LOS connectivity barrier certificate (LOS-CBC) to characterize the state-dependent admissible control space for pairwise robots, from which their resulting motion will keep the two robots LOS connected over time. We then propose the Minimum Line-of-Sight Connectivity Constraint Spanning Tree (MLCCST) as a step-wise bilevel optimization framework to jointly optimize (a) the minimum set of LOS edges to actively maintain, and (b) the control revision with respect to a nominal multi-robot controller due to LOS connectivity maintenance. As proved in the theoretical analysis, this allows the robots to improvise the optimal composition of LOS-CBC control constraints that are least constraining around the nominal controllers, and at the same time enforce the global and subgroup LOS connectivity through the resulting preserved set of pairwise LOS edges. The framework thus leads to robots staying as close to their nominal behaviors, while exhibiting dynamically changing LOS-connected network topology that provides the greatest flexibility for the existing multi-robot tasks in real-time. We demonstrate the effectiveness of our approach through simulations with up to 64 robots.",
        "primary_area": "",
        "author": "Yupeng Yang;Yiwei Lyu;Wenhao Luo;Yupeng Yang;Yiwei Lyu;Wenhao Luo",
        "authorids": "/37089893558;/37088505262;/37085748889;/37089893558;/37088505262;/37085748889",
        "aff": "Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161401/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12938969538384467280&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of North Carolina at Charlotte;Carnegie Mellon University",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.uncc.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UNCC;CMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Charlotte;Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161119",
        "title": "Minimizing Human Assistance: Augmenting a Single Demonstration for Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of human demonstrations in reinforcement learning has proven to significantly improve agent performance. However, any requirement for a human to manually \u2018teach\u2019 the model is somewhat antithetical to the goals of reinforcement learning. This paper attempts to minimize human involvement in the learning process while retaining the performance advantages by using a single human example collected through a simple-to-use virtual reality simulation to assist with RL training. Our method augments a single demonstration to generate numerous human-like demonstrations that, when combined with Deep Deterministic Policy Gradients and Hindsight Experience Replay (DDPG + HER) significantly improve training time on simple tasks and allows the agent to solve a complex task (block stacking) that DDPG + HER alone cannot solve. The model achieves this significant training advantage using a single human example, requiring less than a minute of human input. Moreover, despite learning from a human example, the agent is not constrained to human-level performance, often learning a policy that is significantly different from the human demonstration.",
        "primary_area": "",
        "author": "Abraham George;Alison Bartsch;Amir Barati Farimani;Abraham George;Alison Bartsch;Amir Barati Farimani",
        "authorids": "/37089895802;/37089892368;/37086221401;/37089895802;/37089892368;/37086221401",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University; Department of Mechanical Engineering, Carnegie Mellon University; Department of Mechanical Engineering, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161119/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5106873571314364269&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160392",
        "title": "Mixed Observable RRT: Multi-Agent Mission-Planning in Partially Observable Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers centralized mission-planning for a heterogeneous multi-agent system with the aim of locating a hidden target. We propose a mixed observable setting, consisting of a fully observable state-space and a partially observable environment, using a hidden Markov model. First, we construct rapidly exploring random trees (RRTs) to introduce the mixed observable RRT for finding plausible mission plans giving way-points for each agent. Leveraging this construction, we present a path-selection strategy based on a dynamic programming approach, which accounts for the uncertainty from partial observations and minimizes the expected cost. Finally, we combine the high-level plan with model predictive control algorithms to evaluate the approach on an experimental setup consisting of a quadruped robot and a drone. It is shown that agents are able to make intelligent decisions to explore the area efficiently and locate the target through collaborative actions.",
        "primary_area": "",
        "author": "Kasper Johansson;Ugo Rosolia;Wyatt Ubellacker;Andrew Singletary;Aaron D. Ames;Kasper Johansson;Ugo Rosolia;Wyatt Ubellacker;Andrew Singletary;Aaron D. Ames",
        "authorids": "/37089806434;/37086108959;/37077831700;/37086449553;/37300877900;/37089806434;/37086108959;/37077831700;/37086449553;/37300877900",
        "aff": "Stanford University, Stanford, USA; Amazon, Luxembourg, Luxembourg; California Institute of Technology, Pasadena, USA; California Institute of Technology, Pasadena, USA; California Institute of Technology, Pasadena, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160392/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14835605314614364126&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "Stanford University;Amazon;California Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.amazon.com;https://www.caltech.edu",
        "aff_unique_abbr": "Stanford;Amazon;Caltech",
        "aff_campus_unique_index": "0;2;2;2",
        "aff_campus_unique": "Stanford;;Pasadena",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;Luxembourg"
    },
    {
        "id": "10160777",
        "title": "Mobility Analysis of Screw-Based Locomotion and Propulsion in Various Media",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots \u201cin-the-wild\u201d encounter and must traverse widely varying terrain, ranging from solid ground to granular materials like sand to full liquids. Numerous approaches exist, including wheeled and legged robots, each excelling in specific domains. Screw-based locomotion is a promising approach for multi-domain mobility, leveraged in exploratory robotic designs, including amphibious vehicles and snake robotics. However, unlike other forms of locomotion, there is limited exploration of the models, parameter effects, and efficiency for multi-terrain Archimedes screw locomotion. In this work, we present work towards this missing component in understanding screw-based locomotion: comprehensive experimental results and performance analysis across different media. We designed a mobile test bed for indoor and outdoor experimentation to collect this data. Beyond quantitatively showing the multi-domain mobility of screw-based locomotion, we envision future researchers and engineers using the presented results to design effective screw-based locomotion systems.",
        "primary_area": "",
        "author": "Jason Lim;Calvin Joyce;Elizabeth Peiros;Mingwei Yeoh;Peter V. Gavrilov;Sara G. Wickenhiser;Dimitri A. Schreiber;Florian Richter;Michael C. Yip;Jason Lim;Calvin Joyce;Elizabeth Peiros;Mingwei Yeoh;Peter V. Gavrilov;Sara G. Wickenhiser;Dimitri A. Schreiber;Florian Richter;Michael C. Yip",
        "authorids": "/37089895143;/37089893396;/37089893139;/37089892623;/37088506406;/37089895150;/37087322737;/37086936752;/37085382768;/37089895143;/37089893396;/37089893139;/37089892623;/37088506406;/37089895150;/37087322737;/37086936752;/37085382768",
        "aff": "Electrical and Computer Engineering Department, University of California San Diego, La Jolla, CA, USA; Mechanical and Aerospace Engineering Department, University of California San Diego, La Jolla, CA, USA; Electrical and Computer Engineering Department, University of California San Diego, La Jolla, CA, USA; Electrical and Computer Engineering Department, University of California San Diego, La Jolla, CA, USA; Mechanical and Aerospace Engineering Department, University of California San Diego, La Jolla, CA, USA; Mechanical and Aerospace Engineering Department, University of California San Diego, La Jolla, CA, USA; Electrical and Computer Engineering Department, University of California San Diego, La Jolla, CA, USA; Electrical and Computer Engineering Department, University of California San Diego, La Jolla, CA, USA; Electrical and Computer Engineering Department, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160777/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=429745198443547635&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California San Diego",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161573",
        "title": "Model Based Position Control of Soft Hydraulic Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article, we investigate the model based position control of soft hydraulic actuators arranged in an an-tagonistic pair. A dynamical model of the system is constructed by employing the port-Hamiltonian formulation. A control algorithm is designed with an energy shaping approach, which accounts for the pressure dynamics of the fluid. A nonlinear observer is included to compensate the effect of unknown external forces. Simulations demonstrate the effectiveness of the proposed approach, and experiments achieve positioning accuracy of 0.043 mm with a standard deviation of 0.033 mm in the presence of constant external forces up to 1 N.",
        "primary_area": "",
        "author": "Mark Runciman;Enrico Franco;James Avery;Ferdinando Rodriguez y Baena;George Mylonas;Mark Runciman;Enrico Franco;James Avery;Ferdinando Rodriguez y Baena;George Mylonas",
        "authorids": "/37086937762;/37085386901;/38220704400;/37085615495;/37586568800;/37086937762;/37085386901;/38220704400;/37085615495;/37586568800",
        "aff": "The Hamlyn Centre, Imperial College London, London, UK; Mechanical Engineering Department, The Mechatronics in Medicine Laboratory, Imperial College London, London, UK; The Hamlyn Centre, Imperial College London, London, UK; Mechanical Engineering Department, The Mechatronics in Medicine Laboratory, Imperial College London, London, UK; The Hamlyn Centre, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161573/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17179976066230634339&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "The Hamlyn Centre",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160929",
        "title": "Model Predictive Optimized Path Integral Strategies",
        "track": "main",
        "status": "Poster",
        "abstract": "We generalize the derivation of model predictive path integral control (MPPI) to allow for a single joint distribution across controls in the control sequence. This reformation allows for the implementation of adaptive importance sampling (AIS) algorithms into the original importance sampling step while still maintaining the benefits of MPPI such as working with arbitrary system dynamics and cost functions. The benefit of optimizing the proposal distribution by integrating AIS at each control step is demonstrated in simulated environments including controlling multiple cars around a track. The new algorithm is more sample efficient than MPPI, achieving better performance with fewer samples. This performance disparity grows as the dimension of the action space increases. Results from simulations suggest the new algorithm can be used as an anytime algorithm, increasing the value of control at each iteration versus relying on a large set of samples. Repository\u2014https://github.com/sisl/MPOPIS",
        "primary_area": "",
        "author": "Dylan M. Asmar;Ransalu Senanayake;Shawn Manuel;Mykel J. Kochenderfer;Dylan M. Asmar;Ransalu Senanayake;Shawn Manuel;Mykel J. Kochenderfer",
        "authorids": "/37089895178;/38490726500;/37088588488;/37596929200;/37089895178;/38490726500;/37088588488;/37596929200",
        "aff": "Stanford Intelligent Systems Laboratory (SISL), Stanford University; Stanford Intelligent Systems Laboratory (SISL), Stanford University; Stanford Intelligent Systems Laboratory (SISL), Stanford University; Stanford Intelligent Systems Laboratory (SISL), Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160929/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3620847071500120212&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Stanford Intelligent Systems Laboratory (SISL)",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161472",
        "title": "Model- and Acceleration-based Pursuit Controller for High-Performance Autonomous Racing",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous racing is a research field gaining large popularity, as it pushes autonomous driving algorithms to their limits and serves as a catalyst for general autonomous driving. For scaled autonomous racing platforms, the computational constraint and complexity often limit the use of Model Predictive Control (MPC). As a consequence, geometric controllers are the most frequently deployed controllers. They prove to be performant while yielding implementation and operational simplicity. Yet, they inherently lack the incorporation of model dynamics, thus limiting the race car to a velocity domain where tire slip can be neglected. This paper presents Model- and Acceleration-based Pursuit (MAP) a high-performance model-based trajectory tracking controller that preserves the simplicity of geometric approaches while leveraging tire dynamics. The proposed algorithm allows accurate tracking of a trajectory at unprecedented velocities compared to State-of-the-Art (SotA) geometric controllers. The MAP controller is experimentally validated and outperforms the reference geometric controller four-fold in terms of lateral tracking error, yielding a tracking error of 0.055 m at tested speeds up to 11 m/s on a scaled racecar. Code: https://github.com/ETH-PBL/MAP-Controller.",
        "primary_area": "",
        "author": "Jonathan Becker;Nadine Imholz;Luca Schwarzenbach;Edoardo Ghignone;Nicolas Baumann;Michele Magno;Jonathan Becker;Nadine Imholz;Luca Schwarzenbach;Edoardo Ghignone;Nicolas Baumann;Michele Magno",
        "authorids": "/37089894658;/37089894449;/37089894199;/37089892492;/37086825592;/37601742500;/37089894658;/37089894449;/37089894199;/37089892492;/37086825592;/37601742500",
        "aff": "Center for Project Based Learning, D-ITET, ETH, Zurich; Center for Project Based Learning, D-ITET, ETH, Zurich; Center for Project Based Learning, D-ITET, ETH, Zurich; Center for Project Based Learning, D-ITET, ETH, Zurich; Center for Project Based Learning, D-ITET, ETH, Zurich; Center for Project Based Learning, D-ITET, ETH, Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161472/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12211232257972153543&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "D-ITET",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161460",
        "title": "Model-Agnostic Multi-Agent Perception Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing multi-agent perception systems assume that every agent utilizes the same model with identical parameters and architecture. The performance can be degraded with different perception models due to the mismatch in their confidence scores. In this work, we propose a model-agnostic multi-agent perception framework to reduce the negative effect caused by the model discrepancies without sharing the model information. Specifically, we propose a confidence calibrator that can eliminate the prediction confidence score bias. Each agent performs such calibration independently on a standard public database to protect intellectual property. We also propose a corresponding bounding box aggregation algorithm that considers the confidence scores and the spatial agreement of neighboring boxes. Our experiments shed light on the necessity of model calibration across different agents, and the results show that the proposed framework improves the baseline 3D object detection performance of heterogeneous agents. The code can be found at this url.",
        "primary_area": "",
        "author": "Runsheng Xu;Weizhe Chen;Hao Xiang;Xin Xia;Lantao Liu;Jiaqi Ma;Runsheng Xu;Weizhe Chen;Hao Xiang;Xin Xia;Lantao Liu;Jiaqi Ma",
        "authorids": "/37089002744;/37087246657;/37089006777;/37086487632;/37085785167;/37085693088;/37089002744;/37087246657;/37089006777;/37086487632;/37085785167;/37085693088",
        "aff": "University of California, Los Angeles, CA, USA; Indiana University, Bloomington, IN, USA; University of California, Los Angeles, CA, USA; University of California, Los Angeles, CA, USA; Indiana University, Bloomington, IN, USA; University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161460/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14714639230146111728&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "University of California, Los Angeles;Indiana University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucla.edu;https://www.indiana.edu",
        "aff_unique_abbr": "UCLA;IU",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "Los Angeles;Bloomington",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161314",
        "title": "Model-Based Pose Estimation of Steerable Catheters under Bi-Plane Image Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Small catheters undergo significant torsional deflections during endovascular interventions. A key challenge in enabling robot control of these catheters is the estimation of their bending planes. This paper considers approaches for estimating these bending planes based on bi-plane image feedback. The proposed approaches attempt to minimize error between either the direct (position-based) or instantaneous (velocity-based) kinematics with the reconstructed kinematics from bi-plane image feedback. A comparison between these methods is carried out on a setup using two cameras in lieu of a bi-plane fluoroscopy setup. The results show that the position-based approach is less susceptible to segmentation noise and works best when the segment is in a non-straight configuration. These results suggest that estimation of the bending planes can be accompanied with errors under 30\u00b0. Considering that the torsional buildup of these catheters can be more than 180\u00b0, we believe that this method can be used for catheter control with improved safety due to the reduction of this uncertainty.",
        "primary_area": "",
        "author": "Jared Lawson;Rohan Chitale;Nabil Simaan;Jared Lawson;Rohan Chitale;Nabil Simaan",
        "authorids": "/37089891962;/37089224624;/37282380300;/37089891962;/37089224624;/37282380300",
        "aff": "Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Neurological Surgery, Vanderbilt University Medical Center, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161314/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10727016343961641831&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Vanderbilt University;Vanderbilt University Medical Center",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Neurological Surgery",
        "aff_unique_url": "https://www.vanderbilt.edu;https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt;VUMC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160503",
        "title": "Model-Mediated Teleoperation for Remote Haptic Texture Sharing: Initial Study of Online Texture Modeling and Rendering",
        "track": "main",
        "status": "Poster",
        "abstract": "While model-mediated teleoperation (MMT) is an effective alternative for ensuring both transparency and stability, its potential in transmitting surface haptic texture is not yet explored. This paper introduces the first MMT framework capable of sharing surface haptic texture. The follower side collects physical signals contributing to haptic texture perception, e.g., high frequency acceleration, and streams them to the leader side. The leader side uses the signals to build and update a local measurement-based texture simulation model that reflects the remote surface. At the same time, the leader runs local simulation using the model, resulting in non-delayed, stable, and accurate feedback of texture. Considering that rendering haptic texture needs tougher real-time requirements, e.g., higher update rate and lower action-feedback latency, MMT can be a perfect platform for remote texture sharing. An initial proof-of-concept system supporting single and homogeneous surface is implemented and evaluated, demonstrating the potential of the approach.",
        "primary_area": "",
        "author": "Mudassir Ibrahim Awan;Tatyana Ogay;Waseem Hassan;Dongbeom Ko;Sungjoo Kang;Seokhee Jeon;Mudassir Ibrahim Awan;Tatyana Ogay;Waseem Hassan;Dongbeom Ko;Sungjoo Kang;Seokhee Jeon",
        "authorids": "/37086027855;/37086992677;/37085807225;/37089738183;/37290239300;/37085398008;/37086027855;/37086992677;/37085807225;/37089738183;/37290239300;/37085398008",
        "aff": "Department of Computer Science and Engineering, Kyung Hee University, South Korea; Department of Computer Science and Engineering, Kyung Hee University, South Korea; Department of Computer Science and Engineering, Kyung Hee University, South Korea; AI Research Laboratory, ETRI, South Korea; AI Research Laboratory, ETRI, South Korea; Department of Computer Science and Engineering, Kyung Hee University, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160503/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4212469311348315846&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Kyung Hee University;ETRI",
        "aff_unique_dep": "Department of Computer Science and Engineering;AI Research Laboratory",
        "aff_unique_url": "http://www.khu.ac.kr;https://www.etri.re.kr",
        "aff_unique_abbr": "KHU;ETRI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161076",
        "title": "Modeling and Inertial Parameter Estimation of Cart-like Nonholonomic Systems Using a Mobile Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "To enable a mobile manipulator to effectively maneuver a cart, we derive a dynamic model for the cart that incorporates the nonholonomic constraints on its motion, and use this model to formulate an estimator for the cart's inertial parameters. By deriving the dynamic equations of the cart using a constrained Euler-Lagrange formulation, we are able to directly incorporate nonholonomic constraints into the dynamics in a way that is independent of the kinematic parameters of the cart (e.g., specific wheel configuration, wheel radius, etc.), eliminating the need to either calibrate or estimate these kinematic parameters. We then construct an extended Kalman filter (including an explicit calculation of the linearized system and observation matrices) that uses an augmented state representation to estimate the cart's inertial parameters. We validate our approach both in simulation and experimentally using a mobile manipulator to maneuver a typical shopping cart. These experiments confirm the accuracy of our estimator, show that accurate estimation of the inertial parameters can significantly reduce the force/torque needed to successfully control the system, and illuminate the effects of varying the contact points at which the mobile manipulator applies forces and torques to guide the cart along a desired trajectory.",
        "primary_area": "",
        "author": "Sergio Aguilera;Muhammad Ali Murtaza;Jonathan Rogers;Seth Hutchinson;Sergio Aguilera;Muhammad Ali Murtaza;Jonathan Rogers;Seth Hutchinson",
        "authorids": "/37085576930;/37088316016;/37085897392;/37282386200;/37085576930;/37088316016;/37085897392;/37282386200",
        "aff": "Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161076/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12045484428702733007&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute of Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161486",
        "title": "Modeling of a Robotic Transcatheter Delivery System",
        "track": "main",
        "status": "Poster",
        "abstract": "Intracardiac transcatheter systems guided by advanced imaging modalities are gaining popularity in treating mitral regurgitation in non-surgical candidates. Robotically steerable transcatheter systems must use model-based control strategies to ensure safer and more effective transcatheter procedures with less trauma while using smaller control gains. In this paper, a 4-DoF robotically steerable tendon-driven robot was fabricated, and the relationship between the tendon displacement and the joint angle was derived. This relation was derived in two parts to make this approach applicable to any other catheter system. A model was derived to determine the tendon tensions needed to achieve desired joint angles. Then, the tendon characteristics were studied, and a tendon elongation (TE) model was derived as a function of tendon length. Executing the modeling process in two steps makes it easy to introduce additional parameters like length, friction, and pose, to characterize complex systems like catheters. The TE model was used to actuate the joints of the robot and RMSE was computed to characterize its performance. Also, PID control was used along with the TE model to improve the system's performance, and the contribution of the model and the controller in the system was recorded.",
        "primary_area": "",
        "author": "Namrata U. Nayar;Ronghuai Qi;Jaydev P. Desai;Namrata U. Nayar;Ronghuai Qi;Jaydev P. Desai",
        "authorids": "/37088640098;/37089449698;/37282117700;/37088640098;/37089449698;/37282117700",
        "aff": "Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161486/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8240428454099903331&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Wallace H. Coulter Department of Biomedical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161131",
        "title": "Modular Multi-axis Elastic Actuator with Torque Sensing Capable p-CFH for Highly Impact Resistive Robot Leg",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes a modular Multi-axis Elastic Actuator (MAEA) for legged robots that can effectively cope with impacts that may occur during dynamic maneuvering. MAEA has multi-axis compliance and can measure the torque without additional encoders. Therefore, effective impact resistance is possible with less volume and weight than conventional Series Elastic Actuators (SEA). The 6-axis stiffness analysis of paired-Crossed Flexural Hinge (p-CFH) is extended from small deformation to large deformation, and the accuracy is verified through Finite Element Analysis (FEA) and experiments. Based on the analysis, the torque of p-CFH is measured, and feedback torque control is also performed. Finally, the robot leg was constructed with MAEA, and the multi-axis impact resistance performance of MAEA was demonstrated by analyzing the applied impact during landing experiments at various angles.",
        "primary_area": "",
        "author": "Youngrae Kim;Sunghyun Choi;Jinhyeok Song;Dongwon Yun;Youngrae Kim;Sunghyun Choi;Jinhyeok Song;Dongwon Yun",
        "authorids": "/37089894738;/37089895908;/37089892772;/37589762000;/37089894738;/37089895908;/37089892772;/37589762000",
        "aff": "Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Department of Robotics and Mechatronics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161131/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:FnMIysJNgQwJ:scholar.google.com/&scioq=Modular+Multi-axis+Elastic+Actuator+with+Torque+Sensing+Capable+p-CFH+for+Highly+Impact+Resistive+Robot+Leg&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": "Department of Robotics and Mechatronics Engineering",
        "aff_unique_url": "https://www.dgist.ac.kr",
        "aff_unique_abbr": "DGIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daegu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161052",
        "title": "Modular and Parallelizable Multibody Physics Simulation via Subsystem-Based ADMM",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a new multibody physics simulation framework that utilizes the subsystem-based struc-ture and the Alternating Direction Method of Multiplier (ADMM). The major challenge in simulating complex high degree of freedom systems is a large number of coupled con-straints and large-sized matrices. To address this challenge, we first split the multibody into several subsystems and reformulate the dynamics equation into a subsystem perspective based on the structure of their interconnection. Then we utilize ADMM with our novel subsystem-based variable splitting scheme to solve the equation, which allows parallelizable and modular architecture. The resulting algorithm is fast, scalable, versatile, and converges well while maintaining solution consistency. Sev-eral illustrative examples are implemented with performance evaluation results showing advantages over other state-of-the-art algorithms.",
        "primary_area": "",
        "author": "Jeongmin Lee;Minji Lee;Dongjun Lee;Jeongmin Lee;Minji Lee;Dongjun Lee",
        "authorids": "/37088998350;/37086549787;/37077171500;/37088998350;/37086549787;/37077171500",
        "aff": "Department of Mechanical & Aerospace Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161052/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16010195549715168659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical & Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160945",
        "title": "Moment-Based Kalman Filter: Nonlinear Kalman Filtering with Exact Moment Propagation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper develops a new nonlinear filter, called Moment-based Kalman Filter (MKF), using the exact moment propagation method. Existing state estimation methods use linearization techniques or sampling points to compute approximate values of moments. However, moment propagation of probability distributions of random variables through nonlinear process and measurement models play a key role in the development of state estimation and directly affects their performance. The proposed moment propagation procedure can compute exact moments for non-Gaussian as well as non-independent Gaussian random variables. Thus, MKF can propagate exact moments of uncertain state variables up to any desired order. MKF is derivative-free and does not require tuning parameters. Moreover, MKF has the same computation time complexity as the extended or unscented Kalman filters, i.e., EKF and UKF. The experimental evaluations show that MKF is the preferred filter in comparison to EKF and UKF and outperforms both filters in non-Gaussian noise regimes.",
        "primary_area": "",
        "author": "Yutaka Shimizu;Ashkan Jasour;Maani Ghaffari;Shinpei Kato;Yutaka Shimizu;Ashkan Jasour;Maani Ghaffari;Shinpei Kato",
        "authorids": "/37089197396;/37078643400;/37087056400;/37537228700;/37089197396;/37078643400;/37087056400;/37537228700",
        "aff": "TIER IV, Inc., Shinagawa-ku, Tokyo, Japan; NASA Jet Propulsion Lab, California Institute of Technology; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA; Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160945/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17527128336955583946&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "TIER IV, Inc.;California Institute of Technology;University of Michigan;The University of Tokyo",
        "aff_unique_dep": ";NASA Jet Propulsion Lab;Department of Naval Architecture and Marine Engineering;Graduate School of Information Science and Technology",
        "aff_unique_url": ";https://www.caltech.edu;https://www.umich.edu;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": ";Caltech;UM;UTokyo",
        "aff_campus_unique_index": "1;2;3",
        "aff_campus_unique": ";Pasadena;Ann Arbor;Tokyo",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "10160778",
        "title": "Mono-STAR: Mono-Camera Scene-Level Tracking and Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Mono-STAR, the first real-time 3D reconstruction system that simultaneously supports semantic fusion, fast motion tracking, non-rigid object deformation, and topological change under a unified framework. The proposed system solves a new optimization problem incorporating optical-flow-based 2D constraints to deal with fast motion and a novel semantic-aware deformation graph (SAD-graph) for handling topology change. We test the proposed system under various challenging scenes and demonstrate that it significantly outperforms existing state-of-the-art methods. Supplementary material, including videos, can be found at https://github.com/changhaonan/Mono-STAR-demo.",
        "primary_area": "",
        "author": "Haonan Chang;Dhruv Metha Ramesh;Shijie Geng;Yuqiu Gan;Abdeslam Boularias;Haonan Chang;Dhruv Metha Ramesh;Shijie Geng;Yuqiu Gan;Abdeslam Boularias",
        "authorids": "/37087323802;/37089894302;/37088488356;/37089893642;/37542596800;/37087323802;/37089894302;/37088488356;/37089893642;/37542596800",
        "aff": "Department of Computer Science, Rutgers University, New Brunswick, USA; Department of Computer Science, Rutgers University, New Brunswick, USA; Department of Computer Science, Rutgers University, New Brunswick, USA; Department of Computer Science, Rutgers University, New Brunswick, USA; Department of Computer Science, Rutgers University, New Brunswick, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160778/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11684455511867572957&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160779",
        "title": "MonoGraspNet: 6-DoF Grasping with a Single RGB Image",
        "track": "main",
        "status": "Poster",
        "abstract": "6-DoF robotic grasping is a long-lasting but un-solved problem. Recent methods utilize strong 3D networks to extract geometric grasping representations from depth sensors, demonstrating superior accuracy on common objects but performing unsatisfactorily on photometrically challenging objects, e.g., objects in transparent or reflective materials. The bottleneck lies in that the surface of these objects can not reflect accurate depth due to the absorption or refraction of light. In this paper, in contrast to exploiting the inaccurate depth data, we propose the first RGB-only 6-DoF grasping pipeline called MonoGraspNet that utilizes stable 2D features to simultaneously handle arbitrary object grasping and overcome the problems induced by photometrically challenging objects. MonoGraspNet leverages a keypoint heatmap and a normal map to recover the 6-DoF grasping poses represented by our novel representation parameterized with 2D keypoints with corresponding depth, grasping direction, grasping width, and angle. Extensive experiments in real scenes demonstrate that our method can achieve competitive results in grasping common objects and surpass the depth-based competitor by a large margin in grasping photometrically challenging objects. To further stimulate robotic manipulation research, we annotate and open-source a multi-view grasping dataset in the real world containing 44 sequence collections of mixed photometric complexity with nearly 20M accurate grasping labels.",
        "primary_area": "",
        "author": "Guangyao Zhai;Dianye Huang;Shun-Cheng Wu;HyunJun Jung;Yan Di;Fabian Manhardt;Federico Tombari;Nassir Navab;Benjamin Busam;Guangyao Zhai;Dianye Huang;Shun-Cheng Wu;HyunJun Jung;Yan Di;Fabian Manhardt;Federico Tombari;Nassir Navab;Benjamin Busam",
        "authorids": "/37087322612;/37089895413;/37088643746;/37089231258;/37088505061;/37085664475;/37593332100;/37282965500;/37085664553;/37087322612;/37089895413;/37088643746;/37089231258;/37088505061;/37085664475;/37593332100;/37282965500;/37085664553",
        "aff": "Technical University of Munich (TUM), Munich, Germany; Technical University of Munich (TUM), Munich, Germany; Technical University of Munich (TUM), Munich, Germany; Technical University of Munich (TUM), Munich, Germany; Technical University of Munich (TUM), Munich, Germany; Google.; Google.; Johns Hopkins University, Baltimore, MD, USA; Technical University of Munich (TUM), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160779/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15460657131556044984&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;1;2;0",
        "aff_unique_norm": "Technical University of Munich;Google;Johns Hopkins University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.tum.de;https://www.google.com;https://www.jhu.edu",
        "aff_unique_abbr": "TUM;Google;JHU",
        "aff_campus_unique_index": "0;0;0;0;0;1;1;2;0",
        "aff_campus_unique": "Munich;Mountain View;Baltimore",
        "aff_country_unique_index": "0;0;0;0;0;1;1;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "10161442",
        "title": "MonoPGC: Monocular 3D Object Detection with Pixel Geometry Contexts",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular 3D object detection reveals an economical but challenging task in autonomous driving. Recently center-based monocular methods have developed rapidly with a great trade-off between speed and accuracy, where they usually depend on the object center's depth estimation via 2D features. However, the visual semantic features without sufficient pixel geometry information, may affect the performance of clues for spatial 3D detection tasks. To alleviate this, we propose MonoPGC, a novel end-to-end Monocular 3D object detection framework with rich Pixel Geometry Contexts. We introduce the pixel depth estimation as our auxiliary task and design depth cross-attention pyramid module (DCPM) to inject local and global depth geometry knowledge into visual features. In addition, we present the depth-space-aware transformer (DSAT) to integrate 3D space position and depth-aware features efficiently. Besides, we design a novel depth-gradient positional encoding (DGPE) to bring more distinct pixel geometry contexts into the transformer for better object detection. Extensive experiments demonstrate that our method achieves the state-of-the-art performance on the KITTI dataset.",
        "primary_area": "",
        "author": "Zizhang Wu;Yuanzhu Gan;Lei Wang;Guilian Chen;Jian Pu;Zizhang Wu;Yuanzhu Gan;Lei Wang;Guilian Chen;Jian Pu",
        "authorids": "/37088645948;/37089197542;/37089893772;/37089894686;/37086254785;/37088645948;/37089197542;/37089893772;/37089894686;/37086254785",
        "aff": "Zongmu Technology; Zongmu Technology; Zongmu Technology; Zongmu Technology; Fudan University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161442/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7578398998972929560&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Zongmu Technology;Fudan University",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.fudan.edu.cn",
        "aff_unique_abbr": ";Fudan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160427",
        "title": "Monocular Reactive Collision Avoidance for MAV Teleoperation with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling Micro Aerial Vehicles (MAVs) with semi-autonomous capabilities to assist their teleoperation is crucial in several applications. Remote human operators do not have, in general, the situational awareness to perceive obstacles near the drone, nor the readiness to provide commands to avoid collisions. In this work, we devise a novel teleoperation setting that asks the operator to provide a simple high-level signal encoding the speed and the direction they expect the drone to follow. We then endow the MAV with an end-to-end Deep Reinforcement Learning (DRL) model that computes control commands to track the desired trajectory while performing collision avoidance. Differently from State-of-the-Art (SotA) works, it allows the robot to move freely in the 3D space, requires only the current RGB image captured by a monocular camera and the current robot position, and does not make any assumption about obstacle shape and size. We show the effectiveness and the generalization capabilities of our strategy by comparing it against a SotA baseline in photorealistic simulated environments.",
        "primary_area": "",
        "author": "Raffaele Brilli;Marco Legittimo;Francesco Crocetti;Mirko Leomanni;Mario Luca Fravolini;Gabriele Costante;Raffaele Brilli;Marco Legittimo;Francesco Crocetti;Mirko Leomanni;Mario Luca Fravolini;Gabriele Costante",
        "authorids": "/37089229097;/37089224666;/37085535873;/37085540182;/37300984700;/38541290800;/37089229097;/37089224666;/37085535873;/37085540182;/37300984700;/38541290800",
        "aff": "Department of Engineering, University of Perugia, Perugia; Department of Engineering, University of Perugia, Perugia; Department of Engineering, University of Perugia, Perugia; Department of Engineering, University of Perugia, Perugia; Department of Engineering, University of Perugia, Perugia; Department of Engineering, University of Perugia, Perugia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160427/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18138809131715617508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Perugia",
        "aff_unique_dep": "Department of Engineering",
        "aff_unique_url": "https://www.unipg.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Perugia",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161558",
        "title": "Monocular Simultaneous Localization and Mapping using Ground Textures",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work has shown impressive localization performance using only images of ground textures taken with a downward facing monocular camera. This provides a reliable navigation method that is robust to feature sparse environments and challenging lighting conditions. However, these localization methods require an existing map for comparison. Our work aims to relax the need for a map by introducing a full simultaneous localization and mapping (SLAM) system. By not requiring an existing map, setup times are minimized and the system is more robust to changing environments. This SLAM system uses a combination of several techniques to accomplish this. Image keypoints are identified and projected into the ground plane. These keypoints, visual bags of words, and several threshold parameters are then used to identify overlapping images and revisited areas. The system then uses robust Mestimators to estimate the transform between robot poses with overlapping images and revisited areas. These optimized estimates make up the map used for navigation. We show, through experimental data, that this system performs reliably on many ground textures, but not all.",
        "primary_area": "",
        "author": "Kyle M. Hart;Brendan Englot;Ryan P. O'Shea;John D. Kelly;David Martinez;Kyle M. Hart;Brendan Englot;Ryan P. O'Shea;John D. Kelly;David Martinez",
        "authorids": "/37089892126;/37601539900;/37089893713;/37089892887;/37089892266;/37089892126;/37601539900;/37089893713;/37089892887;/37089892266",
        "aff": "Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Aircraft Division (NAWCAD), Naval Air Warfare Center, Lakehurst, NJ, USA; Aircraft Division (NAWCAD), Naval Air Warfare Center, Lakehurst, NJ, USA; Aircraft Division (NAWCAD), Naval Air Warfare Center, Lakehurst, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161558/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5226183988214570306&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "Stevens Institute of Technology;Naval Air Warfare Center Aircraft Division",
        "aff_unique_dep": "Department of Mechanical Engineering;Aircraft Division (NAWCAD)",
        "aff_unique_url": "https://www.stevens.edu;",
        "aff_unique_abbr": "SIT;NAWCAD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hoboken;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161013",
        "title": "Monocular Visual-Inertial Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a visual-inertial depth estimation pipeline that integrates monocular depth estimation and visual- inertial odometry to produce dense depth estimates with metric scale. Our approach performs global scale and shift alignment against sparse metric depth, followed by learning-based dense alignment. We evaluate on the TartanAir and VOID datasets, observing up to 30% reduction in inverse RMSE with dense scale alignment relative to performing just global alignment alone. Our approach is especially competitive at low density; with just 150 sparse metric depth points, our dense- to-dense depth alignment method achieves over 50 % lower iRMSE over sparse-to-dense depth completion by KBNet, currently the state of the art on VOID. We demonstrate successful zero-shot transfer from synthetic TartanAir to real-world VOID data and perform generalization tests on NYUv2 and VCU-RVI. Our approach is modular and is compatible with a variety of monocular depth estimation models.",
        "primary_area": "",
        "author": "Diana Wofk;Ren\u00e9 Ranftl;Matthias M\u00fcller;Vladlen Koltun;Diana Wofk;Ren\u00e9 Ranftl;Matthias M\u00fcller;Vladlen Koltun",
        "authorids": "/37086936574;/38252786800;/37088216388;/37739465900;/37086936574;/38252786800;/37088216388;/37739465900",
        "aff": "Intel Labs.; Intel Labs.; Intel Labs.; Apple",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161013/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4338760266243829301&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Intel Corporation;Apple Inc.",
        "aff_unique_dep": "Intel Labs;",
        "aff_unique_url": "https://www.intel.com;https://www.apple.com",
        "aff_unique_abbr": "Intel;Apple",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160620",
        "title": "Monocular Visual-Inertial Odometry with Planar Regularities",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art monocular visual-inertial odometry (VIO) approaches rely on sparse point features in part due to their efficiency, robustness, and prevalence, while ignoring high-level structural regularities such as planes that are common to man-made environments and can be exploited to further constrain motion. Generally, planes can be observed by a camera for significant periods of time due to their large spatial presence and thus, are amenable for long-term navigation. Therefore, in this paper, we design a novel real-time monocular VIO system that is fully regularized by planar features within a lightweight multi-state constraint Kalman filter (MSCKF). At the core of our method is an efficient robust monocular-based plane detection algorithm, which does not require additional sensing modalities such as a stereo or depth camera as commonly seen in the literature, while enabling real-time regularization of point features to environmental planes. Specifically, in the proposed MSCKF, long-lived planes are maintained in the state vector, while shorter ones are marginalized after use for efficiency. Planar regularities are applied to both in-state SLAM features and out-of-state MSCKF features, thus fully exploiting the environmental plane information to improve VIO performance. The proposed approach is evaluated with extensive Monte-Carlo simulations and different real-world experiments including an author-collected AR scenario, and shown to outperform the point-based VIO in structured environments. Video Demonstration https://youtu.be/bec7LbYaOS8AR Table Dataset https://github.com/rpng/ar_table_dataset",
        "primary_area": "",
        "author": "Chuchu Chen;Patrick Geneva;Yuxiang Peng;Woosik Lee;Guoquan Huang;Chuchu Chen;Patrick Geneva;Yuxiang Peng;Woosik Lee;Guoquan Huang",
        "authorids": "/37088486425;/37086125563;/37089895185;/37087323297;/37077670600;/37088486425;/37086125563;/37089895185;/37087323297;/37077670600",
        "aff": "Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160620/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17142695229215206003&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161107",
        "title": "Morphological Characteristics That Enable Stable and Efficient Walking in Hexapod Robot Driven by Reflex-based Intra-limb Coordination",
        "track": "main",
        "status": "Poster",
        "abstract": "Insects exhibit adaptive walking behavior in an unstructured environment, despite having only an extremely small number of neurons (105 to 106). This suggests that not only the brain nervous system but also properties of the physical body, such as the morphological characteristics, play an essential role in generating such adaptive behavior. Our study aims at investigating the effect of body morphological characteristics on the walking performance in a robot model, which is designed to mimic an insect. To this end, we constructed an insect-like hexapod model in a simulation environment that implements a reflex-based intra-limb coordination control. Herein, for a set of walking parameters, which were optimized to maximize the energy efficiency at the target speed, we investigated the effects of changes in the standard posture of the two leg joints on the walking success rate for various initial conditions and cost of transport (CoT) as an index of energy efficiency. Simulation results indicated that robots with specific morphological characteristics similar to those of insects exhibited high gait stability and energetic efficiency. Because only the reflex-based control was employed, the inter-leg coordination occurred spontaneously, suggesting that our approach would lead to a useful design methodology from the perspective of computational cost in generating the walking locomotion.",
        "primary_area": "",
        "author": "Wataru Sato;Jun Nishii;Mitsuhiro Hayashibe;Dai Owaki;Wataru Sato;Jun Nishii;Mitsuhiro Hayashibe;Dai Owaki",
        "authorids": "/37401789000;/37371362900;/37586645600;/37294593400;/37401789000;/37371362900;/37586645600;/37294593400",
        "aff": "Department of Robotics, Neuro-Robotics Lab, Graduate School of Engineering, Tohoku University, Sendai, Japan; Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Yamaguchi, Japan; Department of Robotics, Neuro-Robotics Lab, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Robotics, Neuro-Robotics Lab, Graduate School of Engineering, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161107/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16935012677500543596&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Tohoku University;Yamaguchi University",
        "aff_unique_dep": "Department of Robotics;Graduate School of Sciences and Technology for Innovation",
        "aff_unique_url": "https://www.tohoku.ac.jp;https://www.yamaguchi-u.ac.jp",
        "aff_unique_abbr": "Tohoku U;Yamaguchi U",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Sendai;Yamaguchi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160218",
        "title": "Motion Planning for a Climbing Robot with Stochastic Grasps",
        "track": "main",
        "status": "Poster",
        "abstract": "ReachBot is a robot that uses extendable and retractable booms as limbs to move around unpredictable environments such as martian caves. Each boom is capped by a microspine gripper designed for grasping rocky surfaces. Motion planning for ReachBot must be versatile to accommo-date variable terrain features and robust to mitigate risks from the stochastic nature of grasping with spines. In this paper, we introduce a graph traversal algorithm to select a discrete sequence of grasps based on available terrain features suitable for grasping. This discrete plan is complemented by a decoupled motion planner that considers the alternating phases of body movement and end-effector movement, using a combination of sampling-based planning and sequential convex programming to optimize individual phases. We use our motion planner to plan a trajectory across a simulated 2D cave environment with at least 90% probability of success and demonstrate improved robustness over a baseline trajectory. Finally, we use a simplified prototype to verify a body movement trajectory generated by our motion planning algorithm.",
        "primary_area": "",
        "author": "Stephanie Newdick;Nitin Ongole;Tony G. Chen;Edward Schmerling;Mark R. Cutkosky;Marco Pavone;Stephanie Newdick;Nitin Ongole;Tony G. Chen;Edward Schmerling;Mark R. Cutkosky;Marco Pavone",
        "authorids": "/37089837283;/37089893568;/37086420715;/37085548931;/37329470000;/37307912900;/37089837283;/37089893568;/37086420715;/37085548931;/37329470000;/37307912900",
        "aff": "Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Mechanical Engineering, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Mechanical Engineering, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160218/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11134473856740724013&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161017",
        "title": "Multi-Agent Active Search using Detection and Location Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Active search, in applications like environment monitoring or disaster response missions, involves autonomous agents detecting targets in a search space using decision making algorithms that adapt to the history of their observations. Active search algorithms must contend with two types of uncertainty: detection uncertainty and location uncertainty. The more common approach in robotics is to focus on location uncertainty and remove detection uncertainty by thresholding the detection probability to zero or one. In contrast, it is common in the sparse signal processing literature to assume the target location is accurate and instead focus on the uncertainty of its detection. In this work, we first propose an inference method to jointly handle both target detection and location uncertainty. We then build a decision making algorithm on this inference method that uses Thompson sampling to enable decentralized multi-agent active search. We perform simulation experiments to show that our algorithms outperform competing baselines that only account for either target detection or location uncertainty. We finally demonstrate the real world transferability of our algorithms using a realistic simulation environment we created on the Unreal Engine 4 platform with an AirSim plugin.",
        "primary_area": "",
        "author": "Arundhati Banerjee;Ramina Ghods;Jeff Schneider;Arundhati Banerjee;Ramina Ghods;Jeff Schneider",
        "authorids": "/37089892110;/37085690543;/37281084800;/37089892110;/37085690543;/37281084800",
        "aff": "School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161017/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6960803887300884342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161511",
        "title": "Multi-Agent Path Integral Control for Interaction-Aware Motion Planning in Urban Canals",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles that operate in urban environments shall comply with existing rules and reason about the interactions with other decision-making agents. In this paper, we introduce a decentralized and communication-free interaction-aware motion planner and apply it to Autonomous Surface Vessels (ASVs) in urban canals. We build upon a sampling-based method, namely Model Predictive Path Integral control (MPPI), and employ it to, in each time instance, compute both a collision-free trajectory for the vehicle and a prediction of other agents' trajectories, thus modeling interactions. To improve the method's efficiency in multi-agent scenarios, we introduce a two-stage sample evaluation strategy and define an appropriate cost function to achieve rule compliance. We evaluate this decentralized approach in simulations with multiple vessels in real scenarios extracted from Amsterdam's canals, showing superior performance than a state-of-the-art trajectory optimization framework and robustness when encountering different types of agents.",
        "primary_area": "",
        "author": "Lucas Streichenberg;Elia Trevisan;Jen Jen Chung;Roland Siegwart;Javier Alonso-Mora;Lucas Streichenberg;Elia Trevisan;Jen Jen Chung;Roland Siegwart;Javier Alonso-Mora",
        "authorids": "/37089895426;/37089446928;/37085668354;/37281398300;/38271697300;/37089895426;/37089446928;/37085668354;/37281398300;/38271697300",
        "aff": "Autonomous Systems Lab, ETH, Zurich; Cognitive Robotics Department, Delft, TU; School of ITEE, The University of Queensland; Autonomous Systems Lab, ETH, Zurich; Cognitive Robotics Department, Delft, TU",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161511/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18001945541771471553&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;1",
        "aff_unique_norm": "ETH Zurich;Delft University of Technology;The University of Queensland",
        "aff_unique_dep": "Autonomous Systems Lab;Cognitive Robotics Department;School of ITEE",
        "aff_unique_url": "https://www.ethz.ch;https://www.tudelft.nl;https://www.uq.edu.au",
        "aff_unique_abbr": "ETHZ;TU Delft;UQ",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Zurich;Delft;",
        "aff_country_unique_index": "0;1;2;0;1",
        "aff_country_unique": "Switzerland;Netherlands;Australia"
    },
    {
        "id": "10160617",
        "title": "Multi-Agent Spatial Predictive Control with Application to Drone Flocking",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce Spatial Predictive Control (SPC), a technique for solving the following problem: given a collection of robotic agents with black-box positional low-level controllers (PLLCs) and a mission-specific distributed cost function, how can a distributed controller achieve and maintain cost-function minimization without a plant model and only positional observations of the environment? Our fully distributed SPC controller is based strictly on the position of the agent itself and on those of its neighboring agents. This information is used in every time step to compute the gradient of the cost function and to perform a spatial look-ahead to predict the best next target position for the PLLC. Using a simulation environment, we show that SPC outperforms Potential Field Controllers, a related class of controllers, on the drone flocking problem. We also show that SPC works on real hardware, and is therefore able to cope with the potential sim-to-real transfer gap. We demonstrate its performance using as many as 16 Crazyflie 2.1 drones in a number of scenarios, including obstacle avoidance.",
        "primary_area": "",
        "author": "Andreas Brandst\u00e4tter;Scott A. Smolka;Scott D. Stoller;Ashish Tiwari;Radu Grosu;Andreas Brandst\u00e4tter;Scott A. Smolka;Scott D. Stoller;Ashish Tiwari;Radu Grosu",
        "authorids": "/37089534584;/37352046100;/37443486400;/37333988500;/37442339800;/37089534584;/37352046100;/37443486400;/37333988500;/37442339800",
        "aff": "CPS, Technische Universit\u00e4t Wien (TU Wien), Austria; Department of Computer Science, Stony Brook University, USA; Department of Computer Science, Stony Brook University, USA; Microsoft, USA; CPS, Technische Universit\u00e4t Wien (TU Wien), Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160617/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14023653558686978998&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "Technische Universit\u00e4t Wien;Stony Brook University;Microsoft Corporation",
        "aff_unique_dep": "CPS;Department of Computer Science;",
        "aff_unique_url": "https://www.tuwien.ac.at;https://www.stonybrook.edu;https://www.microsoft.com",
        "aff_unique_abbr": "TU Wien;SBU;Microsoft",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Stony Brook",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "Austria;United States"
    },
    {
        "id": "10161395",
        "title": "Multi-Alpha Soft Actor-Critic: Overcoming Stochastic Biases in Maximum Entropy Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The successful application of robotic control requires intelligent decision-making to handle the long tail of complex scenarios that arise in real-world environments. Recently, Deep Reinforcement Learning (DRL) has provided a data-driven framework to automatically learn effective policies in such complex settings. Since its introduction in 2018, Soft Actor-Critic (SAC) remains as one of the most popular off-policy DRL algorithms and has been used extensively to learn performant robotic control policies. However, in this paper we argue that by relying on the maximum entropy formalism to define learning objectives, previous work introduces a significant bias away from optimal decision making, which often requires near-deterministic behaviour for high-precision tasks. Moreover, we show that when training with the original variants of SAC, overcoming this bias by reducing entropy budgets or entropy coefficients introduces separate issues that lead to slow or unstable learning. We address these shortcomings by treating the entropy coefficient \\alpha\\alpha as a random variable and introduce Multi-Alpha Soft Actor-Critic (MAS). We show how MAS overcomes the stochastic bias of SAC in a variety of robotic control tasks including the CARLA urban-driving simulator, while maintaining the stability and sample efficiency of the original algorithms.",
        "primary_area": "",
        "author": "Conor Igoe;Swapnil Pande;Siddarth Venkatraman;Jeff Schneider;Conor Igoe;Swapnil Pande;Siddarth Venkatraman;Jeff Schneider",
        "authorids": "/37088854537;/37089895387;/37088536019;/37281084800;/37088854537;/37089895387;/37088536019;/37281084800",
        "aff": "Machine Learning Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161395/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5439043104770745168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161551",
        "title": "Multi-Contact Task and Motion Planning Guided by Video Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "This work aims at leveraging instructional video to guide the solving of complex multi-contact task-and-motion planning tasks in robotics. Towards this goal, we propose an extension of the well-established Rapidly-Exploring Random Tree (RRT) planner, which simultaneously grows multiple trees around grasp and release states extracted from the guiding video. Our key novelty lies in combining contact states, and 3D object poses extracted from the guiding video with a traditional planning algorithm that allows us to solve tasks with sequential dependencies, for example, if an object needs to be placed at a specific location to be grasped later. To demonstrate the benefits of the proposed video-guided planning approach, we design a new benchmark with three challenging tasks: (i) 3D re-arrangement of multiple objects between a table and a shelf, (ii) multi-contact transfer of an object through a tunnel, and (iii) transferring objects using a tray in a similar way a waiter transfers dishes. We demonstrate the effectiveness of our planning algorithm on several robots, including the Franka Emika Panda and the KUKA KMR iiwa.",
        "primary_area": "",
        "author": "Kateryna Zorina;David Kovar;Florent Lamiraux;Nicolas Mansard;Justin Carpentier;Josef Sivic;Vladimir Petrik;Kateryna Zorina;David Kovar;Florent Lamiraux;Nicolas Mansard;Justin Carpentier;Josef Sivic;Vladimir Petrik",
        "authorids": "/37089171036;/37089894838;/37279738200;/37542913400;/37085506841;/37282919700;/37085341098;/37089171036;/37089894838;/37279738200;/37542913400;/37085506841;/37282919700;/37085341098",
        "aff": "CIIRC, Czech Technical University in Prague; CIIRC, Czech Technical University in Prague; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse; INRIA, Paris; CIIRC, Czech Technical University in Prague; CIIRC, Czech Technical University in Prague",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161551/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16384565176113040321&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;2;0;0",
        "aff_unique_norm": "Czech Technical University in Prague;LAAS-CNRS;INRIA",
        "aff_unique_dep": "CIIRC;;",
        "aff_unique_url": "https://www.ciirc.cvut.cz/;https://www.laas.fr/;https://www.inria.fr",
        "aff_unique_abbr": "CTU;LAAS-CNRS;INRIA",
        "aff_campus_unique_index": "0;0;1;1;2;0;0",
        "aff_campus_unique": "Prague;Toulouse;Paris",
        "aff_country_unique_index": "0;0;1;1;1;0;0",
        "aff_country_unique": "Czech Republic;France"
    },
    {
        "id": "10160426",
        "title": "Multi-Head Attention Machine Learning for Fault Classification in Mixed Autonomous and Human-Driven Vehicle Platoons",
        "track": "main",
        "status": "Poster",
        "abstract": "Connected Autonomous Vehicle (CAV) platoons have been extensively studied to protect against cyber and physical vulnerabilities. Faults can occur in all layers of the platoon system or could be introduced by impaired human drivers. Since different types of faults may require different fault resolution methods, identifying the fault class facilitates the selection of the best mitigation strategy. This paper introduces a Multi-Head Attention Machine Learning (MHA-ML) approach to classify a set of five different faults and abnormalities in mixed autonomous and human-driven vehicle platoons. Autonomous vehicles can face actuator faults, False Data Injection (FDI) attacks, and Denial-of-Service (DoS) attacks, while abnormalities such as drunk or distracted human drivers could occur. MHA-ML is developed to identify faulty vehicle behavior over long sequences of sensor measurements. MHA-ML is trained on a mixed platoon simulation model and then tested on mobile laboratory robots. The experiment classifies the five fault categories with 90% accuracy and outperforms a baseline recurrent neural network approach.",
        "primary_area": "",
        "author": "Theodore Wu;Satvick Acharya;Abdelrahman Khalil;Ahmad F. Aljanaideh;Mohammad Al Janaideh;Deepa Kundur;Theodore Wu;Satvick Acharya;Abdelrahman Khalil;Ahmad F. Aljanaideh;Mohammad Al Janaideh;Deepa Kundur",
        "authorids": "/37089892556;/37089894257;/37088482852;/37089894058;/37542671600;/37269460100;/37089892556;/37089894257;/37088482852;/37089894058;/37542671600;/37269460100",
        "aff": "Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada; Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada; Department of Mechanical Engineering, Memorial University, St. John's, NL, Canada; Bentley University, Waltham, MA, USA; School of Engineering, University of Guelph, Guelph, ON, Canada; Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160426/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2009020255858123956&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;3;0",
        "aff_unique_norm": "University of Toronto;Memorial University;Bentley University;University of Guelph",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Mechanical Engineering;;School of Engineering",
        "aff_unique_url": "https://www.utoronto.ca;https://www.mun.ca;https://www.bentley.edu;https://www.uoguelph.ca",
        "aff_unique_abbr": "U of T;;Bentley;U of G",
        "aff_campus_unique_index": "0;0;1;2;3;0",
        "aff_campus_unique": "Toronto;St. John's;Waltham;Guelph",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "10161255",
        "title": "Multi-Modal Learning and Relaxation of Physical Conflict for an Exoskeleton Robot with Proprioceptive Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Exoskeleton robots provide assistive forces to suit the human subject via physical human-robot interaction. During the closely-coupled interaction, a mismatch between the wearer and the robot may result in physical conflict, which could affect assistance efficiency or even compromise safety. Therefore, such conflicts should be accurately detected and then properly relaxed by adjusting the robot's action. This paper proposes a new learning scheme to detect physical conflicts between humans and robots. The constructed learning network receives multi-modal information from proprioceptive sensors and then outputs the anomaly score to specify the physical conflict, which score is further used to continuously adjust the robot impedance to ensure a safe and efficient interaction. Such a formulation allows the robot to explore the semantic information during the interaction (e.g., gait phases, imbalance, human fatigue) and hence react properly to the physical conflict. Experimental results and comparative studies on a lower-limb exoskeleton robot are presented to illustrate that the proposed learning scheme can deal with physical conflicts in a faster and more accurate manner.",
        "primary_area": "",
        "author": "Xuan Zhang;Yana Shu;Yu Chen;Gong Chen;Jing Ye;Xiu Li;Xiang Li;Xuan Zhang;Yana Shu;Yu Chen;Gong Chen;Jing Ye;Xiu Li;Xiang Li",
        "authorids": "/37088947374;/37089892031;/37089660961;/37089850867;/37075370700;/38667875300;/37280877200;/37088947374;/37089892031;/37089660961;/37089850867;/37075370700;/38667875300;/37280877200",
        "aff": "Tsinghua Shenzhen International Graduate School, Tsinghua University, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, China; Department of Automation, Tsinghua University, China; Shenzhen MileBot Robotics Co., Ltd, China; Shenzhen MileBot Robotics Co., Ltd, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, China; Department of Automation, Tsinghua University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161255/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7911229572840458222&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;0;0",
        "aff_unique_norm": "Tsinghua University;Shenzhen MileBot Robotics Co., Ltd",
        "aff_unique_dep": "International Graduate School;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;",
        "aff_unique_abbr": "THU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161030",
        "title": "Multi-Object Navigation in real environments using hybrid policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigation has been classically solved in robotics through the combination of SLAM and planning. More recently, beyond waypoint planning, problems involving significant components of (visual) high-level reasoning have been explored in simulated environments, mostly addressed with large-scale machine learning, in particular RL, offline-RL or imitation learning. These methods require the agent to learn various skills like local planning, mapping objects and querying the learned spatial representations. In contrast to simpler tasks like waypoint planning (PointGoal), for these more complex tasks the current state-of-the-art models have been thoroughly evaluated in simulation but, to our best knowledge, not yet in real environments. In this work we focus on sim2real transfer. We target the challenging Multi-Object Navigation (Multi-ON) task [41] and port it to a physical environment containing real replicas of the originally virtual Multi-ON objects. We introduce a hybrid navigation method, which decomposes the problem into two different skills: (1) waypoint navigation is addressed with classical SLAM combined with a symbolic planner, whereas (2) exploration, semantic mapping and goal retrieval are dealt with deep neural networks trained with a combination of supervised learning and RL. We show the advantages of this approach compared to end-to-end methods both in simulation and a real environment and outperform the SOTA for this task [28].",
        "primary_area": "",
        "author": "Assem Sadek;Guillaume Bono;Boris Chidlovskii;Atilla Baskurt;Christian Wolf;Assem Sadek;Guillaume Bono;Boris Chidlovskii;Atilla Baskurt;Christian Wolf",
        "authorids": "/37088686419;/37089161767;/37373194900;/37269935300;/37285119900;/37088686419;/37089161767;/37373194900;/37269935300;/37285119900",
        "aff": "Naver Labs Europe, Meylan, France; Naver Labs Europe, Meylan, France; Naver Labs Europe, Meylan, France; INSA-Lyon, LIRIS, Universit\u00e9 de Lyon, Villeurbanne, France; Naver Labs Europe, Meylan, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161030/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17538190956571666162&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Naver Labs Europe;INSA-Lyon",
        "aff_unique_dep": ";LIRIS",
        "aff_unique_url": "https://labs.naver.com;https://www.insa-lyon.fr",
        "aff_unique_abbr": "NLE;INSA-Lyon",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Meylan;Villeurbanne",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160642",
        "title": "Multi-Objective Ergodic Search for Dynamic Information Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic explorers are essential tools for gathering information about regions that are inaccessible to humans. For applications like planetary exploration or search and rescue, robots use prior knowledge about the area to guide their search. Ergodic search methods find trajectories that effectively balance exploring unknown regions and exploiting prior information. In many search based problems, the robot must take into account multiple factors such as scientific information gain, risk, and energy, and update its belief about these dynamic objectives as they evolve over time. However, existing ergodic search methods either consider multiple static objectives or consider a single dynamic objective, but not multiple dynamic objectives. We address this gap in existing methods by presenting an algorithm called Dynamic Multi-Objective Ergodic Search (D-MO-ES) that efficiently plans an ergodic trajectory on multiple changing objectives. Our experiments show that our method requires up to nine times less compute time than a na\u00efve approach with comparable coverage of each objective.",
        "primary_area": "",
        "author": "Ananya Rao;Abigail Breitfeld;Alberto Candela;Benjamin Jensen;David Wettergreen;Howie Choset;Ananya Rao;Abigail Breitfeld;Alberto Candela;Benjamin Jensen;David Wettergreen;Howie Choset",
        "authorids": "/37089699067;/37089893743;/37086316796;/37089891900;/37270533700;/37281322200;/37089699067;/37089893743;/37086316796;/37089891900;/37270533700;/37281322200",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160642/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15021909912712911247&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161276",
        "title": "Multi-Robot 3D Gas Distribution Mapping: Coordination, Information Sharing and Environmental Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "Environmental monitoring and mapping operations are an essential tool to combat climate change. An important branch of this domain concerns the construction of reliable gas maps. Adaptive navigation strategies coupled with multi-robot systems improve the outcome of an environmental mapping mission by focusing more efficiently on informative areas. This direction is yet to be explored in the context of gas mapping, which presents peculiar challenges due to the hard-to-sense and expensive-to-model nature of the underlying phenomenon. In this paper, we introduce the application of a multi-robot system to a gas mission with severe time constraints. We study the impact of information-based navigation strategies, coupled with increasing levels of coordination among the robots, on information gathering and consequent map reconstruction performance. We also focus on proposing solutions that inject additional knowledge into the system to enhance the final mapping outcome. We tested the strategies through extensive high-fidelity simulation experiments, and we compared the proposed approaches to three relevant baseline methods.",
        "primary_area": "",
        "author": "Chiara Ercolani;Shashank Mahendra Deshmukh;Thomas Laurent Peeters;Alcherio Martinoli;Chiara Ercolani;Shashank Mahendra Deshmukh;Thomas Laurent Peeters;Alcherio Martinoli",
        "authorids": "/37086574560;/37089893524;/37089894146;/37325252600;/37086574560;/37089893524;/37089894146;/37325252600",
        "aff": "Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161276/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3498401124870897251&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL)",
        "aff_unique_dep": "School of Architecture, Civil and Environmental Engineering",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10160998",
        "title": "Multi-Robot Coordination and Cooperation with Task Precedence Relationships",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new formulation for the multi-robot task planning and allocation problem that incorporates (a) precedence relationships between tasks; (b) coordination for tasks allowing multiple robots to achieve increased efficiency; and (c) cooperation through the formation of robot coalitions for tasks that cannot be performed by individual robots alone. In our formulation, the tasks and the relationships between the tasks are specified by a task graph. We define a set of reward functions over the task graph's nodes and edges. These functions model the effect of robot coalition size on task performance while incorporating the influence of one task's performance on a dependent task. Solving this problem optimally is NP-hard. However, using the task graph formulation allows us to leverage min-cost network flow approaches to obtain approximate solutions efficiently. Additionally, we explore a mixed integer programming approach, which gives optimal solutions for small instances of the problem but is computationally expensive. We also develop a greedy heuristic algorithm as a baseline. Our modeling and solution approaches result in task plans that leverage task precedence relationships and robot coordination and cooperation to achieve high mission performance, even in large missions with many agents.",
        "primary_area": "",
        "author": "Walker Gosrich;Siddharth Mayya;Saaketh Narayan;Matthew Malencia;Saurav Agarwal;Vijay Kumar;Walker Gosrich;Siddharth Mayya;Saaketh Narayan;Matthew Malencia;Saurav Agarwal;Vijay Kumar",
        "authorids": "/37088741101;/37085621013;/37089195110;/37088506525;/37089477142;/37280341400;/37088741101;/37085621013;/37089195110;/37088506525;/37089477142;/37280341400",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; Amazon Robotics, North Reading, MA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160998/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12548060545409178874&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania;Amazon Robotics",
        "aff_unique_dep": "GRASP Laboratory;",
        "aff_unique_url": "https://www.upenn.edu;https://www.amazonrobotics.com",
        "aff_unique_abbr": "UPenn;Amazon Robotics",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Philadelphia;North Reading",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160344",
        "title": "Multi-Robot Mission Planning in Dynamic Semantic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses a new semantic multi-robot planning problem in uncertain and dynamic environments. Particularly, the environment is occupied with mobile and uncertain semantic targets. These targets are governed by stochastic dynamics while their current and future positions as well as their semantic labels are uncertain. Our goal is to control mobile sensing robots so that they can accomplish collaborative semantic tasks defined over the uncertain current/future positions and semantic labels of these targets. We express these tasks using Linear Temporal Logic (LTL). We propose a sampling-based approach that explores the robot motion space, the mission specification space, as well as the future configurations of the semantic targets to design optimal paths. These paths are revised online to adapt to uncertain perceptual feedback. To the best of our knowledge, this is the first work that addresses semantic mission planning problems in uncertain and dynamic semantic environments. We provide extensive experiments that demonstrate the efficiency of the proposed method.",
        "primary_area": "",
        "author": "Samarth Kalluraya;George J. Pappas;Yiannis Kantaros;Samarth Kalluraya;George J. Pappas;Yiannis Kantaros",
        "authorids": "/37089476054;/37281547100;/37085499544;/37089476054;/37281547100;/37085499544",
        "aff": "Department of Electrical and Systems Engineering (ESE), Washington University in St. Louis, St. Louis, MO, USA; Department of ESE, University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering (ESE), Washington University in St. Louis, St. Louis, MO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160344/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10464019737133905211&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Washington University in St. Louis;University of Pennsylvania",
        "aff_unique_dep": "Department of Electrical and Systems Engineering;Department of Electrical and Systems Engineering",
        "aff_unique_url": "https://wustl.edu;https://www.upenn.edu",
        "aff_unique_abbr": "WUSTL;UPenn",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "St. Louis;Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160482",
        "title": "Multi-State Tightly-Coupled EKF-Based Radar-Inertial Odometry With Persistent Landmarks",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a Radar-Inertial Odometry (RIO) approach that utilizes performance improving modules, enhanced for the sparse and noisy radar signals, from the vision community in order to estimate the full 6DoF pose and 3D velocity of a robot in an unprepared environment. Our method leverages a multi-state approach in which we make use of several past robot poses and trails of measurements from a lightweight and inexpensive Frequency Modulated Continuous Wave (FMCW) radar sensor. Furthermore, in our estimation framework we include a method for promoting measurement trails to persistent landmarks which correspond to salient features in the environment. In an Extended Kalman Filter (EKF) framework, we fuse the range measurements to the persistent landmarks, trails, and the velocity measurements of the detected 3D points together with the Inertial Measurement Unit (IMU) readings. Our method is particularly relevant for (but not limited to) Unmanned Aerial Vehicles (UAV), enabling them to localize while performing missions in Global Navigation Satellite System (GNSS)-denied environments and, thanks to the properties of the radar sensor, in environments generally challenging for robot perception due to external factors such as smoke or extreme illumination. We show in real flight experiments the effectiveness of our estimator and compare it to the state-of-the-art.",
        "primary_area": "",
        "author": "Jan Michalczyk;Roland Jung;Christian Brommer;Stephan Weiss;Jan Michalczyk;Roland Jung;Christian Brommer;Stephan Weiss",
        "authorids": "/37089462521;/37087323495;/37086574162;/37535323400;/37089462521;/37087323495;/37086574162;/37535323400",
        "aff": "Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160482/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1454458433198722379&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Control of Networked Systems Group",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "10160919",
        "title": "Multi-Target Pursuit by a Decentralized Heterogeneous UAV Swarm using Deep Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent pursuit-evasion tasks involving intelligent targets are notoriously challenging coordination problems. In this paper, we investigate new ways to learn such coordinated behaviors of unmanned aerial vehicles (UAVs) aimed at keeping track of multiple evasive targets. Within a Multi-Agent Reinforcement Learning (MARL) framework, we specifically propose a variant of the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) method. Our approach addresses multi-target pursuit-evasion scenarios within non-stationary and unknown environments with random obstacles. In addition, given the critical role played by collective exploration in terms of detecting possible targets, we implement heterogeneous roles for the pursuers for enhanced exploratory actions balanced by exploitation (i.e. tracking) of previously identified targets. Our proposed role-based MADDPG algorithm is not only able to track multiple targets, but also is able to explore for possible targets by means of the proposed Voronoi-based rewarding policy. We implemented, tested and validated our approach in a simulation environment prior to deploying a real-world multi-robot system comprising of Crazyflie drones. Our results demonstrate that a multi-agent pursuit team has the ability to learn highly efficient coordinated control policies in terms of target tracking and exploration even when confronted with multiple fast evasive targets in complex environments.",
        "primary_area": "",
        "author": "Maryam Kouzeghar;Youngbin Song;Malika Meghjani;Roland Bouffanais;Maryam Kouzeghar;Youngbin Song;Malika Meghjani;Roland Bouffanais",
        "authorids": "/37089894807;/37089892553;/37393934900;/37086326507;/37089894807;/37089892553;/37393934900;/37086326507",
        "aff": "Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; University of Ottawa, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160919/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3451808830884357618&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Singapore University of Technology and Design;University of Ottawa",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sutd.edu.sg;https://www.uottawa.ca",
        "aff_unique_abbr": "SUTD;U Ottawa",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Singapore;Canada"
    },
    {
        "id": "10160354",
        "title": "Multi-View Keypoints for Reliable 6D Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "6D Object pose estimation is a fundamental component in robotics enabling efficient interaction with the environment. 6D pose estimation is particularly challenging in bin- picking applications, where many objects are low-feature and reflective, and self-occlusion between objects of the same type is common. We propose a novel multi-view approach leveraging known camera transformations from an eye-in-hand setup to combine heatmap and keypoint estimates into a probability density map over 3D space. The result is a robust approach that is scalable in the number of views. It relies on a confidence score composed of keypoint probabilities and point-cloud alignment error, which allows reliable rejection of false positives. We demonstrate an average pose estimation error of approximately 0.5 mm and 2 degrees across a variety of difficult low-feature and reflective objects in the ROBI dataset, while also surpassing the state-of-art correct detection rate, measured using the 10% object diameter threshold on ADD error.",
        "primary_area": "",
        "author": "Alan Li;Angela P. Schoellig;Alan Li;Angela P. Schoellig",
        "authorids": "/37089893219;/38488605800;/37089893219;/38488605800",
        "aff": "Vector Institute for Artificial Intelligence; Technical University of Munich (TUM)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160354/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13633028580796830841&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Vector Institute for Artificial Intelligence;Technical University of Munich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://vectorinstitute.ai/;https://www.tum.de",
        "aff_unique_abbr": "Vector Institute;TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Canada;Germany"
    },
    {
        "id": "10161034",
        "title": "Multi-embodiment Legged Robot Control as a Sequence Modeling Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots are traditionally bounded by a fixed embodiment during their operational lifetime, which limits their ability to adapt to their surroundings. Co-optimizing control and morphology of a robot, however, is often inefficient due to the complex interplay between the controller and morphology. In this paper, we propose a learning-based control method that can inherently take morphology into consideration such that once the control policy is trained in the simulator, it can be easily deployed to real robots with different embodiments. In particular, we present the Embodiment-aware Transformer (EAT), an architecture that casts this control problem as conditional sequence modeling. EAT outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired robot embodiment, past states, and actions, our EAT model can generate future actions that best fit the current robot embodiment. Experimental results show that EAT can outperform all other alternatives in embodiment-varying tasks, and succeed in an example of real-world evolution tasks: stepping down a stair through updating the morphology alone. We hope that EAT will inspire a new push toward real-world evolution across many domains, where algorithms like EAT can blaze a trail by bridging the field of evolutionary robotics and big data sequence modeling.",
        "primary_area": "",
        "author": "Chen Yu;Weinan Zhang;Hang Lai;Zheng Tian;Laurent Kneip;Jun Wang;Chen Yu;Weinan Zhang;Hang Lai;Zheng Tian;Laurent Kneip;Jun Wang",
        "authorids": "/37089472108;/37086030166;/37089895145;/37089892778;/37569040300;/37086377041;/37089472108;/37086030166;/37089895145;/37089892778;/37569040300;/37086377041",
        "aff": "Digital Brain Lab, Shanghai, China; Dept. of Computer Sci. and Eng., Shanghai Jiao Tong University, China; Dept. of Computer Sci. and Eng., Shanghai Jiao Tong University, China; School of Creativity and Art, ShanghaiTech University, China; School of Info. Sci. and Tech., ShanghaiTech University, China; Centre for Artificial Intelligence, University College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161034/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14815466808733975276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;2;3",
        "aff_unique_norm": "Digital Brain Lab;Shanghai Jiao Tong University;ShanghaiTech University;University College London",
        "aff_unique_dep": ";Dept. of Computer Sci. and Eng.;School of Creativity and Art;Centre for Artificial Intelligence",
        "aff_unique_url": ";https://www.sjtu.edu.cn;https://www.shanghaitech.edu.cn;https://www.ucl.ac.uk",
        "aff_unique_abbr": ";SJTU;ShanghaiTech;UCL",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Shanghai;;London",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10160855",
        "title": "Multi-modal Hierarchical Transformer for Occupancy Flow Field Prediction in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Forecasting the future states of surrounding traffic participants is a crucial capability for autonomous vehicles. The recently proposed occupancy flow field prediction introduces a scalable and effective representation to jointly predict surrounding agents' future motions in a scene. However, the challenging part is to model the underlying social interactions among traffic agents and the relations between occupancy and flow. Therefore, this paper proposes a novel Multi-modal Hierarchical Transformer network that fuses the vectorized (agent motion) and visual (scene flow, map, and occupancy) modalities and jointly predicts the flow and occupancy of the scene. Specifically, visual and vector features from sensory data are encoded through a multi-stage Transformer module and then a late-fusion Transformer module with temporal pixel-wise attention. Importantly, a flow-guided multi-head self-attention (FG-MSA) module is designed to better aggregate the information on occupancy and flow and model the mathematical relations between them. The proposed method is comprehensively validated on the Waymo Open Motion Dataset and compared against several state-of-the-art models. The results reveal that our model with much more compact architecture and data inputs than other methods can achieve comparable performance. We also demonstrate the effectiveness of incorporating vectorized agent motion features and the proposed FG-MSA module. Compared to the ablated model without the FG-MSA module, which won 2 nd place in the 2022 Waymo Occupancy and Flow Prediction Challenge, the current model shows better separability for flow and occupancy and further performance improvements.",
        "primary_area": "",
        "author": "Haochen Liu;Zhiyu Huang;Chen Lv;Haochen Liu;Zhiyu Huang;Chen Lv",
        "authorids": "/37089454713;/37087239692;/37086095836;/37089454713;/37087239692;/37086095836",
        "aff": "School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160855/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3949130191522206588&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160375",
        "title": "Multi-modal Interactive Perception in Human Control of Complex Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing has been increasingly utilized in robot control of unknown objects to infer physical properties and optimize manipulation. However, there is limited understanding about the contribution of different sensory modalities during interactive perception in complex interaction both in robots and in humans. This study investigated the effect of visual and haptic information on humans' exploratory interactions with a \u2018cup of coffee\u2019, an object with nonlinear internal dynamics. Subjects were instructed to rhythmically transport a virtual cup with a rolling ball inside between two targets at a specified frequency, using a robotic interface. The cup and targets were displayed on a screen, and force feedback from the cup-and-ball dynamics was provided via the robotic manipulandum. Subjects were encouraged to explore and prepare the dynamics by \u201cshaking\u201d the cup-and-ball system to find the best initial conditions prior to the task. Two groups of subjects received the full haptic feedback about the cup-and-ball movement during the task; however, for one group the ball movement was visually occluded. Visual information about the ball movement had two distinctive effects on the performance: it reduced preparation time needed to understand the dynamics and, importantly, it led to simpler, more linear input-output interactions between hand and object. The results highlight how visual and haptic information regarding nonlinear internal dynamics have distinct roles for the interactive perception of complex objects.",
        "primary_area": "",
        "author": "Rashida Nayeem;Salah Bazzi;Mohsen Sadeghi;Reza Sharif Razavian;Dagmar Sternad;Rashida Nayeem;Salah Bazzi;Mohsen Sadeghi;Reza Sharif Razavian;Dagmar Sternad",
        "authorids": "/37088507565;/37085815476;/37088998986;/38488619200;/38469397700;/37088507565;/37085815476;/37088998986;/38488619200;/38469397700",
        "aff": "Department of Electrical and Computer Engineering, Biology, Institute for Experiential Robotics, Northeastern University, Boston, MA; Department of Electrical and Computer Engineering, Biology, Institute for Experiential Robotics, Northeastern University, Boston, MA; Department of Electrical and Computer Engineering, Biology, Institute for Experiential Robotics, Northeastern University, Boston, MA; Department of Electrical and Computer Engineering, Biology, Institute for Experiential Robotics, Northeastern University, Boston, MA; Department of Electrical and Computer Engineering, Biology, Institute for Experiential Robotics, Northeastern University, Boston, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160375/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15603388206187753127&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161515",
        "title": "Multi-segmented Adaptive Feet for Versatile Legged Locomotion in Natural Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "Most legged robots are built with leg structures from serially mounted links and actuators and are controlled through complex controllers and sensor feedback. In comparison, animals developed multi-segment legs, mechanical coupling between joints, and multi-segmented feet. They run agile over all terrains, arguably with simpler locomotion control. Here we focus on developing foot mechanisms that resist slipping and sinking also in natural terrain. We present first results of multi-segment feet mounted to a bird-inspired robot leg with multi-joint mechanical tendon coupling. Our one- and two-segment, mechanically adaptive feet show increased viable horizontal forces on multiple soft and hard substrates before starting to slip. We also observe that segmented feet reduce sinking on soft substrates compared to ball-feet and cylinder-feet. We report how multi-segmented feet provide a large range of viable centre of pressure points well suited for bipedal robots, but also for quadruped robots on slopes and natural terrain. Our results also offer a functional understanding of segmented feet in animals like ratite birds.",
        "primary_area": "",
        "author": "Abhishek Chatterjee;An Mo;Bernadett Kiss;Emre Cemal G\u00f6nen;Alexander Badri-Spr\u00f6witz;Abhishek Chatterjee;An Mo;Bernadett Kiss;Emre Cemal G\u00f6nen;Alexander Badri-Spr\u00f6witz",
        "authorids": "/37089894893;/37089658196;/37089663558;/37086919378;/37088340110;/37089894893;/37089658196;/37089663558;/37086919378;/37088340110",
        "aff": "Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Dynamic Locomotion Group, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Department of Mechanical Engineering, KU Leuven, Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161515/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16641855137208037764&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;KU Leuven",
        "aff_unique_dep": "Dynamic Locomotion Group;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.kuleuven.be",
        "aff_unique_abbr": "MPI-IS;KU Leuven",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Stuttgart;Leuven",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Germany;Belgium"
    },
    {
        "id": "10161099",
        "title": "Multi-source Domain Adaptation for Unsupervised Road Defect Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "The performance of road defect segmentation (a.k.a. pixel-level road defect detection) has been improved alongside with remarkable achievement of deep learning. Those improvements need a large-scale and well-constructed dataset. However, road surface materials or designs vary from country to country, and the patterns of defects are hard to pre-define. In this paper, we propose a novel multi-source domain adaptation method to boost the performance of road defect segmentation on an unlabelled dataset. The proposed method generates multi-source ensembled labels using transferred information from models trained with multiple labelled source domains, which are utilised as supervisory signals for the unlabelled target domain. Furthermore, to reduce the domain gap between each source domain and a target domain, these domains are re-aligned with outlier repositioning to improve the defect segmentation performance. We demonstrate the effectiveness of our proposed method on Cracktree200, CRACK500, CFD, and Crack360 datasets. Experimental results show that the proposed method outperforms the existing unsupervised road defect segmentation methods and achieves competitive performance compared with recent supervised methods. The source code is publicly available on https://github.com/andreYoo/MSDA_RDS.git.",
        "primary_area": "",
        "author": "Jongmin Yu;Hyeontaek Oh;Sebastiano Fichera;Paolo Paoletti;Shan Luo;Jongmin Yu;Hyeontaek Oh;Sebastiano Fichera;Paolo Paoletti;Shan Luo",
        "authorids": "/37085574898;/38063839000;/37087009740;/37658465300;/37085478830;/37085574898;/38063839000;/37087009740;/37658465300;/37085478830",
        "aff": "Department of Engineering, King's College London, Strand, London, United Kingdom; Institute for Information Technology Convergence, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Engineering, University of Liverpool, Liverpool, United Kingdom; School of Engineering, University of Liverpool, Liverpool, United Kingdom; Department of Engineering, King's College London, Strand, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161099/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7951459757339367547&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;0",
        "aff_unique_norm": "King's College London;Korea Advanced Institute of Science and Technology;University of Liverpool",
        "aff_unique_dep": "Department of Engineering;Institute for Information Technology Convergence;School of Engineering",
        "aff_unique_url": "https://www.kcl.ac.uk;https://www.kaist.ac.kr;https://www.liverpool.ac.uk",
        "aff_unique_abbr": "KCL;KAIST;UoL",
        "aff_campus_unique_index": "0;1;2;2;0",
        "aff_campus_unique": "Strand;Daejeon;Liverpool",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United Kingdom;South Korea"
    },
    {
        "id": "10161299",
        "title": "Multi-swarm Genetic Gray Wolf Optimizer with Embedded Autoencoders for High-dimensional Expensive Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "High-dimensional expensive problems are often encountered in the design and optimization of complex robotic and automated systems and distributed computing systems, and they suffer from a time-consuming fitness evaluation process. It is extremely challenging and difficult to produce promising solutions in a high-dimensional search space. This work proposes an evolutionary optimization framework with embedded autoencoders that effectively solve optimization problems with high-dimensional search space. Autoencoders provide strong dimension reduction and feature extraction abilities that compress a high-dimensional space to an informative low-dimensional one. Search operations are performed in a low-dimensional space, thereby guiding whole population to converge to the optimal solution more efficiently. Multiple subpopulations coevolve iteratively in a distributed manner. One subpopulation is embedded by an autoencoder, and the other one is guided by a newly proposed Multi-swarm Gray-wolf-optimizer based on Genetic-learning (MGG). Thus, the proposed multi-swarm framework is named Autoencoder-based MGG (AMGG). AMGG consists of three proposed strategies that balance exploration and exploitation abilities, i.e., a dynamic subgroup number strategy for reducing the number of subpopulations, a subpopulation reorganization strategy for sharing useful information about each subpopulation, and a purposeful detection strategy for escaping from local optima and improving exploration ability. AMGG is compared with several widely used algorithms by solving benchmark problems and a real-life optimization one. The results well verify that AMGG outperforms its peers in terms of search accuracy and convergence efficiency.",
        "primary_area": "",
        "author": "Jing Bi;Jiahui Zhai;Haitao Yuan;Ziqi Wang;Junfei Qiao;Jia Zhang;MengChu Zhou;Jing Bi;Jiahui Zhai;Haitao Yuan;Ziqi Wang;Junfei Qiao;Jia Zhang;MengChu Zhou",
        "authorids": "/37530385000;/37089294113;/37592390300;/37088771177;/37273179900;/37281461700;/37273591600;/37530385000;/37089294113;/37592390300;/37088771177;/37273179900;/37281461700;/37273591600",
        "aff": "Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Department of Computer Science, Lyle School of Engineering at Southern Methodist University, Dallas, TX, USA; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161299/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10044702111950282363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;2;3",
        "aff_unique_norm": "Beijing University of Technology;Beihang University;Southern Methodist University;New Jersey Institute of Technology",
        "aff_unique_dep": "Faculty of Information Technology;School of Automation Science and Electrical Engineering;Department of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.bit.edu.cn;http://www.buaa.edu.cn;https://www.smu.edu;https://www.njit.edu",
        "aff_unique_abbr": "BIT;BUAA;SMU;NJIT",
        "aff_campus_unique_index": "0;0;0;0;0;1;2",
        "aff_campus_unique": "Beijing;Dallas;Newark",
        "aff_country_unique_index": "0;0;0;0;0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160496",
        "title": "Multi-to-Single Knowledge Distillation for Point Cloud Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "3D point cloud semantic segmentation is one of the fundamental tasks for environmental understanding. Although significant progress has been made in recent years, the performance of classes with few examples or few points is still far from satisfactory. In this paper, we propose a novel multi-to-single knowledge distillation framework for the 3D point cloud semantic segmentation task to boost the performance of those hard classes. Instead of fusing all the points of multi-scans directly, only the instances that belong to the previously defined hard classes are fused. To effectively and sufficiently distill valuable knowledge from multi-scans, we leverage a multilevel distillation framework, i.e., feature representation distillation, logit distillation, and affinity distillation. We further develop a novel instance-aware affinity distillation algorithm for capturing high-level structural knowledge to enhance the distillation efficacy for hard classes. Finally, we conduct experiments on the SemanticKITTI dataset, and the results on both the validation and test sets demonstrate that our method yields substantial improvements compared with the baseline method. The code is available at https://github.com/skyshoumeng/M2SKD.",
        "primary_area": "",
        "author": "Shoumeng Qiu;Feng Jiang;Haiqiang Zhang;Xiangyang Xue;Jian Pu;Shoumeng Qiu;Feng Jiang;Haiqiang Zhang;Xiangyang Xue;Jian Pu",
        "authorids": "/37089893057;/37089893778;/37089688728;/37272718600;/37086254785;/37089893057;/37089893778;/37089688728;/37272718600;/37086254785",
        "aff": "Fudan University; Fudan University; Mogo Auto; Fudan University; Fudan University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160496/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2636274249100640970&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Fudan University;Mogo Auto",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.fudan.edu.cn;",
        "aff_unique_abbr": "Fudan;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "10161514",
        "title": "Multi-view object pose estimation from correspondence distributions and epipolar geometry",
        "track": "main",
        "status": "Poster",
        "abstract": "In many automation tasks involving manipulation of rigid objects, the poses of the objects must be acquired. Vision-based pose estimation using a single RGB or RGB-D sensor is especially popular due to its broad applicability. However, single-view pose estimation is inherently limited by depth ambiguity and ambiguities imposed by various phenom-ena like occlusion, self-occlusion, reflections, etc. Aggregation of information from multiple views can potentially resolve these ambiguities, but the current state-of-the-art multi-view pose estimation method only uses multiple views to aggregate single-view pose estimates, and thus rely on obtaining good single-view estimates. We present a multi-view pose estimation method which aggregates learned 2D-3D distributions from multiple views for both the initial estimate and optional refinement. Our method performs probabilistic sampling of 3D-3D correspondences under epipolar constraints using learned 2D-3D correspondence distributions which are implicitly trained to respect visual ambiguities such as symmetry. Evaluation on the T-LESS dataset shows that our method reduces pose estimation errors by 80\u201391% compared to the best single-view method, and we present state-of-the-art results on T-LESS with four views, even compared with methods using five and eight views.",
        "primary_area": "",
        "author": "Rasmus Laurvig Haugaard;Thorbjorn Mosekjaer Iversen;Rasmus Laurvig Haugaard;Thorbjorn Mosekjaer Iversen",
        "authorids": "/37089538190;/37086208129;/37089538190;/37086208129",
        "aff": "SDU Robotics, Maersk Mc-Kinney Moller Institute, University of Southern Denmark.; SDU Robotics, Maersk Mc-Kinney Moller Institute, University of Southern Denmark.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161514/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6795934470297450424&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "SDU Robotics, Maersk Mc-Kinney Moller Institute",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "10161067",
        "title": "Multiagent Reinforcement Learning for Autonomous Routing and Pickup Problem with Adaptation to Variable Demand",
        "track": "main",
        "status": "Poster",
        "abstract": "We derive a learning framework to generate routing/pickup policies for a fleet of autonomous vehicles tasked with servicing stochastically appearing requests on a city map. We focus on policies that 1) give rise to coordination amongst the vehicles, thereby reducing wait times for servicing requests, 2) are non-myopic, and consider a-priori potential future requests, 3) can adapt to changes in the underlying demand distribution. Specifically, we are interested in policies that are adaptive to fluctuations of actual demand conditions in urban environments, such as on-peak vs. off-peak hours. We achieve this through a combination of (i) an online play algorithm that improves the performance of an offline-trained policy, and (ii) an offline approximation scheme that allows for adapting to changes in the underlying demand model. In particular, we achieve adaptivity of our learned policy to different demand distributions by quantifying a region of validity using the q-valid radius of a Wasserstein Ambiguity Set. We propose a mechanism for switching the originally trained offline approximation when the current demand is outside the original validity region. In this case, we propose to use an offline architecture, trained on a historical demand model that is closer to the current demand in terms of Wasserstein distance. We learn routing and pickup policies over real taxicab requests in San Francisco with high variability between on-peak and off-peak hours, demonstrating the ability of our method to adapt to real fluctuation in demand distributions. Our numerical results demonstrate that our method outperforms alternative rollout-based reinforcement learning schemes, as well as other classical methods from operations research.",
        "primary_area": "",
        "author": "Daniel Garces;Sushmita Bhattacharya;Stephanie Gil;Dimitri Bertsekas;Daniel Garces;Sushmita Bhattacharya;Stephanie Gil;Dimitri Bertsekas",
        "authorids": "/37089893002;/37088380490;/37396689900;/37299959200;/37089893002;/37088380490;/37396689900;/37299959200",
        "aff": "REACT lab, Harvard University, Boston, MA, USA; REACT lab, Harvard University, Boston, MA, USA; REACT lab, Harvard University, Boston, MA, USA; Department of Electrical Engineering and Computer Science, Arizona State University, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161067/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3074537686138760823&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Harvard University;Arizona State University",
        "aff_unique_dep": "REACT lab;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.harvard.edu;https://www.asu.edu",
        "aff_unique_abbr": "Harvard;ASU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Boston;AZ",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161567",
        "title": "Multimodal Image Registration for GPS-denied UAV Navigation Based on Disentangled Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual navigation plays an important role for Unmanned Aerial Vehicles(UAVs). In some applications, the landmark image and the real-time image may be heterogeneous, like near-infrared and visible images. In this work, we propose a multimodal image registration method to deal with near-infrared and visible images so that it can be applied to visual navigation system for the localization of UAVs in GPS-denied environments. At first, a new feature extraction strategy is developed to embed different modalities of images into the common feature space based on disentangled representations. Such common space is independent of the image modality, and this can eliminate the modality differences. Meanwhile, an intensity loss is introduced to measure the similarity of mono-modal images. In the proposed method, we can directly predict the transformation parameters and thus accelerates the localization of UAV s. Extensive experiments on synthetic datasets are conducted to demonstrate the validity of our method, and the experimental results show that the proposed method can effectively improve the localization accuracy.",
        "primary_area": "",
        "author": "Huandong Li;Zhunga Liu;Yanyi Lyu;Feiyan Wu;Huandong Li;Zhunga Liu;Yanyi Lyu;Feiyan Wu",
        "authorids": "/37089894191;/37958001400;/37089895782;/37089895502;/37089894191;/37958001400;/37089895782;/37089895502",
        "aff": "School of Automation, Northwestern Polytechnical University, China; School of Automation, Northwestern Polytechnical University, China; School of Automation, Northwestern Polytechnical University, China; School of Automation, Northwestern Polytechnical University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161567/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4783401362920841053&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Northwestern Polytechnical University",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "https://www.nwpu.edu.cn",
        "aff_unique_abbr": "NPU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160388",
        "title": "Multimodal Neural Radiance Field",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the challenge of reconstructing a scene with a neural radiance field (NeRF) for robot vision and scene understanding using multiple modalities. Researchers have introduced the use of NeRF to represent an object for synthesizing and rendering novel views of complex scenes by optimizing a 3-D radiance field for ray casting and rendering for 2-D RGB images. However, using RGB images alone introduces additional geometry ambiguities with transparent objects or complex scenes and cannot accurately depict the 3-D shapes. We discuss and solve this problem and use multiple modalities as input for the same NeRF model to build a multimodal NeRF by incorporating point clouds and infrared image supervision to prevent such bias. In contrast to RGB images, infrared images and point clouds are typically taken by separate cameras that cannot be aligned with the RGB camera. We further introduce the alignment of different modalities based on point cloud registration to estimate the relative transformation matrices between them before training a NeRF model with multiple modalities. We evaluate our model on chosen scenes from the ScanNet and M2DGR datasets and demonstrate that it outperforms existing state-of-the-art methods.",
        "primary_area": "",
        "author": "Haidong Zhu;Yuyin Sun;Chi Liu;Lu Xia;Jiajia Luo;Nan Qiao;Ram Nevatia;Cheng\u2013Hao Kuo;Haidong Zhu;Yuyin Sun;Chi Liu;Lu Xia;Jiajia Luo;Nan Qiao;Ram Nevatia;Cheng\u2013Hao Kuo",
        "authorids": "/37088449649;/37089939953;/37089895235;/37089919794;/37089892157;/37089713130;/37279644100;/37089939406;/37088449649;/37089939953;/37089895235;/37089919794;/37089892157;/37089713130;/37279644100;/37089939406",
        "aff": "Department of Computer Science, University of Southern California; Amazon Lab126, USA; Amazon Lab126, USA; Amazon Lab126, USA; Amazon Lab126, USA; Amazon Lab126, USA; Department of Computer Science, University of Southern California; Amazon Lab126, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160388/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9656410856104521216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;1;0;1",
        "aff_unique_norm": "University of Southern California;Amazon Lab126",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.usc.edu;https://www.amazon.com",
        "aff_unique_abbr": "USC;Lab126",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161223",
        "title": "Multimodal Time Series Learning of Robots Based on Distributed and Integrated Modalities: Verification with a Simulator and Actual Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We have developed an autonomous robot motion generation model based on distributed and integrated multimodal learning. Since each modality used as a robot's senses, such as image, joint angle, and torque, has a different physical meaning and time characteristic, the generation of autonomous motions using multimodal learning has sometimes failed due to overlearning in one of the modalities. Inspired by the sensory processing of the human brain, our model is based on the processing of each sense performed in the primary somatosensory cortex and the integrated processing of multiple senses in the association cortex and the primary motor cortex. Specifically, the proposed model utilizes two types of recurrent neural networks: sensory RNNs, which learn each sense in a time series, and a union RNN, which communicates with sensory RNNs and learns sensory integration. The simulation results of multiple tasks showed that our model processes multiple modalities appropriately and generates smoother motions with lower jerk than the conventional model. We also demonstrated a chair assembly task by combining fixed motions and autonomous motions with our model.",
        "primary_area": "",
        "author": "Hideyuki Ichiwara;Hiroshi Ito;Kenjiro Yamamoto;Hiroki Mori;Tetsuya Ogata;Hideyuki Ichiwara;Hiroshi Ito;Kenjiro Yamamoto;Hiroki Mori;Tetsuya Ogata",
        "authorids": "/37089449817;/37088235935;/38127848300;/37086432927;/37273829100;/37089449817;/37088235935;/38127848300;/37086432927;/37273829100",
        "aff": "Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Research & Development Group, Hitachi, Ltd., Ibaraki, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161223/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6423384586247045345&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Waseda University;Hitachi, Ltd.",
        "aff_unique_dep": "Department of Intermedia Art and Science;Research & Development Group",
        "aff_unique_url": "https://www.waseda.jp/top;https://www.hitachi.com",
        "aff_unique_abbr": "Waseda;Hitachi",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160701",
        "title": "Multiple Surgical Instruments Tracking-By-Prediction With Graph Hierarchy",
        "track": "main",
        "status": "Poster",
        "abstract": "Current research strive has tremendously changed the horizon of computer vision tasks in multiple agents tracking. Nevertheless, in the research of robotic assisted surgery, reliable surgical instrument tracking imposes challenge due to the high complexity in state modeling for the hierarchical structure of the instrument versus de-coupling the spatial-temporal correlations naturally embedded in the task. In this paper, we present a new tracking paradigm integrating the trajectory prediction to reduce the data association error that is propagated from the false detection. As a key component in the system, a proposed predictor disentangles the hierarchical modeling and agent kinematic learning by introducing inductive attention mechanism in spatial-temporal graph network. Experiments on real anatomical datasets show that our tracking-by-prediction scheme improves overall localization accuracy over the frames by up to 81%, in comparison to the generic pipelines of tracking, even with transductive graph representation learning, with a large margin of gain in terms of precise localization.",
        "primary_area": "",
        "author": "Rui Guo;Xi Liu;Ziheng Wang;Anthony Jarc;Rui Guo;Xi Liu;Ziheng Wang;Anthony Jarc",
        "authorids": "/37086487136;/37089892192;/37075914900;/38666586800;/37086487136;/37089892192;/37075914900;/38666586800",
        "aff": "Intuitive Surgical Inc.; Intuitive Surgical Inc.; Intuitive Surgical Inc.; leading the operative analytics team, Intuitive Surgical Inc., Peachtree Corners, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160701/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9633779693940378418&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Intuitive Surgical Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.intuitivesurgical.com",
        "aff_unique_abbr": "Intuitive Surgical",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Peachtree Corners",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160666",
        "title": "NIFT: Neural Interaction Field and Template for Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce NIFT, Neural Interaction Field and Template, a descriptive and robust interaction representation of object manipulations to facilitate imitation learning. Given a few object manipulation demos, NIFT guides the generation of the interaction imitation for a new object instance by matching the Neural Interaction Template (NIT) extracted from the demos in the target Neural Interaction Field (NIF) defined for the new object. Specifically, the NIF is a neural field that encodes the relationship between each spatial point and a given object, where the relative position is defined by a spherical distance function rather than occupancies or signed distances, which are commonly adopted by conventional neural fields but less informative. For a given demo interaction, the corresponding NIT is defined by a set of spatial points sampled in the demo NIF with associated neural features. To better capture the interaction, the points are sampled on the Interaction Bisector Surface (IBS), which consists of points that are equidistant to the two interacting objects and has been used extensively for interaction representation. With both point selection and pointwise features defined for better interaction encoding, NIT effectively guides the feature matching in the NIFs of the new object instances such that the relative poses are optimized to realize the manipulation while imitating the demo interactions. Experiments show that our NIFT solution outperforms state-of-the-art imitation learning methods for object manipulation and generalizes better to objects from new categories.",
        "primary_area": "",
        "author": "Zeyu Huang;Juzhan Xu;Sisi Dai;Kai Xu;Hao Zhang;Hui Huang;Ruizhen Hu;Zeyu Huang;Juzhan Xu;Sisi Dai;Kai Xu;Hao Zhang;Hui Huang;Ruizhen Hu",
        "authorids": "/37089893167;/37088864883;/37089892411;/37085628970;/37089893383;/37086110259;/37087102312;/37089893167;/37088864883;/37089892411;/37085628970;/37089893383;/37086110259;/37087102312",
        "aff": "Shenzhen University; Shenzhen University; National University of Defense Technology; National University of Defense Technology; Simon Fraser University; Shenzhen University; Shenzhen University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160666/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10749006425830944683&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;2;0;0",
        "aff_unique_norm": "Shenzhen University;National University of Defense Technology;Simon Fraser University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.szu.edu.cn;http://www.nudt.edu.cn/;https://www.sfu.ca",
        "aff_unique_abbr": "SZU;NUDT;SFU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;0;0",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "10160663",
        "title": "NOCaL: Calibration-Free Semi-Supervised Learning of Odometry and Camera Intrinsics",
        "track": "main",
        "status": "Poster",
        "abstract": "There are a multitude of emerging imaging technologies that could benefit robotics. However the need for bespoke models, calibration and low-level processing represents a key barrier to their adoption. In this work we present NOCaL, Neural Odometry and Calibration using Light fields, a semi-supervised learning architecture capable of interpreting previously unseen cameras without calibration. NOCaL learns to estimate camera parameters, relative pose, and scene appearance. It employs a scene-rendering hypernetwork pre-trained on a large number of existing cameras and scenes, and adapts to previously unseen cameras using a small supervised training set to enforce metric scale. We demonstrate NOCaL on rendered and captured imagery using conventional cameras, demonstrating calibration-free odometry and novel view synthesis. This work represents a key step toward automating the interpretation of general camera geometries and emerging imaging technologies. Code and datasets are available at https://roboticimaging.org/Projects/NOCaL/.",
        "primary_area": "",
        "author": "Ryan Griffiths;Jack Naylor;Donald G. Dansereau;Ryan Griffiths;Jack Naylor;Donald G. Dansereau",
        "authorids": "/37085652497;/37089894281;/37270808500;/37085652497;/37089894281;/37270808500",
        "aff": "Australian Centre For Robotics, School of Aerospace, Mechanical and Mechatronic Engineering, The University of Sydney; Australian Centre For Robotics, School of Aerospace, Mechanical and Mechatronic Engineering, The University of Sydney; Australian Centre For Robotics, School of Aerospace, Mechanical and Mechatronic Engineering, The University of Sydney",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160663/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18414597519145568168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Sydney",
        "aff_unique_dep": "School of Aerospace, Mechanical and Mechatronic Engineering",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10161352",
        "title": "NOPA: Neurally-guided Online Probabilistic Assistance for Building Socially Intelligent Home Assistants",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we study how to build socially intelligent robots to assist people in their homes. In particular, we focus on assistance with online goal inference, where robots must simultaneously infer humans' goals and how to help them achieve those goals. Prior assistance methods either lack the adaptivity to adjust helping strategies (i.e., when and how to help) in response to uncertainty about goals or the scalability to conduct fast inference in a large goal space. Our NOPA (Neurally-guided Online Probabilistic Assistance) method addresses both of these challenges. NOPA consists of (1) an online goal inference module combining neural goal proposals with inverse planning and particle filtering for robust inference under uncertainty, and (2) a helping planner that discovers valuable subgoals to help with and is aware of the uncertainty in goal inference. We compare NOPA against multiple baselines in a new embodied AI assistance challenge: Online Watch-And-Help, in which a helper agent needs to simultaneously watch a main agent's action, infer its goal, and help perform a common household task faster in realistic virtual home environments. Experiments show that our helper agent robustly updates its goal inference and adapts its helping plans to the changing level of uncertainty.11Code and a supplementary video are available at https://www.tshu.io/online_watch_and_help.",
        "primary_area": "",
        "author": "Xavier Puig;Tianmin Shu;Joshua B. Tenenbaum;Antonio Torralba;Xavier Puig;Tianmin Shu;Joshua B. Tenenbaum;Antonio Torralba",
        "authorids": "/37086231197;/37085659891;/37622583000;/38183107900;/37086231197;/37085659891;/37622583000;/38183107900",
        "aff": "MIT, India; MIT, India; MIT, India; MIT, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161352/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4673597103731839284&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Manipal Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://mit.ac.in",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "10160592",
        "title": "NVRadarNet: Real-Time Radar Obstacle and Free Space Detection for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting obstacles is crucial for safe and efficient autonomous driving. To this end, we present NVRadarNet, a deep neural network (DNN) that detects dynamic obstacles and drivable free space using automotive RADAR sensors. The network utilizes temporally accumulated data from multiple RADAR sensors to detect dynamic obstacles and compute their orientation in a top-down bird's-eye view (BEV). The network also regresses drivable free space to detect unclassified obstacles. Our DNN is the first of its kind to utilize sparse RADAR signals in order to perform obstacle and free space detection in real time from RADAR data only. The network has been successfully used for perception on our autonomous vehicles in real self-driving scenarios. The network runs faster than real time on an embedded GPU and shows good generalization across geographic regions.11Video at https://youtu.be/WlwJJMltoJY.",
        "primary_area": "",
        "author": "Alexander Popov;Patrik Gebhardt;Ke Chen;Ryan Oldja;Alexander Popov;Patrik Gebhardt;Ke Chen;Ryan Oldja",
        "authorids": "/37088689805;/37089893235;/37088689269;/37088687173;/37088689805;/37089893235;/37088689269;/37088687173",
        "aff": "Heeseok Lee, Shane Murray, Ruchi Bhargava, Nikolai Smolyanskiy, NVIDIA; Heeseok Lee, Shane Murray, Ruchi Bhargava, Nikolai Smolyanskiy, NVIDIA; Heeseok Lee, Shane Murray, Ruchi Bhargava, Nikolai Smolyanskiy, NVIDIA; Heeseok Lee, Shane Murray, Ruchi Bhargava, Nikolai Smolyanskiy, NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160592/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13499062397870847484&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NVIDIA Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161258",
        "title": "NanoFlowNet: Real-time Dense Optical Flow on a Nano Quadcopter",
        "track": "main",
        "status": "Poster",
        "abstract": "Nano quadcopters are small, agile, and cheap platforms that are well suited for deployment in narrow, cluttered environments. Due to their limited payload, these vehicles are highly constrained in processing power, rendering conventional vision-based methods for safe and autonomous navigation incompatible. Recent machine learning developments promise high-performance perception at low latency, while dedicated edge computing hardware has the potential to augment the processing capabilities of these limited devices. In this work, we present NanoFlowNet, a lightweight convolutional neural network for real-time dense optical flow estimation on edge computing hardware. We draw inspiration from recent advances in semantic segmentation for the design of this network. Additionally, we guide the learning of optical flow using motion boundary ground truth data, which improves performance with no impact on latency. Validation results on the MPI-Sintel dataset show the high performance of the proposed network given its constrained architecture. Additionally, we successfully demonstrate the capabilities of NanoFlowNet by deploying it on the ultra-low power GAP8 microprocessor and by applying it to vision-based obstacle avoidance on board a Bitcraze Crazyflie, a 34 g nano quadcopter.",
        "primary_area": "",
        "author": "Rik J. Bouwmeester;Federico Paredes-Vall\u00e9s;Guido C. H. E. de Croon;Rik J. Bouwmeester;Federico Paredes-Vall\u00e9s;Guido C. H. E. de Croon",
        "authorids": "/37089895959;/37088432114;/37698062600;/37089895959;/37088432114;/37698062600",
        "aff": "Micro Air Vehicle Laboratory, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Micro Air Vehicle Laboratory, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Micro Air Vehicle Laboratory, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161258/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12943786131852282535&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Faculty of Aerospace Engineering",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10160906",
        "title": "Natural Language Instruction Understanding for Robotic Manipulation: a Multisensory Perception Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "It has always been expected that the robot can understand the natural language instruction and thus a more natural human-robot interaction is achieved. Currently, the robot usually interprets the instruction by visually grounding the textual information to its surroundings, while it may be not enough for some complex situations with only visual perception. So it is reasonable for the robot to leverage its multisensory perception ability to better understand the instruction. In this paper, we propose a multisensory perception approach to tackle the task of natural language instruction understanding for robotic manipulation, in which the robot coordinates its visual, tactile and auditory perception to fully understand the instruction and then executes the manipulation task. Extensive experiments have been conducted demonstrating the superiority of the multisensory perception compared with single sensory perception for instruction understanding. Moreover, we establish a user-friendly human-robot interaction interface where the human sends instruction to the robot via a mobile APP.",
        "primary_area": "",
        "author": "Weihua Wang;Xiaofei Li;Yanzhi Dong;Jun Xie;Di Guo;Huaping Liu;Weihua Wang;Xiaofei Li;Yanzhi Dong;Jun Xie;Di Guo;Huaping Liu",
        "authorids": "/37089637069;/37089892057;/37089597515;/37089895976;/37085360957;/37310126400;/37089637069;/37089892057;/37089597515;/37089895976;/37085360957;/37310126400",
        "aff": "Department of Physics and Electronic Information, Yantai University, Yantai, China; Department of Information and Computers, Taiyuan University of Technology, Taiyuan, China; Department of Physics and Electronic Information, Yantai University, Yantai, China; Department of Information and Computers, Taiyuan University of Technology, Taiyuan, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160906/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9740093182117769539&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;2;3",
        "aff_unique_norm": "Yantai University;Taiyuan University of Technology;Beijing University of Posts and Telecommunications;Tsinghua University",
        "aff_unique_dep": "Department of Physics and Electronic Information;Department of Information and Computers;School of Artificial Intelligence;Department of Computer Science and Technology",
        "aff_unique_url": "http://www.ytu.edu.cn;;http://www.bupt.edu.cn/;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": ";;BUPT;THU",
        "aff_campus_unique_index": "0;1;0;1;2;2",
        "aff_campus_unique": "Yantai;Taiyuan;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161540",
        "title": "Navigating Soft Robots through Wireless Heating",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work on battery-free soft robotics has demonstrated the use of liquid crystal elastomers (LCE) to build shape-changing materials activated by applied external heat. However, sources of heat must typically be in direct field-of-view of the robot (i.e. NIR, laser, and visual light EM sources or convective heats guns), be tethered to an external power supply (i.e. thermoelectric heating or resistive joule heaters), or require a heavy on-board battery that limits mobility and range. This paper presents a novel battery-free soft-robotics platform that can crawl through confined, enclosed, and hard-to-reach spaces (e.g. packages, machinery, pipes, etc.), hidden from view of heating infrastructure. This is achieved through the co-design of a soft robotics platform and integrated soft conductive traces that enable wireless (microwave) heating through remote stimulation. We achieve fast actuation through a careful choice of materials and the overall mechanical structure of the robot to maximize heating efficiency. Further, the robot is actively tracked through enclosed spaces using a mm Wave radar to direct heat to its location. We provide a detailed evaluation on the robot's heating efficiency, location-tracking accuracy and crawling speed.",
        "primary_area": "",
        "author": "Yiwen Song;Mason Zadan;Kushaan Misra;Zefang Li;Jingxian Wang;Carmel Majidi;Swarun Kumar;Yiwen Song;Mason Zadan;Kushaan Misra;Zefang Li;Jingxian Wang;Carmel Majidi;Swarun Kumar",
        "authorids": "/37088992099;/37089893508;/37089895895;/37089893731;/37089895572;/37589572800;/37089894617;/37088992099;/37089893508;/37089895895;/37089893731;/37089895572;/37589572800;/37089894617",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161540/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=952933035421361116&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160561",
        "title": "Navigation with polytopes and B-spline path planner",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper firstly presents our optimal path planning algorithm within a 2\\mathrm{D}2\\mathrm{D} non-convex, polytopic region defined as a sequence of connected convex polytopes. The path is a B-spline curve but being parametrized with its equivalent B\u00e9zier representation. By doing this, the local convexity bound of each curve's interval is significantly tighter. Thus, it allows many more possibilities for constraining the entire curve to remain inside the region by using only linear constraints on the control points of the curve. We further guarantee the existence of the valid path by pointing out an algebraic solution. We integrate the algorithm, together with our previously published results, into the Navigation with polytopes toolbox which can be used as a global path planner, compatible with ROS navigation tools. It provides a framework for constructing a polytope map from a standard occupancy gridmap, searching for an appropriate sequence of connected polytopes and finally, planning a minimal-length path with different options on B-spline or B\u00e9zier parametrizations. The validation and comparison with existing methods are done using gridmaps collected under Gazebo simulations and real experiments.",
        "primary_area": "",
        "author": "Ngoc Thinh Nguyen;Pranav Tej Gangavarapu;Arne Sahrhage;Georg Schildbach;Floris Ernst;Ngoc Thinh Nguyen;Pranav Tej Gangavarapu;Arne Sahrhage;Georg Schildbach;Floris Ernst",
        "authorids": "/37086093218;/37089895356;/37089893841;/38232682600;/38580466700;/37086093218;/37089895356;/37089893841;/38232682600;/38580466700",
        "aff": "University of Luebeck (UzL), Institute for Robotics and Cognitive Systems, Luebeck, Germany; University of Luebeck (UzL), Institute for Robotics and Cognitive Systems, Luebeck, Germany; University of Luebeck (UzL), Institute for Robotics and Cognitive Systems, Luebeck, Germany; UzL, Institute for Electrical Engineering in Medicine, Luebeck, Germany; University of Luebeck (UzL), Institute for Robotics and Cognitive Systems, Luebeck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160561/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=886681068799669072&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Luebeck",
        "aff_unique_dep": "Institute for Robotics and Cognitive Systems",
        "aff_unique_url": "https://www.uni-luebeck.de",
        "aff_unique_abbr": "UzL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Luebeck",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161420",
        "title": "NeRF-Loc: Visual Localization with Conditional Neural Radiance Field",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel visual re-localization method based on direct matching between the implicit 3D descriptors and the 2D image with transformer. A conditional neural radiance field(NeRF) is chosen as the 3D scene representation in our pipeline, which supports continuous 3D descriptors generation and neural rendering. By unifying the feature matching and the scene coordinate regression to the same framework, our model learns both generalizable knowledge and scene prior respectively during two training stages. Furthermore, to improve the localization robustness when domain gap exists between training and testing phases, we propose an appearance adaptation layer to explicitly align styles between the 3D model and the query image. Experiments show that our method achieves higher localization accuracy than other learning-based approaches on multiple benchmarks. Code is available at https://github.com/JenningsL/nerf-loc.",
        "primary_area": "",
        "author": "Jianlin Liu;Qiang Nie;Yong Liu;Chengjie Wang;Jianlin Liu;Qiang Nie;Yong Liu;Chengjie Wang",
        "authorids": "/37089894682;/37086798026;/37089651051;/37088458007;/37089894682;/37086798026;/37089651051;/37088458007",
        "aff": "Tencent, Shennan Boulevard, Nanshan District, Shenzhen, China; Tencent, Shennan Boulevard, Nanshan District, Shenzhen, China; Tencent, Shennan Boulevard, Nanshan District, Shenzhen, China; Tencent, Shennan Boulevard, Nanshan District, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161420/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3257870668027109195&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tencent",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tencent.com",
        "aff_unique_abbr": "Tencent",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161544",
        "title": "NeRF2Real: Sim2real Transfer of Vision-guided Bipedal Motion Skills using Neural Radiance Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a system for applying sim2real approaches to \u201cin the wild\u201d scenes with realistic visuals, and to policies which rely on active perception using RGB cameras. Given a short video of a static scene collected using a generic phone, we learn the scene's contact geometry and a function for novel view synthesis using a Neural Radiance Field (NeRF). We augment the NeRF rendering of the static scene by overlaying the rendering of other dynamic objects (e.g. the robot's own body, a ball). A simulation is then created using the rendering engine in a physics simulator which computes contact dynamics from the static scene geometry (estimated from the NeRF vol-ume density) and the dynamic objects' geometry and physical properties (assumed known). We demonstrate that we can use this simulation to learn vision-based whole body navigation and ball pushing policies for a 20 degree-of-freedom humanoid robot with an actuated head-mounted RGB camera, and we successfully transfer these policies to a real robot.",
        "primary_area": "",
        "author": "Arunkumar Byravan;Jan Humplik;Leonard Hasenclever;Arthur Brussee;Francesco Nori;Tuomas Haarnoja;Ben Moran;Steven Bohez;Fereshteh Sadeghi;Bojan Vujatovic;Nicolas Heess;Arunkumar Byravan;Jan Humplik;Leonard Hasenclever;Arthur Brussee;Francesco Nori;Tuomas Haarnoja;Ben Moran;Steven Bohez;Fereshteh Sadeghi;Bojan Vujatovic;Nicolas Heess",
        "authorids": "/37085466102;/37089895652;/37089663333;/37089894232;/37295476700;/37660891300;/37089892578;/37085637809;/37669775100;/37089893636;/38467156100;/37085466102;/37089895652;/37089663333;/37089894232;/37295476700;/37660891300;/37089892578;/37085637809;/37669775100;/37089893636;/38467156100",
        "aff": "DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161544/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4523949781309282835&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161040",
        "title": "NeRFing it: Offline Object Segmentation Through Implicit Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Most recently proposed methods for robotic per-ception are based on deep learning, which require very large datasets to perform well. The accuracy of a learned model is mainly dependent on the data distribution it was trained on. Thus for deploying such models, it is crucial to use training data belonging to the robot's environment. However, collecting and labeling data is a significant bottleneck, necessitating efficient data collection and labeling pipelines. This paper presents a method to compute high-quality object segmentation maps for RGB-D video sequences using minimal human labeling effort. We leverage the density learned by a Neural Radiance Field (NeRF) to infer the geometry of the scene, which we use to compute dense segmentation maps using a single 3D bounding box provided by a user. We study the accuracy of the computed segmentation maps and present a way to generate additional synthetic training examples observing the scene from novel viewpoints using the learned radiance fields. Our results show that our method is able to compute accurate segmentation maps, outperforming baseline and state-of-the-art methods. We also show that using the synthetic training examples improves performance on a downstream object detection task.",
        "primary_area": "",
        "author": "Kenneth Blomqvist;Jen Jen Chung;Lionel Ott;Roland Siegwart;Kenneth Blomqvist;Jen Jen Chung;Lionel Ott;Roland Siegwart",
        "authorids": "/37089619841;/37085668354;/38251784400;/37281398300;/37089619841;/37085668354;/38251784400;/37281398300",
        "aff": "ETH Z\u00fcrich, Autonomous Systems Lab; School of ITEE, The University of Queensland, Australia; ETH Z\u00fcrich, Autonomous Systems Lab; ETH Z\u00fcrich, Autonomous Systems Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161040/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4687599711370026600&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich;The University of Queensland",
        "aff_unique_dep": "Autonomous Systems Lab;School of ITEE",
        "aff_unique_url": "https://www.ethz.ch;https://www.uq.edu.au",
        "aff_unique_abbr": "ETH;UQ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Switzerland;Australia"
    },
    {
        "id": "10160526",
        "title": "Neural Contact Fields: Tracking Extrinsic Contact with Tactile Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Neural Contact Fields, a method that brings together neural fields and tactile sensing to address the problem of tracking extrinsic contact between object and environment. Knowing where the external contact occurs is a first step towards methods that can actively control it in facilitating downstream manipulation tasks. Prior work for localizing environmental contacts typically assume a contact type (e.g. point or line), does not capture contact/no-contact transitions, and only works with basic geometric-shaped objects. Neural Contact Fields are the first method that can track arbitrary multi-modal extrinsic contacts without making any assumptions about the contact type. Our key insight is to estimate the probability of contact for any 3D point in the latent space of object's shapes, given vision-based tactile inputs that sense the local motion resulting from the external contact. In experiments, we find that Neural Contact Fields are able to localize multiple contact patches without making any assumptions about the geometry of the contact, and capture contact/no-contact transitions for known categories of objects with unseen shapes in unseen environment configurations. In addition to Neural Contact Fields, we also release our YCB-Extrinsic-Contact dataset of simulated extrinsic contact interactions to enable further research in this area. Project page: https://github.com/carolinahiguera/NCF",
        "primary_area": "",
        "author": "Carolina Higuera;Siyuan Dong;Byron Boots;Mustafa Mukadam;Carolina Higuera;Siyuan Dong;Byron Boots;Mustafa Mukadam",
        "authorids": "/37089295203;/37086249096;/37085459219;/37085562050;/37089295203;/37086249096;/37085459219;/37085562050",
        "aff": "University of Washington; University of Washington; University of Washington; Meta AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160526/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12400618045439812962&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Washington;Meta Platforms, Inc.",
        "aff_unique_dep": ";Meta AI",
        "aff_unique_url": "https://www.washington.edu;https://meta.com",
        "aff_unique_abbr": "UW;Meta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160217",
        "title": "Neural Grasp Distance Fields for Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We formulate grasp learning as a neural field and present Neural Grasp Distance Fields (NGDF). Here, the input is a 6D pose of a robot end effector and output is a distance to a continuous manifold of valid grasps for an object. In contrast to current approaches that predict a set of discrete candidate grasps, the distance-based NGDF representation is easily interpreted as a cost, and minimizing this cost produces a successful grasp pose. This grasp distance cost can be incorporated directly into a trajectory optimizer for joint optimization with other costs such as trajectory smoothness and collision avoidance. During optimization, as the various costs are balanced and minimized, the grasp target is allowed to smoothly vary, as the learned grasp field is continuous. We evaluate NGDF on joint grasp and motion planning in simulation and the real world, outperforming baselines by 63 % execution success while generalizing to unseen query poses and unseen object shapes. Project page: https://sites.google.com/view/neural-grasp-distance-fields.",
        "primary_area": "",
        "author": "Thomas Weng;David Held;Franziska Meier;Mustafa Mukadam;Thomas Weng;David Held;Franziska Meier;Mustafa Mukadam",
        "authorids": "/37085767512;/37408101800;/38227805500;/37085562050;/37085767512;/37408101800;/38227805500;/37085562050",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Meta AI; Meta AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160217/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10061866806459029918&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Carnegie Mellon University;Meta Platforms, Inc.",
        "aff_unique_dep": ";Meta AI",
        "aff_unique_url": "https://www.cmu.edu;https://meta.com",
        "aff_unique_abbr": "CMU;Meta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161206",
        "title": "Neural Implicit Surface Reconstruction using Imaging Sonar",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a technique for dense 3D reconstruction of objects using an imaging sonar, also known as forward-looking sonar (FLS). Compared to previous methods that model the scene geometry as point clouds or volumetric grids, we represent the geometry as a neural implicit function. Additionally, given such a representation, we use a differentiable volumetric renderer that models the propagation of acoustic waves to synthesize imaging sonar measurements. We perform experiments on real and synthetic datasets and show that our algorithm reconstructs high-fidelity surface geometry from multi-view FLS images at much higher quality than was possible with previous techniques and without suffering from their associated memory overhead.",
        "primary_area": "",
        "author": "Mohamad Qadri;Michael Kaess;Ioannis Gkioulekas;Mohamad Qadri;Michael Kaess;Ioannis Gkioulekas",
        "authorids": "/37089659857;/37324200400;/37595566500;/37089659857;/37324200400;/37595566500",
        "aff": "The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161206/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16684767532460142551&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160339",
        "title": "Neural Optimal Control using Learned System Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of generating control laws for systems with unknown dynamics. Our approach is to represent the controller and the value function with neural networks, and to train them using loss functions adapted from the Hamilton-Jacobi-Bellman (HJB) equations. In the absence of a known dynamics model, our method first learns the state transitions from data collected by interacting with the system in an offline process. The learned transition function is then integrated to the HJB equations and used to forward simulate the control signals produced by our controller in a feedback loop. In contrast to trajectory optimization methods that optimize the controller for a single initial state, our controller can generate near-optimal control signals for initial states from a large portion of the state space. Compared to recent model-based reinforcement learning algorithms, we show that our method is more sample efficient and trains faster by an order of magnitude. We demonstrate our method in a number of tasks, including the control of a quadrotor with 12 state variables.",
        "primary_area": "",
        "author": "Selim Engin;Volkan Isler;Selim Engin;Volkan Isler",
        "authorids": "/37086938133;/37298487800;/37086938133;/37298487800",
        "aff": "Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160339/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=410253844111346548&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161351",
        "title": "Neural-Kalman GNSS/INS Navigation for Precision Agriculture",
        "track": "main",
        "status": "Poster",
        "abstract": "Precision agricultural robots require high-resolution navigation solutions. In this paper, we introduce a robust neural-inertial sequence learning approach to track such robots with ultra-intermittent GNSS updates. First, we propose an ultra-lightweight neural-Kalman filter that can track agricultural robots within 1.4 m (1.4\u20135.8\u00d7 better than competing techniques), while tracking within 2.75 m with 20 mins of GPS outage. Second, we introduce a user-friendly video-processing toolbox to generate high-resolution (\u00b15 cm) position data for fine-tuning pre-trained neural-inertial models in the field. Third, we introduce the first and largest (6.5 hours, 4.5 km, 3 phases) public neural-inertial navigation dataset for precision agricultural robots. The dataset, toolbox, and code are available at: https://github.com/nesl/agrobot.",
        "primary_area": "",
        "author": "Yayun Du;Swapnil Sayan Saha;Sandeep Singh Sandha;Arthur Lovekin;Jason Wu;S. Siddharth;Mahesh Chowdhary;Mohammad Khalid Jawed;Mani Srivastava;Yayun Du;Swapnil Sayan Saha;Sandeep Singh Sandha;Arthur Lovekin;Jason Wu;S. Siddharth;Mahesh Chowdhary;Mohammad Khalid Jawed;Mani Srivastava",
        "authorids": "/37088689145;/37089609919;/37085444849;/37089895240;/37089892884;/37089893278;/37088213610;/37088686728;/37272238500;/37088689145;/37089609919;/37085444849;/37089895240;/37089892884;/37089893278;/37088213610;/37088686728;/37272238500",
        "aff": "Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA, United States; Department of Electrical & Computer Engineering, University of California, Los Angeles, Los Angeles, CA, United States; Amazon, Seattle, WA, United States; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA, United States; Department of Electrical & Computer Engineering, University of California, Los Angeles, Los Angeles, CA, United States; STMicroelectronics, Santa Clara, CA, United States; STMicroelectronics, Santa Clara, CA, United States; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA, United States; Department of Electrical & Computer Engineering, University of California, Los Angeles, Los Angeles, CA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161351/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1170966440360581179&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;0;0;2;2;0;0",
        "aff_unique_norm": "University of California, Los Angeles;Amazon;STMicroelectronics",
        "aff_unique_dep": "Department of Mechanical & Aerospace Engineering;;",
        "aff_unique_url": "https://www.ucla.edu;https://www.amazon.com;https://www.st.com",
        "aff_unique_abbr": "UCLA;Amazon;STM",
        "aff_campus_unique_index": "0;0;1;0;0;2;2;0;0",
        "aff_campus_unique": "Los Angeles;Seattle;Santa Clara",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161113",
        "title": "Neuro-Adaptive Dynamic Control with Edge-Computing for Collaborative Digital Twin of an Industrial Robotic Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "With the advancement of industrial manufacturing and an increase in introduction of robots in the workspace, the need of safe operation, communication and information sharing is paramount. The work presented here focuses on cyber-physical system integration through Digital Twin (DT) technology. Our novel DT architecture is based on a model-free Neuro-Adaptive controller (NAC), and an edge-computing scheme for scene monitoring. The NAC can account for varying robot dynamics in both real and virtual environments, and allows for the DT system to expand the realm of cyber-physical integration without expensive model tuning. The edge-computing device introduced in our architecture, observes the robot's workspace from a distance with a wider field of view. This wide viewpoint, enhances the detection and mitigation of any obstacles entering the robot's workspace during operation. We experimentally evaluated the performance of our proposed architecture by introducing dynamic obstacles during a pick-and-place task that both the physical robot and its digital twin had to avoid. Results show that the proposed DT architecture successfully integrates the novel controller and edge-computing elements and successfully performs the given navigation task. The results also show that NAC outperforms a PD controller with more than 70% improvement in joint tracking error between the physical and virtual robots. It was observed that the latency experienced while using NAC is about 48 % lower than when Proportional-Derivative (PD) controller was operational.",
        "primary_area": "",
        "author": "Sumit Kumar Das;Mohammad Helal Uddin;Dan O. Popa;Sabur Baidya;Sumit Kumar Das;Mohammad Helal Uddin;Dan O. Popa;Sabur Baidya",
        "authorids": "/37085338915;/37089201075;/37283733600;/37086071911;/37085338915;/37089201075;/37283733600;/37086071911",
        "aff": "Louisville Automation and Robotics Research Institute (LARRI), University of Louisville, Kentucky, USA; Louisville Automation and Robotics Research Institute (LARRI), University of Louisville, Kentucky, USA; Louisville Automation and Robotics Research Institute (LARRI), University of Louisville, Kentucky, USA; Louisville Automation and Robotics Research Institute (LARRI), University of Louisville, Kentucky, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161113/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11421412316176901458&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Louisville",
        "aff_unique_dep": "Louisville Automation and Robotics Research Institute (LARRI)",
        "aff_unique_url": "https://www.louisville.edu",
        "aff_unique_abbr": "UofL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Louisville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161484",
        "title": "New Bracket Polynomials Associated with the General Gough-Stewart Parallel Robot Singularities",
        "track": "main",
        "status": "Poster",
        "abstract": "It is well known that the singularities of a Gough-Stewart platform arise when the determinant of the Pl\u00fccker coordinates of the robot leg lines vanish. The direct expansion of this determinant in terms of the configuration of the moving platform leads to an intimidating algebraic expression which is difficult to organize in a manner that facilitates extracting geometric conditions for singularities to occur. The use of Grassmann-Cayley algebra has permitted expressing this determinant as a bracket polynomial which is easier to manipulate symbolically. Each monomial in this polynomial is the product of three brackets, 4\u00d74 determinants involving the homogeneous coordinates of four leg attachments. In this paper, we show how to derive, using elementary linear algebra arguments, bracket polynomials where all brackets can be interpreted as reciprocal products between lines. Contrarily to what one might expect, these new bracket polynomials are simpler in general than those previously obtained using Grassmann-Cayley algebra.",
        "primary_area": "",
        "author": "Federico Thomas;Federico Thomas",
        "authorids": "/38308384700;/38308384700",
        "aff": "Institut de Rob\u00f2tica i Informatica Industrial (CSIC-UPC), Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161484/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6220703921649158162&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Informatica Industrial",
        "aff_unique_dep": "CSIC-UPC",
        "aff_unique_url": "https://www.iri.upc.edu",
        "aff_unique_abbr": "IRI",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10160821",
        "title": "Noise and Environmental Justice in Drone Fleet Delivery Paths: A Simulation-Based Audit and Algorithm for Fairer Impact Distribution",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the growing interest in the use of drone fleets for delivery of food and parcels, the negative impact of such technology is still poorly understood. In this paper we investigate the impact of such fleets in terms of noise pollution and environmental justice. We use simulation with real population data to analyze the spatial distribution of noise, and find that: 1) noise increases rapidly with fleet size; and 2) drone fleets can produce noise hotspots that extend far beyond warehouses or charging stations, at levels that lead to annoyance and interference of human activities. This, we will show, leads to concerns of fairness of noise distribution. We then propose an algorithm that successfully balances the spatial distribution of noise across the city, and discuss the limitations of such purely technical approaches. We complement the work with a discussion of environmental justice, showing how careless UAV fleet development and regulation can lead to reinforcing well-being deficiencies of poor and marginalized communities.",
        "primary_area": "",
        "author": "Zewei Zhou;Martim Brand\u00e3o;Zewei Zhou;Martim Brand\u00e3o",
        "authorids": "/843744726722423;/38542529000;/843744726722423;/38542529000",
        "aff": "King's College, London, UK; King's College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160821/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7409887861725309760&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "King's College London",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kcl.ac.uk",
        "aff_unique_abbr": "KCL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160580",
        "title": "Non-Minimal Solvers for Relative Pose Estimation with a Known Relative Rotation Angle",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowing the relative rotation angle improves relative pose estimation accuracy. We consider the problem of computing relative motion from a non-minimal number of correspondences with a known relative rotation angle. While several solvers for minimum correspondences have been proposed, no non-minimal solver for this problem currently exists. In this work, we propose two non-minimal solvers for this problem. The first solver solves the problem using convex relaxation and semidefinite programming, yielding certifiable solutions. The second method approaches the problem through local eigenvalue optimization with random initialization. Increasing the number of initial guesses lowers the chances of missing the correct solution. We conduct experiments on synthetic and real data, confirming our methods' advantages over competing methods.",
        "primary_area": "",
        "author": "Deshun Hu;Deshun Hu",
        "authorids": "/37086129601;/37086129601",
        "aff": "Department of Communication Engineering, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160580/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:rAvRYpENFH8J:scholar.google.com/&scioq=Non-Minimal+Solvers+for+Relative+Pose+Estimation+with+a+Known+Relative+Rotation+Angle&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "Department of Communication Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161054",
        "title": "Non-cooperative Stochastic Target Encirclement by Anti-synchronization Control via Range-only Measurement",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the stochastic moving target encirclement problem in a realistic setting. In contrast to typical assumptions in related works, the target in our work is non-cooperative and capable of escaping the circle containment by boosting its speed to maximum for a short duration. In extreme conditions, where GPS signals are not available, weight restrictions are present, and ground guidance is absent, the agents can rely solely on their onboard single-modality perception tools to measure the distances to the target. The distance measurement allows for creating a position estimator by providing a target position-dependent variable. Furthermore, the construction of the unique distributed anti-synchronization controller (DASC) can guarantee that the two agents track and encircle the target swiftly. The convergence of the estimator and controller is rigorously evaluated using the Lyapunov technique. A real-world UAV-based experiment is conducted to illustrate the performance of the proposed methodology in addition to a simulated Matlab numerical sample. Our video demonstration can be found in the URL https://youtu.be/EDVLvP-bk8M.",
        "primary_area": "",
        "author": "Fen Liu;Shenghai Yuan;Wei Meng;Rong Su;Lihua Xie;Fen Liu;Shenghai Yuan;Wei Meng;Rong Su;Lihua Xie",
        "authorids": "/37086603194;/37085527198;/37573720000;/37300594700;/37274139300;/37086603194;/37085527198;/37573720000;/37300594700;/37274139300",
        "aff": "Guangdong Provincial Key Laboratory of Intelligent Decision and Cooperative Control, School of Automation, Guangdong University of Technology, Guangzhou; the Centre for Advanced Robotics Technology Innovation (CARTIN), School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore; Guangdong Provincial Key Laboratory of Intelligent Decision and Cooperative Control, School of Automation, Guangdong University of Technology, Guangzhou; the Centre for Advanced Robotics Technology Innovation (CARTIN), School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore; the Centre for Advanced Robotics Technology Innovation (CARTIN), School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161054/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=849061617640469099&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "Guangdong University of Technology;Nanyang Technological University",
        "aff_unique_dep": "School of Automation;School of Electrical and Electronic Engineering",
        "aff_unique_url": "http://www.gdut.edu.cn;https://www.ntu.edu.sg",
        "aff_unique_abbr": "GDUT;NTU",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Guangzhou;Singapore",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "10160724",
        "title": "Noncontact Particle Manipulation on Water Surface with Ultrasonic Phased Array System and Microscopic Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Noncontact particle manipulation (NPM) shows great application potential than its conventional counterpart particularly in terms of non-invasiveness, and thus has significantly extended robotic manipulation capacity into bio- medical engineering, material science, etc. As NPM by means of electric, magnetic, and optical field has successfully demonstrated powerful strength in both academia and industry, NPM boosted by acoustic field, however, still faces staggering challenges. It is indeed in the very recent years that controllable dynamic airborne or waterborne acoustic field modulation technology emerged in academia. In this paper, we report our latest research regarding dexterous and dynamic noncontact micro-particle manipulation on water surface effected by acoustic field in terms of automated trapping, closed-loop positioning, and real-time motion planning, which can be applied to scenarios such as parallel 3D printing, cell assembly, etc. The main contribution of this work is we demonstrated the feasibility of objective-oriented and fully automated acoustic manipulation of micro-particle in precision scale based on robotic approach in 2D plane. Experiment results showed that the repetitive positioning accuracy can reach as high as 16 \u03bcm, which is essentially the pixel scale factor.",
        "primary_area": "",
        "author": "Yexin Zhang;Jiaqi Li;Yuyu Jia;Teng Li;Yang Wang;David C. Jeong;Hu Su;Song Liu;Yexin Zhang;Jiaqi Li;Yuyu Jia;Teng Li;Yang Wang;David C. Jeong;Hu Su;Song Liu",
        "authorids": "/37089895212;/37089626651;/37088961912;/37089626327;/37085613649;/37088749138;/37965624300;/37089083036;/37089895212;/37089626651;/37088961912;/37089626327;/37085613649;/37088749138;/37965624300;/37089083036",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Department of Communication, Santa Clara University, Santa Clara, CA, USA; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Shanghai Engineering Research Center of Intelligent Vision and Imaging, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160724/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15641833023060409180&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;2;3",
        "aff_unique_norm": "ShanghaiTech University;Santa Clara University;Chinese Academy of Sciences;Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "aff_unique_dep": "School of Information Science and Technology;Department of Communication;Institute of Automation;",
        "aff_unique_url": "https://www.shanghaitech.edu.cn;https://www.scu.edu;http://www.ia.cas.cn;",
        "aff_unique_abbr": "ShanghaiTech;SCU;CAS;",
        "aff_campus_unique_index": "0;0;0;0;0;1;2",
        "aff_campus_unique": "Shanghai;Santa Clara;Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160873",
        "title": "Nonlinear Model Predictive Control of a 3D Hopping Robot: Leveraging Lie Group Integrators for Dynamically Stable Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "Achieving stable hopping has been a hallmark challenge in the field of dynamic legged locomotion. Controlled hopping is notably difficult due to extended periods of under-actuation combined with very short ground phases wherein ground interactions must be modulated to regulate global state. In this work, we explore the use of hybrid nonlinear model predictive control paired with a low-level feedback controller in a multi-rate hierarchy to achieve dynamically stable motions on a novel 3D hopping robot. In order to demonstrate richer behaviors on the manifold of rotations, both the planning and feedback layers must be designed in a geometrically consistent fashion; therefore, we develop the necessary tools to employ Lie group integrators and appropriate feedback controllers. We experimentally demonstrate stable 3D hopping on a novel robot, as well as trajectory tracking and flipping in simulation.",
        "primary_area": "",
        "author": "Noel Csomay-Shanklin;Victor D. Dorobantu;Aaron D. Ames;Noel Csomay-Shanklin;Victor D. Dorobantu;Aaron D. Ames",
        "authorids": "/37086862522;/37087325294;/37300877900;/37086862522;/37087325294;/37300877900",
        "aff": "Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160873/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18165015692739160747&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Computing and Mathematical Sciences",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161577",
        "title": "Novel Spring Mechanism Enables Iterative Energy Accumulation under Force and Deformation Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Springs can provide force at zero net energy cost by recycling negative mechanical work to benefit motor-driven robots or spring-augmented humans. However, humans have limited force and range of motion, and motors have a limited ability to produce force. These limits constrain how much energy a conventional spring can store and, consequently, how much assistance a spring can provide. In this paper, we introduce an approach to accumulating negative work in assistive springs over several motion cycles. We show that, by utilizing a novel floating spring mechanism, the weight of a human or robot can be used to iteratively increase spring compression, irrespective of the potential energy stored by the spring. Decoupling the force required to compress a spring from the energy stored by a spring advances prior works, and could enable spring-driven robots and humans to perform physically demanding tasks without the use of large actuators.",
        "primary_area": "",
        "author": "Cole A. Dempsey;David J. Braun;Cole A. Dempsey;David J. Braun",
        "authorids": "/37089893884;/37609773600;/37089893884;/37609773600",
        "aff": "Department of Mechanical Engineering, Vanderbilt University, Nashville, Tennessee, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, Tennessee, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161577/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:dhrEZEKNr2wJ:scholar.google.com/&scioq=Novel+Spring+Mechanism+Enables+Iterative+Energy+Accumulation+under+Force+and+Deformation+Constraints&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160562",
        "title": "OPT-Mimic: Imitation of Optimized Trajectories for Dynamic Quadruped Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) has seen many recent successes for quadruped robot control. The imitation of reference motions provides a simple and powerful prior for guiding solutions towards desired solutions without the need for meticulous reward design. While much work uses motion capture data or hand-crafted trajectories as the reference motion, relatively little work has explored the use of reference motions coming from model-based trajectory optimization. In this work, we investigate several design considerations that arise with such a framework, as demonstrated through four dynamic behaviours: trot, front hop, 180 backflip, and biped stepping. These are trained in simulation and transferred to a physical Solo 8 quadruped robot without further adaptation. In particular, we explore the space of feed-forward designs afforded by the trajectory optimizer to understand its impact on RL learning efficiency and sim - to- real transfer. These findings contribute to the long standing goal of producing robot controllers that combine the interpretability and precision of model-based optimization with the robustness that model-free RL- based controllers offer.",
        "primary_area": "",
        "author": "Yuni Fuchioka;Zhaoming Xie;Michiel Van de Panne;Yuni Fuchioka;Zhaoming Xie;Michiel Van de Panne",
        "authorids": "/37089895334;/37086574317;/37283212000;/37089895334;/37086574317;/37283212000",
        "aff": "Faculty of Computer Science, The University of British Columbia; Department of Computer Science, Stanford University; Faculty of Computer Science, The University of British Columbia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160562/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4145410057517863960&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "The University of British Columbia;Stanford University",
        "aff_unique_dep": "Faculty of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.ubc.ca;https://www.stanford.edu",
        "aff_unique_abbr": "UBC;Stanford",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Vancouver;Stanford",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "10160997",
        "title": "ORORA: Outlier-Robust Radar Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Radar sensors are emerging as solutions for perceiving surroundings and estimating ego-motion in extreme weather conditions. Unfortunately, radar measurements are noisy and suffer from mutual interference, which degrades the performance of feature extraction and matching, triggering imprecise matching pairs, which are referred to as outliers. To tackle the effect of outliers on radar odometry, aa novel outlier-robust method called ORORA is proposed, which is an abbreviation of Outlier-RObust RAdar odometry. To this end, a novel decoupling-based method is proposed, which consists of graduated non-convexity (GNC)-based rotation estimation and anisotropic component-wise translation estimation (A-COTE). Furthermore, our method leverages the anisotropic characteristics of radar measurements, each of whose uncertainty along the azimuthal direction is somewhat larger than that along the radial direction. As verified in the public dataset, it was demonstrated that our proposed method yields robust ego-motion estimation performance compared with other state-of-the-art methods. Our code is available at https://github.com/url-kaist/outlier-robust-radar-odometry.",
        "primary_area": "",
        "author": "Hyungtae Lim;Kawon Han;Gunhee Shin;Giseop Kim;Songcheol Hong;Hyun Myung;Hyungtae Lim;Kawon Han;Gunhee Shin;Giseop Kim;Songcheol Hong;Hyun Myung",
        "authorids": "/37086920570;/37086698334;/37089893982;/37086578593;/37278990200;/37424926900;/37086920570;/37086698334;/37089893982;/37086578593;/37278990200;/37424926900",
        "aff": "School of Electrical Engineering, KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea; School of Electrical Engineering, KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea; A research intern in Urban Robotics Lab., KAIST, Daejeon, Republic of Korea; NAVER LABS, Seongnam, Gyeonggi-do, Republic of Korea; School of Electrical Engineering, KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea; School of Electrical Engineering, KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160997/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13410367513415736908&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;KAIST;NAVER LABS",
        "aff_unique_dep": "School of Electrical Engineering;Urban Robotics Lab;",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.kaist.ac.kr;https://www.naverlabs.com",
        "aff_unique_abbr": "KAIST;KAIST;NAVER LABS",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Daejeon;Seongnam",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160377",
        "title": "Object Reconfiguration with Simulation-Derived Feasible Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "3D object reconfiguration encompasses common robot manipulation tasks in which a set of objects must be moved through a series of physically feasible state changes into a desired final configuration. Object reconfiguration is challenging to solve in general, as it requires efficient reasoning about environment physics that determine action validity. This information is typically manually encoded in an explicit transition system. Constructing these explicit encodings is tedious and error-prone, and is often a bottleneck for planner use. In this work, we explore embedding a physics simulator within a motion planner to implicitly discover and specify the valid actions from any state, removing the need for manual specification of action semantics. Our experiments demonstrate that the resulting simulation-based planner can effectively produce physically valid rearrangement trajectories for a range of 3D object reconfiguration problems without requiring more than an environment description and start and goal arrangements.",
        "primary_area": "",
        "author": "Yiyuan Lee;Wil Thomason;Zachary Kingston;Lydia E. Kavraki;Yiyuan Lee;Wil Thomason;Zachary Kingston;Lydia E. Kavraki",
        "authorids": "/37088504931;/37088908744;/37085542480;/37279015600;/37088504931;/37088908744;/37085542480;/37279015600",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160377/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16719493539991690356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160309",
        "title": "Object-based SLAM utilizing unambiguous pose parameters considering general symmetry types",
        "track": "main",
        "status": "Poster",
        "abstract": "Existence of symmetric objects, whose observation at different viewpoints can be identical, can deteriorate the performance of simultaneous localization and mapping (SLAM). This work proposes a system for robustly optimizing the pose of cameras and objects even in the presence of symmetric objects. We classify objects into three categories depending on their symmetry characteristics, which is efficient and effective in that it allows to deal with general objects and the objects in the same category can be associated with the same type of ambiguity. Then we extract only the unambiguous parameters corresponding to each category and use them in data association and joint optimization of the camera and object pose. The proposed approach provides significant robustness to the SLAM performance by removing the ambiguous parameters and utilizing as much useful geometric information as possible. Comparison with baseline algorithms confirms the superior performance of the proposed system in terms of object tracking and pose estimation, even in challenging scenarios where the baseline fails.",
        "primary_area": "",
        "author": "Taekbeom Lee;Youngseok Jang;H. Jin Kim;Taekbeom Lee;Youngseok Jang;H. Jin Kim",
        "authorids": "/37089895641;/37087502351;/37599626400;/37089895641;/37087502351;/37599626400",
        "aff": "Aerospace Engineering Department, Seoul National University, South Korea; Mechanical and Aerospace Engineering Department, Seoul National University, South Korea; Aerospace Engineering Department, Seoul National University, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160309/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15888910699620059919&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Aerospace Engineering Department",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160520",
        "title": "Obscuring Objectives with Pareto-Optimal Privacy-Aware Trajectories in Multi-Robot Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an algorithm for generating Pareto-optimal privacy-aware trajectories for multi-robot coverage. Our approach utilizes a genetic algorithm to generate a set of modified trajectories for a team of robots that wishes to obscure its goal from an observer. A novel velocity-constrained crossover algorithm ensures all child trajectories are feasible for a holonomic vehicle. The Pareto front of generated trajectories allows a team to select an allowable trade-off between privacy and coverage cost given within their task. Simulation results demonstrate the performance of our algorithm in Voronoi-based coverage control. We show our approach successfully obscures the objective from our proposed observer.",
        "primary_area": "",
        "author": "Brennan Brodt;Alyssa Pierson;Brennan Brodt;Alyssa Pierson",
        "authorids": "/37089895658;/37085345711;/37089895658;/37085345711",
        "aff": "Department of Mechanical Engineering, Boston University, Boston, MA, USA; Department of Mechanical Engineering, Boston University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160520/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13263506894542234628&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160636",
        "title": "Observability-Aware Active Extrinsic Calibration of Multiple Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "The extrinsic parameters play a crucial role in multi-sensor fusion, such as visual-inertial Simultaneous Localization and Mapping(SLAM), as they enable the accurate alignment and integration of measurements from different sensors. However, extrinsic calibration is challenging in scenarios, such as underwater, where in-view structures are scanty and visibility is limited, causing incorrect extrinsic calibration due to insufficient motion on all degrees of freedom. In this paper, we propose an entropy-based active extrinsic calibration algorithm leverages observability analysis and information entropy to enhance the accuracy and reliability of extrinsic calibration. It determines the system observability numerically by using singular value decomposition (SVD) of the Fisher Information Matrix (FIM). Furthermore, when the extrinsic parameter is not fully observable, our method actively searches for the next best motion to recover the system's observability via entropy-based optimization. Experimental results on synthetic data, in a simulation, and using an actual underwater vehicle verify that the proposed method is able to avoid the calibration failure while improving the calibration accuracy and reliability.",
        "primary_area": "",
        "author": "Shida Xu;Jonatan Scharff Willners;Ziyang Hong;Kaicheng Zhang;Yvan R. Petillot;Sen Wang;Shida Xu;Jonatan Scharff Willners;Ziyang Hong;Kaicheng Zhang;Yvan R. Petillot;Sen Wang",
        "authorids": "/37089197042;/37086222444;/37088217691;/37089195030;/37282015500;/37086278300;/37089197042;/37086222444;/37088217691;/37089195030;/37282015500;/37086278300",
        "aff": "Department of Electrical and Electronic Engineering, Imperial College London, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK; Department of Electrical and Electronic Engineering, Imperial College London, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK; Department of Electrical and Electronic Engineering, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160636/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2674048382100411836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;1;0",
        "aff_unique_norm": "Imperial College London;Heriot-Watt University",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering;School of Engineering and Physical Sciences",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.hw.ac.uk",
        "aff_unique_abbr": "ICL;HWU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160444",
        "title": "Obstacle Identification and Ellipsoidal Decomposition for Fast Motion Planning in Unknown Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision avoidance in the presence of dynamic obstacles in unknown environments is one of the most critical challenges for unmanned systems. In this paper, we present a method that identifies obstacles in terms of ellipsoids to estimate linear and angular obstacle velocities. Our proposed method is based on the idea of any object can be approximately expressed by ellipsoids. To achieve this, we propose a method based on variational Bayesian estimation of Gaussian mixture model, the Kyachiyan algorithm, and a refinement algorithm. Our proposed method does not require knowledge of the number of clusters and can operate in real-time, unlike existing optimization-based methods. In addition, we define an ellipsoid-based feature vector to match obstacles given two timely close point frames. Our method can be applied to any environment with static and dynamic obstacles, including ones with rotating obstacles. We compare our algorithm with other clustering methods and show that when coupled with a trajectory planner, the overall system can efficiently traverse unknown environments in the presence of dynamic obstacles.",
        "primary_area": "",
        "author": "Mehmetcan Kaymaz;Naz\u0131m Kemal Ure;Mehmetcan Kaymaz;Naz\u0131m Kemal Ure",
        "authorids": "/37089892536;/38189666100;/37089892536;/38189666100",
        "aff": "Faculty of Aeronautics and Astronautics, Istanbul Technical University, Istanbul, Turkey; Faculty of Computer and Informatics Engineering, Istanbul Technical University, Istanbul, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160444/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16170896850849270469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Istanbul Technical University",
        "aff_unique_dep": "Faculty of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.itu.edu.tr",
        "aff_unique_abbr": "ITU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Istanbul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Turkey"
    },
    {
        "id": "10161365",
        "title": "Obstacle avoidance using Raycasting and Riemannian Motion Policies at kHz rates for MAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel method for using Riemannian Motion Policies on volumetric maps, shown in the example of obstacle avoidance for Micro Aerial Vehicles (MAVs), Today, most robotic obstacle avoidance algorithms rely on sampling or optimization-based planners with volumetric maps. However, they are computationally expensive and often have inflexible monolithic architectures. Riemannian Motion Policies are a modular, parallelizable, and efficient navigation alternative but are challenging to use with the widely used voxel-based environment representations. We propose using GPU raycasting and tens of thousands of concurrent policies to provide direct obstacle avoidance using Riemannian Motion Policies in voxelized maps without needing map smoothing or pre-processing. Additionally, we present how the same method can directly plan on LiDAR scans without any intermediate map. We show how this reactive approach compares favorably to traditional planning methods and can evaluate up to 200 million rays per second. We demonstrate the planner successfully on a real MAV for static and dynamic obstacles. The presented planner is made available as an open-source package11https://github.com/ethz-asl/reactive_avoidance.",
        "primary_area": "",
        "author": "Michael Pantic;Isar Meijer;Rik B\u00e4hnemann;Nikhilesh Alatur;Olov Andersson;Cesar Cadena;Roland Siegwart;Lionel Ott;Michael Pantic;Isar Meijer;Rik B\u00e4hnemann;Nikhilesh Alatur;Olov Andersson;Cesar Cadena;Roland Siegwart;Lionel Ott",
        "authorids": "/37087468483;/37089893344;/37086172378;/37088507022;/37085816587;/37593590400;/37281398300;/38251784400;/37087468483;/37089893344;/37086172378;/37088507022;/37085816587;/37593590400;/37281398300;/38251784400",
        "aff": "Autonomous Systems Lab, ETH, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161365/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15740641749377711427&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161295",
        "title": "Obstacle-Aware Topological Planning over Polyhedral Representation for Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel mapping-planning framework for autonomous quadrotor navigation. First, a polyhedron-based mapping algorithm is presented to fully exploit the information of the onboard sensor data. Polyhedra are generated to approximate the segmented clusters of occupied voxels. Then, customized data structures are designed to extract information for motion planning in real time. With complete knowledge of the shape, position, and number of the observed obstacles, we can conveniently generate smooth trajectories with sufficient obstacle clearance along the most desired direction. Before searching for the initial path, a local topological graph is constructed to keep the path expanding in the most favorable topology class. The following path search is segmented based on the graph vertices, which allows fast convergence. The refined trajectory is obtained after smoothing, and large deviations are penalized in the formulated optimization problem to preserve the original clearance. Finally, we analyze and validate the proposed framework through extensive simulations and real-world quadrotor flights.",
        "primary_area": "",
        "author": "Junjie Gao;Fenghua He;Wei Zhang;Yu Yao;Junjie Gao;Fenghua He;Wei Zhang;Yu Yao",
        "authorids": "/37089560214;/37392837700;/38508496200;/37289622500;/37089560214;/37392837700;/38508496200;/37289622500",
        "aff": "School of Astronautics, Harbin Institute of Technology, Harbin, China; School of Astronautics, Harbin Institute of Technology, Harbin, China; School of Astronautics, Harbin Institute of Technology, Harbin, China; School of Astronautics, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161295/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9210774525445353604&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Astronautics",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160650",
        "title": "Occlusion Reasoning for Skeleton Extraction of Self-Occluded Tree Canopies",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a method to extract the skeleton of a self-occluded tree canopy by estimating the unobserved structures of the tree. A tree skeleton compactly describes the topological structure and contains useful information such as branch geometry, positions and hierarchy. This can be critical to planning contact interactions for agricultural manipulation, yet is difficult to gain due to occlusion by leaves, fruits and other branches. Our method uses an instance segmentation network to detect visible trunk, branches, and twigs. Then, based on the observed tree structures, we build a custom 3D likelihood map in the form of an occupancy grid to hypothesize on the presence of occluded skeletons through a series of minimum cost path searches. We show that our method outperforms baseline methods in highly occluded scenes, demonstrated through a set of experiments on a synthetic tree dataset. Qualitative results are also presented on a real tree dataset collected from the field.",
        "primary_area": "",
        "author": "Chung Hee Kim;George Kantor;Chung Hee Kim;George Kantor",
        "authorids": "/37086595964;/37273878300;/37086595964;/37273878300",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160650/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1675124175312598583&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160715",
        "title": "Occlusion-Aware Crowd Navigation Using People as Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation in crowded spaces poses a challenge for mobile robots due to the highly dynamic, partially observable environment. Occlusions are highly prevalent in such settings due to a limited sensor field of view and obstructing human agents. Previous work has shown that observed interactive behaviors of human agents can be used to estimate potential obstacles despite occlusions. We propose integrating such social inference techniques into the planning pipeline. We use a variational autoencoder with a specially designed loss function to learn representations that are meaningful for occlusion inference. This work adopts a deep reinforcement learning approach to incorporate the learned representation into occlusion-aware planning. In simulation, our occlusion-aware policy achieves comparable collision avoidance performance to fully observable navigation by estimating agents in occluded spaces. We demonstrate successful policy transfer from simulation to the real-world Turtlebot 2i. To the best of our knowledge, this work is the first to use social occlusion inference for crowd navigation. Our implementation is available at https://github.com/yejimun/PaS_CrowdNav.",
        "primary_area": "",
        "author": "Ye-Ji Mun;Masha Itkina;Shuijing Liu;Katherine Driggs-Campbell;Ye-Ji Mun;Masha Itkina;Shuijing Liu;Katherine Driggs-Campbell",
        "authorids": "/37089449010;/37087102957;/37088687174;/37085509519;/37089449010;/37087102957;/37088687174;/37085509519",
        "aff": "Electrical and Computer Engineering Department, University of Illinois at Urbana-Champaign, USA; Aeronautics and Astronautics Department, Stanford University, USA; Electrical and Computer Engineering Department, University of Illinois at Urbana-Champaign, USA; Electrical and Computer Engineering Department, University of Illinois at Urbana-Champaign, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160715/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6754625364707601058&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign;Stanford University",
        "aff_unique_dep": "Electrical and Computer Engineering Department;Aeronautics and Astronautics Department",
        "aff_unique_url": "https://illinois.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UIUC;Stanford",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Urbana-Champaign;Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161566",
        "title": "Off-policy Imitation Learning from Visual Inputs",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, various successful applications utilizing expert states in imitation learning (IL) have been witnessed. However, IL from visual inputs (ILfVI), which has a greater promise to be widely applied by using online visual resources, suffers from low data-efficiency and poor performance resulted from on-policy learning and high-dimensional visual inputs. We propose OPIfVI (Off-Policy Imitation from Visual Inputs), which is composed of an off-policy learning manner, data augmentation, and encoder techniques, to tackle the mentioned challenges, respectively. More specifically, to improve data-efficiency, OPIfVI conducts IL in an off-policy manner, with which sampled data used multiple times. In addition, we enhance the stability of OPIfVI with spectral normalization to mitigate the side effect of off-policy training. The core factor, contributing to the poor performance of ILfVI, that we think is agents could not extract meaningful features from visual inputs. Hence, OPIfVI employs data augmentation from computer vision to help train encoders to better extract features from visual inputs. Besides, a specific structure of gradient backpropagation for the encoder is designed to stabilize the encoder training. At last, we demonstrate that OPIfVI can achieve expert-level performance and outperform existing baselines via extensive experiments using DeepMind Control Suite.",
        "primary_area": "",
        "author": "Zhihao Cheng;Li Shen;Dacheng Tao;Zhihao Cheng;Li Shen;Dacheng Tao",
        "authorids": "/37089706658;/37088876322;/37269935500;/37089706658;/37088876322;/37269935500",
        "aff": "University of Sydney, Australia; JD Explore Academy, China; University of Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161566/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13388432950874666954&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Sydney;JD Explore Academy",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sydney.edu.au;",
        "aff_unique_abbr": "USYD;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Australia;China"
    },
    {
        "id": "10160624",
        "title": "On Domain-Specific Pre- Training for Effective Semantic Perception in Agricultural Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Agricultural robots have the prospect to enable more efficient and sustainable agricultural production of food, feed, and fiber. Perception of crops and weeds is a central component of agricultural robots that aim to monitor fields and assess the plants as well as their growth stage in an automatic manner. Semantic perception mostly relies on deep learning using supervised approaches, which require time and qualified workers to label fairly large amounts of data. In this paper, we look into the problem of reducing the amount of labels without compromising the final segmentation performance. For robots operating in the field, pre-training networks in a supervised way is already a popular method to reduce the number of required labeled images. We investigate the possibility of pre-training in a self-supervised fashion using data from the target domain. To better exploit this data, we propose a set of domain-specific augmentation strategies. We evaluate our pre-training on semantic segmentation and leaf instance segmentation, two important tasks in our domain. The experimental results suggest that pre-training with domain-specific data paired with our data augmentation strategy leads to superior performance compared to commonly used pre-trainings. Furthermore, the pre-trained networks obtain similar performance to the fully supervised with less labeled data.",
        "primary_area": "",
        "author": "Gianmarco Roggiolani;Federico Magistri;Tiziano Guadagnino;Jan Weyler;Giorgio Grisetti;Cyrill Stachniss;Jens Behley;Gianmarco Roggiolani;Federico Magistri;Tiziano Guadagnino;Jan Weyler;Giorgio Grisetti;Cyrill Stachniss;Jens Behley",
        "authorids": "/37089894689;/37086805350;/37087324270;/37088687551;/37324134600;/37329668600;/37593243900;/37089894689;/37086805350;/37087324270;/37088687551;/37324134600;/37329668600;/37593243900",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; La Sapienza University of Rome, Italy; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160624/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=392235578473224768&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;0",
        "aff_unique_norm": "University of Bonn;La Sapienza University of Rome;Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.uniroma1.it;",
        "aff_unique_abbr": "UBonn;Sapienza;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;0;0",
        "aff_country_unique": "Germany;Italy"
    },
    {
        "id": "10161171",
        "title": "On Human Grasping and Manipulation in Kitchens: Automated Annotation, Insights, and Metrics for Effective Data Collection",
        "track": "main",
        "status": "Poster",
        "abstract": "The advancement in robotic grasping and manipulation has elicited an increased research interest in the development of household robots capable of performing a plethora of complex tasks. These advancements require the shift of robotics research from a laboratory setting to dynamic and unstructured home environments. In this work, we focus on a comprehensive data collection and analysis of key attributes involved in the selection of grasping and manipulation strategies for the successful execution of kitchen tasks. An unprecedented dataset that comprises over 7 hours of high-definition videos that were analyzed to classify more than 10,000 kitchen activities annotated with 24 attributes each has been created. Machine learning techniques were employed to automate the annotation process partially by extracting grasp types, hand, and object information from the videos. The annotated dataset was analyzed using clustering algorithms to identify underlying patterns. This study also identifies key attributes and specific data that require focus during data collection based on inter-subject variability. The insights from this study can be used to improve the speed, quality, and effectiveness of data collection. It also helps identify the strategies employed by the humans for the execution of kitchen tasks and transfer the necessary skills to a robotic end-effector enabling it to complete the tasks autonomously or collaborate with humans.",
        "primary_area": "",
        "author": "Nathan Elangovan;Ricardo V. Godoy;Felipe Sanches;Ke Wang;Tom White;Patrick Jarvis;Minas Liarokapis;Nathan Elangovan;Ricardo V. Godoy;Felipe Sanches;Ke Wang;Tom White;Patrick Jarvis;Minas Liarokapis",
        "authorids": "/37087236413;/37087469104;/37088226006;/37089448683;/37089893385;/37088456883;/38558084100;/37087236413;/37087469104;/37088226006;/37089448683;/37089893385;/37088456883;/38558084100",
        "aff": "Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Acumino, USA; Acumino, USA; Acumino, USA; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161171/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17318758087367008481&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;0",
        "aff_unique_norm": "The University of Auckland;Acumino",
        "aff_unique_dep": "Department of Mechanical and Mechatronics Engineering;",
        "aff_unique_url": "https://www.auckland.ac.nz;",
        "aff_unique_abbr": "UoA;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;1;1;0",
        "aff_country_unique": "New Zealand;United States"
    },
    {
        "id": "10160261",
        "title": "On Improving Boundary Quality of Instance Segmentation in Cluttered and Chaotic Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Instance segmentation is a long-standing task for supporting robotic bin picking. However, objects of diverse classes can be closely packed with occlusions in cluttered and chaotic scenes, hence, even recent methods could have difficulty in locating clear and precise boundaries to distinguish nearby objects. In this work, we aim to improve the boundary quality of the instance masks for robust and precise instance segmentation in these challenging scenarios. Technical-wise, we first formulate an IoU-based Boundary-aware Mask head (IBM head) for predicting the instance-level mask, boundary, and their corresponding IoU scores. With this core module, we then follow the coarse-to-fine strategy and design our pipeline with two stages: an 1IoUNet to learn localization-based objectness cue and a hierarchical mask refiner to produce sharper and cleaner boundaries. We deploy the IBM head throughout the framework. Extensive experimental results on three grasping benchmarks manifest that our method attains the best instance segmentation performance, compared with the state-of-the-art approaches. Practically, we conduct real-world picking tests to show that with the objectness and boundary IoU scores as guidance, we are able to filter invalid (occluded) instances and select high-fidelity (exposed) instances for grasping.",
        "primary_area": "",
        "author": "Biqi Yang;Xiaojie Gao;Xianzhi Li;Yun-Hui Liu;Chi-Wing Fu;Pheng-Ann Heng;Biqi Yang;Xiaojie Gao;Xianzhi Li;Yun-Hui Liu;Chi-Wing Fu;Pheng-Ann Heng",
        "authorids": "/37089307076;/37088506701;/37086569101;/37279412600;/37336329800;/37283077400;/37089307076;/37088506701;/37086569101;/37279412600;/37336329800;/37283077400",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; School of Computer Science and Technology, Huazhong University of Science and Technology; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems, Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160261/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18051017914488451033&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;2",
        "aff_unique_norm": "The Chinese University of Hong Kong;Huazhong University of Science and Technology;Chinese Academy of Sciences",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Computer Science and Technology;Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.hust.edu.cn;http://www.cas.cn",
        "aff_unique_abbr": "CUHK;HUST;CAS",
        "aff_campus_unique_index": "0;0;0;0;2",
        "aff_campus_unique": "Hong Kong SAR;;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160572",
        "title": "On Legible and Predictable Robot Navigation in Multi-Agent Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Legible motion is intent-expressive, which when employed during social robot navigation, allows others to quickly infer the intended avoidance strategy. Predictable motion matches an observer's expectation which, during navigation, allows others to confidently carryout the interaction. In this work, we present a navigation framework capable of reasoning on its legibility and predictability with respect to dynamic interactions, e.g., a passing side. Our approach generalizes the previously formalized notions of legibility and predictability by allowing dynamic goal regions in order to navigate in dynamic environments. This generalization also allows us to quantitatively evaluate the legibility and the predictability of trajectories with respect to navigation interactions. Our approach is shown to promote legible behavior in ambiguous scenarios and predictable behavior in unambiguous scenarios. In a multi-agent environment, this yields an increase in safety while remaining competitive in terms of goal-efficiency when compared to other robot navigation planners in multi-agent environments. The code of this work is made publicly available1.",
        "primary_area": "",
        "author": "Jean-Luc Bastarache;Christopher Nielsen;Stephen L. Smith;Jean-Luc Bastarache;Christopher Nielsen;Stephen L. Smith",
        "authorids": "/37089891848;/37301501500;/37335139700;/37089891848;/37301501500;/37335139700",
        "aff": "Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160572/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15798923991072943458&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Waterloo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161181",
        "title": "On Locally Optimal Redundancy Resolution using the Basis of the Null Space",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents two methods for the computation of the null space velocity command in redundant robots. Both these methods resort to the solution of a constrained optimization problem. The first one is a formalization of the traditional Gradient Projection Method (GPM) which guarantees the respect of the joint bounds and a gradual activation/deactivation of the null space command. The second one, called Null Space Basis Optimal Linear Combination Method (NSBM), finds the optimal coefficients of a basis of the null space of the Jacobian, ensuring in turn that the joint bounds are respected and that the null space is activated and deactivated gradually. The two methods are applied to the case study of a welding application in which the null space command must avoid the collision between the robot and an obstacle. The comparison of the results of the case study shows that NSBM performs better than GPM. The proposed algorithms are also tested on a real robotic platform to demonstrate that their computational time is compatible with the real-time requirements of the robot.",
        "primary_area": "",
        "author": "Eugenio Monari;Yi Chen;Rocco Vertechy;Eugenio Monari;Yi Chen;Rocco Vertechy",
        "authorids": "/37089892861;/37088221816;/37546543600;/37089892861;/37088221816;/37546543600",
        "aff": "Department of Industrial Engineering, University of Bologna, Bologna, Italy; Department of Industrial Engineering, University of Bologna, Bologna, Italy; Department of Industrial Engineering, University of Bologna, Bologna, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161181/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=908119694555756624&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bologna",
        "aff_unique_dep": "Department of Industrial Engineering",
        "aff_unique_url": "https://www.unibo.it",
        "aff_unique_abbr": "UNIBO",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bologna",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161550",
        "title": "On Shortest Arc-To-Arc Dubins Path",
        "track": "main",
        "status": "Poster",
        "abstract": "For a given set of orbits, the Orbiting Dubins Traveling Salesman Problem (ODTSP) involves finding Dubins tour that is tangential to each orbit at some point. We consider a shortest Arc-to-Arc Dubins (ATAD) path problem that arrives in solving lower bound to the ODTSP. Given an initial and a final arc, the objective of ATAD is to find the shortest Dubins path such that the initial and final point lie on the given two arcs, and the path is tangential to the arcs. We analyze the six Dubins modes and the degenerate cases to find local minima. We present the optimal solution for the ATAD, along with an algorithm that uses this solution to compute tight lower bounds for the ODTSP. We test the lower bounding algorithm on several random instances and report the results. Using this algorithm, we show that the percent gap between upper and lower bounds is less than 10% for most instances.",
        "primary_area": "",
        "author": "Satyanarayana G. Manyam;David W. Casbeer;Satyanarayana G. Manyam;David W. Casbeer",
        "authorids": "/38096429300;/37273056100;/38096429300;/37273056100",
        "aff": "Infoscitex Corporation, Dayton, OH, USA; Control Science Center, Air-Force Research Laboratories, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161550/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ebx2qQNXW-gJ:scholar.google.com/&scioq=On+Shortest+Arc-To-Arc+Dubins+Path&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Infoscitex Corporation;Air-Force Research Laboratories",
        "aff_unique_dep": ";Control Science Center",
        "aff_unique_url": ";https://www.afrl.af.mil/",
        "aff_unique_abbr": ";AFRL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161208",
        "title": "On Tendon Driven Continuum Robots with Compressible Backbones",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper discusses the effect of axial backbone compression on tendon-driven continuum robots. A new mechanics model for compensating for this effect that does not require tendon tension sensing or knowledge of manipulator material properties/stiffnesses is introduced and analyzed. In addition, we provide an analytical expression for the minimum preload on the tendons to achieve a given bend, a quantity determined empirically thus far. Our model is computationally efficient and achieves real time control on low cost hardware. The analysis is supported by experimental results demonstrating significant improvement over kinematics in open loop control of a tendon-driven continuum hose robot.",
        "primary_area": "",
        "author": "Manu Srivastava;Ian D. Walker;Manu Srivastava;Ian D. Walker",
        "authorids": "/37089448270;/37276152000;/37089448270;/37276152000",
        "aff": "Electrical and Computer Engineering, Clemson University, USA; Electrical and Computer Engineering, Clemson University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161208/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13146299751813704428&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Clemson University",
        "aff_unique_dep": "Electrical and Computer Engineering",
        "aff_unique_url": "https://www.clemson.edu",
        "aff_unique_abbr": "Clemson",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160323",
        "title": "On the Impact of Interruptions During Multi-Robot Supervision Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Human supervisors in multi-robot systems are primarily responsible for monitoring robots, but can also be assigned with secondary tasks. These tasks can act as interruptions and can be categorized as either intrinsic, i.e., being directly related to the monitoring task, or extrinsic, i.e., being unrelated. In this paper, we investigate the impact of these two types of interruptions through a user study (N = 39), where participants monitor a number of remote mobile robots while intermittently being interrupted by either a robot fault correction task (intrinsic) or a messaging task (extrinsic). We find that task performance of participants does not change significantly with the interruptions but depends greatly on the number of robots. However, interruptions result in an increase in perceived workload, and extrinsic interruptions have a more negative effect on workload across all NASA-TLX scales. Participants also reported switching between extrinsic interruptions and the primary task to be more difficult compared to the intrinsic interruption case. Statistical significance of these results is confirmed using ANOVA and one-sample t-test. These findings suggest that when deciding task assignment in such supervision systems, one should limit interruptions from secondary tasks, especially extrinsic ones, in order to limit user workload.",
        "primary_area": "",
        "author": "Abhinav Dahiya;Yifan Cai;Oliver Schneider;Stephen L. Smith;Abhinav Dahiya;Yifan Cai;Oliver Schneider;Stephen L. Smith",
        "authorids": "/37085777896;/37089681428;/37085771818;/37335139700;/37085777896;/37089681428;/37085771818;/37335139700",
        "aff": "Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Management Sciences, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160323/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=641025908222153251&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Waterloo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161088",
        "title": "On the Learned Balance Manifold of Underactuated Balance Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Tracking control of underactuated balance robots needs to estimate balance profiles, that is, balance equilibrium manifold (BEM) of the unactuated subsystems. We present a learning-based approach to obtain the balance manifold for underactuated balance robots. We first establish the relationship between the BEM and the zero dynamics of the underactuated balance robots. The analysis shows that the BEM is a close approximation of the equilibria of the zero dynamics under perfectly tracking control. A Gaussian process learning-based method is proposed to estimate and obtain the BEM and zero dynamics, avoiding the direct inversion of the physics-based robot dynamic model. We demonstrate the analysis and applications experimentally on a rotary inverted pendulum and a bipedal robot.",
        "primary_area": "",
        "author": "Feng Han;Jingang Yi;Feng Han;Jingang Yi",
        "authorids": "/37088527188;/37277001600;/37088527188;/37277001600",
        "aff": "Department of Mechanical and Aerospace Engineering, Rutgers University, Piscataway, NJ, USA; Department of Mechanical and Aerospace Engineering, Rutgers University, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161088/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1669234634623246159&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160823",
        "title": "On the Use of Torque Measurement in Centroidal State Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art legged robots are either capable of measuring torque at the output of their drive systems, or have transparent drive systems which enable the computation of joint torques from motor currents. In either case, this sensor modality is seldom used in state estimation. In this paper, we propose to use joint torque measurements to estimate the centroidal states of legged robots. To do so, we project the whole-body dynamics of a legged robot into the nullspace of the contact constraints, allowing expression of the dynamics independent of the contact forces. Using the constrained dynamics and the centroidal momentum matrix, we are able to directly relate joint torques and centroidal states dynamics. Using the resulting model as the process model of an Extended Kalman Filter (EKF), we fuse the torque measurement in the centroidal state estimation problem. Through real-world experiments on a quadruped robot executing different gaits, we demonstrate that the estimated centroidal states from our torque-based EKF drastically improve the recovery of these quantities compared to direct computation.",
        "primary_area": "",
        "author": "Shahram Khorshidi;Ahmad Gazar;Nicholas Rotella;Maximilien Naveau;Ludovic Righetti;Maren Bennewitz;Majid Khadiv;Shahram Khorshidi;Ahmad Gazar;Nicholas Rotella;Maximilien Naveau;Ludovic Righetti;Maren Bennewitz;Majid Khadiv",
        "authorids": "/37089895764;/37088663968;/37085431072;/37085505956;/37295828600;/37324765000;/38667118200;/37089895764;/37088663968;/37085431072;/37085505956;/37295828600;/37324765000;/38667118200",
        "aff": "Humanoid Robots Lab, University of Bonn, Germany; Max-Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Agility Robotics, Oregon, USA; LAAS-CNRS, Toulouse, France; Tandon School of Engineering, New York University, USA; Humanoid Robots Lab, University of Bonn, Germany; Max-Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160823/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14119699029470253629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;4;0;1",
        "aff_unique_norm": "University of Bonn;Max-Planck Institute for Intelligent Systems;Agility Robotics;LAAS-CNRS;New York University",
        "aff_unique_dep": "Humanoid Robots Lab;;;;Tandon School of Engineering",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.mpi-is.mpg.de;;https://www.laas.fr/;https://www.nyu.edu",
        "aff_unique_abbr": ";MPI-IS;;;NYU",
        "aff_campus_unique_index": "1;2;3;1",
        "aff_campus_unique": ";T\u00fcbingen;Toulouse;New York",
        "aff_country_unique_index": "0;0;1;2;1;0;0",
        "aff_country_unique": "Germany;United States;France"
    },
    {
        "id": "10161182",
        "title": "On the Utility of Buffers in Pick-n-Swap Based Lattice Rearrangement",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the utility of employing multiple buffers in solving a class of rearrangement problems with pick- n-swap manipulation primitives. In this problem, objects stored randomly in a lattice are to be sorted using a robot arm with k 1 swap spaces or buffers, capable of holding up to kk objects on its end-effector simultaneously. On the structural side, we show that the addition of each new buffer brings diminishing returns in saving the end-effector travel distance while holding the total number of pick-n-swap operations at a minimum. This is due to an interesting recursive cycle structure in random m-permutation, where the largest cycle covers over 60% of objects. On the algorithmic side, we propose fast algorithms for 1D and 2D lattice rearrangement problems that can effectively use multiple buffers to boost solution optimality. Numerical experiments demonstrate the efficiency and scalability of our methods, as well as confirm the diminishing return structure as more buffers are employed. Introduction video: https://youtu.be/KtBxoARGaVQ",
        "primary_area": "",
        "author": "Kai Gao;Jingjin Yu;Kai Gao;Jingjin Yu",
        "authorids": "/37088997464;/37536570700;/37088997464;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161182/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13813947046913550947&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160972",
        "title": "On the programming effort required to generate Behavior Trees and Finite State Machines for robotic applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we provide a practical demonstration of how the modularity in a Behavior Tree (BT) decreases the effort in programming a robot task when compared to a Finite State Machine (FSM). In recent years the way to represent a task plan to control an autonomous agent has been shifting from the standard FSM towards BTs. Many works in the literature have highlighted and proven the benefits of such design compared to standard approaches, especially in terms of modularity, reactivity and human readability. However, these works have often failed in providing a tangible comparison in the implementation of those policies and the programming effort required to modify them. This is a relevant aspect in many robotic applications, where the design choice is dictated both by the robustness of the policy and by the time required to program it. In this work, we compare backward chained BTs with a fault-tolerant design of FSMs by evaluating the cost to modify them. We validate the analysis with a set of experiments in a simulation environment where a mobile manipulator solves an item fetching task.",
        "primary_area": "",
        "author": "Matteo Iovino;Julian F\u00f6rster;Pietro Falco;Jen Jen Chung;Roland Siegwart;Christian Smith;Matteo Iovino;Julian F\u00f6rster;Pietro Falco;Jen Jen Chung;Roland Siegwart;Christian Smith",
        "authorids": "/37089000726;/37088912058;/38076626900;/37085668354;/37281398300;/37559467400;/37089000726;/37088912058;/38076626900;/37085668354;/37281398300;/37559467400",
        "aff": "Division of Robotics, Perception and Learning, KTH - Royal Institute of Technology, Stockholm, Sweden; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; ABB Corporate Research, V\u00e4ster\u00e5s, Sweden; School of ITEE, The University of Queensland, Australia; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Division of Robotics, Perception and Learning, KTH - Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160972/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9009389838782558543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;1;0",
        "aff_unique_norm": "KTH - Royal Institute of Technology;ETH Z\u00fcrich;ABB Corporate Research;The University of Queensland",
        "aff_unique_dep": "Division of Robotics, Perception and Learning;Autonomous Systems Lab;;School of ITEE",
        "aff_unique_url": "https://www.kth.se;https://www.ethz.ch;https://new.abb.com/research;https://www.uq.edu.au",
        "aff_unique_abbr": "KTH;ETH;ABB;UQ",
        "aff_campus_unique_index": "0;1;2;1;0",
        "aff_campus_unique": "Stockholm;Z\u00fcrich;V\u00e4ster\u00e5s;",
        "aff_country_unique_index": "0;1;0;2;1;0",
        "aff_country_unique": "Sweden;Switzerland;Australia"
    },
    {
        "id": "10160398",
        "title": "On-Demand Multi-Agent Basket Picking for Shopping Stores",
        "track": "main",
        "status": "Poster",
        "abstract": "Imagine placing an online order on your way to the grocery store, then being able to pick the collected basket upon arrival or shortly after. Likewise, imagine placing any online retail order, made ready for pickup in minutes instead of days. In order to realize such a low-latency automatic warehouse logistics system, solvers must be made to be basket-aware. That is, it is more important that the full order (the basket) is picked timely and fast, than that any single item in the order is picked quickly. Current state-of-the-art methods are not basket-aware. Nor are they optimized for a positive customer experience, that is; to prioritize customers based on queue place and the difficulty associated with picking their order. An example of the latter is that it is preferable to prioritize a customer ordering a pack of diapers over a customer shopping a larger order, but only as long as the second customer has not already been waiting for too long. In this work we formalize the problem outlined, propose a new method that significantly outperforms the state-of-the-art, and present a new realistic simulated benchmark. The proposed method is demonstrated to work in an on-line and real-time setting, and to solve the on-demand multi-agent basket picking problem for automated shopping stores under realistic conditions.",
        "primary_area": "",
        "author": "Mattias Tiger;David Bergstr\u00f6m;Simon Wijk Stranius;Evelina Holmgren;Daniel de Leng;Fredrik Heintz;Mattias Tiger;David Bergstr\u00f6m;Simon Wijk Stranius;Evelina Holmgren;Daniel de Leng;Fredrik Heintz",
        "authorids": "/37085670359;/37086127965;/37089891874;/37089461104;/37077064400;/37658898500;/37085670359;/37086127965;/37089891874;/37089461104;/37077064400;/37658898500",
        "aff": "Department of Computer and Information Science, Link\u00f6ping University, Link\u00f6pinz, Sweden; Department of Computer and Information Science, Link\u00f6ping University, Link\u00f6pinz, Sweden; NearbyStore Sverige AB, Link\u00f6ping, Sweden; Department of Computer and Information Science, Link\u00f6ping University, Link\u00f6pinz, Sweden; Department of Computer and Information Science, Link\u00f6ping University, Link\u00f6pinz, Sweden; Department of Computer and Information Science, Link\u00f6ping University, Link\u00f6pinz, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160398/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1147088919746892650&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Link\u00f6ping University;NearbyStore Sverige AB",
        "aff_unique_dep": "Department of Computer and Information Science;",
        "aff_unique_url": "https://www.liu.se;",
        "aff_unique_abbr": "LiU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Link\u00f6ping;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "10160630",
        "title": "Onboard Controller Design for Nano UAV Swarm in Operator-Guided Collective Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a swarm of Crazyflie nano-drones. The swarm can show various collective behaviors: Flocking, gradient following, going to a chosen point, formation, and scattered search of the environment. The methodology behind the behaviors is executed entirely on-board. Crazyflies use a common radio channel to share positions with each other. If desired, an operator can use the same channel and start, end, change or guide the collective behaviors online during the flight. We use the virtual force vectors and modify the way they are combined to achieve different behaviors instead of developing unique algorithms for each. This allows us to develop more collective behavior types with less effort. In the results, we show a detailed analysis of the behaviors and assess the coordination and the safety of the agents in addition to the performance as a collective. We conclude that our swarm of 6 Crazyflies was successful in the desired behaviors.",
        "primary_area": "",
        "author": "Tugay Alperen Karag\u00fczel;Victor Retamal;Eliseo Ferrante;Tugay Alperen Karag\u00fczel;Victor Retamal;Eliseo Ferrante",
        "authorids": "/37089893621;/37089893488;/38230571500;/37089893621;/37089893488;/38230571500",
        "aff": "Vrije Universiteit Amsterdam, Noord-Holland, The Netherlands; Vrije Universiteit Amsterdam, Noord-Holland, The Netherlands; Technology Innovation Institute, Abu Dhabi, United Arab Emirates",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160630/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=670487836091065064&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Vrije Universiteit Amsterdam;Technology Innovation Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.vu.nl;",
        "aff_unique_abbr": "VU Amsterdam;",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Amsterdam;Abu Dhabi",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Netherlands;United Arab Emirates"
    },
    {
        "id": "10161552",
        "title": "One Training for Multiple Deployments: Polar-based Adaptive BEV Perception for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Current on-board chips usually have different computing power, which means multiple training processes are needed for adapting the same learning-based algorithm to different chips, costing huge computing resources. The situation becomes even worse for 3D perception methods with large models. Previous vision-centric 3D perception approaches are trained with regular grid-represented feature maps of fixed resolutions, which is not applicable to adapt to other grid scales, limiting wider deployment. In this paper, we leverage the Polar representation when constructing the BEV feature map from images in order to achieve the goal of training once for multiple deployments. Specifically, the feature along rays in Polar space can be easily adaptively sampled and projected to the feature in Cartesian space with arbitrary resolutions. To further improve the adaptation capability, we make multi-scale contextual information interact with each other to enhance the feature representation. Experiments on a large-scale autonomous driving dataset show that our method outperforms others as for the good property of one training for multiple deployments.",
        "primary_area": "",
        "author": "Huitong Yang;Xuyang Bai;Xinge Zhu;Yuexin Ma;Huitong Yang;Xuyang Bai;Xinge Zhu;Yuexin Ma",
        "authorids": "/37089892295;/37088457608;/37086492460;/37089018085;/37089892295;/37088457608;/37086492460;/37089018085",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology; Department of Information Engineering, The Chinese University of Hong Kong; School of Information Science and Technology, ShanghaiTech University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161552/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9837799238029778285&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "ShanghaiTech University;Hong Kong University of Science and Technology;The Chinese University of Hong Kong",
        "aff_unique_dep": "School of Information Science and Technology;Department of Computer Science and Engineering;Department of Information Engineering",
        "aff_unique_url": "https://www.shanghaitech.edu.cn;https://www.ust.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "ShanghaiTech;HKUST;CUHK",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Shanghai;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160643",
        "title": "One-Shot Reachability Analysis of Neural Network Dynamical Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "The arising application of neural networks (NN) in robotic systems has driven the development of safety verification methods for neural network dynamical systems (NNDS). Recursive techniques for reachability analysis of dynamical systems in closed-loop with a NN controller, planner or perception can over-approximate the reachable sets of the NNDS by bounding the outputs of the NN and propagating these NN output bounds forward. However, this recursive reachability analysis may suffer from compounding errors, rapidly becoming overly conservative over a longer horizon. In this work, we prove that an alternative one-shot reachability analysis framework which directly verifies the unrolled NNDS can significantly mitigate the compounding errors, enabling the use of the rolling horizon as a design parameter for verification purposes. We characterize the performance gap between the recursive and one-shot frameworks for NNDS with general computational graphs. The applicability of one-shot analysis is demonstrated through numerical examples on a cart-pole system.",
        "primary_area": "",
        "author": "Shaoru Chen;Victor M. Preciado;Mahyar Fazlyab;Shaoru Chen;Victor M. Preciado;Mahyar Fazlyab",
        "authorids": "/37087113051;/37322298800;/37085444820;/37087113051;/37322298800;/37085444820",
        "aff": "Department of Electrical and Systems Engineering, University of Pennsylvania; Department of Electrical and Systems Engineering, University of Pennsylvania; Mathematical Institute for Data Science, Johns Hopkins University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160643/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10608894648539727666&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Pennsylvania;Johns Hopkins University",
        "aff_unique_dep": "Department of Electrical and Systems Engineering;Mathematical Institute for Data Science",
        "aff_unique_url": "https://www.upenn.edu;https://www.jhu.edu",
        "aff_unique_abbr": "UPenn;JHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160944",
        "title": "One-shot Visual Imitation via Attributed Waypoints and Demonstration Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we analyze the behavior of existing techniques and design new solutions for the problem of one-shot visual imitation. In this setting, an agent must solve a novel instance of a novel task given just a single visual demonstration. Our analysis reveals that current methods fall short because of three errors: the DAgger problem arising from purely offline training, last centimeter errors in interacting with objects, and mis-fitting to the task context rather than to the actual task. This motivates the design of our modular approach where we a) separate out task inference (what to do) from task execution (how to do it), and b) develop data augmentation and generation techniques to mitigate mis-fitting. The former allows us to leverage hand-crafted motor primitives for task execution which side-steps the DAgger problem and last centimeter errors, while the latter gets the model to focus on the task rather than the task context. Our model gets 100% and 48% success rates on two recent benchmarks, improving upon the current state-of-the-art by absolute 90% and 20% respectively.",
        "primary_area": "",
        "author": "Matthew Chang;Saurabh Gupta;Matthew Chang;Saurabh Gupta",
        "authorids": "/37089893827;/37089922149;/37089893827;/37089922149",
        "aff": "University of Illinois Urbana-Champaign, Illinois, USA; University of Illinois Urbana-Champaign, Illinois, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160944/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8040702146587108475&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160785",
        "title": "Online Consistent Video Depth with Gaussian Mixture Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "We demonstrate how off-the-shelf single-image depth estimation methods can be augmented with guidance from optical flow to achieve consistent and accurate online depth estimation using video sequences of static scenes. While previous work has successfully leveraged the complementary nature of optical flow and depth estimation, these techniques use computationally expensive test time optimization strategies that do not generalize beyond a single video sequence and also require knowledge of the future. In contrast, we present a computationally efficient feed-forward design that runs in an online fashion by utilizing learned data priors from previously seen video sequences. To accomplish this, we propose a continuous geometric scene representation that parametrically and compositionally represents the scene as a Gaussian Mixture Model (GMM). Based on this representation, our pipeline learns to estimate consistent depths and associated camera poses from video sequences of static scenes without direct supervision. Our online method achieves state-of-the-art results compared against offline methods that require all sequence frames.",
        "primary_area": "",
        "author": "Chao Liu;Benjamin Eckart;Jan Kautz;Chao Liu;Benjamin Eckart;Jan Kautz",
        "authorids": "/37087235623;/38180746900;/37889927400;/37087235623;/38180746900;/37889927400",
        "aff": "NVIDIA Research, Santa Clara, CA, USA; NVIDIA Research, Santa Clara, CA, USA; NVIDIA Research, Santa Clara, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160785/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:RCKtFGU4ouUJ:scholar.google.com/&scioq=Online+Consistent+Video+Depth+with+Gaussian+Mixture+Representation&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "NVIDIA Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://research.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Santa Clara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160733",
        "title": "Online Coverage Path Planning Scheme for a Size-Variable Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Coverage Path Planning (CPP) is an essential feature of robots deployed for applications such as lawn mowing, cleaning, painting, and exploration. However, most of the state-of-the-art CPP methods are proposed for fixed-morphology robots, and the coverage performance is limited by physical constraints such as the inaccessibility of narrow spaces. Apart from area coverage, productivity depends on coverage time and energy usage. A robot capable of varying its footprint size could be a solution for improving productivity in these aspects. In addition to that, the environments, where robots are deployed for coverage, are often subjected to changes causing uncertainties. Therefore, this paper proposes an online CPP scheme for a size-variable robot to improve coverage productivity. The navigation planning of the proposed Size-Variable CPP (VSCPP) scheme has been implemented by adapting a Glasius bio-inspired neural network that guides a robot in an efficient path for coverage while coping with dynamic changes. The size variation required for a situation is determined by analyzing a set of occupancy grid maps corresponding to the size steps of the robot. According to the results, the proposed VSCPP can ascertain coverage while coping with dynamic changes in an environment. The reduction of the coverage time due to the size variability is significant compared to a robot with no VSCPP scheme.",
        "primary_area": "",
        "author": "M. A. Viraj J. Muthugala;S. M. Bhagya P. Samarakoon;Mohan Rajesh Elara;M. A. Viraj J. Muthugala;S. M. Bhagya P. Samarakoon;Mohan Rajesh Elara",
        "authorids": "/37085785341;/37086182161;/37546093700;/37085785341;/37086182161;/37546093700",
        "aff": "Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160733/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8600606002387825931&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10161340",
        "title": "Online Hand-Eye Calibration with Decoupling by 3D Textureless Object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Hand-eye calibration estimates the pose of a camera relative to a robot, which is a fundamental problem for visually guided robots, especially for dynamic object grasping. Most methods use 2D fiducial markers with distinctive visual features and require pre-calibration for accurate calibration, which can not work online. In this paper, we propose a novel hand-eye calibration method based on the natural 3D object, which can work online and automatically even if the object is textureless or weakly textured. We first propose a Pose Refinement Network (PR-Net) to improve the accuracy of 3D object tracking. Then we build a 3D convergence point constraint based on the multi-view information with the accurate object pose to adjust the object position. Finally, we optimize the hand-eye pose by the closed-loop constraint with the optimized object position, solving the problem that is easy to fall into a local minimum. The experiments show that the average error of our hand-eye calibration method is 1.20 degrees and 23.18 mm. The results achieve state-of-the-art by using the working object to realize the online hand-eye calibration.",
        "primary_area": "",
        "author": "Li Jin;Kang Xie;Wenxuan Chen;Xin Cao;Yuehua Li;Jiachen Li;Jiankai Qian;Xueying Qin;Li Jin;Kang Xie;Wenxuan Chen;Xin Cao;Yuehua Li;Jiachen Li;Jiankai Qian;Xueying Qin",
        "authorids": "/37089893041;/37089894062;/37089939591;/37089541607;/37089892617;/37088584401;/37089895588;/37529094300;/37089893041;/37089894062;/37089939591;/37089541607;/37089892617;/37088584401;/37089895588;/37529094300",
        "aff": "Engineering Research Center of Digital Media Technology, Ministry of Education, P.R. China; Engineering Research Center of Digital Media Technology, Ministry of Education, P.R. China; Zhejiang Lab, Intelligent Robot Research Center, P.R. China; Engineering Research Center of Digital Media Technology, Ministry of Education, P.R. China; Zhejiang Lab, Intelligent Robot Research Center, P.R. China; State Key Lab of CAD&CG, Zheiiang-University, P.R. China; Engineering Research Center of Digital Media Technology, Ministry of Education, P.R. China; Engineering Research Center of Digital Media Technology, Ministry of Education, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161340/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17100045606069886109&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;1;2;0;0",
        "aff_unique_norm": "Engineering Research Center of Digital Media Technology;Zhejiang Lab;Zhejiang University",
        "aff_unique_dep": "Ministry of Education;Intelligent Robot Research Center;State Key Lab of CAD&CG",
        "aff_unique_url": ";;http://www.zju.edu.cn",
        "aff_unique_abbr": ";;ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161190",
        "title": "Online Learning and Suppression of Vibration in Collaborative Robots with Power Tools",
        "track": "main",
        "status": "Poster",
        "abstract": "Vibration suppression is an important skill for future robots that will collaborate with humans in industrial settings. The vibration through physical interaction is a common problem in such settings, especially in operations involving hand-held vibrating tools. The existing human-robot collaboration (HRC) works addressing this problem mostly focus on the oscillations caused by the human operator, and suppress them by adapting the admittance parameters. This, however, usually results in stiffer robot behavior and contributes to reducing the overall performance of the task, in particular when impedance planning is a requirement. In this work, we focus on the vibration coming from external sources such as power tools and suppress it actively. We learn the vibration using the bandlimited multiple Fourier linear combiner (BMFLC) algorithm and apply it as a feedforward Cartesian force to cancel the vibration. We combine the feedforward force control with variable impedance learning and show that it improves the vibration suppression performance in simulation and real-world experiments. The feedforward approach can suppress the vibration better while keeping a more compliant set of impedance parameters, which is crucial in HRC.",
        "primary_area": "",
        "author": "Gokhan Solak;Arash Ajoudani;Gokhan Solak;Arash Ajoudani",
        "authorids": "/37086112812;/37945239900;/37086112812;/37945239900",
        "aff": "HRI2 Lab of Italian Institute of Technology (IIT), Genoa, Italy; HRI2 Lab of Italian Institute of Technology (IIT), Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161190/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9909883264174569454&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Italian Institute of Technology",
        "aff_unique_dep": "HRI2 Lab",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161086",
        "title": "Online Non-linear Centroidal MPC for Humanoid Robots Payload Carrying with Contact-Stable Force Parametrization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we consider the problem of allowing a humanoid robot that is subject to a persistent disturbance, in the form of a payload-carrying task, to follow given planned footsteps. To solve this problem, we combine an online nonlinear centroidal Model Predictive Controller - MPC with a contact stable force parametrization. The cost function of the MPC is augmented with terms handling the disturbance and regularizing the parameter. The performance of the resulting controller is validated both in simulations and on the humanoid robot iCub. Finally, the effect of using the parametrization on the computational time of the controller is briefly studied.",
        "primary_area": "",
        "author": "Mohamed Elobaid;Giulio Romualdi;Gabriele Nava;Lorenzo Rapetti;Hosameldin Awadalla Omer Mohamed;Daniele Pucci;Mohamed Elobaid;Giulio Romualdi;Gabriele Nava;Lorenzo Rapetti;Hosameldin Awadalla Omer Mohamed;Daniele Pucci",
        "authorids": "/37088752671;/37086598289;/37086044221;/37087238330;/37089892761;/37706167200;/37088752671;/37086598289;/37086044221;/37087238330;/37089892761;/37706167200",
        "aff": "Artificial and Mechanical Intelligence AMI, Italian Insititute of Technology, Genoa, Italy; Artificial and Mechanical Intelligence AMI, Italian Insititute of Technology, Genoa, Italy; Artificial and Mechanical Intelligence AMI, Italian Insititute of Technology, Genoa, Italy; Machine Learning and Optimisation, The University of Manchester, Manchester, United Kingdom; Mechanical engineering department, Politecnico di Milano, Milano, Italy; Machine Learning and Optimisation, The University of Manchester, Manchester, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161086/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17624641288839001731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;1",
        "aff_unique_norm": "Italian Institute of Technology;The University of Manchester;Politecnico di Milano",
        "aff_unique_dep": "Artificial and Mechanical Intelligence AMI;Machine Learning and Optimisation;Mechanical engineering department",
        "aff_unique_url": "https://www.iit.it;https://www.manchester.ac.uk;https://www.polimi.it",
        "aff_unique_abbr": "IIT;UoM;Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0;1;2;1",
        "aff_campus_unique": "Genoa;Manchester;Milano",
        "aff_country_unique_index": "0;0;0;1;0;1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "10161312",
        "title": "Online Safety Property Collection and Refinement for Safe Deep Reinforcement Learning in Mapless Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is essential for deploying Deep Reinforcement Learning (DRL) algorithms in real-world scenarios. Recently, verification approaches have been proposed to allow quantifying the number of violations of a DRL policy over input-output relationships, called properties. However, such properties are hard-coded and require task-level knowledge, making their application intractable in challenging safety-critical tasks. To this end, we introduce the Collection and Refinement of Online Properties (CROP) framework to design properties at training time. CROP employs a cost signal to identify unsafe interactions and use them to shape safety properties. Hence, we propose a refinement strategy to combine properties that model similar unsafe interactions. Our evaluation compares the benefits of computing the number of violations using standard hard-coded properties and the ones generated with CROP. We evaluate our approach in several robotic mapless navigation tasks and demonstrate that the violation metric computed with CROP allows higher returns and lower violations over previous Safe DRL approaches.",
        "primary_area": "",
        "author": "Luca Marzari;Enrico Marchesini;Alessandro Farinelli;Luca Marzari;Enrico Marchesini;Alessandro Farinelli",
        "authorids": "/37089223813;/37086805241;/37266396700;/37089223813;/37086805241;/37266396700",
        "aff": "Department of Computer Science, University of Verona, Italy; Khoury College of Computer Sciences, Northeastern University, US; Department of Computer Science, University of Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161312/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17671759911703049441&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Verona;Northeastern University",
        "aff_unique_dep": "Department of Computer Science;Khoury College of Computer Sciences",
        "aff_unique_url": "https://www.univr.it;https://www.northeastern.edu",
        "aff_unique_abbr": ";NU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "10160603",
        "title": "Online Social Robot Navigation in Indoor, Large and Crowded Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "New robotics applications require robots to complete tasks in social spaces (i.e. environments shared with people), thus arising the necessity of enabling robots to operate in a socially acceptable manner. Some social spaces tend to be large and crowded (e.g. museums, shopping malls), which require robots to move around while showing appropriate social behaviors (e.g. not interfering with human's comfortable areas). Moving under such conditions is generally called social robot navigation, and there are different approaches to do so. Nonetheless, current approaches are mostly limited to navigate large and outdoor spaces, where both robots and people can easily avoid each other. Other approaches have been tested in indoor environments, however, the test environments tend to be small and largely empty. In this paper, we present an online social robot navigation framework, which allow robots to navigate indoor, large and crowded environments, while showing social behaviors. Our framework consists of 3 modules: 1) world modeling that incorporates a novel Social Heatmap (SH) to represent crowded areas, 2) multilayered path planning that uses sampling-based approaches, and 3) path following control. We extensively benchmark our approach against state-of-the-art approaches in challenging simulated scenarios, and ww e also demonstrate its feasibility with the Pepper robot in real-world trials.",
        "primary_area": "",
        "author": "Steven Silva;Nervo Verdezoto;Dennys Paillacho;Samuel Millan-Norman;Juan David Hern\u00e1ndez;Steven Silva;Nervo Verdezoto;Dennys Paillacho;Samuel Millan-Norman;Juan David Hern\u00e1ndez",
        "authorids": "/37089578433;/37086735131;/37086291566;/37089895951;/37085416183;/37089578433;/37086735131;/37086291566;/37089895951;/37085416183",
        "aff": "School of Computer Science & Informatics at Cardiff University, UK; School of Computer Science & Informatics at Cardiff University, UK; Research Development and Innovation Center of Computer Systems - CIDIS at ESPOL Polytechnic University, Ecuador; School of Computer Science & Informatics at Cardiff University, UK; School of Computer Science & Informatics at Cardiff University, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160603/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14432962999082888211&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Cardiff University;ESPOL Polytechnic University",
        "aff_unique_dep": "School of Computer Science & Informatics;Research Development and Innovation Center of Computer Systems - CIDIS",
        "aff_unique_url": "https://www.cardiff.ac.uk;https://www.espol.edu.ec",
        "aff_unique_abbr": "Cardiff;ESPOL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cardiff;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United Kingdom;Ecuador"
    },
    {
        "id": "10160952",
        "title": "Online Tool Selection with Learned Grasp Prediction Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning-based grasp prediction models have become an industry standard for robotic bin-picking systems. To maximize pick success, production environments are often equipped with several end-effector tools that can be swapped on-the-fly, based on the target object. Tool-change, however, takes time. Choosing the order of grasps to perform, and corresponding tool-change actions, can improve system throughput; this is the topic of our work. The main challenge in planning tool change is uncertainty - we typically cannot see objects in the bin that are currently occluded. Inspired by queuing and admission control problems, we model the problem as a Markov Decision Process (MDP), where the goal is to maximize expected throughput, and we pursue an approximate solution based on model predictive control, where at each time step we plan based only on the currently visible objects. Special to our method is the idea of void zones, which are geometrical boundaries in which an unknown object will be present, and therefore cannot be accounted for during planning. Our planning problem can be solved using integer linear programming (ILP). However, we find that an approximate solution based on sparse tree search yields near optimal performance at a fraction of the time. Another question that we explore is how to measure the performance of tool-change planning: we find that throughput alone can fail to capture delicate and smooth behavior, and propose a principled alternative. Finally, we demonstrate our algorithms on both synthetic and real world bin picking tasks.",
        "primary_area": "",
        "author": "Khashayar Rohanimanesh;Jake Metzger;William Richards;Aviv Tamar;Khashayar Rohanimanesh;Jake Metzger;William Richards;Aviv Tamar",
        "authorids": "/37087447373;/37089769536;/37088505284;/37086002269;/37087447373;/37089769536;/37088505284;/37086002269",
        "aff": "Osaro Inc., San Francisco, CA, USA; Accenture Inc., San Francisco, CA, USA; Osaro Inc., San Francisco, CA, USA; Technion - Israel Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160952/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1908504781128070768&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Osaro Inc.;Accenture;Technion - Israel Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.accenture.com;https://www.technion.ac.il",
        "aff_unique_abbr": ";Accenture;Technion",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "San Francisco;Haifa",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "10160828",
        "title": "Online Update of Safety Assurances Using Confidence-Based Predictions",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots such as autonomous vehicles and assistive manipulators are increasingly operating in dynamic environ-ments and close physical proximity to people. In such scenarios, the robot can leverage a human motion predictor to predict their future states and plan safe and efficient trajectories. However, no model is ever perfect - when the observed human behavior deviates from the model predictions, the robot might plan unsafe maneuvers. Recent works have explored maintaining a confidence parameter in the human model to overcome this challenge, wherein the predicted human actions are tempered online based on the likelihood of the observed human action under the prediction model. This has opened up a new research challenge, i.e., how to compute the future human states online as the confidence parameter changes? In this work, we propose a Hamilton-Jacobi (HJ) reachability-based approach to overcome this challenge. Treating the confidence parameter as a virtual state in the system, we compute a parameter-conditioned forward reachable tube (FRT) that provides the future human states as a function of the confidence parameter. Online, as the confidence parameter changes, we can simply query the corresponding FRT, and use it to update the robot plan. Computing parameter-conditioned FRT corre-sponds to an (offline) high-dimensional reachability problem, which we solve by leveraging recent advances in data-driven reachability analysis. Overall, our framework enables online maintenance and updates of safety assurances in human-robot interaction scenarios, even when the human prediction model is incorrect. We demonstrate our approach in several safety-critical autonomous driving scenarios, involving a state-of-the-art deep learning-based prediction model.",
        "primary_area": "",
        "author": "Kensuke Nakamura;Somil Bansal;Kensuke Nakamura;Somil Bansal",
        "authorids": "/37086961952;/37085404900;/37086961952;/37085404900",
        "aff": "MAE Department, Princeton University; ECE department, USC",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160828/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=933400660289069407&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Princeton University;University of Southern California",
        "aff_unique_dep": "MAE Department;Electrical and Computer Engineering",
        "aff_unique_url": "https://www.princeton.edu;https://www.usc.edu",
        "aff_unique_abbr": "Princeton;USC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161464",
        "title": "Online Visual SLAM Adaptation against Catastrophic Forgetting with Cycle-Consistent Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual SLAM (Simultaneous Localisation and Mapping) aims to simultaneously estimate camera poses and depth maps from navigation videos captured. While recent deep learning based methods have achieved great success on this task, they tend to work well on source domain data and suffer from performance degradation on the unseen data of target domain. Hence, we propose an online adaptation approach to continuously adapt a pre-trained visual SLAM model to changing environments in a self-supervised manner. To preserve pre-learned knowledge against catastrophic forgetting, we perform updating on a novel adapter proposed rather than fine-tuning the whole model for adaptation. The adapter includes a cross-domain feature translation module that translates pre-learned features into translated features suitable for adaptation. Ideally, the translated new features should not only contain pre-learned knowledge but also substantially distinct from pre-learned features since these two features represent different domains. We thus introduce cycle-consistent contrastive learning to maximize the dissimilarity between these two features by enlarging the distance between them in the feature space. Besides, our contrastive learning method exploiting cycle-consistency contraint enables the translated features to be transferred back to the pre-learned ones, which helps the translated features better preserve pre-learned knowledge. Comprehensive experiments on both synthetic and real-world datasets demonstrate superior adaptation performance of our proposed method over several state-of-the-art baselines.",
        "primary_area": "",
        "author": "Sangni Xu;Hao Xiong;Qiuxia Wu;Tingting Yao;Zhihui Wang;Zhiyong Wang;Sangni Xu;Hao Xiong;Qiuxia Wu;Tingting Yao;Zhihui Wang;Zhiyong Wang",
        "authorids": "/37089207074;/37088475912;/38004603500;/37086141887;/37404934400;/37335976500;/37089207074;/37088475912;/38004603500;/37086141887;/37404934400;/37335976500",
        "aff": "The University of Sydney; Macquarie University; South China University of Technology; Dalian Maritime University; Dalian University of Technology; The University of Sydney",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161464/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17226364322913602360&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;4;0",
        "aff_unique_norm": "University of Sydney;Macquarie University;South China University of Technology;Dalian Maritime University;Dalian University of Technology",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.mq.edu.au;https://www.scut.edu.cn;http://www.dlmu.edu.cn/;http://www.dlut.edu.cn/",
        "aff_unique_abbr": "USYD;MQ;SCUT;DMU;DUT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;1;1;0",
        "aff_country_unique": "Australia;China"
    },
    {
        "id": "10160767",
        "title": "Online Whole-Body Motion Planning for Quadrotor using Multi-Resolution Search",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the problem of online quadrotor whole-body motion planning (SE(3) planning) in unknown and unstructured environments. We propose a novel multi-resolution search method, which discovers narrow areas requiring full pose planning and normal areas requiring only position planning. As a consequence, a quadrotor planning problem is decomposed into several SE(3) (if necessary) and R3 sub-problems. To fly through the discovered narrow areas, a carefully designed corridor generation strategy for narrow areas is proposed, which significantly increases the planning success rate. The overall problem decomposition and hierarchical planning framework substantially accelerate the planning process, making it possible to work online with fully onboard sensing and computation in unknown environments. Extensive simulation benchmark comparisons show that the proposed method is one to several orders of magnitude faster than the state-of-the-art methods in computation time while maintaining high planning success rate. The proposed method is finally integrated into a LiDAR-based autonomous quadrotor, and various real-world experiments in unknown and unstructured environments are conducted to demonstrate the outstanding performance of the proposed method.",
        "primary_area": "",
        "author": "Yunfan Ren;Siqi Liang;Fangcheng Zhu;Guozheng Lu;Fu Zhang;Yunfan Ren;Siqi Liang;Fangcheng Zhu;Guozheng Lu;Fu Zhang",
        "authorids": "/37087243712;/37089895082;/37089661744;/37086816388;/38245883800;/37087243712;/37089895082;/37089661744;/37086816388;/38245883800",
        "aff": "Department of Mechanical Engineering, University of Hong Kong; School of Mechanical Engineering and Automation, Harbin Institute of Technology; Department of Mechanical Engineering, University of Hong Kong; Department of Mechanical Engineering, University of Hong Kong; Department of Mechanical Engineering, University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160767/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10031440875633688192&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Hong Kong;Harbin Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Mechanical Engineering and Automation",
        "aff_unique_url": "https://www.hku.hk;http://www.hit.edu.cn/",
        "aff_unique_abbr": "HKU;HIT",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;Harbin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161003",
        "title": "Online augmentation of learned grasp sequence policies for more adaptable and data-efficient in-hand manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "When using a tool, the grasps used for picking it up, reposing, and holding it in a suitable pose for the desired task could be distinct. Therefore, a key challenge for autonomous in-hand tool manipulation is finding a sequence of grasps that facilitates every step of the tool use process while continuously maintaining force closure and stability. Due to the complexity of modeling the contact dynamics, reinforcement learning (RL) techniques can provide a solution in this continuous space subject to highly parameterized physical models. However, these techniques impose a trade-off in adaptability and data efficiency. At test time the tool properties, desired trajectory, and desired application forces could differ substantially from training scenarios. Adapting to this necessitates more data or computationally expensive online policy updates. In this work, we apply the principles of discrete dynamic programming (DP) to augment RL performance with domain knowledge. Specifically, we first design a computationally simple approximation of our environment. We then demonstrate in physical simulation that performing tree searches (i.e., lookaheads) and policy rollouts with this approximation can improve an RL-derived grasp sequence policy with minimal additional online computation. Additionally, we show that pretraining a deep RL network with the DP-derived solution to the discretized problem can speed up policy training.",
        "primary_area": "",
        "author": "Ethan K. Gordon;Rana Soltani Zarrin;Ethan K. Gordon;Rana Soltani Zarrin",
        "authorids": "/37088688098;/37089249858;/37088688098;/37089249858",
        "aff": "Department of Computer Science and Engineering, University of Washington, Seattle, WA; the Honda Research Institute, San Jose, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161003/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12066098824585091400&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Washington;Honda Research Institute",
        "aff_unique_dep": "Department of Computer Science and Engineering;",
        "aff_unique_url": "https://www.washington.edu;https://honda.com",
        "aff_unique_abbr": "UW;HRI",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Seattle;San Jose",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161272",
        "title": "OpTaS: An Optimization-based Task Specification Library for Trajectory Optimization and Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents OpTaS, a task specification Python library for Trajectory Optimization (TO) and Model Predictive Control (MPC) in robotics. Both TO and MPC are increasingly receiving interest in optimal control and in particular handling dynamic environments. While a flurry of software libraries exists to handle such problems, they either provide interfaces that are limited to a specific problem formulation (e.g. TracIK, CHOMP), or are large and statically specify the problem in configuration files (e.g. EXOTica, eTaSL). OpTaS, on the other hand, allows a user to specify custom nonlinear constrained problem formulations in a single Python script allowing the controller parameters to be modified during execution. The library provides interface to several open source and commercial solvers (e.g. IPOPT, SNOPT, KNITRO, SciPy) to facilitate integration with established workflows in robotics. Further benefits of OpTaS are highlighted through a thorough comparison with common libraries. An additional key advantage of OpTaS is the ability to define optimal control tasks in the joint-space, task-space, or indeed simultaneously. The code for OpTaS is easily installed via pip, and the source code with examples can be found at github.com/cmower/optas.",
        "primary_area": "",
        "author": "Christopher E. Mower;Jo\u00e3o Moura;Nazanin Zamani Behabadi;Sethu Vijayakumar;Tom Vercauteren;Christos Bergeles;Christopher E. Mower;Jo\u00e3o Moura;Nazanin Zamani Behabadi;Sethu Vijayakumar;Tom Vercauteren;Christos Bergeles",
        "authorids": "/37086311529;/37086411872;/37089896055;/37295595500;/37283803200;/37399073100;/37086311529;/37086411872;/37089896055;/37295595500;/37283803200;/37399073100",
        "aff": "School of Biomedical Engineering & Imaging Sciences, King's College, London, UK; School of Informatics, University of Edinburgh, UK; Nazanin Zamani Behabadi; School of Informatics, University of Edinburgh, UK; School of Biomedical Engineering & Imaging Sciences, King's College, London, UK; School of Biomedical Engineering & Imaging Sciences, King's College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161272/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2532932136459695808&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "King's College London;University of Edinburgh;",
        "aff_unique_dep": "School of Biomedical Engineering & Imaging Sciences;School of Informatics;",
        "aff_unique_url": "https://www.kcl.ac.uk;https://www.ed.ac.uk;",
        "aff_unique_abbr": "KCL;Edinburgh;",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "London;Edinburgh;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom;"
    },
    {
        "id": "10161534",
        "title": "Open-vocabulary Queryable Scene Representations for Real World Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Large language models (LLMs) have unlocked new capabilities of task planning from human instructions. However, prior attempts to apply LLMs to real-world robotic tasks are limited by the lack of grounding in the surrounding scene. In this paper, we develop NLMap, an open-vocabulary and queryable scene representation to address this problem. NLMap serves as a framework to gather and integrate contextual information into LLM planners, allowing them to see and query available objects in the scene before generating a context-conditioned plan. NLMap first establishes a natural language queryable scene representation with Visual Language models (VLMs). An LLM based object proposal module parses instructions and proposes involved objects to query the scene representation for object availability and location. An LLM planner then plans with such information about the scene. NLMap allows robots to operate without a fixed list of objects nor executable options, enabling real robot operation unachievable by previous methods. Project website: https://nlmap-saycan.github.io.",
        "primary_area": "",
        "author": "Boyuan Chen;Fei Xia;Brian Ichter;Kanishka Rao;Keerthana Gopalakrishnan;Michael S. Ryoo;Austin Stone;Daniel Kappler;Boyuan Chen;Fei Xia;Brian Ichter;Kanishka Rao;Keerthana Gopalakrishnan;Michael S. Ryoo;Austin Stone;Daniel Kappler",
        "authorids": "/37089893856;/37089893973;/37086034185;/37089891969;/37089892387;/37397559800;/37086248227;/37992308100;/37089893856;/37089893973;/37086034185;/37089891969;/37089892387;/37397559800;/37086248227;/37992308100",
        "aff": "MIT; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Everyday Robots",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161534/",
        "gs_citation": 209,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10576556543384228225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;1;1;2",
        "aff_unique_norm": "Massachusetts Institute of Technology;Google;Everyday Robots",
        "aff_unique_dep": ";Robotics;",
        "aff_unique_url": "https://web.mit.edu;https://www.google.com;https://www.everydayrobots.com",
        "aff_unique_abbr": "MIT;Google Robotics;",
        "aff_campus_unique_index": "1;1;1;1;1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161389",
        "title": "Operating with Inaccurate Models by Integrating Control-Level Discrepancy Information into Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Typical robotic systems rely on models for planning. Therefore, the quality of the robot's behavior is heavily dependent on how accurately the model can predict the outcome of the robot's actions in the environment. A challenge, however, is that no model is perfect; moreover, we often do not know where discrepancies between the model's prediction and the actual outcome occur prior to observing executions in the real-world. One way to address this is to bias the planner away from these discrepancies by inflating the cost of states and actions where we previously observed the model to be inaccurate. Making such decisions about where and how to bias purely at the planning-level, however, neglects valuable information from the control-level, which gives a more fine-grained understanding of where and how the model went wrong during execution. Based on this observation, our key idea is to first infer a statistical model over discrepancies in the control-level's model. Then, we translate this model to the planning-level, where we use it to more informatively bias the planner away from states and actions where the model's predicted outcome is likely to be inaccurate. We demonstrate that our framework enables a robot to complete tasks, despite an inaccurate planning model, with greater efficiency than existing approaches. We do so through an experimental evaluation in simulation and real-robot experiments on NASA's Astrobee free-flyer.",
        "primary_area": "",
        "author": "Ellis Ratner;Claire J. Tomlin;Maxim Likhachev;Ellis Ratner;Claire J. Tomlin;Maxim Likhachev",
        "authorids": "/37085587523;/37271692600;/37309318800;/37085587523;/37271692600;/37309318800",
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161389/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13284358473520770375&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of California, Berkeley;Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences;Robotics Institute",
        "aff_unique_url": "https://www.berkeley.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UC Berkeley;CMU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Berkeley;Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161545",
        "title": "Operative Action Captioning for Estimating System Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-assistive systems, such as robots, need to correctly understand the surrounding situation based on obser-vations and output the required support actions for humans. Language is one of the important channels to communicate with humans, and robots are required to have the ability to express their understanding and action-planning results. In this study, we propose a new task of operative action captioning that estimates and verbalizes the actions to be taken by the system in a human-assisting domain. We constructed a system that outputs a verbal description of a possible operative action that changes the current state to the given target state. We collected a dataset consisting of two images as observations, which express the current state and the state changed by actions and a caption that describes the actions that change the current state to the target state, by crowdsourcing in daily life situations. Then we constructed a system that estimates an operative action by a caption. Since the operative action's caption is expected to contain some state-changing actions, we use scene graph prediction as an auxiliary task because the events written in the scene graphs correspond to the state changes. Experimental results showed that our system successfully described the operative actions that should be conducted between the current and target states. The auxiliary tasks that predict the scene graphs improved the quality of the estimation results.",
        "primary_area": "",
        "author": "Taiki Nakamura;Seiya Kawano;Akishige Yuguchi;Yasutomo Kawanishi;Koichiro Yoshino;Taiki Nakamura;Seiya Kawano;Akishige Yuguchi;Yasutomo Kawanishi;Koichiro Yoshino",
        "authorids": "/37089894766;/37085373438;/37086354965;/37085608108;/37085667925;/37089894766;/37085373438;/37086354965;/37085608108;/37085667925",
        "aff": "Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Guardian Robot Project, R-IH, RIKEN, Kyoto, Japan; Guardian Robot Project, R-IH, RIKEN, Kyoto, Japan; Guardian Robot Project, R-IH, RIKEN, Kyoto, Japan; Guardian Robot Project, R-IH, RIKEN, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161545/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:j-pWLvNT-50J:scholar.google.com/&scioq=Operative+Action+Captioning+for+Estimating+System+Actions&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "The University of Tokyo;RIKEN",
        "aff_unique_dep": "Graduate School of Information Science and Technology;Guardian Robot Project",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Tokyo;Kyoto",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161357",
        "title": "OptiGap: A Modular Optical Sensor System for Bend Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the novel use of air gaps in flexible optical light pipes to create coded patterns for use in bend localization. The OptiGap sensor system allows for the creation of extrinsic intensity modulated bend sensors that function as flexible absolute linear encoders. Coded air gap patterns are identified by a Gaussian naive Bayes (GNB) classifier running on an STM32 microcontroller. The fitting of the classifier is aided by a custom software suite that simplifies data collection and processing from the sensor. The sensor model is analyzed and verified through simulation and experiments, highlighting key properties and parameters that aid in the design of OptiGap sensors using different light pipe materials and for various applications. The OptiGap system allows for real-time and accurate bend localization in many robotics and automation applications, in both wet and dry conditions.",
        "primary_area": "",
        "author": "Paul Bupe;C. K. Harnett;Paul Bupe;C. K. Harnett",
        "authorids": "/37085508688;/37322827000;/37085508688;/37322827000",
        "aff": "Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, USA; Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161357/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14556039941774574254&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Louisville",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.louisville.edu",
        "aff_unique_abbr": "UofL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Louisville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161320",
        "title": "Optimal Allocation of Many Robot Guards for Sweep-Line Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of allocating many mobile robots for the execution of a pre-defined sweep schedule in a known two-dimensional environment, with applications toward search and rescue, coverage, surveillance, monitoring, pursuit-evasion, and so on. The mobile robots (or agents) are assumed to have one-dimensional sensing capability with probabilistic guarantees that deteriorate as the sensing distance increases. In solving such tasks, a time-parameterized distribution of robots along the sweep frontier must be computed, to minimize the number of robots used to achieve some desired coverage quality guarantee or to maximize the probabilistic guarantee for a given the number of robots. We propose a max-flow-based algorithm for solving the allocation task, which builds on a decomposition technique of the workspace as a generalization of the well-known boustrophedon decomposition. Our proposed algorithm has a very low polynomial running time and completes in under two seconds for polygonal environments with over 105 vertices. Simulation experiments are carried out on three realistic use cases with randomly generated obstacles of varying shapes, sizes, and spatial distributions, demonstrating our proposed method's applicability and scalability. Introduction video: https://youtu.be/8taX92rzC5k.",
        "primary_area": "",
        "author": "Si Wei Feng;Teng Guo;Jingjin Yu;Si Wei Feng;Teng Guo;Jingjin Yu",
        "authorids": "/37087233222;/37088998158;/37536570700;/37087233222;/37088998158;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, New Brunswick, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, New Brunswick, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, New Brunswick, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161320/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15930475256414689805&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161455",
        "title": "Optimal Grasps and Placements for Task and Motion Planning in Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "Many methods that solve robot planning problems, such as task and motion planners, employ discrete symbolic search to find sequences of valid symbolic actions that are grounded with motion planning. Much of the efficacy of these planners lies in this grounding-bad placement and grasp choices can lead to inefficient planning when a problem has many geometric constraints. Moreover, grounding methods such as na\u00efve sampling often fail to find appropriate values for these choices in the presence of clutter. Towards efficient task and motion planning, we present a novel optimization-based approach for grounding to solve cluttered problems that have many constraints that arise from geometry. Our approach finds an optimal grounding and can provide feedback to discrete search for more effective planning. We demonstrate our method against baseline methods in complex simulated environments.",
        "primary_area": "",
        "author": "Carlos Quintero-Pe\u00f1a;Zachary Kingston;Tianyang Pan;Rahul Shome;Anastasios Kyrillidis;Lydia E. Kavraki;Carlos Quintero-Pe\u00f1a;Zachary Kingston;Tianyang Pan;Rahul Shome;Anastasios Kyrillidis;Lydia E. Kavraki",
        "authorids": "/37088997672;/37085542480;/37086938153;/37085557993;/37713417100;/37279015600;/37088997672;/37085542480;/37086938153;/37085557993;/37713417100;/37279015600",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161455/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18139987091226939484&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160265",
        "title": "Optimal Multi-Robot Coverage Path Planning for Agricultural Fields using Motion Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Coverage path planning (CPP) is the task of computing an optimal path within a region to completely scan or survey the area of interest by using robotic sensor footprints. In this work, we propose a novel approach to find the multi-robot optimal coverage path of an agricultural field using motion dynamics while minimizing the mission time. Our approach consists of three steps: (i) divide the agricultural field into convex polygonal areas to optimally distribute them among the robots, (ii) generate an optimal coverage path to ensure minimum coverage time for each of the polygonal areas, and (iii) generate the trajectory for each coverage path using Dubins motion dynamics. Several experiments and simulations were performed to check the validity and feasibility of our approach, and the results and limitations are discussed.",
        "primary_area": "",
        "author": "Jahid Chowdhury Choton;Pavithra Prabhakar;Jahid Chowdhury Choton;Pavithra Prabhakar",
        "authorids": "/37086689194;/37671515300;/37086689194;/37671515300",
        "aff": "Kansas State University, Manhattan, Kansas, USA; Kansas State University, Manhattan, Kansas, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160265/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8708758601703865234&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kansas State University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.k-state.edu",
        "aff_unique_abbr": "K-State",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Manhattan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160901",
        "title": "Optimal Parameterized Joints Selection to Improve Motion Planning Performance of Redundant Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "The redundant manipulators' analytical solutions can be obtained by the parameterization method. Multiple parameterized joints and their corresponding parametric representations exist for a redundant manipulator. However, how to select the optimal parameterized joints has yet to be well-addressed. This paper delves into the mechanism of the parameterization method and proposes a method to select the optimal parametric representations to improve the motion planning performance of manipulators. We tested the proposed method on an 8-degree-of-freedom (DOF) manipulator. First, all feasible parametric representations are derived, followed by an approach to obtain solution manifolds. We then introduce a metric called the \u201cfeasible rate,\u201d which characterizes the percentage of the solution manifold in the joint space. This metric is used to rapidly assess the influence of different parameterized joints on the manipulator's motion planning performance. To verify the proposed method's correctness, we evaluated the performance of different representations with the MOEA/D algorithm in solving the same path optimization problems based on the algorithm running time and overall motion magnitude of the manipulator. Our simulation results demonstrate that different selections of parameterized joints affect the motion planning performance, and the performance planned by the optimal parametric representation is up to four times greater than that of the worst one.",
        "primary_area": "",
        "author": "Bin Xie;Qingfeng Wang;Di Wu;Bin Xie;Qingfeng Wang;Di Wu",
        "authorids": "/37085376783;/37089894539;/37088505283;/37085376783;/37089894539;/37088505283",
        "aff": "School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160901/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=484246773991942284&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Central South University",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "http://www.csu.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160528",
        "title": "Optimal Scheduling of Models and Horizons for Model Hierarchy Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Model predictive control (MPC) is a powerful tool to control systems with non-linear dynamics and constraints, but its computational demands impose limitations on the dynamics model used for planning. Instead of using a single complex model along the MPC horizon, model hierarchy predictive control (MHPC) reduces solve times by planning over a sequence of models of varying complexity within a single horizon. Choosing this model sequence can become intractable when considering all possible combinations of reduced order models and prediction horizons. We propose a framework to systematically optimize a model schedule for MHPC. We leverage trajectory optimization (TO) to approximate the accumulated cost of the closed-loop controller. We trade off performance and solve times by minimizing the number of decision variables of the MHPC problem along the horizon while keeping the approximate closed-loop cost near optimal. The framework is validated in simulation with a planar humanoid robot as a proof of concept. We find that the approximated closed-loop cost matches the simulated one for most of the model schedules, and show that the proposed approach finds optimal model schedules that transfer directly to simulation, and with total horizons that vary between 1.1 and 1.6 walking steps.",
        "primary_area": "",
        "author": "Charles Khazoom;Steve Heim;Daniel Gonzalez-Diaz;Sangbae Kim;Charles Khazoom;Steve Heim;Daniel Gonzalez-Diaz;Sangbae Kim",
        "authorids": "/37086876458;/37086397602;/37089676012;/37537397200;/37086876458;/37086397602;/37089676012;/37537397200",
        "aff": "Department of Mechanical Engineering Department, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Mechanical Engineering Department, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Mechanical Engineering Department, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Mechanical Engineering Department, Massachusetts Institute of Technology, Cambridge, MA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160528/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8526385330759772293&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161031",
        "title": "Optimal Workpiece Placement Based on Robot Reach, Manipulability and Joint Torques",
        "track": "main",
        "status": "Poster",
        "abstract": "Workpiece placement with respect to an industrial robot plays an important role in robotic manufacturing due to its influence on the configuration-dependent properties of industrial robots. Suboptimal placements of the workpiece may increase the required joint torques and decrease the dexterity of the robot. The focus of this work is to identify an optimal workpiece pose that enables a robot to carry out surface finishing with configurations that require the lowest possible joint torques while having maximum possible manipulability. We present a non-linear optimization-based algorithm to solve this problem and demonstrate the algorithm's capability on dif-ferent workpieces which we share to facilitate further research in this area.",
        "primary_area": "",
        "author": "Baris Balci;Jared Donovan;Jonathan Roberts;Peter Corke;Baris Balci;Jared Donovan;Jonathan Roberts;Peter Corke",
        "authorids": "/37089895172;/37089894633;/37278794400;/37279654600;/37089895172;/37089894633;/37278794400;/37279654600",
        "aff": "Australian Cobotics Centre, Queensland University of Technology, Brisbane, Queensland, Australia; Australian Cobotics Centre, Queensland University of Technology, Brisbane, Queensland, Australia; Australian Cobotics Centre, Queensland University of Technology, Brisbane, Queensland, Australia; Australian Cobotics Centre, Queensland University of Technology, Brisbane, Queensland, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161031/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10976234337617597365&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "Australian Cobotics Centre",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10161057",
        "title": "Optimized Design and Analysis of Active Propeller-driven Capsule Endoscopic Robot for Gastric Examination",
        "track": "main",
        "status": "Poster",
        "abstract": "Capsule endoscopic robot holds great promise for the early diagnosis of gastrointestinal diseases without causing discomfort to patients. However, currently available active capsule endoscopic robots suffer from issues such as complex structure, poor mobility, large size, and high cost, which have hindered their widespread adoption and resulted in a lower screening rate for gastrointestinal diseases. To address these challenges, this paper proposes a highly integrated propeller-driven capsule endoscopic robot (PCER) system that integrates STM32 processor, magnetic sensor, IMU, RF communication unit, and motor drive. The micro propeller of the PCER has been analyzed through finite element simulation to ensure its efficiency. FLUENT software has been utilized to simulate the fluid force acting on the PCER as it moves through a liquid medium. The results of the simulation are then used to determine the optimal pitch angle for the robot's movement. The thrust generated by the capsule robot propellers has been measured using a lever mechanism to investigate the relationship between the thrust and voltage applied to the motors. The experiments confirmed that the PCER is capable of performing flexible motions within fluid environments, such as changing pitch angle during movement, passing circular obstacles, horizontal motion, and spiral ascent. These findings demonstrate the feasibility of the proposed PCER as an effective tool for non-invasive early screening of gastrointestinal diseases.",
        "primary_area": "",
        "author": "Yi Zhang;Weihao Wang;Wende Ke;Chengzhi Hu;Yi Zhang;Weihao Wang;Wende Ke;Chengzhi Hu",
        "authorids": "/37088998162;/37089831455;/37086358011;/38025900900;/37088998162;/37089831455;/37086358011;/38025900900",
        "aff": "Guangdong Provincial Key Laboratory of Human-Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Human-Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Human-Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Human-Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161057/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18263758499505930710&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Guangdong Provincial Key Laboratory of Human-Augmentation and Rehabilitation Robotics in Universities",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160436",
        "title": "Optimizing Bipedal Locomotion for The 100m Dash With Comparison to Human Running",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we explore the space of running gaits for the bipedal robot Cassie. Our first contribution is to present an approach for optimizing gait efficiency across a spectrum of speeds with the aim of enabling extremely high-speed running on hardware. This raises the question of how the resulting gaits compare to human running mechanics, which are known to be highly efficient in comparison to quadrupeds. Our second contribution is to conduct this comparison based on established human biomechanical studies. We find that despite morphological differences between Cassie and humans, key properties of the gaits are highly similar across a wide range of speeds. Finally, our third contribution is to integrate the optimized running gaits into a full controller that satisfies the rules of the real-world task of the 100m dash, including starting and stopping from a standing position. We demonstrate this controller on hardware to establish the Guinness World Record for Fastest 100m by a Bipedal Robot.",
        "primary_area": "",
        "author": "Devin Crowley;Jeremy Dao;Helei Duan;Kevin Green;Jonathan Hurst;Alan Fern;Devin Crowley;Jeremy Dao;Helei Duan;Kevin Green;Jonathan Hurst;Alan Fern",
        "authorids": "/37089894386;/37086114282;/37086154386;/37087323965;/37267365600;/37353413400;/37089894386;/37086114282;/37086154386;/37087323965;/37267365600;/37353413400",
        "aff": "Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160436/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7274170039098210887&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160374",
        "title": "Option-Aware Adversarial Inverse Reinforcement Learning for Robotic Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Hierarchical Imitation Learning (HIL) has been proposed to recover highly-complex behaviors in long-horizon tasks from expert demonstrations by modeling the task hierarchy with the option framework. Existing methods either overlook the causal relationship between the subtask and its corresponding policy or cannot learn the policy in an end-to-end fashion, which leads to suboptimality. In this work, we develop a novel HIL algorithm based on Adversarial Inverse Reinforcement Learning and adapt it with the Expectation-Maximization algorithm in order to directly recover a hierarchical policy from the unannotated demonstrations. Further, we introduce a directed information term to the objective function to enhance the causality and propose a Variational Autoencoder framework for learning with our objectives in an end-to-end fashion. Theoretical justifications and evaluations on challenging robotic control tasks are provided to show the superiority of our algorithm. The codes are available at https://github.com/LucasCJYSDL/HierAIRL.",
        "primary_area": "",
        "author": "Jiayu Chen;Tian Lan;Vaneet Aggarwal;Jiayu Chen;Tian Lan;Vaneet Aggarwal",
        "authorids": "/37086562831;/38242520200;/37302263100;/37086562831;/38242520200;/37302263100",
        "aff": "School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, George Washington University, Washington D.C., USA; CS Department, KAUST, Thuwal, Saudi Arabia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160374/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8320017292262894753&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Purdue University;George Washington University;King Abdullah University of Science and Technology",
        "aff_unique_dep": "School of Industrial Engineering;Department of Electrical and Computer Engineering;Computer Science Department",
        "aff_unique_url": "https://www.purdue.edu;https://www.gwu.edu;https://www.kaust.edu.sa",
        "aff_unique_abbr": "Purdue;GWU;KAUST",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "West Lafayette;Washington D.C.;Thuwal",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Saudi Arabia"
    },
    {
        "id": "10160950",
        "title": "Orbeez-SLAM: A Real-time Monocular Visual SLAM with ORB Features and NeRF-realized Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "A spatial AI that can perform complex tasks through visual signals and cooperate with humans is highly anticipated. To achieve this, we need a visual SLAM that easily adapts to new scenes without pre-training and generates dense maps for downstream tasks in real-time. None of the previous learning-based and non-learning-based visual SLAMs satisfy all needs due to the intrinsic limitations of their components. In this work, we develop a visual SLAM named Orbeez-SLAM, which successfully collaborates with implicit neural representation and visual odometry to achieve our goals. Moreover, Orbeez-SLAM can work with the monocular camera since it only needs RGB inputs, making it widely applicable to the real world. Results show that our SLAM is up to 800x faster than the strong baseline with superior rendering outcomes. Code link: https://github.com/MarvinChung/Orbeez-SLAM.",
        "primary_area": "",
        "author": "Chi-Ming Chung;Yang-Che Tseng;Ya-Ching Hsu;Xiang-Qian Shi;Yun-Hung Hua;Jia-Fong Yeh;Wen-Chin Chen;Yi-Ting Chen;Winston H. Hsu;Chi-Ming Chung;Yang-Che Tseng;Ya-Ching Hsu;Xiang-Qian Shi;Yun-Hung Hua;Jia-Fong Yeh;Wen-Chin Chen;Yi-Ting Chen;Winston H. Hsu",
        "authorids": "/37088475868;/37089892590;/37089894338;/37089891913;/37089895683;/37088934139;/37088230745;/37089895467;/37272584600;/37088475868;/37089892590;/37089894338;/37089891913;/37089895683;/37088934139;/37088230745;/37089895467;/37272584600",
        "aff": "National Taiwan University; National Taiwan University; National Taiwan University; National Taiwan University; National Taiwan University; National Taiwan University; National Taiwan University; National Yang Ming Chiao Tung University; Mobile Drive Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160950/",
        "gs_citation": 137,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18278031807210684245&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;1;2",
        "aff_unique_norm": "National Taiwan University;National Yang Ming Chiao Tung University;Mobile Drive Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ntu.edu.tw;https://www.nycu.edu.tw;",
        "aff_unique_abbr": "NTU;NYCU;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "10160943",
        "title": "Origami Folding Enhances Modularity and Mechanical Efficiency of Soft Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots have long been attractive to robotic engineers due to their remarkable dexterity; however, reports that standardize soft actuators into modularized off-shelf devices akin to rigid robots are still rare, and the mechanical efficiency of existing designs is still limited. This work identifies origami folding to enable the design of LEGO-like modularized soft actuators with high mechanical efficiency in terms of payload capability and workspace. Herein, three modularized origami actuators that can generate translational, bending, and twisting motion are designed, prototyped, and tested. The translational actuator can contract to 40% of its original length, and the twisting and bending actuators can exert 31\u00b0 and 52\u00b0 angular motions, respectively. The translational actuator can exert a blocked force of about 821 times self-weight. The motion of origami soft actuators is accurately modeled using rigid body kinematics, and complex systems built by them are captured by homogeneous transformation. Finally, the modularized design and efficient kinematic model are verified on a manipulator and a reconfigurable letter. Benefiting from the unprecedented modularity and mechanical efficiency, these LEGO-like origami actuators are promising for practical applications like food handling and healthcare.",
        "primary_area": "",
        "author": "Zheng Wang;Yazhou Song;Zhongkui Wang;Hongying Zhang;Zheng Wang;Yazhou Song;Zhongkui Wang;Hongying Zhang",
        "authorids": "/37085463419;/37089892548;/37404934700;/37900170900;/37085463419;/37089892548;/37404934700;/37900170900",
        "aff": "National University of Singapore (Suzhou) Research Institute, Suzhou, China; National University of Singapore (Suzhou) Research Institute, Suzhou, China; Department of Robotics, Ritsumeikan University, Kusatsu, Japan; Department of Mechanical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160943/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1915533261322978152&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "National University of Singapore;Ritsumeikan University",
        "aff_unique_dep": "Research Institute;Department of Robotics",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "NUS;Ritsumeikan",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Suzhou;Kusatsu;",
        "aff_country_unique_index": "0;0;1;2",
        "aff_country_unique": "China;Japan;Singapore"
    },
    {
        "id": "10160891",
        "title": "Output Mode Switching for Parallel Five-bar Manipulators Using a Graph-based Path Planner",
        "track": "main",
        "status": "Poster",
        "abstract": "The configuration spaces of parallel manipulators exhibit more nonlinearity than serial manipulators. Qualitatively, they can be seen to possess extra folds. Projection onto smaller spaces of engineering relevance, such as an output workspace or an input actuator space, these folds cast edges that exhibit boundary behavior. For example, inside the global workspace bounds of a five-bar linkage appear several local workspace bounds that only constrain certain output modes of the mechanism. The presence of such boundaries, which manifest in both input and output projections, serve as a source of confusion when these projections are studied exclusively instead of the configuration space itself. Particularly, the design of nonsymmetric parallel manipulators has been confounded by the presence of exotic projections in their input and output spaces. In this paper, we represent the configuration space with a radius graph, then weight each edge by solving an optimization problem using homotopy continuation to quantify transmission quality. We then employ a graph path planner to approximate geodesics between configuration points that avoid regions of low transmission quality. Our methodology automatically generates paths capable of transitioning between non-neighboring output modes, a motion which involves osculating multiple workspace boundaries (local, global, or both). We apply our technique to two nonsymmetric five-bar examples that demonstrate how transmission properties and other characteristics of the workspace can be selected by switching output modes.",
        "primary_area": "",
        "author": "Parker B. Edwards;Aravind Baskar;Caroline Hills;Mark Plecnik;Jonathan D. Hauenstein;Parker B. Edwards;Aravind Baskar;Caroline Hills;Mark Plecnik;Jonathan D. Hauenstein",
        "authorids": "/37087995879;/37088998829;/37089895660;/37085786438;/37087996614;/37087995879;/37088998829;/37089895660;/37085786438;/37087996614",
        "aff": "Department of Applied and Computational Mathematics and Statistics, University of Notre Dame, Notre Dame, IN, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Applied and Computational Mathematics and Statistics, University of Notre Dame, Notre Dame, IN, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Applied and Computational Mathematics and Statistics, University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160891/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5076947517607535508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Applied and Computational Mathematics and Statistics",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160830",
        "title": "OysterNet: Enhanced Oyster Detection Using Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Oysters play a pivotal role in the bay living ecosystem and are considered the living filters for the ocean. In recent years, oyster reefs have undergone major devastation caused by commercial over-harvesting, requiring preservation to maintain ecological balance. The foundation of this preservation is to estimate the oyster density which requires accurate oyster detection. However, systems for accurate oyster detection require large datasets obtaining which is an expensive and labor-intensive task in underwater environments. To this end, we present a novel method to mathematically model oysters and render images of oysters in simulation to boost the detection performance with minimal real data. Utilizing our synthetic data along with real data for oyster detection, we obtain up to 35.1 % boost in performance as compared to using only real data with our OysterNet network. We also improve the state-of-the-art by 12.7%. This shows that using underlying geometrical properties of objects can help to enhance recognition task accuracy on limited datasets successfully and we hope more researchers adopt such a strategy for hard-to-obtain datasets.",
        "primary_area": "",
        "author": "Xiaomin Lin;Nitin J. Sanket;Nare Karapetyan;Yiannis Aloimonos;Xiaomin Lin;Nitin J. Sanket;Nare Karapetyan;Yiannis Aloimonos",
        "authorids": "/37089630983;/37086390746;/37086299803;/37282631400;/37089630983;/37086390746;/37086299803;/37282631400",
        "aff": "Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA; Robotics Engineering, Worcester Polytechnic Institute, MA, USA; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160830/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15805946147762352746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Maryland;Worcester Polytechnic Institute",
        "aff_unique_dep": "Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies;Robotics Engineering",
        "aff_unique_url": "https://www.umd.edu;https://www.wpi.edu",
        "aff_unique_abbr": "UMD;WPI",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "College Park;Worcester",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161380",
        "title": "PARSEC: An Aerial Platform for Autonomous Deployment of Self-Anchoring Payloads on Natural Vertical Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "PARSEC (Payload Anchoring Robotic System for the Exploration of Cliffs) is an autonomy-equipped aerial manipulator that can deploy self-anchoring payloads on rocky vertical surfaces. It consists of a hexacopter and a two Degrees of Freedom (2 DoF) mass balancing manipulator, which can autonomously deploy a self-anchoring payload from its custom end-effector. The payload anchors itself via an actuated microspine gripper. Payload sensor data is wirelessly transmitted to the primary vehicle during and after deployment. A novel state machine controls the four-stage PARSEC deployment process. First, the rotorcraft brings the payload into contact with the surface and applies a constant 6 N normal force through a feedback control loop to preload the payload microspine gripper. Second, while the rotorcraft maintains the constant normal force, the gripper is commanded to close until engagement with the surface is confirmed through the current feedback sensing. Then, the aerial manipulator pulls with 5 N force on the anchored payload to ensure a secure grip before releasing the package and flying away. We present experimental validation of a successful deployment of a 430 g payload on a vertical vesicular basalt surface.",
        "primary_area": "",
        "author": "Patrick Spieler;Skylar X. Wei;Monica Li;Andrew Galassi;Kyle Uckert;Arash Kalantari;Joel W. Burdick;Patrick Spieler;Skylar X. Wei;Monica Li;Andrew Galassi;Kyle Uckert;Arash Kalantari;Joel W. Burdick",
        "authorids": "/37088504609;/37089446656;/37087043201;/37089891865;/38235032100;/37077278800;/37265975700;/37088504609;/37089446656;/37087043201;/37089891865;/38235032100;/37077278800;/37265975700",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Division of Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical Engineering, UC Berkeley, Berkeley, CA, USA; Woodruff School of Mechanical Engineering at the Georgia Tech, Atlanta, GA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Division of Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161380/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8551123399674675858&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;0;0;0",
        "aff_unique_norm": "California Institute of Technology;University of California, Berkeley;Georgia Institute of Technology",
        "aff_unique_dep": "Jet Propulsion Laboratory;Department of Mechanical Engineering;Woodruff School of Mechanical Engineering",
        "aff_unique_url": "https://www.caltech.edu;https://www.berkeley.edu;https://www.gatech.edu",
        "aff_unique_abbr": "Caltech;UC Berkeley;Georgia Tech",
        "aff_campus_unique_index": "0;0;1;2;0;0;0",
        "aff_campus_unique": "Pasadena;Berkeley;Atlanta",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161226",
        "title": "PCGen: Point Cloud Generator for LiDAR Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Chenqi Li;Yuan Ren;Bingbing Liu;Chenqi Li;Yuan Ren;Bingbing Liu",
        "authorids": "/37089893314;/37088997700;/38572992400;/37089893314;/37088997700;/38572992400",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161226/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11393445153838560133&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "10160380",
        "title": "PIEKF-VIWO: Visual-Inertial-Wheel Odometry using Partial Invariant Extended Kalman Filter",
        "track": "main",
        "status": "Poster",
        "abstract": "Invariant Extended Kalman Filter (IEKF) has been successfully applied in Visual-inertial Odometry (VIO) as an advanced achievement of Kalman filter, showing great potential in sensor fusion. In this paper, we propose partial IEKF (PIEKF), which only incorporates rotation-velocity state into the Lie group structure and apply it for Visual-Inertial-Wheel Odometry (VIWO) to improve positioning accuracy and consistency. Specifically, we derive the rotation-velocity measurement model, which combines wheel measurements with kinematic constraints. The model circumvents the wheel odometer's 3D integration and covariance propagation, which is essential for filter consistency. And a plane constraint is also introduced to enhance the position accuracy. A dynamic outlier detection method is adopted, leveraging the velocity state output. Through the simulation and real-world test, we validate the effectiveness of our approach, which outperforms the standard Multi-State Constraint Kalman Filter (MSCKF) based VIWO in consistency and accuracy.",
        "primary_area": "",
        "author": "Tong Hua;Tao Li;Ling Pei;Tong Hua;Tao Li;Ling Pei",
        "authorids": "/37089892878;/37088419419;/37543605200;/37089892878;/37088419419;/37543605200",
        "aff": "Shanghai Key Laboratory of Navigation and Location Based Services, Shanghai Jiao Tong University; Shanghai Key Laboratory of Navigation and Location Based Services, Shanghai Jiao Tong University; Shanghai Key Laboratory of Navigation and Location Based Services, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160380/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1487026439098431967&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Shanghai Key Laboratory of Navigation and Location Based Services",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161117",
        "title": "Parallel Inversion of Neural Radiance Fields for Robust Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a parallelized optimization method based on fast Neural Radiance Fields (NeRF) for estimating 6-DoF pose of a camera with respect to an object or scene. Given a single observed RGB image of the target, we can predict the translation and rotation of the camera by minimizing the residual between pixels rendered from a fast NeRF model and pixels in the observed image. We integrate a momentum-based camera extrinsic optimization procedure into Instant Neural Graphics Primitives, a recent exceptionally fast NeRF implementation. By introducing parallel Monte Carlo sampling into the pose estimation task, our method overcomes local minima and improves efficiency in a more extensive search space. We also show the importance of adopting a more robust pixel-based loss function to reduce error. Experiments demonstrate that our method can achieve improved generalization and robustness on both synthetic and real-world benchmarks.",
        "primary_area": "",
        "author": "Yunzhi Lin;Thomas M\u00fcller;Jonathan Tremblay;Bowen Wen;Stephen Tyree;Alex Evans;Patricio A. Vela;Stan Birchfield;Yunzhi Lin;Thomas M\u00fcller;Jonathan Tremblay;Bowen Wen;Stephen Tyree;Alex Evans;Patricio A. Vela;Stan Birchfield",
        "authorids": "/37088506366;/37089540791;/37086455314;/37088488448;/37074894100;/37089542759;/37329553400;/37371627300;/37088506366;/37089540791;/37086455314;/37088488448;/37074894100;/37089542759;/37329553400;/37371627300",
        "aff": "Georgia Institute of Technology; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; Georgia Institute of Technology; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161117/",
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14614083867126211140&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;1;0;1",
        "aff_unique_norm": "Georgia Institute of Technology;NVIDIA Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;https://www.nvidia.com",
        "aff_unique_abbr": "Georgia Tech;NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160675",
        "title": "Parallel Reinforcement Learning Simulation for Visual Quadrotor Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) is an agent-based approach for teaching robots to navigate within the physical world. Gathering data for RL is known to be a laborious task, and real-world experiments can be risky. Simulators facilitate the collection of training data in a quicker and more cost-effective manner. However, RL frequently requires a significant number of simulation steps for an agent to become skilful at simple tasks. This is a prevalent issue within the field of RL-based visual quadrotor navigation where state dimensions are typically very large and dynamic models are complex. Furthermore, rendering images and obtaining physical properties of the agent can be computationally expensive. To solve this, we present a simulation framework, built on AirSim, which provides efficient parallel training. Building on this framework, Ape-X is modified to incorporate parallel training of AirSim environments to make use of numerous networked computers. Through experiments we were able to achieve a reduction in training time from 3.9 hours to 11 minutes, for a toy problem, using the aforementioned framework and a total of 74 agents and two networked computers. Further details including a github repo and videos about our project, PRL4AirSim, can be found at https://sites.google.com/view/prl4airsim/home",
        "primary_area": "",
        "author": "Jack Saunders;Sajad Saeedi;Wenbin Lil;Jack Saunders;Sajad Saeedi;Wenbin Lil",
        "authorids": "/37089892762;/37089892918;/37089895878;/37089892762;/37089892918;/37089895878",
        "aff": "Department of Computer Science, University of Bath, UK; Department of Mechanical and Industrial Engineering, Toronto Metropolitan University, Toronto, Canada; Department of Computer Science, University of Bath, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160675/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18251720962521444983&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Bath;Toronto Metropolitan University",
        "aff_unique_dep": "Department of Computer Science;Department of Mechanical and Industrial Engineering",
        "aff_unique_url": "https://www.bath.ac.uk;https://www.tmuh.ca",
        "aff_unique_abbr": "Bath;TMU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Canada"
    },
    {
        "id": "10160694",
        "title": "Parameter Optimization for Manipulator Motion Planning using a Novel Benchmark Set",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based motion planning algorithms have been continuously developed for more than two decades. Apart from mobile robots, they are also widely used in manipulator motion planning. Hence, these methods play a key role in collaborative and shared workspaces. Despite numerous improvements, their performance can highly vary depending on the chosen parameter setting. The optimal parameters depend on numerous factors such as the start state, the goal state and the complexity of the environment. Practitioners usually choose these values using their experience and tedious trial and error experiments. To address this problem, recent works combine hyperparameter optimization methods with motion planning. They show that tuning the planner's parameters can lead to shorter planning times and lower costs. It is not clear, however, how well such approaches generalize to a diverse set of planning problems that include narrow passages as well as barely cluttered environments. In this work, we analyze optimized planner settings for a large set of diverse planning problems. We then provide insights into the connection between the characteristics of the planning problem and the optimal parameters. As a result, we provide a list of recommended parameters for various use-cases. Our experiments are based on a novel motion planning benchmark for manipulators which we provide at https://mytuc.org/rybj.",
        "primary_area": "",
        "author": "Carl Gaebert;Sascha Kaden;Benjamin Fischer;Ulrike Thomas;Carl Gaebert;Sascha Kaden;Benjamin Fischer;Ulrike Thomas",
        "authorids": "/37089578920;/37086454781;/37089893957;/37281523200;/37089578920;/37086454781;/37089893957;/37281523200",
        "aff": "Robotics and Human-Machine Interaction Lab, Chemnitz University of Technology, Germany; Robotics and Human-Machine Interaction Lab, Chemnitz University of Technology, Germany; Robotics and Human-Machine Interaction Lab, Chemnitz University of Technology, Germany; Robotics and Human-Machine Interaction Lab, Chemnitz University of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160694/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2537200417778394379&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chemnitz University of Technology",
        "aff_unique_dep": "Robotics and Human-Machine Interaction Lab",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160554",
        "title": "Parameter-Conditioned Reachable Sets for Updating Safety Assurances Online",
        "track": "main",
        "status": "Poster",
        "abstract": "Hamilton-Jacobi (HJ) reachability analysis is a powerful tool for analyzing the safety of autonomous systems. However, the provided safety assurances are often predicated on the assumption that once deployed, the system or its environment does not evolve. Online, however, an autonomous system might experience changes in system dynamics, control authority, external disturbances, and/or the surrounding environment, requiring updated safety assurances. Rather than restarting the safety analysis from scratch, which can be timeconsuming and often intractable to perform online, we propose to compute parameter-conditioned reachable sets. Assuming expected system and environment changes can be parameterized, we treat these parameters as virtual states in the system and leverage recent advances in high-dimensional reachability analysis to solve the corresponding reachability problem offline. This results in a family of reachable sets that is parameterized by the environment and system factors. Online, as these factors change, the system can simply query the corresponding safety function from this family to ensure system safety, enabling a real-time update of the safety assurances. Through various simulation studies, we demonstrate the capability of our approach in maintaining system safety despite the system and environment evolution.",
        "primary_area": "",
        "author": "Javier Borquez;Kensuke Nakamura;Somil Bansal;Javier Borquez;Kensuke Nakamura;Somil Bansal",
        "authorids": "/37086329514;/37086961952;/37085404900;/37086329514;/37086961952;/37085404900",
        "aff": "ECE department, University of Southern California; MAE department, Princeton University; ECE department, University of Southern California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160554/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10994281426626674253&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Southern California;Princeton University",
        "aff_unique_dep": "ECE department;MAE department",
        "aff_unique_url": "https://www.usc.edu;https://www.princeton.edu",
        "aff_unique_abbr": "USC;Princeton",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160922",
        "title": "Passive robotic gripper using a contact-based locking mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic end-effectors have been developed for various applications. Most of them are driven by electric or pneumatic actuator/actuators, which usually make the end-effector bulky and vulnerable due to the external cables and air tubes. In this study, we propose a novel passive robotic gripper with a locking mechanism that does not require any actuators. Locking and unlocking of the gripper fingers are performed through contact with external environment, such as ground, table, and conveyor. To facilitate gripper design, modeling of the deformed finger shape was conducted, and experimental validation was performed. A robotic gripper with eight such passive fingers were fabricated using 3D printer. Experiments were conducted to investigate the grasping capacities in terms of object size and weight. We found that the larger the object, the greater the weight capacity of the gripper, which increased significantly when the object exceeded a certain size. In addition, experiments on grasping various food products were carried out and results suggested that the proposed gripper could grasp objects with complex shapes and soft fragile properties, but damages were caused on very fragile objects due to the rigid structure of the gripper.",
        "primary_area": "",
        "author": "Issei Nate;Zhongkui Wang;Shinichi Hirai;Issei Nate;Zhongkui Wang;Shinichi Hirai",
        "authorids": "/37089504977;/37404934700;/37280572900;/37089504977;/37404934700;/37280572900",
        "aff": "Department of Robotics, Soft Robotics Laboratory, Ritsumeikan University, Shiga, Japan; Department of Robotics, Cloud Robotics Laboratory, Ritsumeikan University, Shiga, Japan; Department of Robotics, Soft Robotics Laboratory, Ritsumeikan University, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160922/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3712024608826893482&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shiga",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160334",
        "title": "Passivity-based Decentralized Control for Collaborative Grasping of Under-Actuated Aerial Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a decentralized passive impedance control scheme for collaborative grasping using under-actuated aerial manipulators (AMs). The AM system is formulated, using a proper coordinate transformation, as an inertially decoupled dynamics with which a passivity-based control design is conducted. Since the interaction for grasping can be interpreted as a feedback interconnection of passive systems, an arbitrary number of AMs can be modularly combined, leading to a decentralized control scheme. Another interesting consequence of the passivity property is that the AMs automatically converge to a certain configuration to accomplish the grasping. Collaborative grasping using 10 AMs is presented in simulation.",
        "primary_area": "",
        "author": "Jinyeong Jeong;Min Jun Kim;Jinyeong Jeong;Min Jun Kim",
        "authorids": "/37088568071;/38239144100;/37088568071;/38239144100",
        "aff": "Intelligent Robotic Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Intelligent Robotic Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160334/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2567047759910729010&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Intelligent Robotic Systems Laboratory",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160524",
        "title": "Path Planning Under Uncertainty to Localize mmWave Sources",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study a navigation problem where a mobile robot needs to locate a mmWave wireless signal. Using the directionality properties of the signal, we propose an estimation and path planning algorithm that can efficiently navigate in cluttered indoor environments. We formulate Extended Kalman filters for emitter location estimation in cases where the signal is received in line-of-sight or after reflections. We then propose to plan motion trajectories based on belief-space dynamics in order to minimize the uncertainty of the position estimates. The associated non-linear optimization problem is solved by a state-of-the-art constrained iLQR solver. In particular, we propose a method that can handle a large number of obstacles (\u223c 300) with reasonable computation times. We validate the approach in an extensive set of simulations. We show that our estimators can help increase navigation success rate and that planning to reduce estimation uncertainty can improve the overall task completion speed.",
        "primary_area": "",
        "author": "Kai Pfeiffer;Yuze Jia;Mingsheng Yin;Akshaj Kumar Veldanda;Yaqi Hu;Amee Trivedi;Jeff Zhang;Siddharth Garg;Elza Erkip;Sundeep Rangan;Ludovic Righetti;Kai Pfeiffer;Yuze Jia;Mingsheng Yin;Akshaj Kumar Veldanda;Yaqi Hu;Amee Trivedi;Jeff Zhang;Siddharth Garg;Elza Erkip;Sundeep Rangan;Ludovic Righetti",
        "authorids": "/37679306000;/37089893505;/37088834173;/37089242707;/37089401283;/37089340574;/37086579229;/37289176300;/37266656500;/38516986200;/37295828600;/37679306000;/37089893505;/37088834173;/37089242707;/37089401283;/37089340574;/37086579229;/37289176300;/37266656500;/38516986200;/37295828600",
        "aff": "Schaffler Hub for Advanced Research at NTU and School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; Tandon School of Engineering, New York University, New York, USA; Tandon School of Engineering, New York University, New York, USA; Tandon School of Engineering, New York University, New York, USA; Tandon School of Engineering, New York University, New York, USA; University of British Columbia, Vancouver, BC, Canada; Harvard University, Cambridge, MA, USA; Tandon School of Engineering, New York University, New York, USA; Tandon School of Engineering, New York University, New York, USA; Tandon School of Engineering, New York University, New York, USA; Tandon School of Engineering, New York University, New York, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160524/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16263197447428799058&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;1;1;1;1;2;3;1;1;1;1",
        "aff_unique_norm": "Nanyang Technological University;New York University;University of British Columbia;Harvard University",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering;Tandon School of Engineering;;",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.nyu.edu;https://www.ubc.ca;https://www.harvard.edu",
        "aff_unique_abbr": "NTU;NYU;UBC;Harvard",
        "aff_campus_unique_index": "1;1;1;1;2;3;1;1;1;1",
        "aff_campus_unique": ";New York;Vancouver;Cambridge",
        "aff_country_unique_index": "0;1;1;1;1;2;1;1;1;1;1",
        "aff_country_unique": "Singapore;United States;Canada"
    },
    {
        "id": "10161318",
        "title": "PedFormer: Pedestrian Behavior Prediction via Cross-Modal Attention Modulation and Gated Multitask Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting pedestrian behavior is a crucial task for intelligent driving systems. Accurate predictions require a deep understanding of various contextual elements that could impact the way pedestrians behave. To address this challenge, we propose a novel framework that relies on different data modalities to predict future trajectories and crossing actions of pedestrians from an egocentric perspective. Specifically, our model utilizes a cross-modal Transformer architecture to capture dependencies between different data types. The output of the Transformer is augmented with representations of interactions between pedestrians and other traffic agents conditioned on the pedestrian and ego-vehicle dynamics that are generated via a semantic attentive interaction module. Lastly, the context encodings are fed into a multi-stream decoder framework using a gated-shared network. We evaluate our algorithm on public pedestrian behavior benchmarks, PIE and JAAD, and show that our model improves state-of-the-art in trajectory and action prediction by up to 22% and 13% respectively on various metrics. The advantages of the proposed components are investigated via extensive ablation studies.",
        "primary_area": "",
        "author": "Amir Rasouli;Iuliia Kotseruba;Amir Rasouli;Iuliia Kotseruba",
        "authorids": "/37086037019;/37086031537;/37086037019;/37086031537",
        "aff": "Noah's Ark Laboratory, Huawei, Canada; Department of Computer Science and Electrical Engineering, York University, Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161318/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1807720813533235064&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Huawei;York University",
        "aff_unique_dep": "Noah's Ark Laboratory;Department of Computer Science and Electrical Engineering",
        "aff_unique_url": "https://www.huawei.com;https://www.yorku.ca",
        "aff_unique_abbr": "Huawei;York U",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160273",
        "title": "Pedestrian Crossing Action Recognition and Trajectory Prediction with 3D Human Keypoints",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate understanding and prediction of human behaviors are critical prerequisites for autonomous vehicles, especially in highly dynamic and interactive scenarios such as intersections in dense urban areas. In this work, we aim at identifying crossing pedestrians and predicting their future trajectories. To achieve these goals, we not only need the context information of road geometry and other traffic participants but also need fine-grained information of the human pose, motion and activity, which can be inferred from human keypoints. In this paper, we propose a novel multi-task learning framework for pedestrian crossing action recognition and trajectory pre-diction, which utilizes 3D human keypoints extracted from raw sensor data to capture rich information on human pose and activity. Moreover, we propose to apply two auxiliary tasks and contrastive learning to enable auxiliary supervisions to improve the learned keypoints representation, which further enhances the performance of major tasks. We validate our approach on a large-scale in-house dataset, as well as a public benchmark dataset, and show that our approach achieves state-of-the-art performance on a wide range of evaluation metrics. The effectiveness of each model component is validated in a detailed ablation study.",
        "primary_area": "",
        "author": "Jiachen Li;Xinwei Shi;Feiyu Chen;Jonathan Stroud;Zhishuai Zhang;Tian Lan;Junhua Mao;Jeonhyung Kang;Khaled S. Refaat;Weilong Yang;Eugene Ie;Congcong Li;Jiachen Li;Xinwei Shi;Feiyu Chen;Jonathan Stroud;Zhishuai Zhang;Tian Lan;Junhua Mao;Jeonhyung Kang;Khaled S. Refaat;Weilong Yang;Eugene Ie;Congcong Li",
        "authorids": "/37086309095;/37089499463;/37089893635;/37086433941;/37086290920;/37089893378;/37088458829;/37089894672;/37540952100;/37089895934;/38031199100;/37088454829;/37086309095;/37089499463;/37089893635;/37086433941;/37086290920;/37089893378;/37088458829;/37089894672;/37540952100;/37089895934;/38031199100;/37088454829",
        "aff": "Stanford University; Waymo; Waymo; Waymo; Waymo; Waymo; Waymo; Waymo; Waymo; Waymo; Waymo; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160273/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10194031626180564915&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;1;1;1;1;1;1;1;1;1;1;0",
        "aff_unique_norm": "Stanford University;Waymo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.waymo.com",
        "aff_unique_abbr": "Stanford;Waymo",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160338",
        "title": "Perceiving Unseen 3D Objects by Poking the Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel approach to interactive 3D object perception for robots. Unlike previous perception algorithms that rely on known object models or a large amount of annotated training data, we propose a poking-based approach that automatically discovers and reconstructs 3D objects. The poking process not only enables the robot to discover unseen 3D objects but also produces multi-view observations for 3D reconstruction of the objects. The reconstructed objects are then memorized by neural networks with regular supervised learning and can be recognized in new test images. The experiments on real-world data show that our approach could unsupervisedly discover and reconstruct unseen 3D objects with high quality, and facilitate real-world applications such as robotic grasping. The code and supplementary materials are available at the project page: https://zju3dv.github.io/poking_perception/.",
        "primary_area": "",
        "author": "Linghao Chen;Yunzhou Song;Hujun Bao;Xiaowei Zhou;Linghao Chen;Yunzhou Song;Hujun Bao;Xiaowei Zhou",
        "authorids": "/37088457247;/37089892573;/37271755400;/37087235480;/37088457247;/37089892573;/37271755400;/37087235480",
        "aff": "State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160338/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18198797229104989242&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Lab of CAD&CG",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160348",
        "title": "Performance Evaluation of 3D Keypoint Detectors and Descriptors on Coloured Point Clouds in Subsea Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent development of high-precision subsea optical scanners allows for 3D keypoint detectors and feature descriptors to be leveraged on point cloud scans from subsea environments. However, the literature lacks a comprehensive survey to identify the best combination of detectors and descriptors to be used in these challenging and novel environments. This paper aims to identify the best detector/descriptor pair using a challenging field dataset collected using a commercial underwater laser scanner. Furthermore, studies have shown that incorporating texture information to extend geometric features adds robustness to feature matching on synthetic datasets. This paper also proposes a novel method of fusing images with underwater laser scans to produce coloured point clouds, which are used to study the effectiveness of 6D point cloud descriptors.",
        "primary_area": "",
        "author": "Kyungmin Jung;Thomas Hitchcox;James Richard Forbes;Kyungmin Jung;Thomas Hitchcox;James Richard Forbes",
        "authorids": "/37089891846;/37088569552;/37543396800;/37089891846;/37088569552;/37543396800",
        "aff": "department of Mechanical Engineering, McGill University, Montreal, QC, Canada; department of Mechanical Engineering, McGill University, Montreal, QC, Canada; department of Mechanical Engineering, McGill University, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160348/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14229906141987896911&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161169",
        "title": "Perturbation-Based Best Arm Identification for Efficient Task Planning with Monte-Carlo Tree Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Combining task and motion planning (TAMP) is crucial for intelligent robots to perform complex and long-horizon tasks. In TAMP, many approaches generally employ Monte-Carlo tree search (MCTS) with upper confidence bound (UCB) for task planning to handle exploration-exploitation trade-off and find globally optimal solutions. However, since UCB basically considers the estimation error caused by noise, the error caused by insufficient optimization of the sub-tree is not represented. Hence, UCB-based approaches have the disadvantage of not exploring underestimated sub-trees. To alleviate this issue, we propose a novel tree search method using perturbation-based best-arm identification (PBAI). We theoretically prove the bound of the simple regret of our method and empirically verify that PBAI finds the optimal task plans faster and more efficiently than the existing algorithms. The source code of our proposed algorithm is available at https://github.com/jdj2261/pytamp.",
        "primary_area": "",
        "author": "Daejong Jin;Juhan Park;Kyungjae Lee;Daejong Jin;Juhan Park;Kyungjae Lee",
        "authorids": "/37089894300;/37089892737;/493655068209513;/37089894300;/37089892737;/493655068209513",
        "aff": "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea; Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea; Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161169/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6941331993659950760&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chung-Ang University",
        "aff_unique_dep": "Department of Artificial Intelligence",
        "aff_unique_url": "http://www.cau.ac.kr",
        "aff_unique_abbr": "CAU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160736",
        "title": "Pick2Place: Task-aware 6DoF Grasp Estimation via Object-Centric Perspective Affordance",
        "track": "main",
        "status": "Poster",
        "abstract": "The choice of a grasp plays a critical role in the success of downstream manipulation tasks. Consider a task of placing an object in a cluttered scene; the majority of possible grasps may not be suitable for the desired placement. In this paper, we study the synergy between the picking and placing of an object in a cluttered scene to develop an algorithm for task-aware grasp estimation. We present an object-centric action space that encodes the relationship between the geometry of the placement scene and the object to be placed in order to provide placement affordance maps directly from perspective views of the placement scene. This action space enables the computation of a one-to-one mapping between the placement and picking actions allowing the robot to generate a diverse set of pick-and-place proposals and to optimize for a grasp under other task constraints such as robot kinematics and collision avoidance. With experiments both in simulation and on a real robot we demonstrate that with our method, the robot is able to successfully complete the task of placement-aware grasping with over 89 % accuracy in such a way that generalizes to novel objects and scenes.",
        "primary_area": "",
        "author": "Zhanpeng He;Nikhil Chavan-Dafle;Jinwook Huh;Shuran Song;Volkan Isler;Zhanpeng He;Nikhil Chavan-Dafle;Jinwook Huh;Shuran Song;Volkan Isler",
        "authorids": "/37088687305;/37085487604;/37085775953;/37085613509;/37298487800;/37088687305;/37085487604;/37085775953;/37085613509;/37298487800",
        "aff": "Samsung AI Center, New York, NY; Samsung AI Center, New York, NY; Samsung AI Center, New York, NY; Samsung AI Center, New York, NY; Samsung AI Center, New York, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160736/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17224842821945757927&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Samsung AI Center",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160404",
        "title": "Picking by Tilting: In-Hand Manipulation for Object Picking using Effector with Curved Form",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a robotic in-hand manipulation technique that can be applied to pick an object too large to grasp in a prehensile manner, by taking advantage of its contact interactions with a curved, passive end-effector, and two flat support surfaces. First, the object is tilted up while being held between the end-effector and the supports. Then, the end-effector is tucked into the gap underneath the object, which is formed by tilting, in order to obtain a grasp against gravity. In this paper, we first examine the mechanics of tilting to understand the different ways in which the object can be initially tilted. We then present a strategy to tilt up the object in a secure manner. Finally, we demonstrate successful picking of objects of various size and geometry using our technique through a set of experiments performed with a custom-made robotic device and a conventional robot arm. Our experiment results show that object picking can be performed reliably with our method using simple hardware and control, and when possible, with appropriate fixture design.",
        "primary_area": "",
        "author": "Yanshu Song;Abdullah Nazir;Darwin Lau;Yun\u2013Hui Liu;Yanshu Song;Abdullah Nazir;Darwin Lau;Yun\u2013Hui Liu",
        "authorids": "/37089892628;/37086938255;/37075801900;/37279412600;/37089892628;/37086938255;/37075801900;/37279412600",
        "aff": "The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160404/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Ba35Mmo3MfAJ:scholar.google.com/&scioq=Picking+by+Tilting:+In-Hand+Manipulation+for+Object+Picking+using+Effector+with+Curved+Form&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160506",
        "title": "Place Recognition under Occlusion and Changing Appearance via Disentangled Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition is a critical and challenging task for mobile robots, aiming to retrieve an image captured at the same place as a query image from a database. Existing methods tend to fail while robots move autonomously under occlusion (e.g., car, bus, truck) and changing appearance (e.g., illumination changes, seasonal variation). Because they encode the image into only one code, entangling place features with appearance and occlusion features. To overcome this limitation, we propose PROCA, an unsupervised approach to decompose the image representation into three codes: a place code used as a descriptor to retrieve images, an appearance code that captures appearance properties, and an occlusion code that encodes occlusion content. Extensive experiments show that our model outperforms the state-of-the-art methods. Our code and data are available at https://github.com/rover-xingyu/PROCA.",
        "primary_area": "",
        "author": "Yue Chen;Xingyu Chen;Yicen Li;Yue Chen;Xingyu Chen;Yicen Li",
        "authorids": "/37089542444;/37085568094;/37089892140;/37089542444;/37085568094;/37089892140",
        "aff": "Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; McMaster University, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160506/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:AnF6P_XZW5wJ:scholar.google.com/&scioq=Place+Recognition+under+Occlusion+and+Changing+Appearance+via+Disentangled+Representations&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Xi'an Jiaotong University;McMaster University",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://en.xjtu.edu.cn/;https://www.mcmaster.ca",
        "aff_unique_abbr": "XJTU;McMaster",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "10160424",
        "title": "Planning Assembly Sequence with Graph Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "Assembly Sequence Planning (ASP) is the essential process for modern manufacturing, proven to be NP-complete thus its effective and efficient solution has been a challenge for researchers in the field. In this paper, we present a graph-transformer based framework for the ASP problem which is trained and demonstrated on a self-collected ASP database. The ASP database contains a self-collected set of LEGO models. The LEGO model is abstracted to a heterogeneous graph structure after a thorough analysis of the original structure and feature extraction. The ground truth assembly sequence is first generated by brute-force search and then adjusted manually to be in line with human rational habits. Based on this self-collected ASP dataset, we propose a heterogeneous graph-transformer framework to learn the latent rules for assembly planning. We evaluated the proposed framework in a series of experiments. The results show that the similarity of the predicted and ground truth sequences can reach 0.44, a medium correlation measured by Kendall's \u03c4. Meanwhile, we compared the different effects of node features and edge features and generated a feasible and reasonable assembly sequence as a benchmark for further research. Our dataset and code are available on: htps://github.com/AIR-DISCOVER/ICRA_ASP.",
        "primary_area": "",
        "author": "Lin Ma;Jiangtao Gong;Hao Xu;Hao Chen;Hao Zhao;Wenbing Huang;Guyue Zhou;Lin Ma;Jiangtao Gong;Hao Xu;Hao Chen;Hao Zhao;Wenbing Huang;Guyue Zhou",
        "authorids": "/37089894295;/37089661527;/37089450837;/37089892527;/37086217629;/37085481327;/37085489402;/37089894295;/37089661527;/37089450837;/37089892527;/37086217629;/37085481327;/37085489402",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R. China; Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R. China; Qianzhi Technology, China; Qianzhi Technology, China; Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R. China; Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R. China; Institute for AI Industry Research (AIR), Tsinghua University, Beijing, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160424/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=827261804709029264&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;0;0;0",
        "aff_unique_norm": "Tsinghua University;Qianzhi Technology",
        "aff_unique_dep": "Institute for AI Industry Research (AIR);",
        "aff_unique_url": "https://www.tsinghua.edu.cn;",
        "aff_unique_abbr": "Tsinghua;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161006",
        "title": "Planning for Complex Non-prehensile Manipulation Among Movable Objects by Interleaving Multi-Agent Pathfinding and Physics-Based Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-world manipulation problems in heavy clutter require robots to reason about potential contacts with objects in the environment. We focus on pick-and-place style tasks to retrieve a target object from a shelf where some \u2018movable\u2019 objects must be rearranged in order to solve the task. In particular, our motivation is to allow the robot to reason over and consider non-prehensile rearrangement actions that lead to complex robot-object and object-object interactions where multiple objects might be moved by the robot simultaneously, and objects might tilt, lean on each other, or topple. To support this, we query a physics-based simulator to forward simulate these interaction dynamics which makes action evaluation during planning computationally very expensive. To make the planner tractable, we establish a connection between the domain of Manipulation Among Movable Objects and Multi-Agent Pathfinding that lets us decompose the problem into two phases our M4M algorithm iterates over. First we solve a multi-agent planning problem that reasons about the configurations of movable objects but does not forward simulate a physics model. Next, an arm motion planning problem is solved that uses a physics-based simulator but does not search over possible configurations of movable objects. We run simulated and real-world experiments with the PR2 robot and compare against relevant baseline algorithms. Our results highlight that M4M generates complex 3D interactions, and solves at least twice as many problems as the baselines with competitive performance.",
        "primary_area": "",
        "author": "Dhruv Mauria Saxena;Maxim Likhachev;Dhruv Mauria Saxena;Maxim Likhachev",
        "authorids": "/37086188218;/37309318800;/37086188218;/37309318800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161006/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12367408820600299285&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161204",
        "title": "Planning for Multi-Object Manipulation with Graph Neural Network Relational Classifiers",
        "track": "main",
        "status": "Poster",
        "abstract": "Objects rarely sit in isolation in human environments. As such, we'd like our robots to reason about how multiple objects relate to one another and how those relations may change as the robot interacts with the world. To this end, we propose a novel graph neural network framework for multi-object manipulation to predict how inter-object relations change given robot actions. Our model operates on partial-view point clouds and can reason about multiple objects dynamically interacting during the manipulation, By learning a dynamics model in a learned latent graph embedding space, our model enables multi-step planning to reach target goal relations. We show our model trained purely in simulation transfers well to the real world. Our planner enables the robot to rearrange a variable number of objects with a range of shapes and sizes using both push and pick-and-place skills.",
        "primary_area": "",
        "author": "Yixuan Huang;Adam Conkey;Tucker Hermans;Yixuan Huang;Adam Conkey;Tucker Hermans",
        "authorids": "/37089225909;/37088340960;/38230909600;/37089225909;/37088340960;/38230909600",
        "aff": "University of Utah; University of Utah; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161204/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11409273517334625780&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Utah;NVIDIA Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utah.edu;https://www.nvidia.com",
        "aff_unique_abbr": "Utah;NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160604",
        "title": "Planning with Occluded Traffic Agents using Bi-Level Variational Occlusion Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Reasoning with occluded traffic agents is a significant open challenge for planning for autonomous vehicles. Recent deep learning models have shown impressive results for predicting occluded agents based on the behaviour of nearby visible agents; however, as we show in experiments, these models are difficult to integrate into downstream planning. To this end, we propose Bi-Ievel Variational Occlusion Models (BiVO), a two-step generative model that first predicts likely locations of occluded agents, and then generates likely trajectories for the occluded agents. In contrast to existing methods, BiVO outputs a trajectory distribution which can then be sampled from and integrated into standard downstream planning. We evaluate the method in closed-loop replay simulation using the real-world nuScenes dataset. Our results suggest that BiVO can successfully learn to predict occluded agent trajectories, and these predictions lead to better subsequent motion plans in critical scenarios.",
        "primary_area": "",
        "author": "Filippos Christianos;Peter Karkus;Boris Ivanovic;Stefano V. Albrecht;Marco Pavone;Filippos Christianos;Peter Karkus;Boris Ivanovic;Stefano V. Albrecht;Marco Pavone",
        "authorids": "/37089893146;/37085591628;/37086527859;/37088996736;/37307912900;/37089893146;/37085591628;/37086527859;/37088996736;/37307912900",
        "aff": "School of Informatics, University of Edinburgh.; NVIDIA Research, NVIDIAz, Santa Clara, CA.; NVIDIA Research, NVIDIAz, Santa Clara, CA.; School of Informatics, University of Edinburgh.; Department of Aeronautics and Astronautics, Stanford University.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160604/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2788880983159496232&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;2",
        "aff_unique_norm": "University of Edinburgh;NVIDIA;Stanford University",
        "aff_unique_dep": "School of Informatics;NVIDIA Research;Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.nvidia.com/research;https://www.stanford.edu",
        "aff_unique_abbr": "Edinburgh;NVIDIA;Stanford",
        "aff_campus_unique_index": "0;1;1;0;2",
        "aff_campus_unique": "Edinburgh;Santa Clara;Stanford",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "10160897",
        "title": "Planning with SiMBA: Motion Planning under Uncertainty for Temporal Goals using Simplified Belief Guides",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new multi-layered algorithm for motion planning under motion and sensing uncertainties for Linear Temporal Logic specifications. We propose a technique to guide a sampling-based search tree in the combined task and belief space using trajectories from a simplified model of the system, to make the problem computationally tractable. Our method eliminates the need to construct fine and accurate finite abstractions. We prove correctness and probabilistic completeness of our algorithm, and illustrate the benefits of our approach on several case studies. Our results show that guidance with a simplified belief space model allows for significant speed-up in planning for complex specifications.",
        "primary_area": "",
        "author": "Qi Heng Ho;Zachary N. Sunberg;Morteza Lahijanian;Qi Heng Ho;Zachary N. Sunberg;Morteza Lahijanian",
        "authorids": "/37087321977;/38488385500;/37398443600;/37087321977;/38488385500;/37398443600",
        "aff": "department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160897/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5712993762635039478&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160225",
        "title": "PointCloudLab: An Environment for 3D Point Cloud Annotation with Adapted Visual Aids and Levels of Immersion",
        "track": "main",
        "status": "Poster",
        "abstract": "The annotation of 3D point cloud datasets is an expensive and tedious task. To optimize the annotation process, recent works have proposed the use of environments with higher levels of immersion in combination with different types of visual aids. However, two problems remain unresolved. First, the proposed environments limit the user to a unique level of immersion and a fixed hardware setup. Second, their design overlooks the interaction effects between the level of immersion and the visual aids on the quality of the annotation process. To address these issues, we propose PointCloudLab, an environment for 3D point cloud annotation that allows the use of different levels of immersion that work in combination with visual aids. Using PointCloudLab, we conducted a controlled experiment (N=20) to investigate the effects of levels of immersion and visual aids on the annotation process. Our findings reveal that higher levels of immersion combined with object-based visual aids lead to a faster and more accurate annotation. Furthermore, we found significant interaction effects between the levels of immersion and the visual aids on the accuracy of the annotation.",
        "primary_area": "",
        "author": "Achref Doula;Tobias G\u00fcdelh\u00f6fer;Andrii Matviienko;Max M\u00fchlh\u00e4user;Alejandro Sanchez Guinea;Achref Doula;Tobias G\u00fcdelh\u00f6fer;Andrii Matviienko;Max M\u00fchlh\u00e4user;Alejandro Sanchez Guinea",
        "authorids": "/37089365525;/37089891947;/37089895932;/37328724600;/37085558091;/37089365525;/37089891947;/37089895932;/37328724600;/37085558091",
        "aff": "Telecooperation Lab, Technical University of Darmstadt, Germany; Telecooperation Lab, Technical University of Darmstadt, Germany; Media Technology and Interaction Design, KTH Royal Institute of Technology, Sweden; Telecooperation Lab, Technical University of Darmstadt, Germany; Telecooperation Lab, Technical University of Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160225/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4682857976168512758&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Technical University of Darmstadt;KTH Royal Institute of Technology",
        "aff_unique_dep": "Telecooperation Lab;Media Technology and Interaction Design",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.kth.se",
        "aff_unique_abbr": "TUD;KTH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Germany;Sweden"
    },
    {
        "id": "10161109",
        "title": "Policy-Guided Lazy Search with Feedback for Task and Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "PDDLStream solvers have recently emerged as viable solutions for Task and Motion Planning (TAMP) problems, extending PDDL to problems with continuous action spaces. Prior work has shown how PDDLStream problems can be reduced to a sequence of PDDL planning problems, which can then be solved using off-the-shelf planners. However, this approach can suffer from long runtimes. In this paper we propose LAZY, a solver for PDDLStream problems that maintains a single integrated search over action skeletons, which gets progressively more geometrically informed, as samples of possible motions are lazily drawn during motion planning. We explore how learned models of goal-directed policies and current motion sampling data can be incorporated in LAZY to adaptively guide the task planner. We show that this leads to significant speed-ups in the search for a feasible solution evaluated over unseen test environments of varying numbers of objects, goals, and initial conditions. We evaluate our TAMP approach by comparing to existing solvers for PDDLStream problems on a range of simulated 7DoF rearrangement/manipulation problems. Code can be found at https://rvl.cs.toronto.edu/learning-based-tamp.",
        "primary_area": "",
        "author": "Mohamed Khodeir;Atharv Sonwane;Ruthrash Hari;Florian Shkurti;Mohamed Khodeir;Atharv Sonwane;Ruthrash Hari;Florian Shkurti",
        "authorids": "/37089742951;/37089893802;/37089662016;/37706697200;/37089742951;/37089893802;/37089662016;/37706697200",
        "aff": "Robot Vision and Learning Lab, University of Toronto Robotics Institute; Dept. of Computer Science, University of BITS Pilani; Dept. of Mathematical and Computational Sciences, University of Toronto; Robot Vision and Learning Lab, University of Toronto Robotics Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161109/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9017758943202268035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Toronto;University of BITS Pilani",
        "aff_unique_dep": "Robotics Institute;Dept. of Computer Science",
        "aff_unique_url": "https://www.utoronto.ca;https://www.bits-pilani.ac.in",
        "aff_unique_abbr": "U of T;BITS Pilani",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Canada;India"
    },
    {
        "id": "10160957",
        "title": "Portable Multi-Hypothesis Monte Carlo Localization for Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-localization is a fundamental capability that mobile robot navigation systems integrate to move from one point to another using a map. Thus, any enhancement in localization accuracy is crucial to perform delicate dexterity tasks. This paper describes a new localization algorithm that maintains several populations of particles using the Monte Carlo Localization (MCL) algorithm, always choosing the best one as the system's output. As novelties, our work includes a multi-scale map-matching algorithm to create new MCL populations and a metric to determine the most reliable. It also contributes the state of the art implementations, enhancing recovery times from erroneous estimates or unknown initial positions. The proposed method is evaluated in ROS2 in a module fully integrated with Nav2 and compared with the current state-of-the-art Adaptive AMCL solution, obtaining good accuracy/recovery times.",
        "primary_area": "",
        "author": "Alberto Garc\u00eda;Francisco Mart\u00edn;Jos\u00e9 Miguel Guerrero;Francisco J. Rodr\u00edguez;Vicente Matell\u00e1n;Alberto Garc\u00eda;Francisco Mart\u00edn;Jos\u00e9 Miguel Guerrero;Francisco J. Rodr\u00edguez;Vicente Matell\u00e1n",
        "authorids": "/37089894196;/37292303000;/37089893965;/37080860300;/37296887900;/37089894196;/37292303000;/37089893965;/37080860300;/37296887900",
        "aff": "Intelligent Robotics Lab, Rey Juan Carlos University; Intelligent Robotics Lab, Rey Juan Carlos University; Intelligent Robotics Lab, Rey Juan Carlos University; Robotics group, Universidad de Le\u00f3n; Robotics group, Universidad de Le\u00f3n",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160957/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6725431632396917469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Rey Juan Carlos University;Universidad de Le\u00f3n",
        "aff_unique_dep": "Intelligent Robotics Lab;Robotics group",
        "aff_unique_url": "https://www.urjc.es;https://www.unileon.es",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10161123",
        "title": "Pose Quality Prediction for Vision Guided Robotic Shoulder Arthroplasty",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical assistive robots offer the potential for drastically improved patient outcomes through more accurate, more repeatable surgical procedures like shoulder arthroplasty operations. Existing robotic systems typically rely on optical marker tracking and require invasive marker attachment for localization, complicating the surgical workflow and patient recovery. But moving towards a markerless system is very challenging, both because of the absolute difficulty and the large variation in localization conditions across thousands of surgical procedures. In this paper we propose an alternative approach: rather than try to create a \u201cperfect\u201d and fully generalizable markerless localization system, instead create a reliable and trustworthy localization system that is able to continually self-assess the likely quality of its localization esti-mates, and act accordingly. We propose a lightweight method for predicting vision-based pose estimation performance using internal pipeline artifacts (without needing external ground truth from a marker-based system). Using extensive real robot experiments with challenging actual imagery from surgery, we demonstrate our prediction system accurately self-characterizes the localization system's performance across a wide range of localization conditions, and demonstrate that this prediction system generalizes to a range of surgical conditions. We then show how online performance prediction can drive active robot navigation that minimizes localization error, reducing target pose estimation error by 96.1% for rotation and 96.7% for translation compared to rejected alternative trajectories.",
        "primary_area": "",
        "author": "Morgan Windsor;Jing Peng;Ashish Gupta;Peter Pivonka;Michael J Milford;Morgan Windsor;Jing Peng;Ashish Gupta;Peter Pivonka;Michael J Milford",
        "authorids": "/37089893369;/37089892222;/37089917998;/37062354800;/37283633100;/37089893369;/37089892222;/37089917998;/37062354800;/37283633100",
        "aff": "QUT Centre for Robotics, School of Electrical Engineering and Robotics at the Queensland University of Technology; QUT Centre for Robotics, School of Electrical Engineering and Robotics at the Queensland University of Technology; Queensland Unit for Advanced Shoulder Research and Greenslopes Private Hospital, Brisbane, QLD, Australia; QUT Centre for Biomedical Technologies, School of Mechanical, Medical, and Process Engineering at the Queensland University of Technology; QUT Centre for Robotics, School of Electrical Engineering and Robotics at the Queensland University of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161123/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16530831186338164281&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Queensland University of Technology;Queensland Unit for Advanced Shoulder Research",
        "aff_unique_dep": "School of Electrical Engineering and Robotics;Shoulder Research",
        "aff_unique_url": "https://www.qut.edu.au;",
        "aff_unique_abbr": "QUT;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Brisbane",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10161259",
        "title": "Pose Relation Transformer Refine Occlusions for Human Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately estimating the human pose is an essential task for many applications in robotics. However, existing pose estimation methods suffer from poor performance when occlusion occurs. Recent advances in NLP have been very successful in predicting the missing words conditioned on visible words. We draw upon the sentence completion analogy in NLP to guide our model to address occlusions in the pose estimation problem. We propose a novel approach that can mitigate the effect of occlusions motivated by the sentence completion task of NLP. In an analogous manner, we designed our model to reconstruct occluded joints given the visible joints utilizing joint correlations by capturing the implicit joint connectivity through the attention mechanism. In this work, we propose a POse Relation Transformer (PORT) that captures the global context of the pose using self-attention and a local context by aggregating adjacent joint features. To supervise PORT in learning joint correlations, we guide PORT to reconstruct randomly masked joints, which we call Masked Joint Modeling (MJM). PORT trained with MJM adds to existing keypoint detection methods and successfully refines occlusions. Notably, PORT is a model-agnostic plug-and-play module for pose refinement under occlusion that can be plugged into any keypoint detector with substantially low computational costs. We conducted extensive experiments to demonstrate the advantage of PORT mitigating the occlusion on the hand and body pose PORT improves the pose estimation accuracy of existing human pose estimation methods by up to 16% with only 5% of additional parameters. The code is publicly available at https://github.com/stnoah1/PORT.",
        "primary_area": "",
        "author": "Hyung-gun Chi;Seunggeun Chi;Stanley Chan;Karthik Ramani;Hyung-gun Chi;Seunggeun Chi;Stanley Chan;Karthik Ramani",
        "authorids": "/37089537979;/37089538662;/37600910000;/37283359200;/37089537979;/37089538662;/37600910000;/37283359200",
        "aff": "School of Electrical and Computer Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161259/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15798768960482433829&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161265",
        "title": "Pose-graph SLAM Using Multi-order Ultrasonic Echoes and Beamforming for Long-range Inspection Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a Graph-based Simultaneous Localization And Mapping (GraphSLAM) approach for a robotic system relying on the reflections of ultrasonic guided waves to enable long-range inspection tasks on plate-based metal structures. A measurement model that can leverage multi-order acoustic echoes is introduced for accurate localization, and beamforming is used for mapping the boundaries of individual metal panels. These two elements are subsequently integrated within a nonlinear least squares optimizer to solve the full offline SLAM problem. We experimentally evaluate the potential of this approach in a laboratory environment. We observe the improved localization accuracy of the multi-order echo model compared to a second model, from previous works, that relies solely on first-order echoes. We also show that the proposed approach can yield accurate SLAM results, hence showcasing the standalone capability of ultrasonic-based GraphSLAM for envisioned long-range inspection applications.",
        "primary_area": "",
        "author": "Othmane-Latif Ouabi;Neil Zeghidour;Nico F. Declercq;Matthieu Geist;C\u00e9dric Pradalier;Othmane-Latif Ouabi;Neil Zeghidour;Nico F. Declercq;Matthieu Geist;C\u00e9dric Pradalier",
        "authorids": "/37088587191;/37085809113;/37271297700;/37643800600;/37279005400;/37088587191;/37085809113;/37271297700;/37643800600;/37279005400",
        "aff": "GeorgiaTech Lorraine and the IRL2958 GT-CNRS, Metz, France; Google Research, Brain Team; Georgia Institute of Technology, Atlanta, GA, USA; Google Research, Brain Team; GeorgiaTech Lorraine and the IRL2958 GT-CNRS, Metz, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161265/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5421910785430439355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Georgia Tech Lorraine;Google;Georgia Institute of Technology",
        "aff_unique_dep": ";Google Research;",
        "aff_unique_url": "https://lorraine.gatech.edu;https://research.google;https://www.gatech.edu",
        "aff_unique_abbr": "GT Lorraine;Google;Georgia Tech",
        "aff_campus_unique_index": "0;1;2;1;0",
        "aff_campus_unique": "Lorraine;Mountain View;Atlanta",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "10161202",
        "title": "Practical Visual Deep Imitation Learning via Task-Level Domain Consistency",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work in visual end-to-end learning for robotics has shown the promise of imitation learning across a variety of tasks. Such approaches are however expensive both because they require large amounts of real world data and rely on time-consuming real-world evaluations to identify the best model for deployment. These challenges can be mitigated by using simulation evaluations to identify high performing policies. However, this introduces the well-known \u201creality gap\u201d problem, where simulator inaccuracies decorrelate performance in simulation from that of reality. In this paper, we build on top of prior work in GAN-based domain adaptation and introduce the notion of a Task Consistency Loss (TCL), a self-supervised loss that encourages sim and real alignment both at the feature and action-prediction levels. We demonstrate the effectiveness of our approach by teaching a 9-DoF mobile manipulator to perform the challenging task of latched door opening purely from visual inputs such as RGB and depth images. We achieve 69% success across twenty seen and unseen meeting rooms using only ~ 16.2 hours of teleoperated demonstrations in sim and real. To the best of our knowledge, this is the first work to tackle latched door opening from a purely end-to-end learning approach, where the task of navigation and manipulation are jointly modeled by a single neural network.",
        "primary_area": "",
        "author": "Mohi Khansari;Daniel Ho;Yuqing Du;Armando Fuentes;Matthew Bennice;Nicolas Sievers;Sean Kirmani;Yunfei Bai;Eric Jang;Mohi Khansari;Daniel Ho;Yuqing Du;Armando Fuentes;Matthew Bennice;Nicolas Sievers;Sean Kirmani;Yunfei Bai;Eric Jang",
        "authorids": "/37088456107;/37267934200;/37088999884;/37089895644;/37089892161;/37089895081;/37086513246;/37086454356;/37086455574;/37088456107;/37267934200;/37088999884;/37089895644;/37089892161;/37089895081;/37086513246;/37086454356;/37086455574",
        "aff": "Everyday Robots; Everyday Robots; UC, Berkeley; Everyday Robots; Everyday Robots; Everyday Robots; Everyday Robots; Everyday Robots; Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161202/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17175411473014156095&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;0;0;0;0;0;2",
        "aff_unique_norm": "Everyday Robots;University of California, Berkeley;Google",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.everydayrobots.com;https://www.berkeley.edu;https://www.google.com",
        "aff_unique_abbr": ";UC Berkeley;Google",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160933",
        "title": "PredRecon: A Prediction-boosted Planning Framework for Fast and High-quality Autonomous Aerial Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous UAV path planning for 3D reconstruction has been actively studied in various applications for high-quality 3D models. However, most existing works have adopted explore-then-exploit, prior-based or exploration-based strategies, demonstrating inefficiency with repeated flight and low autonomy. In this paper, we propose PredRecon, a prediction-boosted planning framework that can autonomously generate paths for high 3D reconstruction quality. We obtain inspiration from humans can roughly infer the complete construction structure from partial observation. Hence, we devise a surface prediction module (SPM) to predict the coarse complete surfaces of the target from the current partial reconstruction. Then, the uncovered surfaces are produced by online volumetric mapping waiting for observation by UAV. Lastly, a hierarchical planner plans motions for 3D reconstruction, which sequentially finds efficient global coverage paths, plans local paths for maximizing the performance of Multi-View Stereo (MVS), and generates smooth trajectories for image-pose pairs acquisition. We conduct benchmarks in the realistic simulator, which validates the performance of PredRecon compared with the classical and state-of-the-art methods. The open-source code is released at https://github.com/HKUST-Aerial-Robotics/PredRecon.",
        "primary_area": "",
        "author": "Chen Feng;Haojia Li;Fei Gao;Boyu Zhou;Shaojie Shen;Chen Feng;Haojia Li;Fei Gao;Boyu Zhou;Shaojie Shen",
        "authorids": "/37089895500;/37086544200;/37086045143;/37086574790;/37954847200;/37089895500;/37086544200;/37086045143;/37086574790;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Huzhou Institute, Zhejiang University, Huzhou, China; School of Artificial Intelligence, Sun Yat-Sen University, Zhuhai, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160933/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9431148734648096661&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "The Hong Kong University of Science and Technology;Zhejiang University;Sun Yat-Sen University",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;Huzhou Institute;School of Artificial Intelligence",
        "aff_unique_url": "https://www.ust.hk;https://www.zju.edu.cn;http://www.sysu.edu.cn",
        "aff_unique_abbr": "HKUST;ZJU;SYSU",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Hong Kong;Huzhou;Zhuhai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160752",
        "title": "Predicting Motion Plans for Articulating Everyday Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile manipulation tasks such as opening a door, pulling open a drawer, or lifting a toilet seat require constrained motion of the end-effector under environmental and task constraints. This, coupled with partial information in novel environments, makes it challenging to employ classical motion planning approaches at test time. Our key insight is to cast it as a learning problem to leverage past experience of solving similar planning problems to directly predict motion plans for mobile manipulation tasks in novel situations at test time. To enable this, we develop a simulator, ArtObjSim, that simulates articulated objects placed in real scenes. We then introduce \\mathbf{SeqIK}+\\theta_{0}\\mathbf{SeqIK}+\\theta_{0}, a fast and flexible representation for motion plans. Finally, we learn models that use \\mathbf{SeqIK}+\\theta_{0}\\mathbf{SeqIK}+\\theta_{0} to quickly predict motion plans for articulating novel objects at test time. Experimental evaluation shows improved speed and accuracy at generating motion plans than pure search-based methods and pure learning methods.",
        "primary_area": "",
        "author": "Arjun Gupta;Max E. Shepherd;Saurabh Gupta;Arjun Gupta;Max E. Shepherd;Saurabh Gupta",
        "authorids": "/37089892446;/37089895039;/37089922149;/37089892446;/37089895039;/37089922149",
        "aff": "University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160752/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:4QIRH5GPjW0J:scholar.google.com/&scioq=Predicting+Motion+Plans+for+Articulating+Everyday+Objects&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160434",
        "title": "Predictive Runtime Verification of Skill-based Robotic Systems using Petri Nets",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a novel approach for the online supervision of robotic systems assembled from multiple complex components with skillset-based architectures, using Petri nets (PN). Predictive runtime verification is performed, which warns the system user about actions that would lead to the violation of safety specifications, using online model-checking tools on the system PNs.",
        "primary_area": "",
        "author": "Baptiste Pelletier;Charles Lesire;Christophe Grand;David Doose;Mathieu Rognant;Baptiste Pelletier;Charles Lesire;Christophe Grand;David Doose;Mathieu Rognant",
        "authorids": "/37089893533;/38275129600;/38335131900;/38072337700;/37540402100;/37089893533;/38275129600;/38335131900;/38072337700;/37540402100",
        "aff": "ONERA/DTIS, University of Toulouse, France; ONERA/DTIS, University of Toulouse, France; ONERA/DTIS, University of Toulouse, France; ONERA/DTIS, University of Toulouse, France; ONERA/DTIS, University of Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160434/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12449144918162591816&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ONERA",
        "aff_unique_dep": "DTIS",
        "aff_unique_url": "https://www.onera.fr",
        "aff_unique_abbr": "ONERA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160518",
        "title": "Preliminary Evaluation of a Wearable Thruster for Arresting Backwards Falls",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents preliminary results assessing the efficacy of a backpack-worn cold-gas thruster to potentially arrest impending backwards falls. Specifically, a nitrogen-based cold gas thruster system was integrated into a backpack-worn prototype device, and experiments were conducted to assess the effect of the wearable device on backwards falls. Although the device is eventually intended for individuals at fall risk, these preliminary experiments were conducted on three healthy subjects. The experiments compared each subject's ability to recover from an impending fall with and without assistance from the thruster. Results suggest that the likelihood of a fall was substantially reduced with the thruster assistance.",
        "primary_area": "",
        "author": "Michael Finn-Henry;Jose Leonardo Brenes;Almaskhan Baimyshev;Michael Goldfarb;Michael Finn-Henry;Jose Leonardo Brenes;Almaskhan Baimyshev;Michael Goldfarb",
        "authorids": "/37088533205;/37089893072;/37085651156;/37284476400;/37088533205;/37089893072;/37085651156;/37284476400",
        "aff": "Harvard John A. Paulson School of Engineering and Applied Sciences, Boston, MA, USA; Vanderbilt University, School of Engineering, Nashville, TN, USA; Vanderbilt University, School of Engineering, Nashville, TN, USA; Vanderbilt University, School of Engineering, Nashville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160518/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8898766064558270886&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Harvard University;Vanderbilt University",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences;School of Engineering",
        "aff_unique_url": "https://www.seas.harvard.edu;https://www.vanderbilt.edu",
        "aff_unique_abbr": "Harvard SEAS;Vanderbilt",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Boston;Nashville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161356",
        "title": "PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "Lane detection is one of the fundamental modules in self-driving. In this paper we employ a transformer-only method for lane detection, thus it could benefit from the blooming development of fully vision transformer and achieve the state-of-the-art (SOTA) performance on both CULane and TuSimple benchmarks, by fine-tuning the weight fully pre-trained on large datasets. More importantly, this paper proposes a novel and general framework called PriorLane, which is used to enhance the segmentation performance of the fully vision transformer by introducing the low-cost local prior knowledge. Specifically, PriorLane utilizes an encoder-only transformer to fuse the feature extracted by a pre-trained segmentation model with prior knowledge embeddings. Note that a Knowledge Embedding Alignment (KEA) module is adapted to enhance the fusion performance by aligning the knowledge embedding. Extensive experiments on our Zjlab dataset show that PriorLane outperforms SOTA lane detection methods by a 2.82% mIoU when prior knowledge is employed, and the code will be released at: https://github.com/vincentqqb/PriorLane.",
        "primary_area": "",
        "author": "Qibo Qiu;Haiming Gao;Wei Hua;Gang Huang;Xiaofei He;Qibo Qiu;Haiming Gao;Wei Hua;Gang Huang;Xiaofei He",
        "authorids": "/37089892330;/37086356139;/37089196345;/37085627794;/37407014800;/37089892330;/37086356139;/37089196345;/37085627794;/37407014800",
        "aff": "State Key Lab of CAD&CG, College of Computer Science, Zhejiang University, Hangzhou, P. R. China; Zhejiang Lab, Hangzhou, P. R. China; Zhejiang Lab, Hangzhou, P. R. China; Zhejiang Lab, Hangzhou, P. R. China; State Key Lab of CAD&CG, College of Computer Science, Zhejiang University, Hangzhou, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161356/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6060490346526936851&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Zhejiang University;Zhejiang Lab",
        "aff_unique_dep": "College of Computer Science;",
        "aff_unique_url": "http://www.zju.edu.cn;http://www.zhejianglab.com",
        "aff_unique_abbr": "ZJU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161118",
        "title": "Prioritized Robotic Exploration with Deadlines: A Comparison of Greedy, Orienteering, and Profitable Tour Approaches",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of robotic exploration of unknown indoor environments with deadlines. Indoor exploration using mobile robots has typically focused on exploring the entire environment without considering deadlines. The objective of the prioritized exploration in this paper is to rapidly compute the geometric layout of an initially unknown environment by exploring key regions of the environment and returning to the home location within a deadline. This prioritized exploration is useful for time-critical and dangerous environments where rapid robot exploration can provide vital information for subsequent operations. For example, firefighters, for whom time is of the essence, can utilize the map generated by this robotic exploration to navigate a building on fire. In our previous work, we showed that a priority-based greedy algorithm can outperform a cost-based greedy algorithm for exploration under deadlines. This paper models the prioritized exploration problem as an Orienteering Problem (OP) and a Profitable Tour Problem (PTP) in an attempt to generate exploration strategies that can explore a greater percentage of the environment in a given amount of time. The paper presents simulation results on multiple graph-based and Gazebo environments. We found that in many cases the priority-based greedy algorithm performs on par or better than the OP and PTP-based algorithms. We analyze the potential reasons for this counterintuitive result.",
        "primary_area": "",
        "author": "Sayantan Datta;Srinivas Akella;Sayantan Datta;Srinivas Akella",
        "authorids": "/37089194827;/37280235600;/37089194827;/37280235600",
        "aff": "Department of Computer Science, University of North Carolina, Charlotte, NC, USA; Department of Computer Science, University of North Carolina, Charlotte, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161118/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7787660573235975429&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of North Carolina, Charlotte",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uncc.edu",
        "aff_unique_abbr": "UNCC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlotte",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161205",
        "title": "Privacy-Preserving Video Conferencing via Thermal-Generative Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the COVID-19 epidemic, video conferencing has evolved as a new paradigm of communication and teamwork. However, private and personal information can be easily leaked through cameras during video conferencing. This includes leakage of a person's appearance as well as the contents in the background. This paper proposes a novel way of using online low-resolution thermal images as conditions to guide the synthesis of RGB images, bringing a promising solution for real-time video conferencing when privacy leakage is a concern. SPADE-SR [1] (Spatially-Adaptive De-normalization with Self Resampling), a variant of SPADE, is adopted to incorporate the spatial property of a thermal heatmap and the non-thermal property of a normal, privacy-free pre-recorded RGB image provided in a form of latent code. We create a PAIR-LRT-Human (LRT = Low-Resolution Thermal) dataset to validate our claims. The result enables a convenient way of video conferencing where users no longer need to groom themselves and tidy up backgrounds for a short meeting. Additionally, it allows a user to switch to a different appearance and background during a conference.",
        "primary_area": "",
        "author": "Sheng\u2013Yang Chiu;Yu\u2013Ting Huang;Chieh\u2013Ting Lin;Yu\u2013Chee Tseng;Jen\u2013Jee Chen;Meng\u2013Hsuan Tu;Bo\u2013Chen Tung;YuJou Nieh;Sheng\u2013Yang Chiu;Yu\u2013Ting Huang;Chieh\u2013Ting Lin;Yu\u2013Chee Tseng;Jen\u2013Jee Chen;Meng\u2013Hsuan Tu;Bo\u2013Chen Tung;YuJou Nieh",
        "authorids": "/37089205938;/37089894373;/37089894608;/37276276400;/37539205100;/37089892364;/37089893435;/37089895322;/37089205938;/37089894373;/37089894608;/37276276400;/37539205100;/37089892364;/37089893435;/37089895322",
        "aff": "College of Artificial Intelligence, National Yang Ming Chiao Tung University (NYCU), Taiwan; College of Artificial Intelligence, National Yang Ming Chiao Tung University (NYCU), Taiwan; College of Artificial Intelligence, National Yang Ming Chiao Tung University (NYCU), Taiwan; College of Computer Science, NYCU, Miin Wu School of Computing, National Cheng Kung University, Taiwan; College of Artificial Intelligence, National Yang Ming Chiao Tung University (NYCU), Taiwan; College of Artificial Intelligence, National Yang Ming Chiao Tung University (NYCU), Taiwan; College of Artificial Intelligence, National Yang Ming Chiao Tung University (NYCU), Taiwan; College of Artificial Intelligence, National Yang Ming Chiao Tung University (NYCU), Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161205/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9983406194182181549&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;0;0;0;0",
        "aff_unique_norm": "National Yang Ming Chiao Tung University;National Cheng Kung University",
        "aff_unique_dep": "College of Artificial Intelligence;College of Computer Science, Miin Wu School of Computing",
        "aff_unique_url": "https://www.nycu.edu.tw;https://www.ncku.edu.tw",
        "aff_unique_abbr": "NYCU;NCKU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161485",
        "title": "Probabilistic Contact State Estimation for Legged Robots using Inertial Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robot navigation in unstructured and slippery terrains depends heavily on the ability to accurately identify the quality of contact between the robot's feet and the ground. Contact state estimation is regarded as a challenging problem and is typically addressed by exploiting force measurements, joint encoders and/or robot kinematics and dynamics. In contrast to most state of the art approaches, the current work introduces a novel probabilistic method for estimating the contact state based solely on proprioceptive sensing, as it is readily available by Inertial Measurement Units (IMUs) mounted on the robot's end effectors. Capitalizing on the uncertainty of IMU measurements, our method estimates the probability of stable contact. This is accomplished by approximating the multimodal probability density function over a batch of data points for each axis of the IMU with Kernel Density Estimation. The proposed method has been extensively assessed against both real and simulated scenarios on bipedal and quadrupedal robotic platforms such as ATLAS, TALOS and Unitree's GO1.",
        "primary_area": "",
        "author": "Michael Maravgakis;Despina-Ekaterini Argiropoulos;Stylianos Piperakis;Panos Trahanias;Michael Maravgakis;Despina-Ekaterini Argiropoulos;Stylianos Piperakis;Panos Trahanias",
        "authorids": "/37089659866;/37089551373;/37085813142;/37329551300;/37089659866;/37089551373;/37085813142;/37329551300",
        "aff": "Foundation for Research and Technology-Hellas (FORTH), Institute of Computer Science, Heraklion, Greece; Foundation for Research and Technology-Hellas (FORTH), Institute of Computer Science, Heraklion, Greece; Ownage Dynamics L.P.; Foundation for Research and Technology-Hellas (FORTH), Institute of Computer Science, Heraklion, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161485/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8222280424867300997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Foundation for Research and Technology-Hellas;Ownage Dynamics L.P.",
        "aff_unique_dep": "Institute of Computer Science;",
        "aff_unique_url": "https://www.forth.gr;",
        "aff_unique_abbr": "FORTH;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Heraklion;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece;"
    },
    {
        "id": "10160792",
        "title": "Probabilistic Plane Extraction and Modeling for Active Visual-Inertial Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an active visual-inertial mapping framework with points and planes. The key aspect of the proposed framework is a novel probabilistic plane extraction with its associated model for estimation. The approach allows the extraction of plane parameters and their uncertainties based on a modified version of PlaneRCNN [1]. The extracted probabilistic plane features are fused with point features in order to increase the robustness of the estimation system in texture-less environments, where algorithms based on points alone would struggle. A visual-inertial framework based on Iterative Extended Kalman filter (IEKF) is used to demonstrate the approach. The IEKF equations are customized through a measurement extrapolation method, which enables the estimation to handle the delay introduced by the neural network inference time systematically. The system is encompassed within an active mapping framework, based on Informative Path Planning to find the most informative path for minimizing map uncertainty in visual-inertial systems. The results from the conducted experiments with a stereo/IMU system mounted on a robotic arm show that introducing planar features to the map, in order to complement the point features in the state estimation, improves robustness in texture-less environments.",
        "primary_area": "",
        "author": "Mitchell Usayiwevu;Fouad Sukkar;Teresa Vidal-Calleja;Mitchell Usayiwevu;Fouad Sukkar;Teresa Vidal-Calleja",
        "authorids": "/37088688007;/37086937310;/37085384801;/37088688007;/37086937310;/37085384801",
        "aff": "UTS Robotics Institute, University of Technology Sydney, Ultimo, NSW, Australia; Australian Cobotics Centre (ITTC for Collaborative Robotics in Advanced Manufacturing); Australian Cobotics Centre (ITTC for Collaborative Robotics in Advanced Manufacturing)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160792/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2657857232584335115&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Technology Sydney;Australian Cobotics Centre",
        "aff_unique_dep": "UTS Robotics Institute;ITTC for Collaborative Robotics in Advanced Manufacturing",
        "aff_unique_url": "https://www.uts.edu.au;",
        "aff_unique_abbr": "UTS;ACC",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Ultimo;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160678",
        "title": "Probabilistic Planning with Partially Ordered Preferences over Temporal Goals",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study planning in stochastic systems, modeled as Markov decision processes (MDPs), with preferences over temporally extended goals. Prior work on temporal planning with preferences assumes that the user preferences form a total order, meaning that every pair of outcomes are comparable with each other. In this work, we consider the case where the preferences over possible outcomes are a partial order rather than a total order. We first introduce a variant of deterministic finite automaton, referred to as a preference DFA, for specifying the user's preferences over temporally extended goals. Based on the order theory, we translate the preference DFA to a preference relation over policies for probabilistic planning in a labeled MDP. In this treatment, a most preferred policy induces a weak-stochastic nondominated probability distribution over the finite paths in the MDP. The proposed planning algorithm hinges on the construction of a multi-objective MDP. We prove that a weak-stochastic nondominated policy given the preference specification is Pareto-optimal in the constructed multi-objective MDP, and vice versa. Throughout the paper, we employ a running example to demonstrate the proposed preference specification and solution approaches. We show the efficacy of our algorithm using the example with detailed analysis, and then discuss possible future directions.",
        "primary_area": "",
        "author": "Hazhar Rahmani;Abhishek N. Kulkarni;Jie Fu;Hazhar Rahmani;Abhishek N. Kulkarni;Jie Fu",
        "authorids": "/37086453006;/37086432727;/37085509060;/37086453006;/37086432727;/37085509060",
        "aff": "Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160678/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3414508390093425442&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Florida",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ufl.edu",
        "aff_unique_abbr": "UF",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Gainesville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161083",
        "title": "Probabilistic Rare-Event Verification for Temporal Logic Robot Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for calculating the probability that a robot successfully performs a task described using Signal Temporal Logic (STL). We focus on cases where the failure probability is very small, hence a traditional Monte-Carlo method becomes inefficient due to the large number of samples required to observe failures. Using elliptical sliced sampling, normalizing flows, and Bayesian optimization, we develop an algorithm that, under mild assumptions, is applicable to black-box systems, and can be applied to uncertainty sources with non-Gaussian probabilities. We demonstrate the application of our method on three different simulated robots.",
        "primary_area": "",
        "author": "Guy Scher;Sadra Sadraddini;Hadas Kress-Gazit;Guy Scher;Sadra Sadraddini;Hadas Kress-Gazit",
        "authorids": "/37088526154;/37085778307;/38307602100;/37088526154;/37085778307;/38307602100",
        "aff": "Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Dexai Robotics, Boston, MA, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161083/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1619762788124540844&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Cornell University;Dexai Robotics",
        "aff_unique_dep": "Sibley School of Mechanical and Aerospace Engineering;",
        "aff_unique_url": "https://www.cornell.edu;",
        "aff_unique_abbr": "Cornell;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Ithaca;Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161490",
        "title": "Probabilistic Risk Assessment for Chance-Constrained Collision Avoidance in Uncertain Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Balancing safety and efficiency when planning in crowded scenarios with uncertain dynamics is challenging where it is imperative to accomplish the robot's mission without incurring any safety violations. Typically, chance constraints are incorporated into the planning problem to provide probabilistic safety guarantees by imposing an upper bound on the collision probability of the planned trajectory. Yet, this results in an overly conservative behavior on the grounds that the gap between the obtained risk and the specified upper limit is not explicitly restricted. To address this issue, we propose a real-time capable approach to quantify the risk associated with planned trajectories obtained from multiple probabilistic planners, running in parallel, with different upper bounds of the acceptable risk level. Based on the evaluated risk, the least conservative plan is selected provided that its associated risk is below a specified threshold. In such a way, the proposed approach provides probabilistic safety guarantees by attaining a closer bound to the specified risk, while being applicable to generic uncertainties of moving obstacles. We demonstrate the efficiency of our proposed approach, by improving the performance of a state-of-the-art probabilistic planner, in simulations and experiments using a mobile robot in an environment shared with humans.",
        "primary_area": "",
        "author": "Khaled A. Mustafa;Oscar de Groot;Xinwei Wang;Jens Kober;Javier Alonso-Mora;Khaled A. Mustafa;Oscar de Groot;Xinwei Wang;Jens Kober;Javier Alonso-Mora",
        "authorids": "/37089892513;/37088866244;/37086458808;/37542833400;/38271697300;/37089892513;/37088866244;/37086458808;/37542833400;/38271697300",
        "aff": "Dept. of Cognitive Robotics, TU Delft, Delft, CD, The Netherlands; Dept. of Cognitive Robotics, TU Delft, Delft, CD, The Netherlands; Dept. of Cognitive Robotics, TU Delft, Delft, CD, The Netherlands; Dept. of Cognitive Robotics, TU Delft, Delft, CD, The Netherlands; Dept. of Cognitive Robotics, TU Delft, Delft, CD, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161490/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12432014257463575532&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Department of Cognitive Robotics",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10160298",
        "title": "Probabilistic Uncertainty Quantification of Prediction Models with Application to Visual Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "The uncertainty quantification of prediction models (e.g., neural networks) is crucial for their adoption in many robotics applications. This is arguably as important as making accurate predictions, especially for safety-critical applications such as self-driving cars. This paper proposes our approach to uncertainty quantification in the context of visual localization for autonomous driving, where we predict locations from images. Our proposed framework estimates probabilistic uncertainty by creating a sensor error model that maps an internal output of the prediction model to the uncertainty. The sensor error model is created using multiple image databases of visual localization, each with ground-truth location. We demonstrate the accuracy of our uncertainty prediction framework using the Ithaca365 dataset, which includes variations in lighting, weather (sunny, snowy, night), and alignment errors between databases. We analyze both the predicted uncertainty and its incorporation into a Kalman-based localization filter. Our results show that prediction error variations increase with poor weather and lighting condition, leading to greater uncertainty and outliers, which can be predicted by our proposed uncertainty model. Additionally, our probabilistic error model enables the filter to remove ad hoc sensor gating, as the uncertainty automatically adjusts the model to the input data.",
        "primary_area": "",
        "author": "Junan Chen;Josephine Monica;Wei-Lun Chao;Mark Campbell;Junan Chen;Josephine Monica;Wei-Lun Chao;Mark Campbell",
        "authorids": "/37088984645;/37086939060;/37086876034;/37272971700;/37088984645;/37086939060;/37086876034;/37272971700",
        "aff": "Mechanical and Aerospace Engineering Department, Cornell University; Mechanical and Aerospace Engineering Department, Cornell University; Department of Computer Science and Engineering, Ohio State University; Mechanical and Aerospace Engineering Department, Cornell University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160298/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4882742840777837920&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Cornell University;Ohio State University",
        "aff_unique_dep": "Mechanical and Aerospace Engineering Department;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.cornell.edu;https://www.osu.edu",
        "aff_unique_abbr": "Cornell;OSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160916",
        "title": "Proficiency Self-Assessment without Breaking the Robot: Anomaly Detection using Assumption-Alignment Tracking from Safe Experiments",
        "track": "main",
        "status": "Poster",
        "abstract": "Proficiency self-assessment (PSA), the ability to assess how well one can carry out a task, is a desirable capability of autonomous robot systems. Prior work has proposed assumption-alignment tracking (AAT) for performing PSA, and has shown that it can accurately predict robot performance in real-time given a dataset obtained from both normal and abnormal training runs. Obtaining data in abnormal conditions (i.e., conditions in which the robot is not prepared to operate) is difficult and is often not possible. As a result, many realistic datasets contain very few data points for abnormal conditions, making it difficult to apply AAT. This paper hypothesizes that a one-class classifier can be built to detect anomalies using only data collected under normal conditions. Two metrics, difference and separation, are proposed and used to demonstrate that AAT feature vectors from different running conditions tend to form distinct clusters that are identifiable by mainstream one-class classification algorithms. Thus, one-class classifiers trained on AAT feature vectors from normal data can detect anomalous conditions. Furthermore, preliminary results suggest that a few abnormal data points, if available, can be used to classify the abnormality type and, in turn, the degree to which the anomalies will likely impact robot performance. Empirical results from both a simulated navigation robot and a Sawyer robot manipulating blocks show the efficacy of the approach.",
        "primary_area": "",
        "author": "Xuan Cao;Jacob W. Crandall;Ethan Pedersen;Alvika Gautam;Michael A. Goodrich;Xuan Cao;Jacob W. Crandall;Ethan Pedersen;Alvika Gautam;Michael A. Goodrich",
        "authorids": "/37089603400;/37339706800;/37089892108;/37085410010;/37278340100;/37089603400;/37339706800;/37089892108;/37085410010;/37278340100",
        "aff": "Computer Science Department, Brigham Young University, Provo, UT, USA; Computer Science Department, Brigham Young University, Provo, UT, USA; Computer Science Department, Brigham Young University, Provo, UT, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; Computer Science Department, Brigham Young University, Provo, UT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160916/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17946649925348434080&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Brigham Young University;Texas A&M University",
        "aff_unique_dep": "Computer Science Department;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.byu.edu;https://www.tamu.edu",
        "aff_unique_abbr": "BYU;TAMU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Provo;College Station",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161317",
        "title": "ProgPrompt: Generating Situated Robot Task Plans using Large Language Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Task planning can require defining myriad domain knowledge about the world in which a robot needs to act. To ameliorate that effort, large language models (LLMs) can be used to score potential next actions during task planning, and even generate action sequences directly, given an instruction in natural language with no additional domain information. However, such methods either require enumerating all possible next steps for scoring, or generate free-form text that may contain actions not possible on a given robot in its current context. We present a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks. Our key insight is to prompt the LLM with program-like specifications of the available actions and objects in an environment, as well as with example programs that can be executed. We make concrete recommendations about prompt structure and generation constraints through ablation experiments, demonstrate state of the art success rates in VirtualHome household tasks, and deploy our method on a physical robot arm for tabletop tasks. Website at progprompt.github.io",
        "primary_area": "",
        "author": "Ishika Singh;Valts Blukis;Arsalan Mousavian;Ankit Goyal;Danfei Xu;Jonathan Tremblay;Dieter Fox;Jesse Thomason;Animesh Garg;Ishika Singh;Valts Blukis;Arsalan Mousavian;Ankit Goyal;Danfei Xu;Jonathan Tremblay;Dieter Fox;Jesse Thomason;Animesh Garg",
        "authorids": "/37089894102;/37086279571;/37085404794;/37089542343;/37086228189;/37086455314;/37284329000;/37086936057;/37086330576;/37089894102;/37086279571;/37085404794;/37089542343;/37086228189;/37086455314;/37284329000;/37086936057;/37086330576",
        "aff": "University of Southern California; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; University of Southern California; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161317/",
        "gs_citation": 893,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4349782274361996997&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;1;1;0;1",
        "aff_unique_norm": "University of Southern California;NVIDIA Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.usc.edu;https://www.nvidia.com",
        "aff_unique_abbr": "USC;NVIDIA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161173",
        "title": "Proprioceptive Sensor-Based Simultaneous Multi-Contact Point Localization and Force Identification for Robotic Arms",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an algorithm that estimates contact point and force simultaneously. We consider a collaborative robot equipped with proprioceptive sensors, in particular, joint torque sensors (JTSs) and a base force/torque (F/T) sensor. The proposed method has the following advan-tages. First, fast computation is achieved by proper preprocessing of robot meshes. Second, multi-contact can be identified with the aid of the base F/T sensor, while this is challenging when the robot is equipped with only JTSs. The proposed method is a modification of the standard particle filter to cope with mesh preprocessing and with available sensor data. In simulation validation, for a 7 degree-of-freedom robot, the algorithm runs at 2200Hz with 99.96% success rate for the single-contact case. In terms of the run-time, the proposed method was \u22653.5X faster compared to the existing methods. Dual and triple contacts are also reported in the manuscript.",
        "primary_area": "",
        "author": "Seo Wook Han;Min Jun Kim;Seo Wook Han;Min Jun Kim",
        "authorids": "/37089893720;/38239144100;/37089893720;/38239144100",
        "aff": "Intelligent Robotic Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Intelligent Robotic Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161173/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5161062670034059279&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Intelligent Robotic Systems Laboratory",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160706",
        "title": "Puppeteer and Marionette: Learning Anticipatory Quadrupedal Locomotion Based on Interactions of a Central Pattern Generator and Supraspinal Drive",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadruped animal locomotion emerges from the interactions between the spinal central pattern generator (CPG), sensory feedback, and supraspinal drive signals from the brain. Computational models of CPGs have been widely used for investigating the spinal cord contribution to animal locomotion control in computational neuroscience and in bio-inspired robotics. However, the contribution of supraspinal drive to anticipatory behavior, i.e. motor behavior that involves planning ahead of time (e.g. of footstep placements), is not yet properly understood. In particular, it is not clear whether the brain modulates CPG activity and/or directly modulates muscle activity (hence bypassing the CPG) for accurate foot placements. In this paper, we investigate the interaction of supraspinal drive and a CPG in an anticipatory locomotion scenario that involves stepping over gaps. By employing deep reinforcement learning (DRL), we train a neural network policy that replicates the supraspinal drive behavior. This policy can either modulate the CPG dynamics, or directly change actuation signals to bypass the CPG dynamics. Our results indicate that the direct supraspinal contribution to the actuation signal is a key component for a high gap crossing success rate. However, the CPG dynamics in the spinal cord are beneficial for gait smoothness and energy efficiency. Moreover, our investigation shows that sensing the front feet distances to the gap is the most important and sufficient sensory information for learning gap crossing. Our results support the biological hypothesis that cats and horses mainly control the front legs for obstacle avoidance, and that hind limbs follow an internal memory based on the front limbs' information. Our method enables the quadruped robot to cross gaps of up to 20 cm (50% of body-length) without any explicit dynamics modeling or Model Predictive Control (MPC).",
        "primary_area": "",
        "author": "Milad Shafiee;Guillaume Bellegarda;Auke Ijspeert;Milad Shafiee;Guillaume Bellegarda;Auke Ijspeert",
        "authorids": "/37088342567;/37086456120;/37268732300;/37088342567;/37086456120;/37268732300",
        "aff": "BioRobotics Laboratory, Ecole Polytechnique Federale de Lausanne (EPFL); BioRobotics Laboratory, Ecole Polytechnique Federale de Lausanne (EPFL); BioRobotics Laboratory, Ecole Polytechnique Federale de Lausanne (EPFL)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160706/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2001689830011097666&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ecole Polytechnique Federale de Lausanne",
        "aff_unique_dep": "BioRobotics Laboratory",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161523",
        "title": "Pyramid Learnable Tokens for 3D LiDAR Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "3D LiDAR place recognition plays a vital role in various robot applications' including robotic navigation, autonomous driving, and simultaneous localization and mapping. However, most previous studies evaluated their models on accumulated 2D scans instead of real-world 3D LiDAR scans with a larger number of points, which limits the application in real scenarios. To address this limitation, we propose a point transformer network with pyramid learnable tokens (PTNet-PLT) to learn global descriptors for an actual scanned 3D LiDAR place recognition. Specifically, we first present a novel shifted cube attention module that consists of a self-attention module for local feature extraction and a cross-attention module for regional feature aggregation. The self-attention module constrains attention computation on a locally partitioned cube and builds connections across cubes based on the shifted cube scheme. In addition, the cross-attention module introduces several learnable tokens to separately aggregate features of points with similar features but spatially distant into an arbitrarily shaped region, which enables the model to capture long-term dependencies of the points. Next, we build a pyramid architecture network to learn multi-scale features and involve a decreasing number of tokens at each layer to aggregate features over a larger region. Finally, we obtain the global descriptor by concatenating learned region tokens of all layers. Experiments on three datasets, including USyd Campus, Oxford Robot-Car, and KITTI, demonstrate the effectiveness and generalization of the proposed model for large-scale 3D LiDAR place recognition.",
        "primary_area": "",
        "author": "Congcong Wen;Hao Huang;Yu-Shen Liu;Yi Fang;Congcong Wen;Hao Huang;Yu-Shen Liu;Yi Fang",
        "authorids": "/37088951413;/37089893499;/37933979000;/37085619965;/37088951413;/37089893499;/37933979000;/37085619965",
        "aff": "New York University Abu Dhabi, UAE; New York University Abu Dhabi, UAE; School of Software, Tsinghua University, Beijing, P. R. China; New York University Abu Dhabi, UAE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161523/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4438719797231381855&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "New York University;Tsinghua University",
        "aff_unique_dep": ";School of Software",
        "aff_unique_url": "https://nyu.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "NYU;THU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Abu Dhabi;Beijing",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Arab Emirates;China"
    },
    {
        "id": "10161290",
        "title": "QuadMag: A Mobile-Coil System With Enhanced Magnetic Actuation Efficiency and Dexterity",
        "track": "main",
        "status": "Poster",
        "abstract": "Magnetic field is a favorable power source for actuation and control of micro-/nanorobots. To overcome the fast decay of magnetic field for large-workspace microrobotic actuation, mobile field source-based systems have been proposed. In this work, we report a new mobile-coil system, i.e., QuadMag. It consists of four electromagnetic coils, whose motion is actuated by a parallel mechanism. Compared to previous systems with three mobile coils, e.g., DeltaMag, the additional coil in the QuadMag increases the degree-of-freedom (DoF) for magnetic control. However, to control QuadMag, new control methods should be developed for the over-constrained parallel mechanism and for the field/force of the four coils. We derive the Jacobian matrix for the differential motion of the parallel mechanism and then formulate the field, force and simultaneous field and force control methods for magnetic actuation. Comparative experiments validate the enhanced actuation efficiency when controlling torque-driven helical microrobots. Moreover, the magnetic actuation dexterity is also enhanced by the additional coil. We conduct simulated navigation experiments and prove the actuation capability of QuadMag for 3D force-driven microrobot navigation with controlled robot orientation.",
        "primary_area": "",
        "author": "Lidong Yang;Moqiu Zhang;Zhengxin Yang;Haojin Yang;Li Zhang;Lidong Yang;Moqiu Zhang;Zhengxin Yang;Haojin Yang;Li Zhang",
        "authorids": "/37086079463;/37088704045;/37088506149;/37089198025;/37085379138;/37086079463;/37088704045;/37088506149;/37089198025;/37085379138",
        "aff": "CUHK T Stone Robotics Institute and The Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161290/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7608484166637629355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong",
        "aff_unique_dep": "T Stone Robotics Institute",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160854",
        "title": "Quadruped Guidance Robot for the Visually Impaired: A Comfort-Based Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Guidance robots that can guide people and avoid various obstacles, could potentially be owned by more visually impaired people at a fairly low cost. Most of the previous guidance robots for the visually impaired ignored the human response behavior and comfort, treating the human as an appendage dragged by the robot, which can lead to imprecise guidance of the human and sudden changes in the traction force experienced by the human. In this paper, we propose a novel quadruped guidance robot system with a comfort-based concept. We design a controllable traction device that can adjust the length and force between human and robot to ensure comfort. To allow the human to be guided safely and comfortably to the target position in complex environments, our proposed human motion planner can plan the traction force with the force-based human motion model. To track the planned force, we also propose a robot motion planner that can generate the specific robot motion command and design the force control device. Our system has been deployed on Unitree Laikago quadrupedal platform and validated in real-world scenarios. (Video11Video demonstration: https://youtu.be/gd-RcYOqGuo.)",
        "primary_area": "",
        "author": "Yanbo Chen;Zhengzhe Xu;Zhuozhu Jian;Gengpan Tang;Liyunong Yang;Anxing Xiao;Xueqian Wang;Bin Liang;Yanbo Chen;Zhengzhe Xu;Zhuozhu Jian;Gengpan Tang;Liyunong Yang;Anxing Xiao;Xueqian Wang;Bin Liang",
        "authorids": "/37089895876;/37089892526;/37089661474;/37089894072;/37089894407;/37088981835;/37085383477;/37270783900;/37089895876;/37089892526;/37089661474;/37089894072;/37089894407;/37088981835;/37085383477;/37270783900",
        "aff": "School of Mechanical Engineering and Automation at Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation at Harbin Institute of Technology, Shenzhen, China; Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; School of Mechanical Engineering and Automation at Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation at Harbin Institute of Technology, Shenzhen, China; School of Computing, National University of Singapore, Singapore, Singapore; Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Center for Artificial Intelligence and Robotics, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160854/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6231111628181853080&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;0;2;1;1",
        "aff_unique_norm": "Harbin Institute of Technology;Tsinghua University;National University of Singapore",
        "aff_unique_dep": "School of Mechanical Engineering and Automation;Center for Artificial Intelligence and Robotics;School of Computing",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.tsinghua.edu.cn;https://www.nus.edu.sg",
        "aff_unique_abbr": "HIT;Tsinghua;NUS",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Shenzhen;Singapore",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "10160386",
        "title": "Question Generation for Uncertainty Elimination in Referring Expressions in 3D Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a new task of question generation to eliminate the uncertainty of referring expressions in 3D indoor environments (3D-REQ). Referring to an object using natural language is one of the most common occurrences in daily human conversations; therefore, instructing robots to identify a certain object using natural language could be an essential task in var-ious robotic applications, such as room arrangement. However, human instructions are sometimes uncertain. Existing research on visual grounding using natural language in a 3D environment assumes that the referring expression can uniquely identify the object and does not consider that humans unconsciously give uncertain expressions. When faced with uncertainties, humans ask questions to gain further information. Inspired by the above observation, we propose a method that reduces uncertainty by asking questions when being given an obscure referring expression. The purpose of this method is to predict the positions of all candidate objects that satisfy the referring expressions in a 3D indoor environment and then to ask the appropriate questions to narrow down the target objects from them. To achieve this, we constructed a new 3D-REQ dataset, the input of which is a referring expression with uncertainties in the 3D environment and point clouds, and the output of which is the bounding boxes of all candidate objects satisfying the referring expression and a question to eliminate the uncertainty. To the best of our knowledge, 3D-REQ is the first effort to eliminate the uncertainty of referring expressions for object grounding in 3D environments.",
        "primary_area": "",
        "author": "Fumiya Matsuzawa;Yue Qiu;Kenji Iwata;Hirokatsu Kataoka;Yutaka Satoh;Fumiya Matsuzawa;Yue Qiu;Kenji Iwata;Hirokatsu Kataoka;Yutaka Satoh",
        "authorids": "/37089894279;/37086562279;/37667142500;/37845110800;/37289002900;/37089894279;/37086562279;/37667142500;/37845110800;/37289002900",
        "aff": "University of Tsukuba; National Institute of Advanced Industrial Science and Technology (AIST); National Institute of Advanced Industrial Science and Technology (AIST); National Institute of Advanced Industrial Science and Technology (AIST); University of Tsukuba",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160386/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14066810741581398328&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Tsukuba;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tsukuba.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "UT;AIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161410",
        "title": "RAMP-Net: A Robust Adaptive MPC for Quadrotors via Physics-informed Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Model Predictive Control (MPC) is a state-of-the-art (SOTA) control technique which requires solving hard constrained optimization problems iteratively. For uncertain dynamics, analytical model based robust MPC imposes additional constraints, increasing the hardness of the problem. The problem exacerbates in performance-critical applications, when more compute is required in lesser time. Data-driven regression methods such as Neural Networks have been proposed in the past to approximate system dynamics. However, such models rely on high volumes of labeled data, in the absence of symbolic analytical priors. This incurs non-trivial training overheads. Physics-informed Neural Networks (PINNs) have gained traction for approximating non-linear system of ordinary differential equations (ODEs), with reasonable accuracy. In this work, we propose a Robust Adaptive MPC framework via PINNs (RAMP-Net), which uses a neural network trained partly from simple ODEs and partly from data. A physics loss is used to learn simple ODEs representing ideal dynamics. Having access to analytical functions inside the loss function acts as a regularizer, enforcing robust behavior for parametric uncertainties. On the other hand, a regular data loss is used for adapting to residual disturbances (non-parametric uncertainties), unaccounted during mathematical modelling. Experiments are performed in a simulated environment for trajectory tracking of a quadrotor. We report 7.8% to 43.2% and 8.04% to 61.5% reduction in tracking errors for speeds ranging from 0.5 to 1.75m/s compared to two SOTA regression based MPC methods.",
        "primary_area": "",
        "author": "Sourav Sanyal;Kaushik Roy;Sourav Sanyal;Kaushik Roy",
        "authorids": "/37088637844;/37274519700;/37088637844;/37274519700",
        "aff": "Elmore Family School of Electrical and Computer Engineering, Purdue University, United States; Elmore Family School of Electrical and Computer Engineering, Purdue University, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161410/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11586971499205264114&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Elmore Family School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160602",
        "title": "RAMP: A Risk-Aware Mapping and Planning Pipeline for Fast Off-Road Ground Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "A key challenge in fast ground robot navigation in 3D terrain is balancing robot speed and safety. Recent work has shown that 2.5D maps (2D representations with additional 3D information) are ideal for real-time safe and fast planning. However, the prevalent approach of generating 2D occupancy grids through raytracing makes the generated map unsafe to plan in, due to inaccurate representation of unknown space. Additionally, existing planners such as MPPI do not consider speeds in known free and unknown space separately, leading to slower overall plans. The RAMP pipeline proposed here solves these issues using new mapping and planning methods. This work first presents ground point inflation with persistent spatial memory as a way to generate accurate occupancy grid maps from classified pointclouds. Then we present an MPPI-based planner with embedded variability in horizon, to maximize speed in known free space while retaining cautionary penetration into unknown space. Finally, we integrate this mapping and planning pipeline with risk constraints arising from 3D terrain, and verify that it enables fast and safe navigation using simulations and hardware demonstrations.",
        "primary_area": "",
        "author": "Lakshay Sharma;Michael Everett;Donggun Lee;Xiaoyi Cai;Philip Osteen;Jonathan P. How;Lakshay Sharma;Michael Everett;Donggun Lee;Xiaoyi Cai;Philip Osteen;Jonathan P. How",
        "authorids": "/898888629007404;/37418751400;/37086933984;/37087091424;/38251856000;/37276347700;/898888629007404;/37418751400;/37086933984;/37087091424;/38251856000;/37276347700",
        "aff": "Aerospace Controls Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Aerospace Controls Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Aerospace Controls Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Aerospace Controls Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; DEVCOM Army Research Laboratory, MD, USA; Aerospace Controls Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160602/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8988197301326047248&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;DEVCOM Army Research Laboratory",
        "aff_unique_dep": "Aerospace Controls Laboratory;",
        "aff_unique_url": "https://web.mit.edu;",
        "aff_unique_abbr": "MIT;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161185",
        "title": "RAMP: Reaction-Aware Motion Planning of Multi-Legged Robots for Locomotion in Microgravity",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic mobility in microgravity is necessary to expand human utilization and exploration of outer space. Bio-inspired multi-legged robots are a possible solution for safe and precise locomotion. However, a dynamic motion of a robot in microgravity can lead to failures due to gripper detachment caused by excessive motion reactions. We propose a novel Reaction-Aware Motion Planning (RAMP) to improve locomotion safety in microgravity, decreasing the risk of losing contact with the terrain surface by reducing the robot's momentum change. RAMP minimizes the swing momentum with a Low-Reaction Swing Trajectory (LRST) while distributing this momentum to the whole body, ensuring zero velocity for the supporting grippers and minimizing motion reactions. We verify the proposed approach with dynamic simulations indicating the capability of RAMP to generate a safe motion without detachment of the supporting grippers, resulting in the robot reaching its specified location. We further validate RAMP in experiments with an air-floating system, demonstrating a significant reduction in reaction forces and improved mobility in microgravity.",
        "primary_area": "",
        "author": "Warley F. R. Ribeiro;Kentaro Uno;Masazumi Imai;Koki Murase;Kazuya Yoshida;Warley F. R. Ribeiro;Kentaro Uno;Masazumi Imai;Koki Murase;Kazuya Yoshida",
        "authorids": "/37085523498;/37086823375;/37089895284;/37089892087;/37329693000;/37085523498;/37086823375;/37089895284;/37089892087;/37329693000",
        "aff": "Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161185/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11500244142905272970&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160448",
        "title": "RFFCE: Residual Feature Fusion and Confidence Evaluation Network for 6DoF Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel RGBD-based object 6DoF pose estimation network - RFFCE. It is a two-stage method that firstly leverages deep neural networks for feature extraction and object points matching, and then the geometric principles are utilized for final pose computation. Our approach consists of three primary innovations: residual feature fusion for representative RGBD feature extraction; confidence evaluation and confidence-based paired points offsets regression for self-evaluation and self-optimization respectively. Their effectiveness is verified through an ablation study, and our RFFCE achieves the SOTA performance on LineMOD, Occlusion-LineMOD and YCB-Video datasets. Additionally, we also conduct a real-world object grasping experiment for visualization and qualitative evaluation of the RFFCE.",
        "primary_area": "",
        "author": "Qiwei Meng;Shanshan Ji;Shiqiang Zhu;Tianlei Jin;Te Li;Jason Gu;Wei Song;Qiwei Meng;Shanshan Ji;Shiqiang Zhu;Tianlei Jin;Te Li;Jason Gu;Wei Song",
        "authorids": "/37089686524;/37089691867;/37281408900;/37089236029;/37088975486;/37276928500;/37852830600;/37089686524;/37089691867;/37281408900;/37089236029;/37088975486;/37276928500;/37852830600",
        "aff": "Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China; Department of Electrical and Computer Engineering, Dalhousie University, Halifax, NS, Canada; Zhejiang Engineering Research Center for Intelligent Robotics, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160448/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=770258084884713536&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Zhejiang Engineering Research Center for Intelligent Robotics;Dalhousie University",
        "aff_unique_dep": ";Department of Electrical and Computer Engineering",
        "aff_unique_url": ";https://www.dal.ca",
        "aff_unique_abbr": ";Dal",
        "aff_campus_unique_index": "0;0;0;0;0;1;0",
        "aff_campus_unique": "Hangzhou;Halifax",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "10161319",
        "title": "RGB-D Grasp Detection via Depth Guided Learning with Cross-modal Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Planar grasp detection is one of the most fundamental tasks to robotic manipulation, and the recent progress of consumer-grade RGB-D sensors enables delivering more comprehensive features from both the texture and shape modalities. However, depth maps are generally of a relatively lower quality with much stronger noise compared to RGB images, making it challenging to acquire grasp depth and fuse multi-modal clues. To address the two issues, this paper proposes a novel learning based approach to RGB-D grasp detection, namely Depth Guided Cross-modal Attention Network (DGCAN). To better leverage the geometry information recorded in the depth channel, a complete 6-dimensional rectangle representation is adopted with the grasp depth dedicatedly considered in addition to those defined in the common 5-dimensional one. The prediction of the extra grasp depth substantially strengthens feature learning, thereby leading to more accurate results. Moreover, to reduce the negative impact caused by the discrepancy of data quality in two modalities, a Local Cross-modal Attention (LCA) module is designed, where the depth features are refined according to cross-modal relations and concatenated to the RGB ones for more sufficient fusion. Extensive simulation and physical evaluations are conducted and the experimental results highlight the superiority of the proposed approach.",
        "primary_area": "",
        "author": "Ran Qin;Haoxiang Ma;Boyang Gao;Di Huang;Ran Qin;Haoxiang Ma;Boyang Gao;Di Huang",
        "authorids": "/37089273196;/37090017843;/37085855554;/37401456900;/37089273196;/37090017843;/37085855554;/37401456900",
        "aff": "State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; Geometry Robotics and the School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161319/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9657305728869775008&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Beihang University;Harbin Institute of Technology",
        "aff_unique_dep": "School of Computer Science and Engineering;School of Computer Science and Technology",
        "aff_unique_url": "http://www.buaa.edu.cn;http://www.hit.edu.cn/",
        "aff_unique_abbr": "BUAA;HIT",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Beijing;Harbin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161563",
        "title": "RGB-Event Fusion for Moving Object Detection in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Moving Object Detection (MOD) is a critical vision task for successfully achieving safe autonomous driving. Despite plausible results of deep learning methods, most existing approaches are only frame-based and may fail to reach reasonable performance when dealing with dynamic traffic participants. Recent advances in sensor technologies, especially the Event camera, can naturally complement the conventional camera approach to better model moving objects. However, event-based works often adopt a pre-defined time window for event representation, and simply integrate it to estimate image intensities from events, neglecting much of the rich temporal information from the available asynchronous events. Therefore, from a new perspective, we propose RENet, a novel RGB-Event fusion Network, that jointly exploits the two complementary modalities to achieve more robust MOD under challenging scenarios for autonomous driving. Specifically, we first design a temporal multi-scale aggregation module to fully leverage event frames from both the RGB exposure time and larger intervals. Then we introduce a bi-directional fusion module to attentively calibrate and fuse multi-modal features. To evaluate the performance of our network, we carefully select and annotate a sub-MOD dataset from the commonly used DSEC dataset. Extensive experiments demonstrate that our proposed method performs significantly better than the state-of-the-art RGB-Event fusion alternatives. The source code and dataset are publicly available at: https://github.com/ZZY-Zhou/RENet.",
        "primary_area": "",
        "author": "Zhuyun Zhou;Zongwei Wu;R\u00e9mi Boutteau;Fan Yang;C\u00e9dric Demonceaux;Dominique Ginhac;Zhuyun Zhou;Zongwei Wu;R\u00e9mi Boutteau;Fan Yang;C\u00e9dric Demonceaux;Dominique Ginhac",
        "authorids": "/37089895099;/37089230188;/37586304800;/37538164900;/37265984700;/37550324400;/37089895099;/37089230188;/37586304800;/37538164900;/37265984700;/37550324400",
        "aff": "ImViA, University of Burgundy (Universit\u00e9 de Bourgogne), Dijon, France; CVL, ETH, Zurich; LITIS UR 4108, Univ Rouen Normandie, Rouen, France; ImViA, University of Burgundy (Universit\u00e9 de Bourgogne), Dijon, France; CNRS, Inria, LORIA, Universit\u00e9 de Lorraine, Nancy, France; ImViA, University of Burgundy (Universit\u00e9 de Bourgogne), Dijon, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161563/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4914016222112935886&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;0",
        "aff_unique_norm": "University of Burgundy;ETH Zurich;University of Rouen Normandy;CNRS",
        "aff_unique_dep": "ImViA;Computer Vision Laboratory;LITIS UR 4108;",
        "aff_unique_url": "https://u-bourgogne.fr;https://www.ethz.ch;https://www.univ-rouen.fr;https://www.cnrs.fr",
        "aff_unique_abbr": "UB;ETHZ;Univ Rouen Normandie;CNRS",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "Dijon;Zurich;Rouen;",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "France;Switzerland"
    },
    {
        "id": "10160247",
        "title": "RGB-Only Reconstruction of Tabletop Scenes for Collision-Free Manipulator Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a system for collision-free control of a robot manipulator that uses only RGB views of the world. Perceptual input of a tabletop scene is provided by multiple images of an RGB camera (without depth) that is either handheld or mounted on the robot end effector. A NeRF-like process is used to reconstruct the 3D geometry of the scene, from which the Euclidean full signed distance function (ESDF) is computed. A model predictive control algorithm is then used to control the manipulator to reach a desired pose while avoiding obstacles in the ESDF. We show results on a real dataset collected and annotated in our lab. Our results are also available at https://ngp-mpc.github.io/.",
        "primary_area": "",
        "author": "Zhenggang Tang;Balakumar Sundaralingam;Jonathan Tremblay;Bowen Wen;Ye Yuan;Stephen Tyree;Charles Loop;Alexander Schwing;Stan Birchfield;Zhenggang Tang;Balakumar Sundaralingam;Jonathan Tremblay;Bowen Wen;Ye Yuan;Stephen Tyree;Charles Loop;Alexander Schwing;Stan Birchfield",
        "authorids": "/37089894283;/37086455625;/37086455314;/37088488448;/37089893612;/37074894100;/37871856300;/37937546900;/37371627300;/37089894283;/37086455625;/37086455314;/37088488448;/37089893612;/37074894100;/37871856300;/37937546900;/37371627300",
        "aff": "University of Illinois Urbana-Champaign; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; University of Illinois Urbana-Champaign; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160247/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8663258299859721284&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;1;1;0;1",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign;NVIDIA Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://illinois.edu;https://www.nvidia.com",
        "aff_unique_abbr": "UIUC;NVIDIA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161571",
        "title": "RLAfford: End-to-End Affordance Learning for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning to manipulate 3D objects in an interactive environment has been a challenging problem in Reinforcement Learning (RL). In particular, it is hard to train a policy that can generalize over objects with different semantic categories, diverse shape geometry and versatile functionality. In this study, we focused on the contact information in manipulation processes, and proposed a unified representation for critical interactions to describe different kinds of manipulation tasks. Specifically, we take advantage of the contact information generated during the RL training process and employ it as unified visual representation to predict contact map of interest. Such representation leads to an end-to-end learning framework that combined affordance based and RL based methods for the first time. Our unified framework can generalize over different types of manipulation tasks. Surprisingly, the effectiveness of such framework holds even under the multi-stage and multi-agent scenarios. We tested our method on eight types of manipulation tasks. Results showed that our methods outperform baseline algorithms, including visual affordance methods and RL methods, by a large margin on the success rate. The demonstration can be found at https://sites.google.com/view/rlafford/.",
        "primary_area": "",
        "author": "Yiran Geng;Boshi An;Haoran Geng;Yuanpei Chen;Yaodong Yang;Hao Dong;Yiran Geng;Boshi An;Haoran Geng;Yuanpei Chen;Yaodong Yang;Hao Dong",
        "authorids": "/37089895146;/37089892690;/37089893049;/37089541985;/37089659781;/37088968899;/37089895146;/37089892690;/37089893049;/37089541985;/37089659781;/37088968899",
        "aff": "CFCS, School of CS, Peking University; CFCS, School of CS, Peking University; CFCS, School of CS, Peking University; Institute for AI, Peking University; Institute for AI, Peking University; CFCS, School of CS, Peking University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161571/",
        "gs_citation": 73,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1327958673540826122&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Peking University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "http://www.pku.edu.cn",
        "aff_unique_abbr": "PKU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161133",
        "title": "ROSMC: A High-Level Mission Operation Framework for Heterogeneous Robotic Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "Heterogeneous teams of multiple mobile robots will be important for future scientific explorations of extraterrestrial surfaces or hazardous areas. Mission operation in such harsh, unknown environments poses diverse challenges. Robots need to cooperate autonomously due to the large network latency to the ground station while operators need to adapt the ongoing mission flexibly based on new discoveries obtained during execution. Furthermore, shared situational awareness between operators and roboticists is highly required to deal with execution failures promptly. To overcome these challenges, this paper proposes the high-level mission operation framework ROSMC. The concept of mission synchronization to robots enables continuous mission adaptations and future planning by operators while robots execute the mission autonomously. The ROS-based GUIs enable operators to intuitively create and monitor the mission for robots as well as to communicate with roboticists smoothly. The proposed framework was evaluated by a pilot study with a simulator and demonstrated at a Moon-analogue field on Mt. Etna in Sicily, Italy, involving 3 robots and around 70 researchers for 4 weeks.",
        "primary_area": "",
        "author": "Ryo Sakagami;Sebastian G. Brunner;Andreas D\u00f6mel;Armin Wedler;Freek Stulp;Ryo Sakagami;Sebastian G. Brunner;Andreas D\u00f6mel;Armin Wedler;Freek Stulp",
        "authorids": "/37088444769;/37086024404;/38475476900;/37946067800;/37681682200;/37088444769;/37086024404;/38475476900;/37946067800;/37681682200",
        "aff": "DLR (German Aerospace Center), Institute of Robotics and Mechatronics, Wessling, Germany; At DLR at the time of development of ROSMC; DLR (German Aerospace Center), Institute of Robotics and Mechatronics, Wessling, Germany; DLR (German Aerospace Center), Institute of Robotics and Mechatronics, Wessling, Germany; DLR (German Aerospace Center), Institute of Robotics and Mechatronics, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161133/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18379141525773733379&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "German Aerospace Center;Deutsches Zentrum f\u00fcr Luft- und Raumfahrt (DLR)",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;",
        "aff_unique_url": "https://www.dlr.de;https://www.dlr.de",
        "aff_unique_abbr": "DLR;DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161233",
        "title": "RPGD: A Small-Batch Parallel Gradient Descent Optimizer with Explorative Resampling for Nonlinear Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Nonlinear model predictive control often involves nonconvex optimization for which real-time control systems require fast and numerically stable solutions. This work proposes RPGD, a Resampling Parallel Gradient Descent optimizer designed to exploit small-batch parallelism of modern hardware like neural accelerators or multithreaded microcontrollers. After initialization, it continuously maintains a small population of good control trajectory solution candidates and improves them using gradient information, followed by selection of elite candidates and resampling of the others. In simulation on a cartpole, the OpenAI Gym mountain car, a Dubins car with obstacles, and a high input dimensional 2D arm, it produces similar or lower MPC costs than benchmark cross-entropy and path integral methods. On a physical cartpole, it performs swing-up and cart target following of the pole, using either a differential equation or multilayer perceptron as dynamics model. RPGD drives an F1TENTH simulated race car at near-optimal lap times and a real F1TENTH car in laps around a cluttered room. We study alterations of RPGD's building blocks to justify its composition. RPGD compute time in Python with TensorFlow optimization running on CPU is 2 to 4 times slower than the FORCESPRO commercial embedded solver.",
        "primary_area": "",
        "author": "Frederik Heetmeyer;Marcin Paluch;Diego Bolliger;Florian Bolli;Xiang Deng;Ennio Filicicchia;Tobi Delbruck;Frederik Heetmeyer;Marcin Paluch;Diego Bolliger;Florian Bolli;Xiang Deng;Ennio Filicicchia;Tobi Delbruck",
        "authorids": "/37089893561;/37088955596;/37089893819;/37089892280;/37089894531;/37089896084;/37269976700;/37089893561;/37088955596;/37089893819;/37089892280;/37089894531;/37089896084;/37269976700",
        "aff": "Sensors Group, Institute of Neuroinformatics, University of Zurich and ETH Zurich; Sensors Group, Institute of Neuroinformatics, University of Zurich and ETH Zurich; Sensors Group, Institute of Neuroinformatics, University of Zurich and ETH Zurich; Sensors Group, Institute of Neuroinformatics, University of Zurich and ETH Zurich; Sensors Group, Institute of Neuroinformatics, University of Zurich and ETH Zurich; Sensors Group, Institute of Neuroinformatics, University of Zurich and ETH Zurich; Sensors Group, Institute of Neuroinformatics, University of Zurich and ETH Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161233/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18082882857865768246&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Institute of Neuroinformatics",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161310",
        "title": "RTAW: An Attention Inspired Reinforcement Learning Method for Multi-Robot Task Allocation in Warehouse Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel reinforcement learning based algorithm for multi-robot task allocation problem in ware-house environments. We formulate it as a Markov Decision Process and solve via a novel deep multi-agent reinforcement learning method (called RTAW) with attention inspired policy architecture. Hence, our proposed policy network uses global embeddings that are independent of the number of robots/tasks. We utilize proximal policy optimization algorithm for training and use a carefully designed reward to obtain a converged policy. The converged policy ensures cooperation among different robots to minimize total travel delay (TTD) which ultimately improves the makespan for a sufficiently large task-list. In our extensive experiments, we compare the performance of our RTAW algorithm to state of the art methods such as myopic pickup distance minimization (greedy) and regret based baselines on different navigation schemes. We show an improvement of upto 14% (25\u20131000 seconds) in TTD on scenarios with hundreds or thousands of tasks for different challenging warehouse layouts and task generation schemes. We also demonstrate the scalability of our approach by showing performance with up to 1000 robots in simulations.",
        "primary_area": "",
        "author": "Aakriti Agrawal;Amrit Singh Bedi;Dinesh Manocha;Aakriti Agrawal;Amrit Singh Bedi;Dinesh Manocha",
        "authorids": "/37089660072;/37085892109;/37267825600;/37089660072;/37085892109;/37267825600",
        "aff": "The Department of Computer Science, University of Maryland, College Park, MD, USA; The Department of Computer Science, University of Maryland, College Park, MD, USA; The Department of Computer Science, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161310/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18064832764310488511&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Maryland, College Park",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161152",
        "title": "Radar Velocity Transformer: Single-scan Moving Object Segmentation in Noisy Radar Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "The awareness about moving objects in the surroundings of a self-driving vehicle is essential for safe and reliable autonomous navigation. The interpretation of LiDAR and camera data achieves exceptional results but typically requires to accumulate and process temporal sequences of data in order to extract motion information. In contrast, radar sensors, which are already installed in most recent vehicles, can overcome this limitation as they directly provide the Doppler velocity of the detections and, hence incorporate instantaneous motion information within a single measurement. In this paper, we tackle the problem of moving object segmentation in noisy radar point clouds. We also consider differentiating parked from moving cars, to enhance scene understanding. Instead of exploiting temporal dependencies to identify moving objects, we develop a novel transformer-based approach to perform single-scan moving object segmentation in sparse radar scans accurately. The key to our Radar Velocity Transformer is to incorporate the valuable velocity information throughout each module of the network, thereby enabling the precise segmentation of moving and non-moving objects. Additionally, we propose a transformer-based upsampling, which enhances the performance by adaptively combining information and over-coming the limitation of interpolation of sparse point clouds. Finally, we create a new radar moving object segmentation benchmark based on the RadarScenes dataset and compare our approach to other state-of-the-art methods. Our network runs faster than the frame rate of the sensor and shows superior segmentation results using only single-scan radar data.",
        "primary_area": "",
        "author": "Matthias Zeller;Vardeep S. Sandhu;Benedikt Mersch;Jens Behley;Michael Heidingsfeld;Cyrill Stachniss;Matthias Zeller;Vardeep S. Sandhu;Benedikt Mersch;Jens Behley;Michael Heidingsfeld;Cyrill Stachniss",
        "authorids": "/37089454213;/37089892915;/37088917207;/37593243900;/37090017810;/37329668600;/37089454213;/37089892915;/37088917207;/37593243900;/37090017810;/37329668600",
        "aff": "CARIAD SE, University of Bonn, Germany; CARIAD SE, University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; CARIAD, SE, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161152/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15777027760477747299&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "University of Bonn;CARIAD;Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": "CARIAD SE;SE;",
        "aff_unique_url": "https://www.uni-bonn.de;;",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161311",
        "title": "RangedIK: An Optimization-based Robot Motion Generation Method for Ranged-Goal Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating feasible robot motions in real-time requires achieving multiple tasks (i.e., kinematic requirements) simultaneously. These tasks can have a specific goal, a range of equally valid goals, or a range of acceptable goals with a preference toward a specific goal. To satisfy multiple and potentially competing tasks simultaneously, it is important to exploit the flexibility afforded by tasks with a range of goals. In this paper, we propose a real-time motion generation method that accommodates all three categories of tasks within a single, unified framework and leverages the flexibility of tasks with a range of goals to accommodate other tasks. Our method incorporates tasks in a weighted-sum multiple-objective optimization structure and uses barrier methods with novel loss functions to encode the valid range of a task. We demonstrate the effectiveness of our method through a simulation experiment that compares it to state-of-the-art alternative approaches, and by demonstrating it on a physical camera-in-hand robot that shows that our method enables the robot to achieve smooth and feasible camera motions.",
        "primary_area": "",
        "author": "Yeping Wang;Pragathi Praveena;Daniel Rakita;Michael Gleicher;Yeping Wang;Pragathi Praveena;Daniel Rakita;Michael Gleicher",
        "authorids": "/37086294504;/37085879978;/37085893032;/37282585700;/37086294504;/37085879978;/37085893032;/37282585700",
        "aff": "Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI, USA; Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI, USA; Department of Computer Science, Yale University, New Haven, CT, USA; Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161311/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6712992157383646302&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Wisconsin-Madison;Yale University",
        "aff_unique_dep": "Department of Computer Sciences;Department of Computer Science",
        "aff_unique_url": "https://www.wisc.edu;https://www.yale.edu",
        "aff_unique_abbr": "UW-Madison;Yale",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Madison;New Haven",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160732",
        "title": "ReachLipBnB: A branch-and-bound method for reachability analysis of neural autonomous systems using Lipschitz bounds",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel Branch-and-Bound method for reachability analysis of neural networks in both open-loop and closed-loop settings. Our idea is to first compute accurate bounds on the Lipschitz constant of the neural network in certain directions of interest offline using a convex program. We then use these bounds to obtain an instantaneous but conservative polyhedral approximation of the reachable set using Lipschitz continuity arguments. To reduce conservatism, we incorporate our bounding algorithm within a branching strategy to decrease the over-approximation error within an arbitrary accuracy. We then extend our method to reachability analysis of control systems with neural network controllers. Finally, to capture the shape of the reachable sets as accurately as possible, we use sample trajectories to inform the directions of the reachable set over-approximations using Principal Com-ponent Analysis (PCA). We evaluate the performance of the proposed method in several open-loop and closed-loop settings.",
        "primary_area": "",
        "author": "Taha Entesari;Sina Sharifi;Mahyar Fazlyab;Taha Entesari;Sina Sharifi;Mahyar Fazlyab",
        "authorids": "/37088634013;/37089893831;/37085444820;/37088634013;/37089893831;/37085444820",
        "aff": "Department of Electrical and Computer Engineering, Johns Hopkins University; Department of Electrical and Computer Engineering, Johns Hopkins University; Department of Electrical and Computer Engineering, Johns Hopkins University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160732/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12088470027625797042&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161474",
        "title": "Real World Offline Reinforcement Learning with Realistic Data Source",
        "track": "main",
        "status": "Poster",
        "abstract": "Offline reinforcement learning (ORL) holds great promise for robot learning due to its ability to learn from arbitrary pre-generated experience. However, current ORL benchmarks are almost entirely in simulation and utilize contrived datasets like replay buffers of online RL agents or sub-optimal trajectories, and thus hold limited relevance for real-world robotics. In this work (Real-ORL), we posit that data collected from safe operations of closely related tasks are more practical data sources for real-world robot learning. Under these settings, we perform an extensive (6500+ trajectories collected over 800+ robot hours and 270+ human labor hour) empirical study evaluating generalization and transfer capabilities of representative ORL methods on four real-world tabletop manipulation tasks. Our study finds that ORL and imitation learning prefer different action spaces, and that ORL algorithms can generalize from leveraging offline heterogeneous data sources and outperform imitation learning. We release our dataset and implementations at URL: https://sites.google.com/view/real-orl.",
        "primary_area": "",
        "author": "Gaoyue Zhou;Liyiming Ke;Siddhartha Srinivasa;Abhinav Gupta;Aravind Rajeswaran;Vikash Kumar;Gaoyue Zhou;Liyiming Ke;Siddhartha Srinivasa;Abhinav Gupta;Aravind Rajeswaran;Vikash Kumar",
        "authorids": "/37089895938;/37088688640;/37339877600;/37291130800;/37085870445;/37077886400;/37089895938;/37088688640;/37339877600;/37291130800;/37085870445;/37077886400",
        "aff": "Carnegie Mellon University; University of Washington; University of Washington; Carnegie Mellon University; Meta AI; Meta AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161474/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12911370759475426504&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;2;2",
        "aff_unique_norm": "Carnegie Mellon University;University of Washington;Meta Platforms, Inc.",
        "aff_unique_dep": ";;Meta AI",
        "aff_unique_url": "https://www.cmu.edu;https://www.washington.edu;https://meta.com",
        "aff_unique_abbr": "CMU;UW;Meta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161291",
        "title": "Real-Time Constrained 6D Object-Pose Tracking of An In-Hand Suture Needle for Minimally Invasive Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous suturing has been a long-sought-after goal for surgical robotics. Outside of staged environments, accurate localization of suture needles is a critical foundation for automating various suture needle manipulation tasks in the real world. When localizing a needle held by a gripper, previous work usually tracks them separately without considering their relationship. Because of the significant errors that can arise in the stereo-triangulation of objects and instruments, their reconstructions may often not be consistent. This can lead to unrealistic tool-needle grasp reconstructions that are infeasible. Instead, an obvious strategy to improve localization would be to leverage constraints that arise from contact, thereby constraining reconstructions of objects and instruments into a jointly feasible space. In this work, we consider feasible grasping constraints when tracking the 6D pose of an in-hand suture needle. We propose a reparameterization trick to define a new state space for describing a needle pose, where grasp constraints can be easily defined and satisfied. Our proposed state space and feasible grasping constraints are then incorporated into Bayesian filters for real-time needle localization. In the experiments, we show that our constrained methods outperform previous unconstrained tracking approaches and demonstrate the importance of incorporating feasible grasping constraints into automating suture needle manipulation tasks.",
        "primary_area": "",
        "author": "Zih-Yun Chiu;Florian Richter;Michael C. Yip;Zih-Yun Chiu;Florian Richter;Michael C. Yip",
        "authorids": "/37086357053;/37086936752;/37085382768;/37086357053;/37086936752;/37085382768",
        "aff": "Electrical and Computer Engineering Dept., University of California San Diego, La Jolla, CA, USA; Electrical and Computer Engineering Dept., University of California San Diego, La Jolla, CA, USA; Electrical and Computer Engineering Dept., University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161291/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5586234950560702103&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California San Diego",
        "aff_unique_dep": "Electrical and Computer Engineering Dept.",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160902",
        "title": "Real-Time Decentralized Navigation of Nonholonomic Agents Using Shifted Yielding Areas",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a lightweight, decentralized algorithm for navigating multiple nonholonomic agents through challenging environments with narrow passages. Our key idea is to allow agents to yield to each other in large open areas instead of narrow passages, to increase the success rate of conventional decentralized algorithms. At pre-processing time, our method computes a medial axis for the freespace. A reference trajectory is then computed and projected onto the medial axis for each agent. During run time, when an agent senses other agents moving in the opposite direction, our algorithm uses the medial axis to estimate a Point of Impact (POI) as well as the available area around the POI. If the area around the POI is not large enough for yielding behaviors to be successful, we shift the POI to nearby large areas by modulating the agent's reference trajectory and traveling speed. We evaluate our method on a row of 4 environments with up to 15 robots, and we find our method incurs a marginal computational overhead of 10\u201330 ms on average, achieving real-time performance. Afterward, our planned reference trajectories can be tracked using local navigation algorithms to achieve up to a 100% higher success rate over local navigation algorithms alone.",
        "primary_area": "",
        "author": "Liang He;Zherong Pan;Dinesh Manocha;Liang He;Zherong Pan;Dinesh Manocha",
        "authorids": "/37085756943;/37086067204;/37267825600;/37085756943;/37086067204;/37267825600",
        "aff": "University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill; University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160902/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1436269572017425387&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of North Carolina;University of Maryland",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.unc.edu;https://www/umd.edu",
        "aff_unique_abbr": "UNC;UMD",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Chapel Hill;College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160266",
        "title": "Real-Time Dense 3D Mapping of Underwater Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses real-time dense 3D reconstruction for a resource-constrained Autonomous Underwater Vehicle (AUV). Underwater vision-guided operations are among the most challenging as they combine 3D motion in the presence of external forces, limited visibility, and absence of global positioning. Obstacle avoidance and effective path planning require online dense reconstructions of the environment. Autonomous operation is central to environmental monitoring, marine archaeology, resource utilization, and underwater cave exploration. To address this problem, we propose to use SVIn2, a robust VIO method, together with a real-time 3D reconstruction pipeline. We provide extensive evaluation on four challenging underwater datasets. Our pipeline produces comparable reconstruction with that of COLMAP, the state-of-the-art offline 3D reconstruction method, at high frame rates on a single CPU.",
        "primary_area": "",
        "author": "Weihan Wang;Bharat Joshi;Nathaniel Burgdorfer;Konstantinos Batsosc;Alberto Quattrini Lid;Philippos Mordohaia;Ioannis Rekleitisb;Weihan Wang;Bharat Joshi;Nathaniel Burgdorfer;Konstantinos Batsosc;Alberto Quattrini Lid;Philippos Mordohaia;Ioannis Rekleitisb",
        "authorids": "/37090019357;/37087324582;/37089624343;/37089892953;/37089892132;/37089892820;/37089893017;/37090019357;/37087324582;/37089624343;/37089892953;/37089892132;/37089892820;/37089893017",
        "aff": "Stevens Institute of Technology, Hoboken, NJ, USA; University of South Carolina, Columbia, SC, USA; Stevens Institute of Technology, Hoboken, NJ, USA; latitude AI, Palo Alto, CA, USA; Dartmouth College, Hanover, NH, USA; Stevens Institute of Technology, Hoboken, NJ, USA; University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160266/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3268262092869414522&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;3;0;1",
        "aff_unique_norm": "Stevens Institute of Technology;University of South Carolina;latitude AI;Dartmouth College",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.stevens.edu;https://www.sc.edu;;https://www.dartmouth.edu",
        "aff_unique_abbr": "SIT;USC;;Dartmouth",
        "aff_campus_unique_index": "0;1;0;2;3;0;1",
        "aff_campus_unique": "Hoboken;Columbia;Palo Alto;Hanover",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160770",
        "title": "Real-Time Estimation of Walking Speed and Stride Length Using an IMU Embedded in a Robotic Hip Exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "Gait parameters, including walking speed and stride length, are crucial indicators of health status and rehabilitation progress for individuals using wearable robots for exercise or rehabilitation. These metrics play a crucial role in monitoring progress and adjusting training programs, thereby fostering greater engagement in the training. In this paper, we present methods for estimating walking speed and stride length using sensors in wearable hip exoskeleton GEMS-H. Our study collected data from 79 middle-aged healthy individuals walking on a treadmill while wearing GEMS-H under various assistance conditions. To estimate walking speed, we evaluated linear regression models, deep neural networks, and ensemble models using different combinations of joint encoders and an IMU in the GEMS-H hip exoskeleton to form various sets of features. The ensemble of deep neural networks using only 6-DOF IMU signals as features achieved the lowest root-mean-square error (RMSE) for walking speed estimation, which was 0.066 m/s. We also present an algorithm for real-time stride length estimation, building on one of the speed estimation models. The speed and stride length estimation model was tested on 12 middle-aged healthy subjects walking in GEMS-H overground, yielding an RMSE of 0.060 m/s for speed and 7.1 cm for stride length.",
        "primary_area": "",
        "author": "Keehong Seo;Keehong Seo",
        "authorids": "/38251643300;/38251643300",
        "aff": "Samsung Research, Samsung Electronics, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160770/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13132457625324959625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Samsung Electronics",
        "aff_unique_dep": "Samsung Research",
        "aff_unique_url": "https://www.samsung.com",
        "aff_unique_abbr": "Samsung",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160595",
        "title": "Real-Time Fast Marching Tree for Mobile Robot Motion Planning in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes the Real-Time Fast Marching Tree (RT-FMT), a real-time planning algorithm that features local and global path generation, multiple-query planning, and dynamic obstacle avoidance. During the search, RT-FMT quickly looks for the global solution and, in the meantime, generates local paths that can be used by the robot to start execution faster. In addition, our algorithm constantly rewires the tree to keep branches from forming inside the dynamic obstacles and to maintain the tree root near the robot, which allows the tree to be reused multiple times for different goals. Our algorithm is based on the planners Fast Marching Tree (FMT*) and Real-time Rapidly-Exploring Random Tree (RT-RRT*). We show via simulations that RT-FMT outperforms RT- RRT* in both execution cost and arrival time, in most cases. Moreover, we also demonstrate via simulation that it is worthwhile taking the local path before the global path is available in order to reduce arrival time, even though there is a small possibility of taking an inferior path.",
        "primary_area": "",
        "author": "Jefferson Silveira;Kleber Cabral;Sidney Givigi;Joshua A. Marshall;Jefferson Silveira;Kleber Cabral;Sidney Givigi;Joshua A. Marshall",
        "authorids": "/37085667413;/37086171547;/37276446800;/37269656200;/37085667413;/37086171547;/37276446800;/37269656200",
        "aff": "Department of Electrical & Computer Engineering, Ingenuity Labs Research Institute, Queen's University, Kingston, ON, Canada; School of Computing, Queen's University, Kingston, ON, Canada; School of Computing and the Ingenuity Labs Research Institute, Queen's University, Kingston, ON, Canada; Department of Electrical & Computer Engineering, Ingenuity Labs Research Institute, Queen's University, Kingston, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160595/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9988052892978757775&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Queen's University",
        "aff_unique_dep": "Department of Electrical & Computer Engineering",
        "aff_unique_url": "https://www.queensu.ca",
        "aff_unique_abbr": "Queen's U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kingston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161529",
        "title": "Real-Time Generative Grasping with Spatio-temporal Sparse Convolution",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots performing mobile manipulation in unstructured environments must identify grasp affordances quickly and with robustness to perception noise. Yet in domains such as underwater manipulation, where perception noise is severe, computation is constrained, and the environment is dynamic, existing techniques fail. They are too computationally demanding, or too sensitive to noise to allow for closed loop grasping or dynamic replanning, or do not consider 6-DOF grasps. We present a novel grasp synthesis network, TSGrasp, that uses spatio-temporal sparse convolution to process a streaming point cloud in real time. The network generates 6-DOF grasps at greater speed and with less memory than Contact GraspNet, a state-of-the-art algorithm based on Point-Net++. By considering information from multiple successive frames of depth video, TSGrasp boosts robustness to noise or temporary self-occlusion and allows more grasps to be rapidly identified. Our grasp synthesis system was successfully demonstrated in an underwater environment with a Blueprint Labs Bravo robotic arm.",
        "primary_area": "",
        "author": "Timothy R. Player;Dongsik Chang;Li Fuxin;Geoffrey A. Hollinger;Timothy R. Player;Dongsik Chang;Li Fuxin;Geoffrey A. Hollinger",
        "authorids": "/37089550665;/37086937241;/37085538985;/37543482700;/37089550665;/37086937241;/37085538985;/37543482700",
        "aff": "Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161529/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14124336402613078314&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161138",
        "title": "Real-Time Model Predictive Control for Industrial Manipulators with Singularity-Tolerant Hierarchical Task Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a real-time model predictive control (MPC) strategy for accomplishing multiple tasks using robots within a finite-time horizon. In industrial robotic applications, it is crucial to consider various constraints to ensure that joint position, velocity, and torque limits are not exceeded. In addition, singularity-free and smooth motions require executing tasks continuously and safely. Instead of formulating nonlinear MPC problems, we devise linear MPC problems using kinematic and dynamic models linearized along nominal trajectories produced by hierarchical controllers. These linear MPC problems are solvable via the use of Quadratic Pro-gramming; therefore, we significantly reduce the computation time of the proposed MPC framework so the resulting update frequency is higher than 1 kHz. Our proposed MPC framework is more efficient in reducing task tracking errors than a baseline based on operational space control (OSC). We validate our approach in numerical simulations and in real experiments using an industrial manipulator. More specifically, we deploy our method in two practical scenarios for robotic logistics: 1) controlling a robot carrying heavy payloads while accounting for torque limits, and 2) controlling the end-effector while avoiding singularities.",
        "primary_area": "",
        "author": "Jaemin Lee;Mingyo Seo;Andrew Bylard;Robert Sun;Luis Sentis;Jaemin Lee;Mingyo Seo;Andrew Bylard;Robert Sun;Luis Sentis",
        "authorids": "/37089938907;/37086119481;/37085786338;/37089891942;/37426747500;/37089938907;/37086119481;/37085786338;/37089891942;/37426747500",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; University of Texas at Austin, Austin, TX, USA; Dexterity Inc, Redwood City, CA, USA; Dexterity Inc, Redwood City, CA, USA; University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161138/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12067931671054989055&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;1",
        "aff_unique_norm": "California Institute of Technology;University of Texas at Austin;Dexterity Inc",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering;;",
        "aff_unique_url": "https://www.caltech.edu;https://www.utexas.edu;",
        "aff_unique_abbr": "Caltech;UT Austin;",
        "aff_campus_unique_index": "0;1;2;2;1",
        "aff_campus_unique": "Pasadena;Austin;Redwood City",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161044",
        "title": "Real-Time Navigation for Autonomous Surface Vehicles In Ice-Covered Waters",
        "track": "main",
        "status": "Poster",
        "abstract": "Vessel transit in ice-covered waters poses unique challenges in safe and efficient motion planning. When the concentration of ice is high, it may not be possible to find collision-free trajectories. Instead, ice can be pushed out of the way if it is small or if contact occurs near the edge of the ice. In this work, we propose a real-time navigation framework that minimizes collisions with ice and distance travelled by the vessel. We exploit a lattice-based planner with a cost that captures the ship interaction with ice. To address the dynamic nature of the environment, we plan motion in a receding horizon manner based on updated vessel and ice state information. Further, we present a novel planning heuristic for evaluating the cost-to-go, which is applicable to navigation in a channel without a fixed goal location. The performance of our planner is evaluated across several levels of ice concentration both in simulated and in real-world experiments.",
        "primary_area": "",
        "author": "Rodrigue de Schaetzen;Alexander Botros;Robert Gash;Kevin Murrant;Stephen L. Smith;Rodrigue de Schaetzen;Alexander Botros;Robert Gash;Kevin Murrant;Stephen L. Smith",
        "authorids": "/37089892034;/37086438755;/37085385113;/37088567547;/37335139700;/37089892034;/37086438755;/37085385113;/37088567547;/37335139700",
        "aff": "Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; National Research Council, Canada; National Research Council, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161044/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2503146375472337654&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Waterloo;National Research Council",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://uwaterloo.ca;https://www.nrc-cnrc.gc.ca",
        "aff_unique_abbr": "UW;NRC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Waterloo;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160684",
        "title": "Real-Time Reinforcement Learning for Vision-Based Robotics Utilizing Local and Remote Computers",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time learning is crucial for robotic agents adapting to ever-changing, non-stationary environments. A common setup for a robotic agent is to have two different computers simultaneously: a resource-limited local computer tethered to the robot and a powerful remote computer connected wirelessly. Given such a setup, it is unclear to what extent the performance of a learning system can be affected by resource limitations and how to efficiently use the wirelessly connected powerful computer to compensate for any performance loss. In this paper, we implement a real-time learning system called the Remote-Local Distributed (ReLoD) system to distribute computations of two deep reinforcement learning (RL) algorithms, Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO), between a local and a remote computer. The performance of the system is evaluated on two vision-based control tasks developed using a robotic arm and a mobile robot. Our results show that SAC's performance degrades heavily on a resource-limited local computer. Strikingly, when all computations of the learning system are deployed on a remote workstation, SAC fails to compensate for the performance loss, indicating that, without careful consideration, using a powerful remote computer may not result in performance improvement. However, a carefully chosen distribution of computations of SAC consistently and substantially improves its performance on both tasks. On the other hand, the performance of PPO remains largely unaffected by the distribution of computations. In addition, when all computations happen solely on a powerful tethered computer, the performance of our system remains on par with an existing system that is well-tuned for using a single machine. ReLoD is the only publicly available system for real-time RL that applies to multiple robots for vision-based tasks. The source code can be found at https://github.com/rlai-lab/relod",
        "primary_area": "",
        "author": "Yan Wang;Gautham Vasan;A. Rupam Mahmood;Yan Wang;Gautham Vasan;A. Rupam Mahmood",
        "authorids": "/37089157035;/37085743473;/37408373700;/37089157035;/37085743473;/37408373700",
        "aff": "Department of Computing Science, University of Alberta, Edmonton, AB., Canada; Department of Computing Science, University of Alberta, Edmonton, AB., Canada; CIFAR AI Chair, Alberta Machine Intelligence Institute (Amii)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160684/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7538052330726501677&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Alberta;Alberta Machine Intelligence Institute",
        "aff_unique_dep": "Department of Computing Science;AI Chair",
        "aff_unique_url": "https://www.ualberta.ca;https://www.amii.ca",
        "aff_unique_abbr": "UAlberta;Amii",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edmonton;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160713",
        "title": "Real-Time Simultaneous Localization and Mapping with LiDAR Intensity",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel real-time LiDAR intensity image-based simultaneous localization and mapping method, which addresses the geometry degeneracy problem in un-structured environments. Traditional LiDAR-based front-end odometry mostly relies on geometric features such as points, lines and planes. A lack of these features in the environment can lead to the failure of the entire odometry system. To avoid this problem, we extract feature points from the LiDAR-generated point cloud that match features identified in LiDAR intensity images. We then use the extracted feature points to perform scan registration and estimate the robot ego-movement. For the back-end, we jointly optimize the distance between the corresponding feature points, and the point to plane distance for planes identified in the map. In addition, we use the features extracted from intensity images to detect loop closure candidates from previous scans and perform pose graph optimization. Our experiments show that our method can run in real time with high accuracy and works well with illumination changes, low-texture, and unstructured environments.",
        "primary_area": "",
        "author": "Wenqiang Du;Giovanni Beltrame;Wenqiang Du;Giovanni Beltrame",
        "authorids": "/37089894258;/37295768000;/37089894258;/37295768000",
        "aff": "Department of Computer Engineering and Software Engineering, Polytechnique Montreal, University of Montreal, Montreal, QC, Canada; Department of Computer Engineering and Software Engineering, Polytechnique Montreal, University of Montreal, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160713/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11944173246234909368&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Polytechnique Montreal",
        "aff_unique_dep": "Department of Computer Engineering and Software Engineering",
        "aff_unique_url": "https://www.polymtl.ca",
        "aff_unique_abbr": "Polytechnique Montreal",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160577",
        "title": "Real-Time Unified Trajectory Planning and Optimal Control for Urban Autonomous Driving Under Static and Dynamic Obstacle Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory planning and control have historically been separated into two modules in automated driving stacks. Trajectory planning focuses on higher-level tasks like avoiding obstacles and staying on the road surface, whereas the controller tries its best to follow an ever changing reference trajectory. We argue that this separation is (1) flawed due to the mismatch between planned trajectories and what the controller can feasibly execute, and (2) unnecessary due to the flexibility of the model predictive control (MPC) paradigm. Instead, in this paper, we present a unified MPC-based trajectory planning and control scheme that guarantees feasibility with respect to road boundaries, the static and dynamic environment, and enforces passenger comfort constraints. The scheme is evaluated rigorously in a variety of scenarios focused on proving the effectiveness of the optimal control problem (OCP) design and real-time solution methods. The prototype code will be released at github.com/WATonomous/control.",
        "primary_area": "",
        "author": "Rowan Dempster;Mohammad Al-Sharman;Derek Rayside;William Melek;Rowan Dempster;Mohammad Al-Sharman;Derek Rayside;William Melek",
        "authorids": "/37089446930;/37085354251;/37316266400;/38536080800;/37089446930;/37085354251;/37316266400;/38536080800",
        "aff": "WATonomous lab, University of Waterloo, ON, Canada; WATonomous lab, University of Waterloo, ON, Canada; WATonomous lab, University of Waterloo, ON, Canada; WATonomous lab, University of Waterloo, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160577/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6129894239936025577&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "WATonomous lab",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Waterloo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160962",
        "title": "Real-time Acoustic Holography with Iterative Unsupervised Learning for Acoustic Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Phase-only acoustic holography is a fundamental and promising technique for contactless robotic manipulation. Through independently controlling phase-only hologram (POH) of phase array of transducers (PAT) and simultaneously driving each channel by sophisticated circuits, a certain acoustic field is dynamically generated in working medium (e.g., air, water or biological tissues) at certain moment. The phase profile of PAT is required dynamically and precisely as per arbitrary expected acoustic field for the sake of versatile and stable robotic manipulation. However, the most conventional methods rely on iterative optimization algorithms which are inevitably time-consuming and probably non-convergent, moreover hindering versatility and fidelity of acoustic robotic manipulation. To address these issues, this paper reports a real-time phase-only acoustic holography algorithm by virtue of iterative unsupervised learning. Using a physics model to construct two queues, which we refer to as experience pools, data pairs consisting of a target acoustic amplitude hologram in expected acoustic field and corresponding POH of PAT are collected on-the-fly, circumventing costly preparation of annotated dataset in advance. With iterative learning between neural network training and experience pools update, both the solution of objective inverse mapping and the adaptation for arbitrary desired acoustic field are mutually enhanced. The experiments and results validated that the proposed approach surpasses previous algorithms in terms of real time and precision.",
        "primary_area": "",
        "author": "Chengxi Zhong;Zhenhuan Sun;Teng Li;Hu Su;Song Liu;Chengxi Zhong;Zhenhuan Sun;Teng Li;Hu Su;Song Liu",
        "authorids": "/37089190390;/37089624706;/37089626327;/37965624300;/37089083036;/37089190390;/37089624706;/37089626327;/37965624300;/37089083036",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Chinese Academy of Sciences, Institute of Automation, Beijing, China; Shanghai Engineering Research Center of Intelligent Vision and Imaging, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160962/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8295287571451125080&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "ShanghaiTech University;Chinese Academy of Sciences;Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "aff_unique_dep": "School of Information Science and Technology;Institute of Automation;",
        "aff_unique_url": "https://www.shanghaitech.edu.cn;http://www.ia.cas.cn;",
        "aff_unique_abbr": "ShanghaiTech;CAS;",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Shanghai;Beijing;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160223",
        "title": "Real-time Background Subtraction under Varying Lighting Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "Background subtraction is an important topic in computer vision and video analysis. It is challenging to robustly segment foreground and background in complex scenarios. In the literature there are efforts to address some of the main challenges such as illumination change, dynamic backgrounds, hard shadows, and intermittent object motion. However, most of the research has focused on applying advanced mathematical and machine learning models rather than on improving performance in real-time applications. In this paper, we devise a method named EGMM to efficiently handle the illumination change problem and also operate at a real-time execution speed on commodity PC hardware. EGMM is an ensemble algorithm that fuses multiple Gaussian Mixture Models operating on gradient, texture and color features. Detection and removal of shadows is done using a chromaticity-based approach, and spatio-temporal history of foreground blobs is used to handle intermittent object motion. We benchmarked EGMM by creating datasets for two light change scenarios. The results demonstrate that EGMM achieves robust performance in complex illumination change cases, outperforms some state-of-the-art algorithms, and runs at 100 fps (GPU) at 1280\\times7201280\\times720 resolution. Moreover, experiments using the 2012 CDnet dataset show that EGMM achieves generally good performance in varying scenes with overall results better than conventional methods and runs at 1000 fps (GPU) at 320\\times 240320\\times 240 resolution.",
        "primary_area": "",
        "author": "Sisi Liang;Darren Baker;Sisi Liang;Darren Baker",
        "authorids": "/37089895087;/37089895038;/37089895087;/37089895038",
        "aff": "Robotics and Autonomous Systems Group, Data61, CSIRO, Brisbane, QLD, Australia; Robotics and Autonomous Systems Group, Data61, CSIRO, Brisbane, QLD, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160223/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9879783725770509112&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "CSIRO",
        "aff_unique_dep": "Robotics and Autonomous Systems Group",
        "aff_unique_url": "https://www.csiro.au",
        "aff_unique_abbr": "CSIRO",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160654",
        "title": "Real-time event simulation with frame-based cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Event cameras are becoming increasingly popular in robotics and computer vision due to their beneficial properties, e.g., high temporal resolution, high bandwidth, almost no motion blur, and low power consumption. However, these cameras remain expensive and scarce in the market, making them inaccessible to the majority. Using event simulators minimizes the need for real event cameras to develop novel algorithms. However, due to the computational complexity of the simulation, the event streams of existing simulators cannot be generated in real-time but rather have to be pre-calculated from existing video sequences or pre-rendered and then simulated from a virtual 3D scene. Although these offline generated event streams can be used as training data for learning tasks, all response time dependent applications cannot benefit from these simulators yet, as they still require an actual event camera. This work proposes simulation methods that improve the performance of event simulation by two orders of magnitude (making them real-time capable) while remaining competitive in the quality assessment.",
        "primary_area": "",
        "author": "Andreas Ziegler;Daniel Teigland;Jonas Tebbe;Thomas Gossard;Andreas Zell;Andreas Ziegler;Daniel Teigland;Jonas Tebbe;Thomas Gossard;Andreas Zell",
        "authorids": "/37089895130;/37089892657;/37086806680;/37089894184;/37276583400;/37089895130;/37089892657;/37086806680;/37089894184;/37276583400",
        "aff": "Dept. Informatics, Cognitive Systems Group, University of Tuebingen; Dept. Informatics, Cognitive Systems Group, University of Tuebingen; Dept. Informatics, Cognitive Systems Group, University of Tuebingen; Dept. Informatics, Cognitive Systems Group, University of Tuebingen; Dept. Informatics, Cognitive Systems Group, University of Tuebingen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160654/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3327112426631016977&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tuebingen",
        "aff_unique_dep": "Dept. Informatics, Cognitive Systems Group",
        "aff_unique_url": "https://www.uni-tuebingen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160303",
        "title": "Rearrange Indoor Scenes for Human-Robot Co-Activity",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an optimization-based framework for rearranging indoor furniture to accommodate human-robot co-activities better. The rearrangement aims to afford sufficient accessible space for robot activities without compromising everyday human activities. To retain human activities, our algorithm preserves the functional relations among furniture by integrating spatial and semantic co-occurrence extracted from SUNCG and ConceptNet, respectively. By defining the robot's accessible space by the amount of open space it can traverse and the number of objects it can reach, we formulate the rearrangement for human-robot co-activity as an optimization problem, solved by adaptive simulated annealing (ASA) and covariance matrix adaptation evolution strategy (CMA-ES). Our experiments on the SUNCG dataset quantitatively show that rearranged scenes provide a robot with 14% more accessible space and 30% more objects to interact with on average. The quality of the rearranged scenes is qualitatively validated by a human study, indicating the efficacy of the proposed strategy.",
        "primary_area": "",
        "author": "Weiqi Wang;Zihang Zhao;Ziyuan Jiao;Yixin Zhu;Song-Chun Zhu;Hangxin Liu;Weiqi Wang;Zihang Zhao;Ziyuan Jiao;Yixin Zhu;Song-Chun Zhu;Hangxin Liu",
        "authorids": "/37089196788;/37089895011;/37085784268;/37086172463;/37281407500;/37086274715;/37089196788;/37089895011;/37085784268;/37086172463;/37281407500;/37086274715",
        "aff": "UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); College of Engineering, Peking University; National Key Laboratory of General Artificial Intelligence, Beijing Institute for General Artificial Intelligence (BIGAI); Institute for Artificial Intelligence, Peking University; Institute for Artificial Intelligence, Peking University; National Key Laboratory of General Artificial Intelligence, Beijing Institute for General Artificial Intelligence (BIGAI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160303/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14662252154105013034&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;1;2",
        "aff_unique_norm": "University of California, Los Angeles;Peking University;Beijing Institute for General Artificial Intelligence",
        "aff_unique_dep": "Center for Vision, Cognition, Learning, and Autonomy;College of Engineering;National Key Laboratory of General Artificial Intelligence",
        "aff_unique_url": "https://www.ucla.edu;http://www.pku.edu.cn;http://www.bigmodel.cn/",
        "aff_unique_abbr": "UCLA;Peking U;BIGAI",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "10160622",
        "title": "Receding Horizon Planning with Rule Hierarchies for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles must often contend with conflicting planning requirements, e.g., safety and comfort could be at odds with each other if avoiding a collision calls for slamming the brakes. To resolve such conflicts, assigning importance ranking to rules (i.e., imposing a rule hierarchy) has been proposed, which, in turn, induces rankings on trajectories based on the importance of the rules they satisfy. On one hand, imposing rule hierarchies can enhance interpretability, but introduce combinatorial complexity to planning; while on the other hand, differentiable reward structures can be leveraged by modern gradient-based optimization tools, but are less interpretable and unintuitive to tune. In this paper, we present an approach to equivalently express rule hierar-chies as differentiable reward structures amenable to modern gradient-based optimizers, thereby, achieving the best of both worlds. We achieve this by formulating rank-preserving reward functions that are monotonic in the rank of the trajectories induced by the rule hierarchy; i.e., higher ranked trajectories receive higher reward. Equipped with a rule hierarchy and its corresponding rank-preserving reward function, we develop a two-stage planner that can efficiently resolve conflicting planning requirements. We demonstrate that our approach can generate motion plans in ~7-10 Hz for various challenging road navigation and intersection negotiation scenarios.",
        "primary_area": "",
        "author": "Sushant Veer;Karen Leung;Ryan K. Cosner;Yuxiao Chen;Peter Karkus;Marco Pavone;Sushant Veer;Karen Leung;Ryan K. Cosner;Yuxiao Chen;Peter Karkus;Marco Pavone",
        "authorids": "/37085702725;/37086453267;/37088901068;/37088427220;/37085591628;/37307912900;/37085702725;/37086453267;/37088901068;/37088427220;/37085591628;/37307912900",
        "aff": "NVIDIA Research; University of Washington and NVIDIA Research; California Institute of Technology; NVIDIA Research; NVIDIA Research; Stanford University and NVIDIA Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160622/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1075909173283887853&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;3",
        "aff_unique_norm": "NVIDIA Corporation;University of Washington;California Institute of Technology;Stanford University",
        "aff_unique_dep": "NVIDIA Research;;;",
        "aff_unique_url": "https://www.nvidia.com/research;https://www.washington.edu;https://www.caltech.edu;https://www.stanford.edu",
        "aff_unique_abbr": "NVIDIA;UW;Caltech;Stanford",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Pasadena;Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160569",
        "title": "Reconfigurable Inflated Soft Arms",
        "track": "main",
        "status": "Poster",
        "abstract": "Inflatable structures have attracted considerable research attention in many fields owing to their numerous advantages, such as being light and able to engage in interactions safely. However, in most cases, the inflatable structure can only have one stable configuration, which is undesirable for robotic arms. This study proposes a novel inflatable structure that can be easily reconfigured into multiple stable configurations, even with single-body inflation. In the proposed mechanism, the structure length can be freely adjusted, and its respective joints can be set in the desired directions to facilitate the reconfiguration of its pose. An additional advantage of the proposed mechanism is that it can withstand external forces as well as its own weight. This study analyzes and experimentally validates the shape locking and load-carrying properties of the proposed mechanism. Further, the fabrication process and design guidelines for the proposed mechanism are presented. Through a suitable demonstration, the proposed mechanism is shown to exhibit multiple stable configurations and lock its poses.",
        "primary_area": "",
        "author": "Nam Gyun Kim;Jee-Hwan Ryu;Nam Gyun Kim;Jee-Hwan Ryu",
        "authorids": "/37089281823;/37274994300;/37089281823;/37274994300",
        "aff": "Robotics Program, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Civil and Environmental Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160569/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:0t3ja20DJWYJ:scholar.google.com/&scioq=Reconfigurable+Inflated+Soft+Arms&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Robotics Program",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160535",
        "title": "Reconstructing Objects in-the-wild for Realistic Sensor Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Reconstructing objects from real world data and rendering them at novel views is critical to bringing realism, diversity and scale to simulation for robotics training and testing. In this work, we present NeuSim, a novel approach that estimates accurate geometry and realistic appearance from sparse in-the-wild data captured at distance and at limited viewpoints. Towards this goal, we represent the object surface as a neural signed distance function and leverage both LiDAR and camera sensor data to reconstruct smooth and accurate geometry and normals. We model the object appearance with a robust physics-inspired reflectance representation effective for in-the-wild data. Our experiments show that NeuSim has strong view synthesis performance on challenging scenarios with sparse training views. Furthermore, we showcase composing NeuSim assets into a virtual world and generating realistic multi-sensor data for evaluating self-driving perception models. The supplementary material can be found at the project website: https://waabi.ai/research/neusim/",
        "primary_area": "",
        "author": "Ze Yang;Sivabalan Manivasagam;Yun Chen;Jingkang Wang;Rui Hu;Raquel Urtasun;Ze Yang;Sivabalan Manivasagam;Yun Chen;Jingkang Wang;Rui Hu;Raquel Urtasun",
        "authorids": "/37089013341;/37086687618;/37089012045;/37086565842;/37087232841;/37269502900;/37089013341;/37086687618;/37089012045;/37086565842;/37087232841;/37269502900",
        "aff": "University of Toronto; University of Toronto; University of Toronto; University of Toronto; Waabi; University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160535/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9328142936236870624&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Toronto;Waabi",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utoronto.ca;",
        "aff_unique_abbr": "U of T;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada;"
    },
    {
        "id": "10161362",
        "title": "Reinforced Learning for Label-Efficient 3D Face Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "3D face reconstruction plays a major role in many human-robot interaction systems, from automatic face authentication to human-computer interface-based entertainment. To improve robustness against occlusions and noise, 3D face reconstruction networks are often trained on a set of in-the-wild face images preferably captured along different viewpoints of the subject. However, collecting the required large amounts of 3D annotated face data is expensive and time-consuming. To address the high annotation cost and due to the importance of training on a useful set, we propose an Active Learning (AL) framework that actively selects the most informative and representative samples to be labeled. To the best of our knowledge, this paper is the first work on tackling active learning for 3D face reconstruction to enable a label-efficient training strategy. In particular, we propose a Reinforcement Active Learning approach in conjunction with a clustering-based pooling strategy to select informative view-points of the subjects. Experimental results on 300W-LP and AFLW2000 datasets demonstrate that our proposed method is able to 1) efficiently select the most influencing view-points for labeling and outperforms several baseline AL techniques and 2) further improve the performance of a 3D Face Reconstruction network trained on the full dataset.",
        "primary_area": "",
        "author": "Hoda Mohaghegh;Hossein Rahmani;Hamid Laga;Farid Boussaid;Mohammed Bennamoun;Hoda Mohaghegh;Hossein Rahmani;Hamid Laga;Farid Boussaid;Mohammed Bennamoun",
        "authorids": "/37085453818;/37302971100;/37267963300;/37265532500;/37284017200;/37085453818;/37302971100;/37267963300;/37265532500;/37284017200",
        "aff": "School of Computer Science and Software Engineering, University of Western Australia, Australia; Department of Computing and Communications, Lancaster University, England; Information Technology Discipline, Murdoch University, Australia; School of Engineering, Electrical, Electronic and Computer Engineering, University of Western Australia, Australia; School of Computer Science and Software Engineering, University of Western Australia, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161362/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6923043844661530540&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "University of Western Australia;Lancaster University;Murdoch University",
        "aff_unique_dep": "School of Computer Science and Software Engineering;Department of Computing and Communications;Information Technology Discipline",
        "aff_unique_url": "https://www.uwa.edu.au;https://www.lancaster.ac.uk;https://www.murdoch.edu.au",
        "aff_unique_abbr": "UWA;;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Australia;United Kingdom"
    },
    {
        "id": "10160491",
        "title": "Reinforcement Learning Based Pushing and Grasping Objects from Ungraspable Poses",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping an object when it is in an ungraspable pose is a challenging task, such as books or other large flat objects placed horizontally on a table. Inspired by human manipulation, we address this problem by pushing the object to the edge of the table and then grasping it from the hanging part. In this paper, we develop a model-free Deep Reinforcement Learning framework to synergize pushing and grasping actions. We first pre-train a Variational Autoencoder to extract high-dimensional features of input scenario images. One Proximal Policy Optimization algorithm with the common reward and sharing layers of Actor-Critic is employed to learn both pushing and grasping actions with high data efficiency. Experiments show that our one network policy can converge 2.5 times faster than the policy using two parallel networks. Moreover, the experiments on unseen objects show that our policy can generalize to the challenging case of objects with curved surfaces and off-center irregularly shaped objects. Lastly, our policy can be transferred to a real robot without fine-tuning by using CycleGAN for domain adaption and outperforms the push-to-wall baseline.",
        "primary_area": "",
        "author": "Hao Zhang;Hongzhuo Liang;Lin Cong;Jianzhi Lyu;Long Zeng;Pingfa Feng;Jianwei Zhang;Hao Zhang;Hongzhuo Liang;Lin Cong;Jianzhi Lyu;Long Zeng;Pingfa Feng;Jianwei Zhang",
        "authorids": "/37089892966;/37086700920;/37088686324;/37087323631;/37087324062;/37667473200;/37281460600;/37089892966;/37086700920;/37088686324;/37087323631;/37087324062;/37667473200;/37281460600",
        "aff": "Dept. of Informatics, Group TAMS, Universit\u00e4t Hamburg; Dept. of Informatics, Group TAMS, Universit\u00e4t Hamburg; Dept. of Informatics, Group TAMS, Universit\u00e4t Hamburg; Dept. of Informatics, Group TAMS, Universit\u00e4t Hamburg; Division of Advanced Manufacturing, Shenzhen International Graduate School, Tsinghua University; Division of Advanced Manufacturing, Shenzhen International Graduate School, Tsinghua University; Dept. of Informatics, Group TAMS, Universit\u00e4t Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160491/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14180735919029584446&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;0",
        "aff_unique_norm": "Universit\u00e4t Hamburg;Tsinghua University",
        "aff_unique_dep": "Dept. of Informatics, Group TAMS;Division of Advanced Manufacturing",
        "aff_unique_url": "https://www.uni-hamburg.de;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": ";THU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;0;0;0;1;1;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "10160498",
        "title": "Reinforcement Learning Control of a Reconfigurable Planar Cable Driven Parallel Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Cable driven parallel robots (CDPRs) are often challenging to model and to dynamically control due to the inherent flexibility and elasticity of the cables. The additional inclusion of online geometric reconfigurability to a CDPR results in a complex underdetermined system with highly non-linear dynamics. The necessary (numerical) redundancy resolution requires multiple layers of optimization rendering its application computationally prohibitive for real-time control. Here, deep reinforcement learning approaches can offer a model-free framework to overcome these challenges and can provide a real-time capable dynamic control. This study discusses three settings for a model-free DRL implementation in dynamic trajectory tracking: (i) for a standard non-redundant CDPR with a fixed workspace; (ii) in an end-to-end setting with redundancy resolution on a reconfigurable CDPR; and (iii) in a decoupled approach resolving kinematic and actuation redundancies individually.",
        "primary_area": "",
        "author": "Adhiti Raman;Ameya Salvi;Matthias Schmid;Venkat Krovi;Adhiti Raman;Ameya Salvi;Matthias Schmid;Venkat Krovi",
        "authorids": "/37089892063;/37089893999;/37089895957;/37281399700;/37089892063;/37089893999;/37089895957;/37281399700",
        "aff": "Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC; Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC; Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC; Department of Automotive Engineering, Clemson University International Center for Automotive Research (CU-ICAR), Greenville, SC",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160498/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10243664769809268648&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Clemson University",
        "aff_unique_dep": "Department of Automotive Engineering",
        "aff_unique_url": "https://www.clemson.edu",
        "aff_unique_abbr": "Clemson",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Greenville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161334",
        "title": "Reinforcement Learning for Laser Welding Speed Control Minimizing Bead Width Error",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a method for reinforcement learning-based laser welding control. Conventional methods apply standard reinforcement learning formulations to welding tasks, but we show that this formulation can minimize bead width or penetration depth errors only when the welding speed is constant. Therefore, conventional methods are suboptimal for training control parameters including the welding speed. The proposed method discounts future rewards with respect to the welding length instead of time steps to solve this issue. This is easily implemented by (1) modifying the discount factor used for QQ-function updates in existing reinforcement learning algorithms and (2) using an appropriate reward function. Experimental results using simulators show that the proposed method achieves performance that is superior to conventional methods.",
        "primary_area": "",
        "author": "Toshimitsu Kaneko;Gaku Minamoto;Yusuke Hirose;Tetsuo Sakai;Toshimitsu Kaneko;Gaku Minamoto;Yusuke Hirose;Tetsuo Sakai",
        "authorids": "/38560162700;/37089893626;/37089895049;/37089892791;/38560162700;/37089893626;/37089895049;/37089892791",
        "aff": "Media AI Laboratory, Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Media AI Laboratory, Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Optics & Inspection Technology Research Department, Corporate Manufacturing Engineering Center, Toshiba Corporation, Yokohama, Japan; Optics & Inspection Technology Research Department, Corporate Manufacturing Engineering Center, Toshiba Corporation, Yokohama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161334/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2804381081548260058&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Toshiba Corporation",
        "aff_unique_dep": "Media AI Laboratory",
        "aff_unique_url": "https://www.toshiba.co.jp",
        "aff_unique_abbr": "Toshiba",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Kawasaki;Yokohama",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160991",
        "title": "Reinforcement Learning for Safe Robot Control using Control Lyapunov Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) exhibits impressive performance when managing complicated control tasks for robots. However, its wide application to physical robots is limited by the absence of strong safety guarantees. To overcome this challenge, this paper explores the control Lyapunov barrier function (CLBF) to analyze the safety and reachability solely based on data without explicitly employing a dynamic model. We also proposed the Lyapunov barrier actor-critic (LBAC), a model-free RL algorithm, to search for a controller that satisfies the data-based approximation of the safety and reachability conditions. The proposed approach is demonstrated through simulation and real-world robot control experiments, i.e., a 2D quadrotor navigation task. The experimental findings reveal this approach's effectiveness in reachability and safety, surpassing other model-free RL methods.",
        "primary_area": "",
        "author": "Desong Du;Shaohang Han;Naiming Qi;Haitham Bou Ammar;Jun Wang;Wei Pan;Desong Du;Shaohang Han;Naiming Qi;Haitham Bou Ammar;Jun Wang;Wei Pan",
        "authorids": "/37086420254;/37089893730;/37085781111;/37085447874;/37086377041;/37088467306;/37086420254;/37089893730;/37085781111;/37085447874;/37086377041;/37088467306",
        "aff": "Department of Cognitive Robotics, Delft University of Technology, Netherlands; Department of Cognitive Robotics, Delft University of Technology, Netherlands; School of Astronautics, Harbin Institute of Technology, China; Department of Computer Science, University College, London, United Kingdom; Department of Computer Science, University College, London, United Kingdom; Department of Cognitive Robotics, Delft University of Technology, Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160991/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10603567681880061053&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;2;0",
        "aff_unique_norm": "Delft University of Technology;Harbin Institute of Technology;University College London",
        "aff_unique_dep": "Department of Cognitive Robotics;School of Astronautics;Department of Computer Science",
        "aff_unique_url": "https://www.tudelft.nl;http://www.hit.edu.cn/;https://www.ucl.ac.uk",
        "aff_unique_abbr": "TU Delft;HIT;UCL",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0;1;2;2;0",
        "aff_country_unique": "Netherlands;China;United Kingdom"
    },
    {
        "id": "10161418",
        "title": "Reinforcement Learning with Probabilistically Safe Control Barrier Functions for Ramp Merging",
        "track": "main",
        "status": "Poster",
        "abstract": "Prior work has looked at applying reinforcement learning (RL) approaches to autonomous driving scenarios, but the safety of the algorithm is often compromised due to instability or the presence of ill-defined reward functions. With the use of control barrier functions embedded into the RL policy, we arrive at safe policies to optimize the performance of the autonomous driving vehicle through the advantage of a safety layer over the RL methods to ease the design of reward functions. However, control barrier functions need a good approximation of the model of the system. We use probabilistic control barrier functions [4] to account for model uncertainty. Our Safety-Assured Policy Optimization - Ramp Merging (SAPO-RM) algorithm is implemented online in the CARLA [1] Simulator and offline on the US I-80 dataset extracted from the NGSIM Database provided by NHTSA [2]. We further test the algorithm and perform ablation studies of it on the US-101 and exi-D datasets to compare the approaches. The proposed algorithm can also be applied to other driving scenarios by changing the reward and safety constraints.",
        "primary_area": "",
        "author": "Soumith Udatha;Yiwei Lyu;John Dolan;Soumith Udatha;Yiwei Lyu;John Dolan",
        "authorids": "/37088534738;/37088505262;/37283756800;/37088534738;/37088505262;/37283756800",
        "aff": "Carnegie Mellon University, Pittsburgh, United States; Carnegie Mellon University, Pittsburgh, United States; Carnegie Mellon University, Pittsburgh, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161418/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6331456665267279202&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160725",
        "title": "Reinforcement Learning-Based Optimal Multiple Waypoint Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a novel method based on Artificial Potential Field (APF) theory is presented, for optimal motion planning in fully-known, static workspaces, for multiple final goal configurations. Optimization is achieved through a Reinforcement Learning (RL) framework. More specifically, the parameters of the underlying potential field are adjusted through a policy gradient algorithm in order to minimize a cost function. The main novelty of the proposed scheme lies in the method that provides optimal policies for multiple final positions, in contrast to most existing methodologies that consider a single final configuration. An assessment of the optimality of our results is conducted by comparing our novel motion planning scheme against a RRT* method.",
        "primary_area": "",
        "author": "Christos Vlachos;Panagiotis Rousseas;Charalampos P. Bechlioulis;Kostas J. Kyriakopoulos;Christos Vlachos;Panagiotis Rousseas;Charalampos P. Bechlioulis;Kostas J. Kyriakopoulos",
        "authorids": "/37089894296;/37088688420;/37396608300;/38181756700;/37089894296;/37088688420;/37396608300;/38181756700",
        "aff": "Department of Electrical and Computer Engineering, University of Patras, Greece; School of Mechanical Engineering, Control Systems Laboratory, National Technical University of Athens, Greece; Department of Electrical and Computer Engineering, University of Patras, Greece; Center of AI & Robotics (CAIR), New York University, Abu Dhabi",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160725/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8148290363255477198&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Patras;National Technical University of Athens;New York University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;School of Mechanical Engineering, Control Systems Laboratory;Center of AI & Robotics (CAIR)",
        "aff_unique_url": "https://www.upatras.gr;https://www.ntua.gr;https://www.nyu.edu",
        "aff_unique_abbr": ";NTUA;NYU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Abu Dhabi",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Greece;United Arab Emirates"
    },
    {
        "id": "10161532",
        "title": "Relay Pursuit for Multirobot Target Tracking on Tile Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we address a visbility-based target tracking problem in a polygonal environment in which a group of mobile observers try to maintain a line-of-sight with a mobile intruder. We build a bridge between data mining and visibility-based tracking using a novel tiling scheme for the polygon. First, we propose a tracking strategy for a team of guards located on the tiles to dynamically track an intruder when complete coverage of the polygon cannot be ensured. Next, we propose a novel variant of the Voronoi Diagram to construct navigation strategies for a team of co-located guards to track an intruder from any initial position in the environment. We present empirical analysis to illustrate the efficacy of the proposed tiling scheme. Simulations and testbed demonstrations are present in a video attachment.",
        "primary_area": "",
        "author": "Shashwata Mandal;Sourabh Bhattacharya;Shashwata Mandal;Sourabh Bhattacharya",
        "authorids": "/37089196313;/37275362500;/37089196313;/37275362500",
        "aff": "Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Mechanical Engineering, Ames, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161532/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9755289460642516091&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ames",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160397",
        "title": "Rendezvous and Docking of Magnetic Helical Microrobots Along Arc Orbits for Field-directed Assembly and Disassembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the limited cargo/functional element loading and other capabilities of individual microrobots, assembling them for locomotion and disassembling them as arriving at the target is more effective. An approach called rendezvous and docking is proposed in this paper to control the assembly and disassembly of helical microrobots actuated by a uniform rotating magnetic field. Docking is realized around the intersection of their arc orbits with the assistance of a fluidic field. To adjust the distance between the adjacent helical robots suspending in solution but with a distance beyond the acceptable range of the magnetic interaction, their asynchronized velocities are achieved using the interaction between the robots and fluids. For robots rotating at different speeds around their longitudinal axes at a driving frequency lower than the cut-off frequency, different fluidic flows will be generated. Based on the interaction between the robots and the fluids, the translational trajectory paths may be tuned, causing the adjacent robots to move closer. Docking along the tangential direction of rendezvous arc trajectories avoids the instability of the helical robot rotating around the radial direction and the problem of excessive linear speed at the end during assembly so that the robot can rotate stably around its axis while completing the assembly. Besides these, assembled microrobots can also lower the requirements on the imaging resolution of motion tracking and the forces for driving; hence much lower cost for both imaging and driving equipment.",
        "primary_area": "",
        "author": "Shuideng Wang;Zejie Yu;Chaojian Hou;Kun Wang;Lixin Dong;Shuideng Wang;Zejie Yu;Chaojian Hou;Kun Wang;Lixin Dong",
        "authorids": "/37089598350;/37089601197;/37086200868;/37089568990;/37275019100;/37089598350;/37089601197;/37086200868;/37089568990;/37275019100",
        "aff": "Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160397/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:saZBgakhslIJ:scholar.google.com/&scioq=Rendezvous+and+Docking+of+Magnetic+Helical+Microrobots+Along+Arc+Orbits+for+Field-directed+Assembly+and+Disassembly&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "City University of Hong Kong",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.cityu.edu.hk",
        "aff_unique_abbr": "CityU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160745",
        "title": "Repetitive Twisting Durability of Synthetic Fiber Ropes",
        "track": "main",
        "status": "Poster",
        "abstract": "Synthetic fiber ropes are widely used for robots because of their advantages such as lightweight, high tensile strength and flexibility. However, there is limited information on the physical properties of synthetic fiber ropes when used for robots. This study focuses on repetitive twisting of synthetic fiber ropes and provides information for selecting them for robots based on durability. To this end, we conducted repetitive twisting experiments on five types of ropes made from different fibers; we revealed that Dyneema has higher durability against repetitive twisting than the other ropes when a single rope is twisted. In addition, we conducted experiments on Dyneema by applying torsion to two ropes in parallel like a twisted string actuator. The result indicated that two Dyneema ropes in parallel have higher durability than a single rope; however, we revealed that the the tensile strength decreases sharply with an increase in the angle of twist.",
        "primary_area": "",
        "author": "Shinya Sadachika;Masahito Kanekiyo;Hiroyuki Nabae;Gen Endo;Shinya Sadachika;Masahito Kanekiyo;Hiroyuki Nabae;Gen Endo",
        "authorids": "/37089895343;/37089728186;/37085590608;/37282128000;/37089895343;/37089728186;/37085590608;/37282128000",
        "aff": "Department of Mechanical Engineering, Tokyo Institute of Technology, Tokyo, Meguro-ku, Japan; Department of Mechanical Engineering, Tokyo Institute of Technology, Tokyo, Meguro-ku, Japan; Department of Mechanical Engineering, Tokyo Institute of Technology, Tokyo, Meguro-ku, Japan; Department of Mechanical Engineering, Tokyo Institute of Technology, Tokyo, Meguro-ku, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160745/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=931168304382461971&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160801",
        "title": "ResiPlan: Closing the Planning-Acting Loop for Safe Underwater Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous operation in underwater environ-ments is, arguably, one of the most complex domains. It requires safe operations under the presence of unpredictable surge, currents, uncertainty, and dynamic obstacles that challenges to the highest degree real-time motion planning; the primary focus of this paper. Although previous work addressed the problem of safe real-time 3D navigation in cluttered underwater environments, it did not account explicitly for disturbances, currents, dynamic obstacles, or uncertainty growth. This paper presents ResiPlan, a novel motion planning framework that utilizes past information of errors monitoring the path follower's performance, along with estimation of dynamic obstacles and uncertainty, to produce adaptive paths by adjusting the safety margins accordingly. Extensive numerical experiments and simulations validate the safety guarantees of the technique, in a variety of different environments with various types of disturbance, showcasing the strong potential to be utilized for operations in challenging underwater environments.",
        "primary_area": "",
        "author": "Marios Xanthidis;Eleni Kelasidi;Kostas Alexis;Marios Xanthidis;Eleni Kelasidi;Kostas Alexis",
        "authorids": "/37085810183;/37085364070;/37546514600;/37085810183;/37085364070;/37546514600",
        "aff": "Department of Aquaculture, SINTEF Ocean AS, Norway; Department of Aquaculture, SINTEF Ocean AS, Norway; Department of Engineering Cybernetics at NTNU, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160801/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10485007272274780326&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "SINTEF Ocean AS;Norwegian University of Science and Technology",
        "aff_unique_dep": "Department of Aquaculture;Department of Engineering Cybernetics",
        "aff_unique_url": "https://www.sintef.no/Ocean;https://www.ntnu.edu",
        "aff_unique_abbr": ";NTNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "10161253",
        "title": "Resilient Terrain Navigation with a 5 DOF Metal Detector Drone",
        "track": "main",
        "status": "Poster",
        "abstract": "Micro aerial vehicles (MAVs) hold the potential for performing autonomous and contactless land surveys for the detection of landmines and explosive remnants of war (ERW). Metal detectors are the standard detection tool but must be operated close to and parallel to the terrain. A successful combination of MAVs with metal detectors has not been presented yet, as it requires advanced flight capabilities. To this end, we present an autonomous system to survey challenging undulated terrain using a metal detector mounted on a 5 degrees of freedom (DOF) MAV. Based on an online estimate of the terrain, our receding-horizon planner efficiently covers the area, aligning the detector to the surface while considering the kinematic and visibility constraints of the platform. As the survey requires resilient and accurate localization in diverse terrain, we also propose a factor graph-based online fusion of GNSS, IMU, and LiDAR measurements. We validate the robustness of the solution to individual sensor degeneracy by flying under the canopy of trees and over featureless fields. A simulated ablation study shows that the proposed planner reduces coverage duration and improves trajectory smoothness. Real-world flight experiments showcase autonomous mapping of buried metallic objects in undulated and obstructed terrain.",
        "primary_area": "",
        "author": "Patrick Pfreundschuh;Rik B\u00e4hnemann;Tim Kazik;Thomas Mantel;Roland Siegwart;Olov Andersson;Patrick Pfreundschuh;Rik B\u00e4hnemann;Tim Kazik;Thomas Mantel;Roland Siegwart;Olov Andersson",
        "authorids": "/37088687507;/37086172378;/37945064900;/37085483247;/37281398300;/37085816587;/37088687507;/37086172378;/37945064900;/37085483247;/37281398300;/37085816587",
        "aff": "Autonomous Systems Lab, ETH Zurich; Autonomous Systems Lab, ETH Zurich; Autonomous Systems Lab, ETH Zurich; Autonomous Systems Lab, ETH Zurich; Autonomous Systems Lab, ETH Zurich; Autonomous Systems Lab, ETH Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161253/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=283388007782805756&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10160651",
        "title": "Reslicing Ultrasound Images for Data Augmentation and Vessel Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-guided vascular access has the potential to deliver urgent medical care in situations where medical personnel are unavailable. However, this technique requires accurate and reliable segmentation of anatomical landmarks in the body. For the ultrasound imaging modality, obtaining large amounts of training data for a segmentation model is time-consuming and expensive. This paper introduces RESUS (RESlicing of UltraSound Images), a weak supervision data augmentation technique for ultrasound images based on slicing reconstructed 3D volumes from tracked 2D images. This technique allows us to generate views which cannot be easily obtained in vivo due to physical constraints of ultrasound imaging, and use these augmented ultrasound images to train a semantic segmentation model. We demonstrate that RESUS achieves statistically significant improvement over training with non-augmented images and highlight qualitative improvements through vessel reconstruction.",
        "primary_area": "",
        "author": "Cecilia G. Morales;Jason Yao;Tejas Rane;Robert Edman;Howie Choset;Artur Dubrawski;Cecilia G. Morales;Jason Yao;Tejas Rane;Robert Edman;Howie Choset;Artur Dubrawski",
        "authorids": "/37088908823;/37089894230;/37089892350;/37089895187;/37281322200;/37391516100;/37088908823;/37089894230;/37089892350;/37089895187;/37281322200;/37391516100",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160651/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18038550907588182104&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160406",
        "title": "Resolution Complete In-Place Object Retrieval given Known Object Models",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a robot task planning framework for retrieving a target object in a confined workspace among multiple stacked objects that obstruct the target. The robot can use prehensile picking and in-workspace placing actions. The method assumes access to 3D models for the visible objects in the scene. The key contribution is in achieving desirable properties, i.e., to provide (a) safety, by avoiding collisions with sensed obstacles, objects, and occluded regions, and (b) resolution completeness (RC) - or probabilistic completeness (PC) depending on implementation - which indicates a solution will be eventually found (if it exists) as the resolution of algorithmic parameters increases. A heuristic variant of the basic RC algorithm is also proposed to solve the task more efficiently while retaining the desirable properties. Simulation results compare using random picking and placing operations against the basic RC algorithm that reasons about object dependency as well as its heuristic variant. The success rate is higher for the RC approaches given the same amount of time. The heuristic variant is able to solve the problem even more efficiently than the basic approach. The integration of the RC algorithm with perception, where an RGB-D sensor detects the objects as they are being moved, enables real robot demonstrations of safely retrieving target objects from a cluttered shelf.",
        "primary_area": "",
        "author": "Daniel Nakhimovich;Yinglong Miao;Kostas E. Bekris;Daniel Nakhimovich;Yinglong Miao;Kostas E. Bekris",
        "authorids": "/37088995936;/37088664214;/37282424700;/37088995936;/37088664214;/37282424700",
        "aff": "Dept. of Computer Science, Rutgers, New Brunswick, NJ; Dept. of Computer Science, Rutgers, New Brunswick, NJ; Dept. of Computer Science, Rutgers, New Brunswick, NJ",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160406/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:QOgU5fM5EPAJ:scholar.google.com/&scioq=Resolution+Complete+In-Place+Object+Retrieval+given+Known+Object+Models&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160501",
        "title": "Reuse your features: unifying retrieval and feature-metric alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a compact pipeline to unify all the steps of Visual Localization: image retrieval, candidate re-ranking and initial pose estimation, and camera pose refinement. Our key assumption is that the deep features used for these individual tasks share common characteristics, so we should reuse them in all the procedures of the pipeline. Our DRAN (Deep Retrieval and image Alignment Network) is able to extract global descriptors for efficient image retrieval, use intermediate hierarchical features to re-rank the retrieval list and produce an initial pose guess, which is finally refined by means of a feature-metric optimization based on learned deep multi-scale dense features. DRAN is the first single network able to produce the features for the three steps of visual localization. DRAN achieves competitive performance in terms of robustness and accuracy under challenging conditions in public benchmarks, outperforming other unified approaches and consuming lower computational and memory cost than its counterparts using multiple networks. Code and models will be publicly available at github.com/jmorlana/DRAN.",
        "primary_area": "",
        "author": "Javier Morlana;J.M.M. Montiel;Javier Morlana;J.M.M. Montiel",
        "authorids": "/37088996111;/37274019300;/37088996111;/37274019300",
        "aff": "Instituto de Investigaci\u00f3n en Ingenierg\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenierg\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160501/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14801422148419985955&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenierg\u00eda de Arag\u00f3n (I3A)",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "UniZar",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Zaragoza",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10161100",
        "title": "Risk-Aware Model Predictive Path Integral Control Using Conditional Value-at-Risk",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel Model Predictive Control method for autonomous robot planning and control subject to arbitrary forms of uncertainty. The proposed Risk-Aware Model Predictive Path Integral (RA-MPPI) control utilizes the Conditional Value-at-Risk (CVaR) measure to generate optimal control actions for safety-critical robotic applications. Different from most existing Stochastic MPCs and CVaR optimization methods that linearize the original dynamics and formulate control tasks as convex programs, the proposed method directly uses the original dynamics without restricting the form of the cost functions or the noise. We apply the novel RA-MPPI controller to an autonomous vehicle to perform aggressive driving maneuvers in cluttered environments. Our simulations and experiments show that the proposed RA-MPPI controller can achieve similar lap times with the baseline MPPI controller while encountering significantly fewer collisions. The proposed controller performs online computation at an update frequency of up to 80 Hz, utilizing modern Graphics Processing Units (GPUs) to multi-thread the generation of trajectories as well as the CVaR values.",
        "primary_area": "",
        "author": "Ji Yin;Zhiyuan Zhang;Panagiotis Tsiotras;Ji Yin;Zhiyuan Zhang;Panagiotis Tsiotras",
        "authorids": "/37089449275;/37089448852;/37330609800;/37089449275;/37089448852;/37330609800",
        "aff": "D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, GA; D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, GA; D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161100/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11721437819667470876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Aerospace Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Georgia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161473",
        "title": "Risk-Aware Neural Navigation From BEV Input for Interactive Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety has been a key goal for autonomous driving since its inception, and we believe recognizing and responding to risk is a key component of safety. In this work, we aim to answer the question, \u201cHow can explainable risk representations be generated and used to produce risk-averse trajectories?\u201d To answer this question, previous work uses risk metrics to formulate an optimization problem. In contrast, our work is based on research showing the usefulness of grids as a representation to generate image-based risk maps through a trained neural network. We propose a method of determining risk from a bird's eye view (BEV) of an autonomous vehicle's surroundings. Our method consists of (1) a risk map generator, which is trained to recognize risk associated with nearby agents and the map, (2) differentiable value iteration using the risk map to learn a policy, and (3) a trajectory sampler, which samples from this policy to generate a trajectory. We evaluate our planner in a close-loop manner and find improvements in its overall ability to mimic human driving while maintaining comparable safety statistics. Self-ablation also reveals the potential for fine-tuning the behavior of the planner given a designer's needs.",
        "primary_area": "",
        "author": "Suzanna Jiwani;Xiao Li;Sertac Karaman;Daniela Rus;Suzanna Jiwani;Xiao Li;Sertac Karaman;Daniela Rus",
        "authorids": "/37089893654;/37088812042;/37304113000;/37279652300;/37089893654;/37088812042;/37304113000;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161473/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1245358419683870624&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Lab",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161466",
        "title": "Risk-aware Path Planning via Probabilistic Fusion of Traversability Prediction for Planetary Rovers on Heterogeneous Terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine learning (ML) plays a crucial role in assessing traversability for autonomous rover operations on deformable terrains but suffers from inevitable prediction errors. Especially for heterogeneous terrains where the geological features vary from place to place, erroneous traversability prediction can become more apparent, increasing the risk of unrecoverable rover's wheel slip and immobilization. In this work, we propose a new path planning algorithm that explicitly accounts for such erroneous prediction. The key idea is the probabilistic fusion of distinctive ML models for terrain type classification and slip prediction into a single distribution. This gives us a multimodal slip distribution accounting for heterogeneous terrains and further allows statistical risk assessment to be applied to derive risk-aware traversing costs for path planning. Extensive simulation experiments have demonstrated that the proposed method is able to generate more feasible paths on heterogeneous terrains compared to existing methods.",
        "primary_area": "",
        "author": "Masafumi Endo;Tatsunori Taniai;Ryo Yonetani;Genya Ishigami;Masafumi Endo;Tatsunori Taniai;Ryo Yonetani;Genya Ishigami",
        "authorids": "/37089541087;/37089919100;/37085641524;/37546428100;/37089541087;/37089919100;/37085641524;/37546428100",
        "aff": "Department of Mechanical Engineering, Space Robotics Group, Keio University, Kanagawa, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; Department of Mechanical Engineering, Space Robotics Group, Keio University, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161466/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2626726644295152517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Keio University;OMRON SINIC X Corporation",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.keio.ac.jp;",
        "aff_unique_abbr": "Keio;",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Kanagawa;Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161446",
        "title": "Risk-aware Recharging Rendezvous for a Collaborative Team of UAVs and UGVs",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce and investigate the recharging rendezvous problem for a collaborative team of Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs), in which UAVs with limited battery capacity and UGVS persistently monitor an area. The UGVs also act as mobile recharging stations for the UAVs. In contrast to prior work on such problems, we consider the challenge of dealing with stochastic energy consumption in a risk-aware fashion. Specifically, we consider a bi-criteria optimization problem of minimizing the time taken by the UAVs on recharging detours while ensuring that the probability that no UAV runs out of charge is greater than a user-defined risk tolerance. This problem (termed Risk-aware Recharging Rendezvous Problem (RRRP)) is a combinatorial problem with a matching constraint \u2014 to ensure UAVs are assigned to the limited UGV recharging slots, and a knapsack constraint \u2014 to capture the risk tolerance. We propose a novel bicriteria approximation algorithm to solve RRRP and demonstrate its effectiveness in the context of a persistent monitoring mission compared to baseline methods.",
        "primary_area": "",
        "author": "Ahmad Bilal Asghar;Guangyao Shi;Nare Karapetyan;James Humann;Jean-Paul Reddinger;James Dotterweich;Pratap Tokekar;Ahmad Bilal Asghar;Guangyao Shi;Nare Karapetyan;James Humann;Jean-Paul Reddinger;James Dotterweich;Pratap Tokekar",
        "authorids": "/37085346288;/37089000733;/37086299803;/37086385541;/37088917691;/37086936422;/37546532700;/37085346288;/37089000733;/37086299803;/37086385541;/37088917691;/37086936422;/37546532700",
        "aff": "University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; DEVCOM Army Research Laboratory, MD, USA; DEVCOM Army Research Laboratory, MD, USA; DEVCOM Army Research Laboratory, MD, USA; University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161446/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9133086807372725676&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;0",
        "aff_unique_norm": "University of Maryland;DEVCOM Army Research Laboratory",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www/umd.edu;",
        "aff_unique_abbr": "UMD;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Park;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160973",
        "title": "Risk-aware Spatio-temporal Logic Planning in Gaussian Belief Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "In many real-world robotic scenarios, we cannot assume exact knowledge about a robot's state due to unmodeled dynamics or noisy sensors. Planning in belief space addresses this problem by tightly coupling perception and planning modules to obtain trajectories that take into account the environment's stochasticity. However, existing works are often limited to tasks such as the classic reach-avoid problem and do not provide risk awareness. We propose a risk-aware planning strategy in belief space that minimizes the risk of violating a given specification and enables a robot to actively gather information about its state. We use Risk Signal Temporal Logic (RiSTL) as a specification language in belief space to express complex spatio-temporal missions including predicates over Gaussian beliefs. We synthesize trajectories for challenging scenarios that cannot be expressed through classical reach-avoid properties and show that risk-aware objectives improve the uncertainty reduction in a robot's belief.",
        "primary_area": "",
        "author": "Matti Vahs;Christian Pek;Jana Tumova;Matti Vahs;Christian Pek;Jana Tumova",
        "authorids": "/37089892008;/37085906854;/38230312900;/37089892008;/37085906854;/38230312900",
        "aff": "The authors are with the Division of Robotics, Perception and Learning, School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; The authors are with the Division of Robotics, Perception and Learning, School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; The authors are with the Division of Robotics, Perception and Learning, School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160973/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13820248129606802341&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "Division of Robotics, Perception and Learning, School of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "10161388",
        "title": "Rmagine: 3D Range Sensor Simulation in Polygonal Maps via Ray Tracing for Embedded Hardware on Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensor simulation has emerged as a promising and powerful technique to find solutions to many real-world robotic tasks like localization and pose tracking. However, commonly used simulators have high hardware requirements and are therefore used mostly on high-end computers. In this paper, we present an approach to simulate range sensors directly on embedded hardware of mobile robots that use triangle meshes as environment map. This library, called Rmagine, allows a robot to simulate sensor data for arbitrary range sensors directly on board via ray tracing. Since robots typically only have limited computational resources, Rmagine aims at being flexible and lightweight, while scaling well even to large environment maps. It runs on several platforms like Laptops or embedded computing boards like NVIDIA Jetson by putting an unified API over the specific proprietary libraries provided by the hardware manufacturers. This work is designed to support the future development of robotic applications depending on simulation of range data that could previously not be computed in reasonable time on mobile systems.",
        "primary_area": "",
        "author": "Alexander Mock;Thomas Wiemann;Joachim Hertzberg;Alexander Mock;Thomas Wiemann;Joachim Hertzberg",
        "authorids": "/37086361948;/37945726600;/37273307000;/37086361948;/37945726600;/37273307000",
        "aff": "Knowledge Based Systems Group, Institute of Computer Science, Osnabr\u00fcck University, Osnabr\u00fcck, Germany; Plan-based Robot Control, DFKI Niedersachsen, Osnabr\u00fcck, Germany; Plan-based Robot Control, DFKI Niedersachsen, Osnabr\u00fcck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161388/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11205274620078076065&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Osnabr\u00fcck University;German Research Center for Artificial Intelligence (DFKI)",
        "aff_unique_dep": "Institute of Computer Science;DFKI Niedersachsen",
        "aff_unique_url": "https://www.uni-osnabrueck.de;https://www.dfki.de",
        "aff_unique_abbr": ";DFKI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Osnabr\u00fcck",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161203",
        "title": "RoLM: Radar on LiDAR Map Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-sensor fusion-based localization technology has achieved high accuracy in autonomous systems. How to improve the robustness is the main challenge at present. The most commonly used LiDAR and camera are weather-sensitive, while the FMCW radar has strong adaptability but suffers from noise and ghost effects. In this paper, we propose a heterogeneous localization method of Radar on LiDAR Map (RoLM), which can eliminate the accumulated error of radar odometry in real-time to achieve higher localization accuracy without dependence on loop closures. We embed the two sensor modalities into a density map and calculate the spatial vector similarity with offset to seek the corresponding place index in the candidates and calculate the rotation and translation. We use the ICP to pursue perfect matching on the LiDAR submap based on the coarse alignment. Extensive experiments on Mulran Radar Dataset, Oxford Radar RobotCar Dataset, and our data verify the feasibility and effectiveness of our approach.",
        "primary_area": "",
        "author": "Yukai Ma;Xiangrui Zhao;Han Li;Yaqing Gu;Xiaolei Lang;Yong Liu;Yukai Ma;Xiangrui Zhao;Han Li;Yaqing Gu;Xiaolei Lang;Yong Liu",
        "authorids": "/37089516675;/37087122595;/37089894616;/37089651089;/37088939249;/37066946100;/37089516675;/37087122595;/37089894616;/37089651089;/37088939249;/37066946100",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161203/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8421565008032979469&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161106",
        "title": "RoSS: Rotation-induced Aliasing for Audio Source Separation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the problem of audio source separation, where the goal is to isolate a target audio signal (say Alice's speech) from a mixture of multiple interfering signals (e.g., when many people are talking). This problem has gained renewed interest mainly due to the significant growth in voice-controlled devices, including robots in homes, offices, and other public facilities. Although a rich body of work exists on the core topic of source separation, we find that rotational motion of the microphones (e.g., a swiveling robot-head) offers complementary gains. We show that rotating the microphone array to the optimal orientation can produce desirable \u201cdelay aliasing\u201d between two interferers, causing the two interferers to appear as one. In general, a mixture of K signals becomes a mixture of (K - 1) signals, a mathematically concrete gain. We show that the gain translates well to practice, provided two rotation-related challenges can be mitigated. This paper is focused on mitigating these challenges and demonstrating the end-to-end performance on a fully functional prototype. We believe that our Rotational Source Separation (RoSS) module could be plugged into actual robot heads or into other devices (like Amazon Show) that are also capable of rotation.",
        "primary_area": "",
        "author": "Hyungjoo Seo;Sahil Bhandary Karnoor;Romit Roy Choudhury;Hyungjoo Seo;Sahil Bhandary Karnoor;Romit Roy Choudhury",
        "authorids": "/37088526776;/37089593736;/37271818200;/37088526776;/37089593736;/37271818200",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161106/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:W6VvQyaPVhoJ:scholar.google.com/&scioq=RoSS:+Rotation-induced+Aliasing+for+Audio+Source+Separation&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161159",
        "title": "Road Anomaly Segmentation Based on Pixel-wise Logit Variance with Iterative Background Highlighting",
        "track": "main",
        "status": "Poster",
        "abstract": "Anomaly segmentation on the urban landscape scene is an important task in autonomous driving. This process exploits a pre-trained semantic segmentation network to estimate anomalous regions. Anomaly segmentation approaches implemented with extra requirements such as out-of-domain data, extra network, or network retraining might increase the computational cost or degradation of segmentation performance. In this study, to exploit information from the segmentation network for more robust anomaly segmentation, we propose the use of pixel-wise logit variance, which tends to be small for anomalies as network outputs even logits without confidence. Additionally iterative background highlighting is proposed to robustly detect anomalous objects on the background, which is implemented by feeding the logits back into the linear classifier of the network. We achieved state-of-the-art performance among anomaly segmentation approaches without extra requirements, reaching relative average precision improvements of 21.7% on the Fishyscapes Lost&Found and 17.4% on the Fishyscapes Static compared to the state-of-the-art method. The code of this work is available at our Github repository (https://github.com/hagg30/LogitVar).",
        "primary_area": "",
        "author": "Dongkun Lee;Han-Gyu Kim;Ho-Jin Choi;Dongkun Lee;Han-Gyu Kim;Ho-Jin Choi",
        "authorids": "/37086141818;/38529375800;/37277426500;/37086141818;/38529375800;/37277426500",
        "aff": "School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; NAVER Cloud, Gyeonggi-do, Republic of Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161159/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:3lJHrO8-RMYJ:scholar.google.com/&scioq=Road+Anomaly+Segmentation+Based+on+Pixel-wise+Logit+Variance+with+Iterative+Background+Highlighting&hl=en&as_sdt=0,5",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;NAVER Cloud",
        "aff_unique_dep": "School of Computing;",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.naver.com",
        "aff_unique_abbr": "KAIST;NAVER",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161436",
        "title": "RoboSC: a domain-specific language for supervisory controller synthesis of ROS applications",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper presents a novel domain-specific language, RoboSC, for developing supervisory controllers for robotic applications. RoboSC supports concepts of ROS/ROS2 and supervisory control theory. It enables users to focus on the modeling and the synthesis process of supervisory controllers for ROS applications only because it generates all artifacts needed to connect such controllers to ROS applications and deploy them. Validation tests with actual and simulated robots show the approach's feasibility and indicate reduced coding effort.",
        "primary_area": "",
        "author": "Bart Wesselink;Koen de Vos;Ivan Kuertev;Michel Reniers;Elena Torta;Bart Wesselink;Koen de Vos;Ivan Kuertev;Michel Reniers;Elena Torta",
        "authorids": "/37089891976;/37089894326;/37089893187;/37282568000;/38489917800;/37089891976;/37089894326;/37089893187;/37282568000;/38489917800",
        "aff": "Faculty of Computer Science, Eindhoven University of Technology, Netherlands; Faculty of Mechanical engineering, Eindhoven University of Technology, Netherlands; Faculty of Computer Science, Eindhoven University of Technology, Netherlands; Faculty of Mechanical engineering, Eindhoven University of Technology, Netherlands; Faculty of Mechanical engineering, Eindhoven University of Technology, Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161436/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3797594260429890428&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Eindhoven University of Technology",
        "aff_unique_dep": "Faculty of Computer Science",
        "aff_unique_url": "https://www.tue.nl",
        "aff_unique_abbr": "TU/e",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "10161423",
        "title": "Robot Mimicry Attack on Keystroke-Dynamics User Identification and Authentication System",
        "track": "main",
        "status": "Poster",
        "abstract": "Future robots will be very advanced with high flexibility and accurate control performance. They will have the ability to mimic human behaviours or even perform better, which raises the significant risk of robot attack. In this work, we study the robot mimic attack on the current keystroke-dynamic user authentication system. Specifically, we proposed a robot mimicry attack framework for keystroke-dynamics systems. We collected keyboard logging data and acoustical signal data from real users and extracted the timing pattern of keystrokes to understand victim's behaviour for robot imitation attacks. Furthermore, we develop a deep Q-Network (DQN) algorithm to control the velocity of robot which is one of the key challenges of forging the human typing timing features. We tested and evaluated our approach on the real-life robotic testbed. We presented our results considering user identification and user authentication performance. We achieved a 90.3% user identification accuracy with genuine keyboard logging data samples and 89.6% accuracy with robot-forged data samples. Furthermore, we achieved 11.1%, and 36.6% EER for user authentication performance with zero-effort attack, and robot mimicry attack, respectively.",
        "primary_area": "",
        "author": "Rongyu Yu;Burak Kizilkaya;Zhen Meng;Emma Li;Guodong Zhao;Muhammad Imran;Rongyu Yu;Burak Kizilkaya;Zhen Meng;Emma Li;Guodong Zhao;Muhammad Imran",
        "authorids": "/37089893562;/37089406393;/37088483552;/37089892180;/37594998700;/37265529100;/37089893562;/37089406393;/37088483552;/37089892180;/37594998700;/37265529100",
        "aff": "James Watt School of Engineering, University of Glasgow, Glasgow, UK; James Watt School of Engineering, University of Glasgow, Glasgow, UK; James Watt School of Engineering, University of Glasgow, Glasgow, UK; School of Computing Science, University of Glasgow, Glasgow, UK; James Watt School of Engineering, University of Glasgow, Glasgow, UK; James Watt School of Engineering, University of Glasgow, Glasgow, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161423/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7990877880086189882&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Glasgow",
        "aff_unique_dep": "James Watt School of Engineering",
        "aff_unique_url": "https://www.gla.ac.uk",
        "aff_unique_abbr": "UofG",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Glasgow",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160738",
        "title": "Robot Person Following Under Partial Occlusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot person following (RPF) is a capability that supports many useful human-robot-interaction (HRI) applications. However, existing solutions to person following often as-sume full observation of the tracked person. As a consequence, they cannot track the person reliably under partial occlusion where the assumption of full observation is not satisfied. In this paper, we focus on the problem of robot person following under partial occlusion caused by a limited field of view of a monocular camera. Based on the key insight that it is possible to locate the target person when one or more of hislher joints are visible, we propose a method in which each visible joint contributes a location estimate of the followed person. Experiments on a public person-following dataset show that, even under partial occlusion, the proposed method can still locate the person more reliably than the existing SOTA methods. As well, the application of our method is demonstrated in real experiments on a mobile robot.",
        "primary_area": "",
        "author": "Hanjing Ye;Jieting Zhao;Yaling Pan;Weinan Cherr;Li He;Hong Zhang;Hanjing Ye;Jieting Zhao;Yaling Pan;Weinan Cherr;Li He;Hong Zhang",
        "authorids": "/37089346572;/37089895224;/37089692620;/37089893060;/37086300847;/37280789900;/37089346572;/37089895224;/37089692620;/37089893060;/37086300847;/37280789900",
        "aff": "Department of Electronic and Electrical Engineering, Shenzhen Key Laboratory of Robotics and Computer Vision, Southern University of Science and Technology (SUSTech), SUSTech; Department of Electronic and Electrical Engineering, Shenzhen Key Laboratory of Robotics and Computer Vision, Southern University of Science and Technology (SUSTech), SUSTech; Biomimetic and Intelligent Robotics Lab, Guangdong University of Technology; Biomimetic and Intelligent Robotics Lab, Guangdong University of Technology; Department of Electronic and Electrical Engineering, Shenzhen Key Laboratory of Robotics and Computer Vision, Southern University of Science and Technology (SUSTech), SUSTech; Department of Electronic and Electrical Engineering, Shenzhen Key Laboratory of Robotics and Computer Vision, Southern University of Science and Technology (SUSTech), SUSTech",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160738/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8633250140110933442&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Southern University of Science and Technology;Guangdong University of Technology",
        "aff_unique_dep": "Department of Electronic and Electrical Engineering;Biomimetic and Intelligent Robotics Lab",
        "aff_unique_url": "https://www.sustech.edu.cn;http://www.gdut.edu.cn",
        "aff_unique_abbr": "SUSTech;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160711",
        "title": "Robot Trust and Self-Confidence Based Role Arbitration Method for Physical Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Role arbitration in human-robot collaboration (HRC) is a dynamically changing process that is affected by many factors such as physical workload, environmental changes and trust. In order to address this dynamic process, a trust-based role arbitration method is studied in this research. A computational model of robot trust and self-confidence (TSC) in physical human-robot collaboration (pHRC) is proposed. The TSC model is defined as a function of objective robot and human co-worker performance. A role arbitration method is then proposed based on the TSC model presented. The human-in-the-loop experiments with a collaborative robot are conducted to verify the TSC-based role arbitration method. The results show that the proposed method could achieve superior human-robot combined performance, reduce human co-workers' workload, and improve subjective preference.",
        "primary_area": "",
        "author": "Qiao Wang;Dikai Liu;Marc G. Carmichael;Chin-Teng Lin;Qiao Wang;Dikai Liu;Marc G. Carmichael;Chin-Teng Lin",
        "authorids": "/37089285140;/37290601500;/37601543500;/37278412100;/37089285140;/37290601500;/37601543500;/37278412100",
        "aff": "Faculty of Engineering and Information Technology, Robotics Institute, University of Technology Sydney, Ultimo, NSW, Australia; Faculty of Engineering and Information Technology, Robotics Institute, University of Technology Sydney, Ultimo, NSW, Australia; Faculty of Engineering and Information Technology, Robotics Institute, University of Technology Sydney, Ultimo, NSW, Australia; Faculty of Engineering and Information Technology, Australian Artificial Intelligence Institute, School of Computer Science, University of Technology Sydney, Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160711/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11074141595462831482&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Faculty of Engineering and Information Technology, Robotics Institute",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ultimo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10161359",
        "title": "Robot explanatory narratives of collaborative and adaptive experiences",
        "track": "main",
        "status": "Poster",
        "abstract": "In the future, robots are expected to autonomously interact and/or collaborate with humans, who will increase the uncertainty during the execution of tasks, provoking online adaptations of robots' plans. Hence, trustworthy robots must be able to store, retrieve and narrate important knowledge about their collaborations and adaptations. In this article, it is proposed a sound methodology that integrates three main elements. First, an ontology for collaborative robotics and adaptation to model the domain knowledge. Second, an episodic memory for time-indexed knowledge storage and retrieval. Third, a novel algorithm to extract the relevant knowledge and generate textual explanatory narratives. The algorithm produces three different types of outputs, varying the specificity, for diverse uses and preferences. A pilot study was conducted to evaluate the usefulness of the narratives, obtaining promising results. Finally, we discuss how the methodology can be generalized to other ontologies and experiences. This work boosts robot explainability, especially in cases where robots need to narrate the details of their short and long-term past experiences.",
        "primary_area": "",
        "author": "Alberto Olivares-Alarcos;Antonio Andriella;Sergi Foix;Guillem Aleny\u00e0;Alberto Olivares-Alarcos;Antonio Andriella;Sergi Foix;Guillem Aleny\u00e0",
        "authorids": "/37086574817;/37087236278;/37546458900;/37546459500;/37086574817;/37087236278;/37546458900;/37546459500",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Pal Robotics, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161359/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18060661708831885391&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial;Pal Robotics",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.iri.upc.edu/;",
        "aff_unique_abbr": "IRI;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "10160956",
        "title": "Robot-Assisted Eye-Hand Coordination Training System by Estimating Motion Direction Using Smooth-Pursuit Eye Movements",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-assisted eye-hand coordination rehabilitation training system is extremely urgent to study since recent evidence suggests that eye-hand coordination can be brutally disturbed by stroke with critical consequences on motor behavior. In this paper, we develop a robot-assisted eye-hand coordination training system by estimating motion direction using smooth-pursuit eye movements. Firstly, we design a Pong Game, which requires users to extrapolate the direction of a linearly moving ball and to predict whether this ball would be hit. Secondly, the motion direction of the ball is estimated via smooth-pursuit eye movements, allowing the robot quickly establish an assistive force field to hit the ball. Thirdly, adding haptic feedback technology into this training system to make users more immersive. Finally, we conduct a feasibility study with eight healthy subjects to verify the effectiveness of the proposed system. The experimental results show that the mean success rate for hitting the pong ball of the experiment group (assistance turn-on) is 28.33% higher than that of the control group (assistance turn-off), and the mean interception time of the experiment group is 0.35s shorter than that of the control group. Therefore, the developed system may be promising for transferring to the robot-assisted eye-hand coordination rehabilitation training for post-stroke patients.",
        "primary_area": "",
        "author": "Xiao Li;Hong Zeng;Chenhua Yang;Aiguo Song;Xiao Li;Hong Zeng;Chenhua Yang;Aiguo Song",
        "authorids": "/37089072755;/37590328500;/37089892742;/37276033000;/37089072755;/37590328500;/37089892742;/37276033000",
        "aff": "State Key Laboratory of Bioelectronics, Jiangsu Key Laboratory of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; State Key Laboratory of Bioelectronics, Jiangsu Key Laboratory of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; State Key Laboratory of Bioelectronics, Jiangsu Key Laboratory of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; State Key Laboratory of Bioelectronics, Jiangsu Key Laboratory of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160956/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1653244055774390343&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southeast University",
        "aff_unique_dep": "School of Instrument Science and Engineering",
        "aff_unique_url": "https://www.seu.edu.cn/",
        "aff_unique_abbr": "SEU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161321",
        "title": "RobotSweater: Scalable, Generalizable, and Customizable Machine-Knitted Tactile Skins for Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing is essential for robots to perceive and react to the environment. However, it remains a challenge to make large-scale and flexible tactile skins on robots. Industrial machine knitting provides solutions to manufacture customiz-able fabrics. Along with functional yarns, it can produce highly customizable circuits that can be made into tactile skins for robots. In this work, we present RobotSweater, a machine-knitted pressure-sensitive tactile skin that can be easily applied on robots. We design and fabricate a parameterized multi-layer tactile skin using off-the-shelf yarns, and characterize our sensor on both a flat testbed and a curved surface to show its robust contact detection, multi-contact localization, and pressure sensing capabilities. The sensor is fabricated using a well-established textile manufacturing process with a programmable industrial knitting machine, which makes it highly customizable and low-cost. The textile nature of the sensor also makes it easily fit curved surfaces of different robots and have a friendly appearance. Using our tactile skins, we conduct closed-loop control with tactile feedback for two applications: (1) human lead-through control of a robot arm, and (2) human-robot interaction with a mobile robot.",
        "primary_area": "",
        "author": "Zilin Si;Tianhong Catherine Yu;Katrene Morozov;James McCann;Wenzhen Yuan;Zilin Si;Tianhong Catherine Yu;Katrene Morozov;James McCann;Wenzhen Yuan",
        "authorids": "/37089194088;/37089895380;/37089895208;/37088910733;/37085486405;/37089194088;/37089895380;/37089895208;/37088910733;/37085486405",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; University of California, Santa Barbara, Santa Barbara, CA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161321/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10077745559789535389&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;University of California, Santa Barbara",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.ucsb.edu",
        "aff_unique_abbr": "CMU;UCSB",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Pittsburgh;Santa Barbara",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160425",
        "title": "Robotic Control Using Model Based Meta Adaption",
        "track": "main",
        "status": "Poster",
        "abstract": "In machine learning, meta-learning methods aim for fast adaptability to unknown tasks using prior knowledge. Model-based meta-reinforcement learning combines reinforcement learning via world models with Meta Reinforcement Learning (MRL) for increased sample efficiency. However, adaption to unknown tasks does not always result in preferable agent behavior. This paper introduces a new Meta Adaptation Controller (MAC) that employs MRL to apply a preferred robot behavior from one task to many similar tasks. To do this, MAC aims to find actions an agent has to take in a new task to reach a similar outcome as in a learned task. As a result, the agent will adapt quickly to the change in the dynamic and behave appropriately without the need to construct a reward function that enforces the preferred behavior.",
        "primary_area": "",
        "author": "Karam Daaboul;Joel Ikels;J. Marius Z\u00f6llner;Karam Daaboul;Joel Ikels;J. Marius Z\u00f6llner",
        "authorids": "/37089013527;/37089891989;/38558111200;/37089013527;/37089891989;/38558111200",
        "aff": "Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160425/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8334004179928082933&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161139",
        "title": "Robotic Fastening with a Manual Screwdriver",
        "track": "main",
        "status": "Poster",
        "abstract": "The robotic hand is still no match for the human hand on many skills. Manipulation of hand tools, which usually requires sophisticated finger movements and fine controls, not only poses a clear technical challenge but also carries a great potential for enabling the robot to assist humans in a wide range of tasks accomplishable using tools. This paper takes a first step to investigate how a robotic arm mounts a rigidly attached screwdriver onto a screw (pre-mounted in a tapped hole) and then tightens it using the tool. Mounting begins with sliding the screwdriver tip on the screw head along preplanned paths to search for the drive and follows with rotating the screwdriver to drop the tip into the drive. Prevention of a slip off the screw head is achieved via impedance control to install a \u201cvirtual fence\u201d along its boundary. Turning of the screw is conducted via hybrid position/admittance control based on modeling the reaction force between the screw and the substrate. Simulation results with a KUKA Arm demonstrate the smoothness of the entire action.",
        "primary_area": "",
        "author": "Ling Tang;Yan-Bin Jia;Ling Tang;Yan-Bin Jia",
        "authorids": "/37089892879;/37273296400;/37089892879;/37273296400",
        "aff": "Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161139/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1730392927609883211&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ames",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161055",
        "title": "Robotic Method and Instrument to Efficiently Synthesize Faulty Conditions and Mass-Produce Faulty-Conditioned Data for Rotary Machines",
        "track": "main",
        "status": "Poster",
        "abstract": "Condition synthesis is vital for generating data for fault detection and diagnosis studies. Traditional methods rely heavily on human labor. This study proposes a robotic method and its instru-ment to efficiently synthesize faulty conditions and mass-produce data to develop fault detection and diagnosis algorithms. The first contribution is the formalization of a new approach called Robotic Condition Synthesis, which shifts the traditionally labor-intensive task of condition synthesis to a robot-based force control task. The second contribution is developing a new robotic manipulator, which is more effective than current lab-grade robots for the tasks involved in the Robotic Condition Synthesis. The third contribution is empirical evidence of the superiority of this new robot in performing the Robotic Condition Synthesis tasks. This study also explores the potential of the new robot by conducting a three-dimensional system identification of a rotordynamic plant, which lays the foundation for more advanced Robotic Condition Synthesis policies in the future.",
        "primary_area": "",
        "author": "Yip Fun Yeung;Fangzhou Xia;Juliana Covarrubias;Mikio Furokawa;Takayuki Hirano;Kamal Youcef-Toumi;Yip Fun Yeung;Fangzhou Xia;Juliana Covarrubias;Mikio Furokawa;Takayuki Hirano;Kamal Youcef-Toumi",
        "authorids": "/37088687204;/37086186964;/37089894648;/37086933718;/37086934581;/38271700200;/37088687204;/37086186964;/37089894648;/37086933718;/37086934581;/38271700200",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; The Japan Steel Works, LTD., Hiroshima Plant, Japan; The Japan Steel Works, LTD., Hiroshima Plant, Japan; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161055/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8010042678808477725&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;The Japan Steel Works, LTD.",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://web.mit.edu;https://www.jsw.co.jp",
        "aff_unique_abbr": "MIT;JSW",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Cambridge;Hiroshima",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "10160372",
        "title": "Robotic Navigation Autonomy for Subretinal Injection via Intelligent Real-Time Virtual iOCT Volume Slicing",
        "track": "main",
        "status": "Poster",
        "abstract": "In the last decade, various robotic platforms have been introduced that could support delicate retinal surgeries. Concurrently, to provide semantic understanding of the surgical area, recent advances have enabled microscope-integrated intraoperative Optical Coherent Tomography (iOCT) with high-resolution 3D imaging at near video rate. The combination of robotics and semantic understanding enables task autonomy in robotic retinal surgery, such as for subretinal injection. This procedure requires precise needle insertion for best treatment outcomes. However, merging robotic systems with iOCT intro-duces new challenges. These include, but are not limited to high demands on data processing rates and dynamic registration of these systems during the procedure. In this work, we propose a framework for autonomous robotic navigation for subretinal injection, based on intelligent real-time processing of iOCT volumes. Our method consists of an instrument pose estimation method, an online registration between the robotic and the iOCT system, and trajectory planning tailored for navigation to an injection target. We also introduce intelligent virtual B-scans, a volume slicing approach for rapid instrument pose estimation, which is enabled by Convolutional Neural Networks (CNNs). Our experiments on ex-vivo porcine eyes demonstrate the precision and repeatability of the method. Finally, we discuss identified challenges in this work and suggest potential solutions to further the development of such systems.",
        "primary_area": "",
        "author": "Shervin Dehghani;Michael Sommersperger;Peiyao Zhang;Alejandro Martin-Gomez;Benjamin Busam;Peter Gehlbach;Nassir Navab;M. Ali Nasseri;Iulian Iordachita;Shervin Dehghani;Michael Sommersperger;Peiyao Zhang;Alejandro Martin-Gomez;Benjamin Busam;Peter Gehlbach;Nassir Navab;M. Ali Nasseri;Iulian Iordachita",
        "authorids": "/37088645228;/37089447100;/37089280568;/37086939827;/37085664553;/37547001700;/37282965500;/37681019000;/37330620500;/37088645228;/37089447100;/37089280568;/37086939827;/37085664553;/37547001700;/37282965500;/37681019000;/37330620500",
        "aff": "Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Department of Computer Science, Technische Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Department of Computer Science, Technische Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Wilmer Eye Institute, Johns Hopkins Hospital, Baltimore, MD, USA; Whiting School of Engineering, Johns Hopkins University, Baltimore, MD, USA; Augenklinik und Poliklinik, Klinikum rechts der Isar der Technische Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160372/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9503276509148730013&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;0;1;2;0;1;0",
        "aff_unique_norm": "Johns Hopkins University;Technische Universit\u00e4t M\u00fcnchen;Johns Hopkins Hospital",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics;Department of Computer Science;Wilmer Eye Institute",
        "aff_unique_url": "https://www.jhu.edu;https://www.tum.de;https://www.hopkinsmedicine.org",
        "aff_unique_abbr": "JHU;TUM;JHH",
        "aff_campus_unique_index": "0;1;0;0;1;0;0;1;0",
        "aff_campus_unique": "Baltimore;M\u00fcnchen",
        "aff_country_unique_index": "0;1;0;0;1;0;0;1;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "10161542",
        "title": "Robotic Sonographer: Autonomous Robotic Ultrasound using Domain Expertise in Bayesian Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultrasound is a vital imaging modality utilized for a variety of diagnostic and interventional procedures. However, an expert sonographer is required to make accurate maneuvers of the probe over the human body while making sense of the ultrasound images for diagnostic purposes. This procedure requires a substantial amount of training and up to a few years of experience. In this paper, we propose an autonomous robotic ultrasound system that uses Bayesian Optimization (BO) in combination with the domain expertise to predict and effectively scan the regions where diagnostic quality ultrasound images can be acquired. The quality map, which is a distribution of image quality in a scanning region, is estimated using Gaussian process in BO. This relies on a prior quality map modeled using expert's demonstration of the high-quality probing maneuvers. The ultrasound image quality feedback is provided to BO, which is estimated using a deep convolution neural network model. This model was previously trained on database of images labelled for diagnostic quality by expert radiologists. Experiments on three different urinary bladder phantoms validated that the proposed autonomous ultrasound system can acquire ultrasound images for diagnostic purposes with a probing position and force accuracy of 98.7% and 97.8%, respectively.",
        "primary_area": "",
        "author": "Deepak Raina;SH Chandrashekhara;Richard Voyles;Juan Wachs;Subir Kumar Saha;Deepak Raina;SH Chandrashekhara;Richard Voyles;Juan Wachs;Subir Kumar Saha",
        "authorids": "/37088975582;/37089849855;/37283531400;/37327560600;/37346497700;/37088975582;/37089849855;/37283531400;/37327560600;/37346497700",
        "aff": "Purdue University (PU), Indiana, USA; All India Institute of Medical Sciences (AIIMS), Delhi, India; Purdue University (PU), Indiana, USA; Purdue University (PU), Indiana, USA; Indian Institute of Technology (IIT), Delhi, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161542/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15548220030235033473&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Purdue University;All India Institute of Medical Sciences;Indian Institute of Technology Delhi",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.purdue.edu;https://www.aiims.edu;https://www.iitdelhi.ac.in",
        "aff_unique_abbr": "PU;AIIMS;IIT Delhi",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Delhi",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "10161283",
        "title": "Robotic Table Wiping via Reinforcement Learning and Whole-body Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a framework to enable multipurpose assistive mobile robots to autonomously wipe tables to clean spills and crumbs. This problem is challenging, as it requires planning wiping actions while reasoning over uncertain latent dynamics of crumbs and spills captured via high-dimensional visual observations. Simultaneously, we must guarantee constraints satisfaction to enable safe deployment in unstructured cluttered environments. To tackle this problem, we first propose a stochastic differential equation to model crumbs and spill dynamics and absorption with a robot wiper. Using this model, we train a vision-based policy for planning wiping actions in simulation using reinforcement learning (RL). To enable zero-shot sim-to-real deployment, we dovetail the RL policy with a whole-body trajectory optimization framework to compute base and arm joint trajectories that execute the desired wiping motions while guaranteeing constraints satisfaction. We extensively validate our approach in simulation and on hardware. Video of experiments: https://youtu.be/inORKP4F3EI",
        "primary_area": "",
        "author": "Thomas Lew;Sumeet Singh;Mario Prats;Jeffrey Bingham;Jonathan Weisz;Benjie Holson;Xiaohan Zhang;Vikas Sindhwani;Yao Lu;Fei Xia;Peng Xu;Tingnan Zhang;Jie Tan;Montserrat Gonzalez;Thomas Lew;Sumeet Singh;Mario Prats;Jeffrey Bingham;Jonathan Weisz;Benjie Holson;Xiaohan Zhang;Vikas Sindhwani;Yao Lu;Fei Xia;Peng Xu;Tingnan Zhang;Jie Tan;Montserrat Gonzalez",
        "authorids": "/37088471189;/37085589975;/37420647500;/37089194143;/37089918032;/37089893665;/37088687363;/37282057000;/37089893664;/37089893977;/37089895849;/37088504200;/37086455820;/37089892798;/37088471189;/37085589975;/37420647500;/37089194143;/37089918032;/37089893665;/37088687363;/37282057000;/37089893664;/37089893977;/37089895849;/37088504200;/37086455820;/37089892798",
        "aff": "Department of Aeronautics and Astronautics, Stanford University; Robotics at Google; Everyday Robots; Everyday Robots; Everyday Robots; Everyday Robots; Department of Computer Science, SUNY Binghamton; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161283/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4506200663660178388&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 28,
        "aff_unique_index": "0;1;2;2;2;2;3;1;1;1;1;1;1;1",
        "aff_unique_norm": "Stanford University;Google;Everyday Robots;State University of New York at Binghamton",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;Robotics;;Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu;https://www.google.com;https://www.everydayrobots.com;https://www.binghamton.edu",
        "aff_unique_abbr": "Stanford;Google Robotics;;SUNY Binghamton",
        "aff_campus_unique_index": "0;1;3;1;1;1;1;1;1;1",
        "aff_campus_unique": "Stanford;Mountain View;;Binghamton",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161309",
        "title": "Robust Bipedal Locomotion: Leveraging Saltation Matrices for Gait Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to generate robust walking gaits on bipedal robots is key to their successful realization on hard-ware. To this end, this work extends the method of Hybrid Zero Dynamics (HZD) \u2013 which traditionally only accounts for locomotive stability via periodicity constraints under perfect impact events \u2013 through the inclusion of the saltation matrix with a view toward synthesizing robust walking gaits. By jointly minimizing the norm of the extended saltation matrix and the torque of the robot directly in the gait generation process, we demonstrate that the synthesized gaits are more robust than gaits generated with either term alone; these results are shown in simulation and on hardware for the AMBER-3M planar biped and the Atalante lower-body exoskeleton (both with and without a human subject). The end result is experimental validation that combining saltation matrices with HZD methods produces more robust bipedal walking in practice.",
        "primary_area": "",
        "author": "Maegan Tucker;Noel Csomay-Shanklin;Aaron D. Ames;Maegan Tucker;Noel Csomay-Shanklin;Aaron D. Ames",
        "authorids": "/37087122493;/37086862522;/37300877900;/37087122493;/37086862522;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Control and Dynamical Systems, California Institute of Technology, Pasadena, CA; Department of Control and Dynamical Systems, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161309/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11406381365762205401&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160546",
        "title": "Robust Collaborative 3D Object Detection in Presence of Pose Errors",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative 3D object detection exploits information exchange among multiple agents to enhance accuracy of object detection in presence of sensor impairments such as occlusion. However, in practice, pose estimation errors due to imperfect localization would cause spatial message misalignment and significantly reduce the performance of collaboration. To alleviate adverse impacts of pose errors, we propose CoAlign, a novel hybrid collaboration framework that is robust to unknown pose errors. The proposed solution relies on a novel agent-object pose graph modeling to enhance pose consistency among collaborating agents. Furthermore, we adopt a multiscale data fusion strategy to aggregate intermediate features at multiple spatial resolutions. Comparing with previous works, which require ground-truth pose for training supervision, our proposed CoAlign is more practical since it doesn't require any ground-truth pose supervision in the training and makes no specific assumptions on pose errors. Extensive evaluation of the proposed method is carried out on multiple datasets, certifying that CoAlign significantly reduce relative localization error and achieving the state of art detection performance when pose errors exist. Code are made available for the use of the research community at https://github.com/yifanlu0227/CoAlign.",
        "primary_area": "",
        "author": "Yifan Lu;Quanhao Li;Baoan Liu;Mehrdad Dianati;Chen Feng;Siheng Chen;Yanfeng Wang;Yifan Lu;Quanhao Li;Baoan Liu;Mehrdad Dianati;Chen Feng;Siheng Chen;Yanfeng Wang",
        "authorids": "/37088348214;/37089892195;/37087244495;/37398308500;/37086391326;/37085436580;/37085615187;/37088348214;/37089892195;/37087244495;/37398308500;/37086391326;/37085436580;/37085615187",
        "aff": "Cooperative Medianet Innovation Center (CMIC), Shanghai Jiao Tong University, China; Nanjing University, China; Meta Reality Labs, USA; University of Warwick, UK; New York University, USA; Shanghai AI laboratory, China; Shanghai AI laboratory, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160546/",
        "gs_citation": 116,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2140808826279991898&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;4;5;5",
        "aff_unique_norm": "Shanghai Jiao Tong University;Nanjing University;Meta Reality Labs;University of Warwick;New York University;Shanghai AI Laboratory",
        "aff_unique_dep": "Cooperative Medianet Innovation Center (CMIC);;;;;",
        "aff_unique_url": "https://www.sjtu.edu.cn;http://www.nju.edu.cn;;https://www.warwick.ac.uk;https://www.nyu.edu;https://www.shanghaiailab.com",
        "aff_unique_abbr": "SJTU;Nanjing U;;Warwick;NYU;SAIL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;2;1;0;0",
        "aff_country_unique": "China;United States;United Kingdom"
    },
    {
        "id": "10160315",
        "title": "Robust Double-Encoder Network for RGB-D Panoptic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Perception is crucial for robots that act in real-world environments, as autonomous systems need to see and understand the world around them to act properly. Panoptic segmentation provides an interpretation of the scene by computing a pixelwise semantic label together with instance IDs. In this paper, we address panoptic segmentation using RGB-D data of indoor scenes. We propose a novel encoder-decoder neural network that processes RGB and depth separately through two encoders. The features of the individual encoders are progressively merged at different resolutions, such that the RGB features are enhanced using complementary depth information. We propose a novel merging approach called ResidualExcite, which reweighs each entry of the feature map according to its importance. With our double-encoder architecture, we are robust to missing cues. In particular, the same model can train and infer on RGB-D, RGB-only, and depth-only input data, without the need to train specialized models. We evaluate our method on publicly available datasets and show that our approach achieves superior results compared to other common approaches for panoptic segmentation.",
        "primary_area": "",
        "author": "Matteo Sodano;Federico Magistri;Tiziano Guadagnino;Jens Behley;Cyrill Stachniss;Matteo Sodano;Federico Magistri;Tiziano Guadagnino;Jens Behley;Cyrill Stachniss",
        "authorids": "/37089432308;/37086805350;/37087324270;/37593243900;/37329668600;/37089432308;/37086805350;/37087324270;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160315/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7723797979305441950&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Bonn;Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-bonn.de;",
        "aff_unique_abbr": "UBonn;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160721",
        "title": "Robust Forecasting for Robotic Control: A Game-Theoretic Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern robots require accurate forecasts to make optimal decisions in the real world. For example, self-driving cars need an accurate forecast of other agents' future actions to plan safe trajectories. Current methods rely heavily on historical time series to accurately predict the future. However, relying entirely on the observed history is problematic since it could be corrupted by noise, have outliers, or not completely represent all possible outcomes. To solve this problem, we propose a novel framework for generating robust forecasts for robotic control. In order to model real-world factors affecting future forecasts, we introduce the notion of an adversary, which perturbs observed historical time series to increase a robot's ultimate control cost. Specifically, we model this interaction as a zero-sum two-player game between a robot's forecaster and this hypothetical adversary. We show that our proposed game may be solved to a local Nash equilibrium using gradient-based optimization techniques. Furthermore, we show that a forecaster trained with our method performs 30.14% better on out-of-distribution real-world lane change data than baselines.",
        "primary_area": "",
        "author": "Shubhankar Agarwal;David Fridovich-Keil;Sandeep P. Chinchali;Shubhankar Agarwal;David Fridovich-Keil;Sandeep P. Chinchali",
        "authorids": "/37089892268;/37086041251;/37089002336;/37089892268;/37086041251;/37089002336",
        "aff": "Departments of Electrical and Computer Engineering, The University of Texas at Austin; Aerospace Engineering & Engineering Mechanics, The University of Texas at Austin; Departments of Electrical and Computer Engineering, The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160721/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11273462526207658694&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Texas at Austin",
        "aff_unique_dep": "Departments of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160453",
        "title": "Robust Human Pose Estimation under Gaussian Noise",
        "track": "main",
        "status": "Poster",
        "abstract": "Robustness against specific kinds of noise is of high importance for safety-critical components in industrial robot applications, as legal and normative regulations demand the identification and handling of all unacceptable risks. This includes risks from environmental conditions, like noisy data. One such component is human pose estimation, which is needed and crucial for human-robot collaboration tasks and applications. However, little research on human pose estimation under specific noise types has been performed. In our work, we focus on extensively evaluating human pose estimation under specific noise and propose potential countermeasures. We leverage Gaussian noise as specific noise type and the hourglass model as human pose estimator. We show that human pose estimation is already vulnerable to small amounts of Gaussian noise. As countermeasures we propose either denoising images upfront or training the hourglass model to be robust against Gaussian noise. All methods achieve a significantly higher robustness against Gaussian noise, typically at the cost of slightly worse performance on clean data. Three of our methods also achieved slight improvements on clean data.",
        "primary_area": "",
        "author": "Patrick Schlosser;Christoph Ledermann;Patrick Schlosser;Christoph Ledermann",
        "authorids": "/37088366421;/38468554800;/37088366421;/38468554800",
        "aff": "Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160453/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9790749677639229938&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161518",
        "title": "Robust Imaging Sonar-based Place Recognition and Localization in Underwater Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition using SOund Navigation and Ranging (SONAR) images is an important task for simultaneous localization and mapping (SLAM) in underwater environments. This paper proposes a robust and efficient imaging SONAR-based place recognition, SONAR context, and loop closure method. Unlike previous methods, our approach encodes geometric information based on the characteristics of raw SONAR measurements without prior knowledge or training. We also design a hierarchical searching procedure for fast retrieval of candidate SONAR frames and apply adaptive shifting and padding to achieve robust matching on rotation and translation changes. In addition, we can derive the initial pose through adaptive shifting and apply it to the iterative closest point (ICP)-based loop closure factor. We evaluate the SONAR context's performance in the various underwater sequences such as simulated open water, real water tank, and real underwater environments. The proposed approach shows the robustness and improvements of place recognition on various datasets and evaluation metrics. Supplementary materials are available at https://github.com/sparolab/sonar_context.git.",
        "primary_area": "",
        "author": "Hogyun Kim;Gilhwan Kang;Seokhwan Jeong;Seungjun Ma;Younggun Cho;Hogyun Kim;Gilhwan Kang;Seokhwan Jeong;Seungjun Ma;Younggun Cho",
        "authorids": "/37089893328;/37089894614;/37089892559;/37089893623;/37085469522;/37089893328;/37089894614;/37089892559;/37089893623;/37085469522",
        "aff": "Dept. Electrical and Computer Engineering, Inha University, Incheon, South Korea; Dept. Electrical and Computer Engineering, Inha University, Incheon, South Korea; Dept. Electrical and Computer Engineering, Inha University, Incheon, South Korea; Dept. Electrical and Computer Engineering, Inha University, Incheon, South Korea; Dept. Electrical and Computer Engineering, Inha University, Incheon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161518/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16678488184158323977&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Inha University",
        "aff_unique_dep": "Dept. Electrical and Computer Engineering",
        "aff_unique_url": "https://www.inha.edu",
        "aff_unique_abbr": "Inha",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Incheon",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161438",
        "title": "Robust Incremental Smoothing and Mapping (riSAM)",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for robust optimization for online incremental Simultaneous Localization and Mapping (SLAM). Due to the NP-Hardness of data association in the presence of perceptual aliasing, tractable (approximate) approaches to data association will produce erroneous measurements. We require SLAM back-ends that can converge to accurate solutions in the presence of outlier measurements while meeting online efficiency constraints. Existing robust SLAM methods either remain sensitive to outliers, become increasingly sensitive to initialization, or fail to provide online efficiency. We present the robust incremental Smoothing and Mapping (riSAM) algorithm, a robust back-end optimizer for incremental SLAM based on Graduated Non-Convexity. We demonstrate on benchmarking datasets that our algorithm achieves online efficiency, outperforms existing online approaches, and matches or improves the performance of existing offline methods.",
        "primary_area": "",
        "author": "Daniel McGann;John G. Rogers;Michael Kaess;Daniel McGann;John G. Rogers;Michael Kaess",
        "authorids": "/37086862643;/37533731800;/37324200400;/37086862643;/37533731800;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; DEVCOM Army Research Laboratory, Adelphi, MD, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161438/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17515930307546282608&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;DEVCOM Army Research Laboratory",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;",
        "aff_unique_abbr": "CMU;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;Adelphi",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160672",
        "title": "Robust Locomotion on Legged Robots through Planning on Motion Primitive Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "The functional demands of robotic systems often require completing various tasks or behaviors under the effect of disturbances or uncertain environments. Of increasing interest is the autonomy for dynamic robots, such as multirotors, motor vehicles, and legged platforms. Here, disturbances and environmental conditions can have significant impact on the successful performance of the individual dynamic behaviors, referred to as \u201cmotion primitives\u201d. Despite this, robustness can be achieved by switching to and transitioning through suitable motion primitives. This paper contributes such a method by presenting an abstraction of the motion primitive dynamics and a corresponding\u201dmotion primitive transfer function\u201d. From this, a mixed discrete and continuous \u201cmotion primitive graph\u201d is constructed, and an algorithm capable of online search of this graph is detailed. The result is a framework capable of realizing holistic robustness on dynamic systems. This is experimentally demonstrated for a set of motion primitives on a quadrupedal robot, subject to various environmental and intentional disturbances.",
        "primary_area": "",
        "author": "Wyatt Ubellacker;Aaron D. Ames;Wyatt Ubellacker;Aaron D. Ames",
        "authorids": "/37077831700;/37300877900;/37077831700;/37300877900",
        "aff": "Departments of Control and Dynamical Systems, Mechanical and Civil Engineering, California Institute of Technology, Pasaden, CA, USA; Departments of Control and Dynamical Systems, Mechanical and Civil Engineering, California Institute of Technology, Pasaden, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160672/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12970531600800661506&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Departments of Control and Dynamical Systems, Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161244",
        "title": "Robust MADER: Decentralized and Asynchronous Multiagent Trajectory Planner Robust to Communication Delay",
        "track": "main",
        "status": "Poster",
        "abstract": "Although communication delays can disrupt multiagent systems, most of the existing multiagent trajectory planners lack a strategy to address this issue. State-of-the-art approaches typically assume perfect communication environments, which is hardly realistic in real-world experiments. This paper presents Robust MADER (RMADER), a decentralized and asynchronous multiagent trajectory planner that can handle communication delays among agents. By broadcasting both the newly optimized trajectory and the committed trajectory, and by performing a delay check step, RMADER is able to guarantee safety even under communication delay. RMADER was validated through extensive simulation and hardware flight experiments and achieved a 100% success rate of collision-free trajectory generation, outperforming state-of-the-art approaches.",
        "primary_area": "",
        "author": "Kota Kondo;Jesus Tordesillas;Reinaldo Figueroa;Juan Rached;Joseph Merkel;Parker C. Lusk;Jonathan P. How;Kota Kondo;Jesus Tordesillas;Reinaldo Figueroa;Juan Rached;Joseph Merkel;Parker C. Lusk;Jonathan P. How",
        "authorids": "/37089893140;/37086933970;/37089895835;/37089896041;/37089895548;/37088441763;/37276347700;/37089893140;/37086933970;/37089895835;/37089896041;/37089895548;/37088441763;/37276347700",
        "aff": "MIT, Aerospace Controls Laboratory, Cambridge, MA, USA; MIT, Aerospace Controls Laboratory, Cambridge, MA, USA; MIT, Aerospace Controls Laboratory, Cambridge, MA, USA; MIT, Aerospace Controls Laboratory, Cambridge, MA, USA; MIT, Aerospace Controls Laboratory, Cambridge, MA, USA; MIT, Aerospace Controls Laboratory, Cambridge, MA, USA; MIT, Aerospace Controls Laboratory, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161244/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4083273901195645870&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Aerospace Controls Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161072",
        "title": "Robust Map Fusion with Visual Attention Utilizing Multi-agent Rendezvous",
        "track": "main",
        "status": "Poster",
        "abstract": "The map fusion for multi-robot simultaneous localization and mapping (SLAM) consistently combines robot maps built independently into the global map. An established approach to map fusion is utilizing rendezvous, which refers to an encounter between multiple agents, to calculate the transformation into the global map. However, previous works using rendezvous have a limitation in that they are unreliable for certain circumstances, where the amount of agent observations or overlapping landmarks is limited. This work proposes a novel map fusion system which robustly fuses local maps in challenging rendezvous that lack shared information. Our system utilizes the single visual perception from rendezvous and estimates the relative pose between agents with the DOPE. Then our scheme transforms local maps with an estimated relative pose and predicts the misalignment from approximated maps by utilizing the attention mechanism of the vision transformer. Comparisons with the Hough transform-based method show that ours is significantly better when the overlap between local maps is insufficient. We also verify the robustness of our system against a similar real-world scenario.",
        "primary_area": "",
        "author": "Jaein Kim;Dong-Sig Han;Byoung-Tak Zhang;Jaein Kim;Dong-Sig Han;Byoung-Tak Zhang",
        "authorids": "/37086787077;/37089894943;/37336068500;/37086787077;/37089894943;/37336068500",
        "aff": "Artificial Intelligence Institute, Seoul National University; Artificial Intelligence Institute, Seoul National University; Artificial Intelligence Institute, Seoul National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161072/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6400714726413738590&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Artificial Intelligence Institute",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161405",
        "title": "Robust Navigation with Cross-Modal Fusion and Knowledge Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, learning-based approaches show promising results in navigation tasks. However, the poor generalization capability and the simulation-reality gap prevent a wide range of applications. We consider the problem of improving the generalization of mobile robots and achieving sim-to-real transfer for navigation skills. To that end, we propose a cross-modal fusion method and a knowledge transfer framework for better generalization. This is realized by a teacher-student distillation architecture. The teacher learns a discriminative representation and the near-perfect policy in an ideal environment. By imitating the behavior and representation of the teacher, the student is able to align the features from noisy multi-modal input and reduce the influence of variations on navigation policy. We evaluate our method in simulated and real-world environments. Experiments show that our method outperforms the baselines by a large margin and achieves robust navigation performance with varying working conditions.",
        "primary_area": "",
        "author": "Wenzhe Cai;Guangran Cheng;Lingyue Kong;Lu Dong;Changyin Sun;Wenzhe Cai;Guangran Cheng;Lingyue Kong;Lu Dong;Changyin Sun",
        "authorids": "/37089833996;/37087882515;/37089863734;/37085616812;/37279060100;/37089833996;/37087882515;/37089863734;/37085616812;/37279060100",
        "aff": "School of Automation, Southeast University, Nanjing, China; School of Automation, Southeast University, Nanjing, China; School of Automation, Southeast University, Nanjing, China; School of Cyber science and Engineering, Southeast University, Nanjing, China; School of Automation, Southeast University, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161405/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=48734115463884878&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Southeast University",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "https://www.seu.edu.cn/",
        "aff_unique_abbr": "SEU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160921",
        "title": "Robust Output Feedback controller for a Serial Robotic Manipulator with Unknown Nonlinearities and External Disturbances",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a robust output feedback controller for a n-link serial robotic manipulator with unknown dynamics and external disturbances. First, the robotic manipulator's model is formulated with unknown dynamics, including joint coupling, nonlinearities, and external disturbances. Second, an output feedback controller is proposed by combining a backstepping controller and an extended high-gain observer to estimate the unknown dynamic and external disturbances in addition to the system states. Experiments on 4 DOF robotic manipulators verify the proposed control approach. The proposed control approach achieved the end-effector's desired trajectory under unknown system dynamics and disturbances.",
        "primary_area": "",
        "author": "Mohammad Al Saaideh;Almuatazbellah M. Boker;Mohammad Al Janaideh;Mohammad Al Saaideh;Almuatazbellah M. Boker;Mohammad Al Janaideh",
        "authorids": "/37086837206;/38547088600;/37542671600;/37086837206;/38547088600;/37542671600",
        "aff": "Department of Mechanical and Mechatronics Engineering, Memorial University, St. John's, NL, Canada; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; School of Engineering, University of Guelph, Guelph, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160921/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=481683306779498914&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Memorial University;Virginia Tech;University of Guelph",
        "aff_unique_dep": "Department of Mechanical and Mechatronics Engineering;Bradley Department of Electrical and Computer Engineering;School of Engineering",
        "aff_unique_url": "https://www.mun.ca;https://www.vt.edu;https://www.uoguelph.ca",
        "aff_unique_abbr": "MUN;VT;U of G",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "St. John's;Blacksburg;Guelph",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "10161078",
        "title": "Robust Plant Localization and Phenotyping in Dense 3D Point Clouds for Precision Agriculture",
        "track": "main",
        "status": "Poster",
        "abstract": "The determination of a crop's growth-stage is critical information for precision agriculture. Estimates of the growth-stage are used to guide irrigation and the application of agrochemicals. Of particular importance is the use of fertilizers, however, growth-stage estimates may also suggest further investigation of potential crop infections and infestations. Traditionally, the growth-stage is based upon a manual random sample of a very small number of plants that are then analyzed to produce an estimate for the entire crop (up to thousands of acres). In order to increase the sample size (and thus accuracy) and to enable precision agriculture to address non-uniform crop development across a field, we present an analysis methodology that facilitates the automated growth-stage analysis of dense point clouds that are derived from drone imagery. Our method utilizes a standard camera drone and does not use specialized sensors or geo-spatial tagging. We propose a multi-stage unsupervised method, which provides information about the individual plant locations in a field plot with a high probability. The method also produces a measure of individual plant heights, which along with their location are critical for later growth-stage estimation and necessary for robotic precision application. We confirm our method's efficacy with experimental results on corn fields in Minnesota.",
        "primary_area": "",
        "author": "Henry J. Nelson;Christopher E. Smith;Athanasios Bacharis;Nikolaos P. Papanikolopoulos;Henry J. Nelson;Christopher E. Smith;Athanasios Bacharis;Nikolaos P. Papanikolopoulos",
        "authorids": "/37089779778;/37336754800;/37089661881;/37278578300;/37089779778;/37336754800;/37089661881;/37278578300",
        "aff": "Department of Computer Science and Engineering, University of Minnesota; School of Computer Science and Mathematics, Lake Superior State University; Department of Computer Science and Engineering, University of Minnesota; Department of Computer Science and Engineering, University of Minnesota",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161078/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1300461536251480231&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Minnesota;Lake Superior State University",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Computer Science and Mathematics",
        "aff_unique_url": "https://www.umn.edu;https://www.lssu.edu",
        "aff_unique_abbr": "UMN;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161406",
        "title": "Robust Robot Planning for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "In human-robot collaboration, the objectives of the human are often unknown to the robot. Moreover, even assuming a known objective, the human behavior is also uncertain. In order to plan a robust robot behavior, a key preliminary question is then: How to derive realistic human behaviors given a known objective? A major issue is that such a human behavior should itself account for the robot behavior, otherwise collaboration cannot happen. In this paper, we rely on Markov decision models, representing the uncertainty over the human objective as a probability distribution over a finite set of objective functions (inducing a distribution over human behaviors). Based on this, we propose two contributions: 1) an approach to automatically generate an uncertain human behavior (a policy) for each given objective function while accounting for possible robot behaviors; and 2) a robot planning algorithm that is robust to the above-mentioned uncertainties and relies on solving a partially observable Markov decision process (POMDP) obtained by reasoning on a distribution over human behaviors. A co-working scenario allows conducting experiments and presenting qualitative and quantitative results to evaluate our approach.",
        "primary_area": "",
        "author": "Yang You;Vincent Thomas;Francis Colas;Rachid Alami;Olivier Buffet;Yang You;Vincent Thomas;Francis Colas;Rachid Alami;Olivier Buffet",
        "authorids": "/37089201232;/38310687400;/37966799000;/37278643600;/37565063400;/37089201232;/38310687400;/37966799000;/37278643600;/37565063400",
        "aff": "Universit\u00e9 de Lorraine, INRIA, CNRS, LORIA, Nancy, France; Universit\u00e9 de Lorraine, INRIA, CNRS, LORIA, Nancy, France; Universit\u00e9 de Lorraine, INRIA, CNRS, LORIA, Nancy, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; Universit\u00e9 de Lorraine, INRIA, CNRS, LORIA, Nancy, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161406/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14739829786191659799&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Universit\u00e9 de Lorraine;LAAS-CNRS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.univ-lorraine.fr;https://www.laas.fr/",
        "aff_unique_abbr": "UL;LAAS-CNRS",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Nancy;Toulouse",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10161452",
        "title": "Robust Uncertainty Estimation for Classification of Maritime Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "We explore the use of uncertainty estimation in the maritime domain, showing the efficacy on toy datasets (CIFAR10) and proving it on an in-house dataset, SHIPS. We present a method joining the intra-class uncertainty achieved using Monte Carlo Dropout, with recent discoveries in the field of outlier detection, to gain more holistic uncertainty measures. We explore the relationship between the introduced uncertainty measures and examine how well they work on CIFAR10 and in a real-life setting. Our work improves the FPR95 by 8% compared to the current highest-performing work when the models are trained without out-of-distribution data. We increase the performance by 77% compared to a vanilla implementation of the Wide ResNet. We release the SHIPS dataset and show the effectiveness of our method by improving the FPR95 by 44.2 % with respect to the baseline. Our approach is model agnostic, easy to implement, and often does not require model retraining.",
        "primary_area": "",
        "author": "Jonathan Becktor;Frederik Sch\u00f6ller;Evangelos Boukas;Lazaros Nalpantidis;Jonathan Becktor;Frederik Sch\u00f6ller;Evangelos Boukas;Lazaros Nalpantidis",
        "authorids": "/37089479797;/37089213113;/38232071900;/37304022500;/37089479797;/37089213113;/38232071900;/37304022500",
        "aff": "Department of Electrical and Photonics Engineering, DTU - Technical University of Denmark; Department of Electrical and Photonics Engineering, DTU - Technical University of Denmark; Department of Electrical and Photonics Engineering, DTU - Technical University of Denmark; Department of Electrical and Photonics Engineering, DTU - Technical University of Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161452/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6661775213358767381&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Denmark",
        "aff_unique_dep": "Department of Electrical and Photonics Engineering",
        "aff_unique_url": "https://www.dtu.dk",
        "aff_unique_abbr": "DTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "10161134",
        "title": "Robust co-design of robots via cascaded optimisation",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimising mechanical, control and actuator design variables together as a co-design problem enables identifying novel and better-performing robot architectures. Typically, solving such problems using conventional optimisation methods yields a single, point-based solution. Deviating from the computed optima may be necessary to ensure physical feasibility, typically associated with a performance loss. In this work, we present a two-step cascaded optimisation approach to identify non-intuitive designs and recover the loss in performance by constructing a solution space. The solution space provides robustness in the form of permissible ranges of design variable values and enables the selection of a physically feasible design. In our study, we observe (1) up to 20% of the lost performance is recovered and (2) an improvement of 30 % on the task metric in comparison to an existing robot and (3) designs with cost savings of up to 10% can be identified.",
        "primary_area": "",
        "author": "Akhil Sathuluri;Anand Vazhapilli Sureshbabu;Markus Zimmermann;Akhil Sathuluri;Anand Vazhapilli Sureshbabu;Markus Zimmermann",
        "authorids": "/37085990259;/37086116075;/37076625200;/37085990259;/37086116075;/37076625200",
        "aff": "Robot Systems group, Laboratory for Product Development and Lightweight Design, TUM School of Engineering and Design, Technical University of Munich (TUM), Germany; Robot Systems group, Laboratory for Product Development and Lightweight Design, TUM School of Engineering and Design, Technical University of Munich (TUM), Germany; Robot Systems group, Laboratory for Product Development and Lightweight Design, TUM School of Engineering and Design, Technical University of Munich (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161134/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4552228363598204641&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "TUM School of Engineering and Design",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161510",
        "title": "Robust, High-Rate Trajectory Tracking on Insect-Scale Soft-Actuated Aerial Robots with Deep-Learned Tube MPC",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and agile trajectory tracking in sub-gram Micro Aerial Vehicles (MAVs) is challenging, as the small scale of the robot induces large model uncertainties, demanding robust feedback controllers, while the fast dynamics and computational constraints prevent the deployment of computationally expensive strategies. In this work, we present an approach for agile and computationally efficient trajectory tracking on the MIT SoftFly [1], a sub-gram MAV (0.7 grams). Our strategy employs a cascaded control scheme, where an adaptive attitude controller is combined with a neural network (NN) policy trained to imitate a trajectory tracking robust tube model predictive controller (RTMPC). The NN policy is obtained using our recent work [2], which enables the policy to preserve the robustness of RTMPC, but at a fraction of its computational cost. We experimentally evaluate our approach, achieving position Root Mean Square Errors (RMSEs) lower than 1.8 cm even in the more challenging maneuvers, obtaining a 60% reduction in maximum position error compared to [3], and demonstrating robustness to large external disturbances.",
        "primary_area": "",
        "author": "Andrea Tagliabue;Yi-Hsuan Hsiao;Urban Fasel;J. Nathan Kutz;Steven L. Brunton;YuFeng Chen;Jonathan P. How;Andrea Tagliabue;Yi-Hsuan Hsiao;Urban Fasel;J. Nathan Kutz;Steven L. Brunton;YuFeng Chen;Jonathan P. How",
        "authorids": "/37086131568;/37086580197;/37089279510;/37426300800;/37395246400;/37085417667;/37276347700;/37086131568;/37086580197;/37089279510;/37426300800;/37395246400;/37085417667;/37276347700",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Imperial College London; University of Washington; University of Washington; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161510/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1733107439598876517&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;2;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Imperial College London;University of Washington",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://web.mit.edu;https://www.imperial.ac.uk;https://www.washington.edu",
        "aff_unique_abbr": "MIT;ICL;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "10160548",
        "title": "Rotation Synchronization via Deep Matrix Factorization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we address the rotation synchronization problem, where the objective is to recover absolute rotations starting from pairwise ones, where the unknowns and the measures are represented as nodes and edges of a graph, respectively. This problem is an essential task for structure from motion and simultaneous localization and mapping. We focus on the formulation of synchronization via neural networks, which has only recently begun to be explored in the literature. Inspired by deep matrix completion, we express rotation synchronization in terms of matrix factorization with a deep neural network. Our formulation exhibits implicit regularization properties and, more importantly, is unsupervised, whereas previous deep approaches are supervised. Our experiments show that we achieve comparable accuracy to the closest competitors in most scenes, while working under weaker assumptions.",
        "primary_area": "",
        "author": "GK Tejus;Giacomo Zara;Paolo Rota;Andrea Fusiello;Elisa Ricci;Federica Arrigoni;GK Tejus;Giacomo Zara;Paolo Rota;Andrea Fusiello;Elisa Ricci;Federica Arrigoni",
        "authorids": "/37089894482;/37089301005;/37085485522;/37271576300;/37299091700;/37085554179;/37089894482;/37089301005;/37085485522;/37271576300;/37299091700;/37085554179",
        "aff": "Indian Institute of Technology (ISM), Dhanbad, India; University of Trento, Italy; University of Trento, Italy; University of Udine, Italy; University of Trento, Italy; Politecnico di Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160548/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1156817956457617884&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;1;3",
        "aff_unique_norm": "Indian Institute of Technology (ISM);University of Trento;University of Udine;Politecnico di Milano",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.iitism.ac.in;https://www.unitn.it;https://www.uniud.it;https://www.polimi.it",
        "aff_unique_abbr": "IIT (ISM);UniTN;;Polimi",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Dhanbad;",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "India;Italy"
    },
    {
        "id": "10161248",
        "title": "S*: On Safe and Time Efficient Robot Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots and humans increasingly share the same workspace, the development of safe motion plans becomes paramount. For real-world applications, nonetheless, it is critical that safety solutions are achieved without compromising performance. The computation of safe, time-efficient trajectories, however, usually requires rather complex often decoupled planning and optimization methods which degrades the nominal performance. In this work, instead, we cast the problem as a graph search-based scheme that enables us to solve the problem efficiently. The graph search is guided by an informed cost balance criterion. In this context we present the S* algorithm which minimizes the total planning time by equilibrising shortest time-efficient paths and paths with higher safe velocities. The approach is compatible with standards and validated both in rigorous simulation trials on a 6 DoF UR5 robot as well as real world experiments on a Franka Emika 7 DoF research robot.",
        "primary_area": "",
        "author": "Riddhiman Laha;Wenxi Wu;Ruiai Sun;Nico Mansfeld;Luis F.C. Figueredo;Sami Haddadin;Riddhiman Laha;Wenxi Wu;Ruiai Sun;Nico Mansfeld;Luis F.C. Figueredo;Sami Haddadin",
        "authorids": "/37089002102;/37089448845;/37089448539;/38541896600;/37063909900;/37542865300;/37089002102;/37089448845;/37089448539;/38541896600;/37063909900;/37542865300",
        "aff": "Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany; King's College London, London, United Kingdom; Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany; Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany; Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany; Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161248/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5065644191802874550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich;King's College London",
        "aff_unique_dep": "Munich Institute of Robotics and Machine Intelligence;",
        "aff_unique_url": "https://www.tum.de;https://www.kcl.ac.uk",
        "aff_unique_abbr": "TUM;KCL",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Munich;London",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "10161129",
        "title": "SACPlanner: Real-World Collision Avoidance with a Soft Actor Critic Local Planner and Polar State Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the training performance of ROS local planners based on Reinforcement Learning (RL), and the trajectories they produce on real-world robots. We show that recent enhancements to the Soft Actor Critic (SAC) algorithm such as RAD and DrQ achieve almost perfect training after only 10000 episodes. We also observe that on real-world robots the resulting SACPlanner is more reactive to obstacles than traditional ROS local planners such as DWA.",
        "primary_area": "",
        "author": "Khaled Nakhleh;Minahil Raza;Mack Tang;Matthew Andrews;Rinu Boney;Ilija Had\u017ei\u0107;Jeongran Lee;Atefeh Mohajeri;Karina Palyutina;Khaled Nakhleh;Minahil Raza;Mack Tang;Matthew Andrews;Rinu Boney;Ilija Had\u017ei\u0107;Jeongran Lee;Atefeh Mohajeri;Karina Palyutina",
        "authorids": "/37089428710;/37089205588;/37089893069;/37271306500;/37089225971;/37085824139;/37089896134;/37089892231;/37088453716;/37089428710;/37089205588;/37089893069;/37271306500;/37089225971;/37085824139;/37089896134;/37089892231;/37088453716",
        "aff": "Nokia Bell Labs, Murray Hill, Espoo, Cambridge, NJ, UK, Finland, United Kingdom; Nokia Bell Labs, Murray Hill, Espoo, Cambridge, NJ, UK, Finland, United Kingdom; Nokia Bell Labs, Murray Hill, Espoo, Cambridge, NJ, UK, Finland, United Kingdom; Nokia Bell Labs, Murray Hill, Espoo, Cambridge, NJ, UK, Finland, United Kingdom; Nokia Bell Labs, Murray Hill, Espoo, Cambridge, NJ, UK, Finland, United Kingdom; Nokia Bell Labs, Murray Hill, Espoo, Cambridge, NJ, UK, Finland, United Kingdom; Nokia Bell Labs, Murray Hill, Espoo, Cambridge, NJ, UK, Finland, United Kingdom; Nokia Bell Labs, Murray Hill, Espoo, Cambridge, NJ, UK, Finland, United Kingdom; C\u00e1tedras CONACYT\u2013IER\u2013UNAM, Murray Hill, Espoo, Cambridge, NJ, UK, Finland, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161129/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14785117623612422264&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;1",
        "aff_unique_norm": "Nokia Bell Labs;CONACYT\u2013IER\u2013UNAM",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nokia.com bell-labs;",
        "aff_unique_abbr": "Nokia Bell Labs;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Murray Hill;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;1",
        "aff_country_unique": "United States;Mexico"
    },
    {
        "id": "10161033",
        "title": "SAMLoc: Structure-Aware Constraints With Multi-Task Distillation for Long-Term Visual Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time and robust long-term visual localization is a crucial technology for autonomous driving. Season and illumination variance make this problem more challenging. At present, most of excellent visual localization algorithms cannot run in real-time on devices with limited computing resources. In this paper, we propose SAMLoc, a structure-aware and self-supervised visual localization system, for fast and robust 6-DoF localization. To obtain structural features in the scene, we propose local and global structure-aware constraints using edge information. Then, we integrate the structure-aware constraints into the hierarchical localization network of multi-task distillation, which significantly reduces the feature extraction time while ensuring localization accuracy. As a result, real-time and robust large-scale localization can be achieved on mobile devices. Experimental results on public datasets show that our system can achieve high localization accuracy and have satisfactory real-time performance. Compared with several state-of-the-art visual localization systems, our framework achieves a competitive localization performance.",
        "primary_area": "",
        "author": "Jian Ning;Yunzhou Zhang;Xinge Zhao;Sonya Coleman;Kunmo Li;Dermot Kerr;Jian Ning;Yunzhou Zhang;Xinge Zhao;Sonya Coleman;Kunmo Li;Dermot Kerr",
        "authorids": "/37089892540;/37310459100;/37089626230;/37269140600;/37089892955;/37295244700;/37089892540;/37310459100;/37089626230;/37269140600;/37089892955;/37295244700",
        "aff": "College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; School of Computing and Intelligent Systems, Ulster University, N. Ireland, UK; College of Information Science and Engineering, Northeastern University, Shenyang, China; School of Computing and Intelligent Systems, Ulster University, N. Ireland, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161033/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15070969651903675241&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;1",
        "aff_unique_norm": "Northeastern University;Ulster University",
        "aff_unique_dep": "College of Information Science and Engineering;School of Computing and Intelligent Systems",
        "aff_unique_url": "http://www.neu.edu.cn/;https://www.ulster.ac.uk",
        "aff_unique_abbr": "NEU;Ulster",
        "aff_campus_unique_index": "0;0;0;1;0;1",
        "aff_campus_unique": "Shenyang;N. Ireland",
        "aff_country_unique_index": "0;0;0;1;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10160270",
        "title": "SCAN: Socially-Aware Navigation Using Monte Carlo Tree Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing a socially-aware navigation method for crowded environments has become a critical issue in robotics. In order to perform navigation in a crowded environment without causing discomfort to nearby pedestrians, it is necessary to design a global planner that is able to consider both human-robot interaction (HRI) and prediction of future states. In this paper, we propose a socially-aware global planner called SCAN, which is a global planner that generates appropriate local goals considering HRI and prediction of future states. Our method simulates future states considering the effects of the robot's actions on the future intentions of pedestrians using Monte Carlo tree search (MCTS), which estimates the quality of local goals. For fast simulation, we execute pedestrian motion prediction using Y-net and future state simulation using MCTS in parallel. Neural networks are only used in Y-net and not in MCTS, which enables fast simulation and prediction of a long horizon of future states. We evaluate the proposed method based on the proposed socially-aware navigation metric using realistic pedestrian simulation and real-world experiments. The results show that the proposed method outperforms existing methods significantly, indicating the importance of considering human-robot interaction for socially-aware navigation.",
        "primary_area": "",
        "author": "Jeongwoo Oh;Jaeseok Heo;Junseo Lee;Gunmin Lee;Minjae Kang;Jeongho Park;Songhwai Oh;Jeongwoo Oh;Jaeseok Heo;Junseo Lee;Gunmin Lee;Minjae Kang;Jeongho Park;Songhwai Oh",
        "authorids": "/37089660359;/37089662179;/37089896063;/37087323658;/37087323855;/37088567322;/37068116900;/37089660359;/37089662179;/37089896063;/37087323658;/37087323855;/37088567322;/37068116900",
        "aff": "Sequor Robotics, Inc., Seoul, Korea; Sequor Robotics, Inc., Seoul, Korea; Graduate School of Artificial Intelligence (GSAI) and - ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Enginnering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Enginnering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Enginnering and ASRI, Seoul National University, Seoul, Korea; Sequor Robotics, Inc., Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160270/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6447809648651090921&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;1;0",
        "aff_unique_norm": "Sequor Robotics, Inc.;Seoul National University",
        "aff_unique_dep": ";Graduate School of Artificial Intelligence (GSAI)",
        "aff_unique_url": ";https://www.snu.ac.kr",
        "aff_unique_abbr": ";SNU",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Seoul",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10160365",
        "title": "SCARP: 3D Shape Completion in ARbitrary Poses for Improved Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Recovering full 3D shapes from partial observations is a challenging task that has been extensively addressed in the computer vision community. Many deep learning methods tackle this problem by training 3D shape generation networks to learn a prior over the full 3D shapes. In this training regime, the methods expect the inputs to be in a fixed canonical form, without which they fail to learn a valid prior over the 3D shapes. We propose SCARP, a model that performs Shape C ompletion in ARbitrary Poses. Given a partial pointcloud of an object, SCARP learns a disentangled feature representation of pose and shape by relying on rotationally equivariant pose features and geometric shape features trained using a multi-tasking objective. Unlike existing methods that depend on an external canonicalization method, SCARP performs canonicalization, pose estimation, and shape completion in a single network, improving the performance by 45% over the existing baselines. In this work, we use SCARP for improving grasp proposals on tabletop objects. By completing partial tabletop objects directly in their observed poses, SCARP enables a SOTA grasp proposal network improve their proposals by 71.2% on partial shapes. Project page: https://bipashasen.github.io/scarp",
        "primary_area": "",
        "author": "Bipasha Sen;Aditya Agarwal;Gaurav Singh;Brojeshwar B.;Srinath Sridhar;Madhava Krishna;Bipasha Sen;Aditya Agarwal;Gaurav Singh;Brojeshwar B.;Srinath Sridhar;Madhava Krishna",
        "authorids": "/37089710155;/37088814238;/37089894924;/37089893575;/37085473189;/37089108874;/37089710155;/37088814238;/37089894924;/37089893575;/37085473189;/37089108874",
        "aff": "Robotics Research Center, IIIT, Hyderabad; Robotics Research Center, IIIT, Hyderabad; Robotics Research Center, IIIT, Hyderabad; TCS Research, India; Brown University; Robotics Research Center, IIIT, Hyderabad",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160365/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3659638805133880636&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad;Tata Consultancy Services;Brown University",
        "aff_unique_dep": "Robotics Research Center;Research;",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.tcs.com;https://www.brown.edu",
        "aff_unique_abbr": "IIIT Hyderabad;TCS;Brown",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hyderabad;",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "10160787",
        "title": "SCORE: A Second-Order Conic Initialization for Range-Aided SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel initialization technique for the range-aided simultaneous localization and mapping (RA-SLAM) problem. In RA-SLAM we consider measurements of point-to-point distances in addition to measurements of rigid transformations to landmark or pose variables. Standard formulations of RA-SLAM approach the problem as non-convex optimization, which requires a good initialization to obtain quality results. The initialization technique proposed here relaxes the RA-SLAM problem to a convex problem which is then solved to determine an initialization for the original, non-convex problem. The relaxation is a second-order cone program (SOCP), which is derived from a quadratically constrained quadratic program (QCQP) formulation of the RA-SLAM problem. As a SOCP, the method is highly scalable. We name this relaxation Second-order COnic RElaxation for RA-SLAM (SCORE). To our knowledge, this work represents the first convex relaxation for RA-SLAM. We present real-world and simulated experiments which show SCORE initialization permits the efficient recovery of quality solutions for a variety of challenging single- and multi-robot RA-SLAM problems with thousands of poses and range measurements.",
        "primary_area": "",
        "author": "Alan Papalia;Joseph Morales;Kevin J. Doherty;David M. Rosen;John J. Leonard;Alan Papalia;Joseph Morales;Kevin J. Doherty;David M. Rosen;John J. Leonard",
        "authorids": "/37088569409;/37089892752;/37085769742;/38252288400;/37329387400;/37088569409;/37089892752;/37085769742;/38252288400;/37329387400",
        "aff": "Department of Applied Ocean Physics & Engineering, Woods Hole Oceanographic Institution, Woods Hole, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Applied Ocean Physics & Engineering, Woods Hole Oceanographic Institution, Woods Hole, MA, USA; Department of Math, Northeastern University, Boston, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160787/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4013595197941348569&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;1",
        "aff_unique_norm": "Woods Hole Oceanographic Institution;Massachusetts Institute of Technology;Northeastern University",
        "aff_unique_dep": "Department of Applied Ocean Physics & Engineering;Computer Science and Artificial Intelligence Laboratory;Department of Math",
        "aff_unique_url": "https://www.whoi.edu;https://www.mit.edu;https://www.northeastern.edu",
        "aff_unique_abbr": "WHOI;MIT;NU",
        "aff_campus_unique_index": "0;1;0;2;1",
        "aff_campus_unique": "Woods Hole;Cambridge;Boston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161394",
        "title": "SDF-Based Graph Convolutional Q-Networks for Rearrangement of Multiple Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a signed distance field (SDF)-based deep Q-learning framework for multi-object re-arrangement. Our method learns to rearrange objects with non-prehensile manipulation, e.g., pushing, in unstructured environments. To reliably estimate Q-values in various scenes, we train the Q-network using an SDF-based scene graph as the state-goal representation. To this end, we introduce SDFGCN, a scalable Q-network structure which can estimate Q-values from a set of SDF images satisfying permutation invariance by using graph convolutional networks. In contrast to grasping-based rearrangement methods that rely on the performance of grasp predictive models for perception and movement, our approach enables rearrangements on unseen objects, including hard-to-grasp objects. Moreover, our method does not require any expert demonstrations. We observe that SDFGCN is capable of unseen objects in challenging configurations, both in the simulation and the real world.",
        "primary_area": "",
        "author": "Hogun Kee;Minjae Kang;Dohyeong Kim;Jaegoo Choy;Songhwai Oh;Hogun Kee;Minjae Kang;Dohyeong Kim;Jaegoo Choy;Songhwai Oh",
        "authorids": "/37088506967;/37087323855;/37088687766;/37088446661;/37068116900;/37088506967;/37087323855;/37088687766;/37088446661;/37068116900",
        "aff": "Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161394/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16900756418976740497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161569",
        "title": "SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-objective optimization problems are ubiquitous in robotics, e.g., the optimization of a robot manipulation task requires a joint consideration of grasp pose configurations, collisions and joint limits. While some demands can be easily hand-designed, e.g., the smoothness of a trajectory, several task-specific objectives need to be learned from data. This work introduces a method for learning data-driven SE(3) cost functions as diffusion models. Diffusion models can represent highly-expressive multimodal distributions and exhibit proper gradients over the entire space due to their score-matching training objective. Learning costs as diffusion models allows their seamless integration with other costs into a single differentiable objective function, enabling joint gradient-based motion optimization. In this work, we focus on learning SE(3) diffusion models for 6DoF grasping, giving rise to a novel framework for joint grasp and motion optimization without needing to decouple grasp selection from trajectory generation. We evaluate the representation power of our SE(3) diffusion models w.r.t. classical generative models, and we showcase the superior performance of our proposed optimization framework in a series of simulated and real-world robotic manipulation tasks against representative baselines. Videos, code and additional details are available at: https://sites.google.com/view/se3dif",
        "primary_area": "",
        "author": "Julen Urain;Niklas Funk;Jan Peters;Georgia Chalvatzaki;Julen Urain;Niklas Funk;Jan Peters;Georgia Chalvatzaki",
        "authorids": "/37086435541;/37089175184;/37533077600;/37085353493;/37086435541;/37089175184;/37533077600;/37085353493",
        "aff": "Technische Universit\u00e4t Darmstadt (Germany); Technische Universit\u00e4t Darmstadt (Germany); Centre for Cognitive Science; Technische Universit\u00e4t Darmstadt (Germany)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161569/",
        "gs_citation": 174,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4280257371623208855&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;Centre for Cognitive Science",
        "aff_unique_dep": ";Cognitive Science",
        "aff_unique_url": "https://www.tu-darmstadt.de;",
        "aff_unique_abbr": "TUD;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany;"
    },
    {
        "id": "10160295",
        "title": "SEER: Safe Efficient Exploration for Aerial Robots using Learning to Predict Information Gain",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of efficient 3-D exploration in indoor environments for micro aerial vehicles with limited sensing capabilities and payload/power constraints. We develop an indoor exploration framework that uses learning to predict the occupancy of unseen areas, extracts semantic features, samples viewpoints to predict information gains for different exploration goals, and plans informative trajectories to enable safe and smart exploration. Extensive experimentation in simulated and real-world environments shows the proposed approach outperforms the state-of-the-art exploration framework by 24% in terms of the total path length in a structured indoor environment and with a higher success rate during exploration.",
        "primary_area": "",
        "author": "Yuezhan Tao;Yuwei Wu;Beiming Li;Fernando Cladera;Alex Zhou;Dinesh Thakur;Vijay Kumar;Yuezhan Tao;Yuwei Wu;Beiming Li;Fernando Cladera;Alex Zhou;Dinesh Thakur;Vijay Kumar",
        "authorids": "/37089337827;/37088967674;/37089893615;/37089148940;/37086337095;/37085630008;/37280341400;/37089337827;/37088967674;/37089893615;/37089148940;/37086337095;/37085630008;/37280341400",
        "aff": "GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160295/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9983335880687197834&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161252",
        "title": "SEIL: Simulation-augmented Equivariant Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In robotic manipulation, acquiring samples is extremely expensive because it often requires interacting with the real world. Traditional image-level data augmentation has shown the potential to improve sample efficiency in various machine learning tasks. However, image-level data augmentation is insufficient for an imitation learning agent to learn good manipulation policies in a reasonable amount of demonstrations. We propose Simulation-augmented Equivariant Imitation Learning (SEIL), a method that combines a novel data augmentation strategy of supplementing expert trajectories with simulated transitions and an equivariant model that exploits the O(2) symmetry in robotic manipulation. Experimental evaluations demonstrate that our method can learn non-trivial manipulation tasks within ten demonstrations and outperform the baselines by a significant margin.",
        "primary_area": "",
        "author": "Mingxi Jia;Dian Wang;Guanang Su;David Klee;Xupeng Zhu;Robin Walters;Robert Platt;Mingxi Jia;Dian Wang;Guanang Su;David Klee;Xupeng Zhu;Robin Walters;Robert Platt",
        "authorids": "/37089895920;/37089895590;/37089893322;/37089660130;/37089893313;/37089893733;/37273991200;/37089895920;/37089895590;/37089893322;/37089660130;/37089893313;/37089893733;/37273991200",
        "aff": "Khoury College of Computer Sciences, Northeastern University; Khoury College of Computer Sciences, Northeastern University; Khoury College of Computer Sciences, Northeastern University; Khoury College of Computer Sciences, Northeastern University; Khoury College of Computer Sciences, Northeastern University; Khoury College of Computer Sciences, Northeastern University; Khoury College of Computer Sciences, Northeastern University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161252/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1446584162056836921&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Khoury College of Computer Sciences",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161487",
        "title": "SGDViT: Saliency-Guided Dynamic Vision Transformer for UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based object tracking has boosted extensive autonomous applications for unmanned aerial vehicles (UAVs). However, the dynamic changes in flight maneuver and viewpoint encountered in UAV tracking pose significant difficulties, e.g., aspect ratio change, and scale variation. The conventional cross-correlation operation, while commonly used, has limitations in effectively capturing perceptual similarity and incorporates extraneous background information. To mitigate these limitations, this work presents a novel saliency-guided dynamic vision Transformer (SGDViT) for UAV tracking. The proposed method designs a new task-specific object saliency mining network to refine the cross-correlation operation and effectively discriminate foreground and background information. Additionally, a saliency adaptation embedding operation dynamically generates tokens based on initial saliency, thereby reducing the computational complexity of the Transformer architecture. Finally, a lightweight saliency filtering Transformer further refines saliency information and increases the focus on appearance information. The efficacy and robustness of the proposed approach have been thoroughly assessed through experiments on three widely-used UAV tracking benchmarks and real-world scenarios, with results demonstrating its superiority. The source code and demo videos are available at https://github.com/vision4robotics/SGDViT.",
        "primary_area": "",
        "author": "Liangliang Yao;Changhong Fu;Sihang Li;Guangze Zheng;Junjie Ye;Liangliang Yao;Changhong Fu;Sihang Li;Guangze Zheng;Junjie Ye",
        "authorids": "/37089894571;/37086797986;/37089451036;/37088996628;/37088917418;/37089894571;/37086797986;/37089451036;/37088996628;/37088917418",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; Department of Computer Science, the University of Hong Kong, Hong Kong, China; School of Mechanical Engineering, Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161487/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5327710975349153767&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Tongji University;the University of Hong Kong",
        "aff_unique_dep": "School of Mechanical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.hku.hk",
        "aff_unique_abbr": "Tongji;HKU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Shanghai;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160329",
        "title": "SGPT: The Secondary Path Guides the Primary Path in Transformers for HOI Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "HOI detection is essential for human-computer interaction, especially in behavior detection and robot manipulation. Existing mainstream transformer methods of HOI detection are focused on single-stream detection only, e.g., image \\rightarrow HOI(\\mathcal{P}_{1})image \\rightarrow HOI(\\mathcal{P}_{1}), or image \\rightarrow HO\\rightarrow I(\\mathcal{P}_{2})image \\rightarrow HO\\rightarrow I(\\mathcal{P}_{2}). Both paths have their own characteristics of concern, so we propose a novel method, using the Secondary path (\\mathcal{P}_{2})(\\mathcal{P}_{2}) Guides the Primary path (\\mathcal{P}_{1})(\\mathcal{P}_{1}) in Transformers (SGPT). SGPT contains two core modules: the Dual-Path Consistency (DPC) module and the Instance Interaction Attention (IIA) module. DPC keeps human, object and interaction consistent on the dual-path and lets \\mathcal{P}_{2}\\mathcal{P}_{2} guide \\mathcal{P}_{1}\\mathcal{P}_{1} to learn more meaningful features. IIA fuses human and object to enhance interaction in \\mathcal{P}_{2}\\mathcal{P}_{2}, which allows instance to constrain interaction. Our proposed dual-path are employed during training, and only the \\mathcal{P}_{1}\\mathcal{P}_{1} path is used for inference. Hence, SGPT improves generalization without increasing model capacity in HICO-DET and V-COCO datasets compared to the state-of-the-arts. The code of this work is available at https://github.com/visualVk/sgpt.git.",
        "primary_area": "",
        "author": "Sixian Chan;Weixiang Wang;Zhanpeng Shao;Cong Bai;Sixian Chan;Weixiang Wang;Zhanpeng Shao;Cong Bai",
        "authorids": "/37085612133;/37089895674;/37077906300;/37086072518;/37085612133;/37089895674;/37077906300;/37086072518",
        "aff": "Hubei Key Laboratory of Intelligent Vision Based Monitoring for Hydroelectric Engineering, College of Computer and Information at China Three Gorges University, Yichang, China; College of Computer Science and Technology, Zhejiang University of Technology, Zhejiang, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China; College of Computer Science and Technology, Zhejiang University of Technology, Zhejiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160329/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15095120193707480804&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "China Three Gorges University;Zhejiang University of Technology;Hunan Normal University",
        "aff_unique_dep": "College of Computer and Information;College of Computer Science and Technology;College of Information Science and Engineering",
        "aff_unique_url": "http://www.ctgu.edu.cn;;http://www.hnu.edu.cn",
        "aff_unique_abbr": "CTGU;;",
        "aff_campus_unique_index": "0;1;2;1",
        "aff_campus_unique": "Yichang;Zhejiang;Changsha",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160574",
        "title": "SGTM 2.0: Autonomously Untangling Long Cables using Interactive Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Cables are commonplace in homes, hospitals, and industrial warehouses and are prone to tangling. This paper extends prior work on autonomously untangling long cables by introducing novel uncertainty quantification metrics and actions that interact with the cable to reduce perception uncertainty. We present Sliding and Grasping for Tangle Manipulation 2.0 (SGTM 2.0), a system that autonomously untangles cables approximately 3 meters in length with a bilateral robot using estimates of uncertainty at each step to inform actions. By interactively reducing uncertainty, SGTM 2.0 significantly reduces run-time. Physical experiments with 84 trials suggest that SGTM 2.02.0 can achieve 83% untangling success on cables with 1 or 2 overhand and figure-8 knots, and 70% termination detection success across these configurations, outperforming SGTM 1.0 by 43% in untangling accuracy and 200% in completion time. Supplementary material, visualizations, and videos can be found at sites.google.com/view/sgtm2.",
        "primary_area": "",
        "author": "Kaushik Shivakumar;Vainavi Viswanath;Anrui Gu;Yahav Avigal;Justin Kerr;Jeffrey Ichnowski;Richard Cheng;Thomas Kollar;Ken Goldberg;Kaushik Shivakumar;Vainavi Viswanath;Anrui Gu;Yahav Avigal;Justin Kerr;Jeffrey Ichnowski;Richard Cheng;Thomas Kollar;Ken Goldberg",
        "authorids": "/37089659271;/37089196164;/37089895423;/37088504860;/37086803999;/38541287200;/37086493605;/37402789000;/37273026700;/37089659271;/37089196164;/37089895423;/37088504860;/37086803999;/38541287200;/37086493605;/37402789000;/37273026700",
        "aff": "AUTOLAB, University of California, Berkeley; AUTOLAB, University of California, Berkeley; AUTOLAB, University of California, Berkeley; AUTOLAB, University of California, Berkeley; AUTOLAB, University of California, Berkeley; AUTOLAB, University of California, Berkeley; Toyota Research Institute (TRI); Toyota Research Institute (TRI); AUTOLAB, University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160574/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10152521664329310745&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;Toyota Research Institute",
        "aff_unique_dep": "AUTOLAB;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.tri.toyota.com/",
        "aff_unique_abbr": "UC Berkeley;TRI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161449",
        "title": "SHAIL: Safety-Aware Hierarchical Adversarial Imitation Learning for Autonomous Driving in Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing a safe and human-like decision-making system for an autonomous vehicle is a challenging task. Generative imitation learning is one possible approach for automating policy-building by leveraging both real-world and simulated decisions. Previous work that applies generative imitation learning to autonomous driving policies focuses on learning a low-level controller for simple settings. However, to scale to complex settings, many autonomous driving systems combine fixed, safe, optimization-based low-level controllers with high-level decision-making logic that selects the appropriate task and associated controller. In this paper, we attempt to bridge this gap in complexity by employing Safety-Aware Hierarchical Adversarial Imitation Learning (SHAIL), a method for learning a high-level policy that selects from a set of low-level controller instances in a way that imitates low-level driving data on-policy. We introduce an urban roundabout simulator that controls non-ego vehicles using real data from the Interaction dataset. We then demonstrate empirically that even with simple controller options, our approach can produce better behavior than previous approaches in driver imitation that have difficulty scaling to complex environments. Our implementation is available at https://github.com/sisl/InteractionImitation.",
        "primary_area": "",
        "author": "Arec Jamgochian;Etienne Buehrle;Johannes Fischer;Mykel J. Kochenderfer;Arec Jamgochian;Etienne Buehrle;Johannes Fischer;Mykel J. Kochenderfer",
        "authorids": "/37087319905;/37089895487;/37089195294;/37596929200;/37087319905;/37089895487;/37089195294;/37596929200",
        "aff": "Stanford University, Stanford, CA, USA; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161449/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10368894415629989807&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Stanford University;Karlsruhe Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.kit.edu",
        "aff_unique_abbr": "Stanford;KIT",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Stanford;Karlsruhe",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "10160907",
        "title": "SHINE-Mapping: Large-Scale 3D Mapping Using Sparse Hierarchical Implicit Neural Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate mapping of large-scale environments is an essential building block of most outdoor autonomous systems. Challenges of traditional mapping methods include the balance between memory consumption and mapping accuracy. This paper addresses the problem of achieving large-scale 3D reconstruction using implicit representations built from 3D LiDAR measurements. We learn and store implicit features through an octree-based, hierarchical structure, which is sparse and extensible. The implicit features can be turned into signed distance values through a shallow neural network. We leverage binary cross entropy loss to optimize the local features with the 3D measurements as supervision. Based on our implicit representation, we design an incremental mapping system with regularization to tackle the issue of forgetting in continual learning. Our experiments show that our 3D reconstructions are more accurate, complete, and memory-efficient than current state-of-the-art 3D mapping methods.",
        "primary_area": "",
        "author": "Xingguang Zhong;Yue Pan;Jens Behley;Cyrill Stachniss;Xingguang Zhong;Yue Pan;Jens Behley;Cyrill Stachniss",
        "authorids": "/37089895518;/37088999871;/37593243900;/37329668600;/37089895518;/37088999871;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160907/",
        "gs_citation": 84,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11959952198993720499&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Bonn;Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-bonn.de;",
        "aff_unique_abbr": "UBonn;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161279",
        "title": "SIERRA: A Modular Framework for Accelerating Research and Improving Reproducibility",
        "track": "main",
        "status": "Poster",
        "abstract": "We present SIERRA, a novel framework for accelerating development and improving reproducibility of results in robotics research. SIERRA accelerates research by automating the process of generating experiments from queries over independent variables, executing experiments, and processing the results to generate deliverables such as graphs and videos. It shifts the paradigm for testing hypotheses from procedural (\u201cDo these steps to answer the query\u201d) to declarative (\u201cHere is the query to test\u2014GO!\u201d), reducing the burden on researchers. It employs a modular architecture enabling easy customization and extension for the needs of individual researchers, thereby eliminating manual configuration and processing via throw-away scripts. SIERRA improves reproducibility of research by providing automation independent of the execution environment (HPC hardware, real robots, etc.) and targeted platform (simulator, real robots, etc.). This enables exact experiment replication, up to the limit of the execution environment and platform, as well as making it easy for researchers to test hypotheses in different computational environments. Though SIERRA is targeted at robotics research, its design makes it extendable to other fields.",
        "primary_area": "",
        "author": "John Harwell;Maria Gini;John Harwell;Maria Gini",
        "authorids": "/37086396724;/37278152100;/37086396724;/37278152100",
        "aff": "Department of Computer Science & Engineering, University of Minnesota, Minneapolis, MN; Department of Computer Science & Engineering, University of Minnesota, Minneapolis, MN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161279/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4805357010662247262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160639",
        "title": "SLAMER: Simultaneous Localization and Map-Assisted Environment Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a simultaneous localization and map-assisted environment recognition (SLAMER) method. Mobile robots usually have an environment map and environment information can be assigned to the map. Important information such as no entry zone can be predicted from the map if localization has succeeded. However, this prediction is failed when localization does not work. Uncertainty of pose estimate must be considered for robust-map-based environ-mental object prediction. Robots also have external sensors and can recognize environmental object; however, sensor-based recognition of course contain uncertainty. SLAMER fuses map-based prediction and sensor-based recognition while coping with these uncertainties and achieves accurate localization and environment recognition. In this paper, we demonstrate LiDAR-based implementation of SLAMER in two cases. In the first case, we use the SemanticKITTI dataset and show that SLAMER achieves accurate estimate more than traditional methods. In the second case, we use an indoor mobile robot and show that unmeasurable environmental objects such as open doors and no entry lines can be recognized.",
        "primary_area": "",
        "author": "Naoki Akai;Naoki Akai",
        "authorids": "/37085445554;/37085445554",
        "aff": "LOCT Co., Ltd., Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160639/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:qXCipyIkvZ0J:scholar.google.com/&scioq=SLAMER:+Simultaneous+Localization+and+Map-Assisted+Environment+Recognition&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "LOCT Co., Ltd.",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161425",
        "title": "SLAMesh: Real-time LiDAR Simultaneous Localization and Meshing",
        "track": "main",
        "status": "Poster",
        "abstract": "Most current LiDAR simultaneous localization and mapping (SLAM) systems build maps in point clouds, which are sparse when zoomed in, even though they seem dense to human eyes. Dense maps are essential for robotic applications, such as map-based navigation. Due to the low memory cost, mesh has become an attractive dense model for mapping in recent years. However, existing methods usually produce mesh maps by using an offline post-processing step to generate mesh maps. This two-step pipeline does not allow these methods to use the built mesh maps online and to enable localization and meshing to benefit each other. To solve this problem, we propose the first CPU-only real-time LiDAR SLAM system that can simultaneously build a mesh map and perform localization against the mesh map. A novel and direct meshing strategy with Gaussian process reconstruction realizes the fast building, registration, and updating of mesh maps. We perform experiments on several public datasets. The results show that our SLAM system can run at around 40Hz. The localization and meshing accuracy also outperforms the state-of-the-art methods, including the TSDF map and Poisson reconstruction. Our code and video demos are available at: https://github.com/lab-sun/SLAMesh.",
        "primary_area": "",
        "author": "Jianyuan Ruan;Bo Li;Yibo Wang;Yuxiang Sun;Jianyuan Ruan;Bo Li;Yibo Wang;Yuxiang Sun",
        "authorids": "/37087881153;/37087888427;/37089894953;/37085435479;/37087881153;/37087888427;/37089894953;/37085435479",
        "aff": "The Hong Kong Polytechnic University, Hong Kong; Zhejiang University of Science and Technology, Hangzhou, China; The Hong Kong Polytechnic University, Hong Kong; The Hong Kong Polytechnic University, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161425/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16870319648928928732&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "The Hong Kong Polytechnic University;Zhejiang University of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.polyu.edu.hk;http://www.zjust.edu.cn",
        "aff_unique_abbr": "PolyU;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Hong Kong SAR;Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161084",
        "title": "SLURP! Spectroscopy of Liquids Using Robot Pre-Touch Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Liquids and granular media are pervasive throughout human environments. Their free-flowing nature causes people to constrain them into containers. We do so with thousands of different types of containers made out of different materials with varying sizes, shapes, and colors. In this work, we present a state-of-the-art sensing technique for robots to perceive what liquid is inside of an unknown container. We do so by integrating Visible to Near Infrared (VNIR) reflectance spectroscopy into a robot's end effector. We introduce a hierarchical model for inferring the material classes of both containers and internal contents given spectral measurements from two integrated spectrometers. To train these inference models, we capture and open source a dataset of spectral measurements from over 180 different combinations of containers and liquids. Our technique demonstrates over 85% accuracy in identifying 13 different liquids and granular media contained within 13 different containers. The sensitivity of our spectral readings allow our model to also identify the material composition of the containers themselves with 96% accuracy. Overall, VNIR spectroscopy presents a promising method to give household robots a general-purpose ability to infer the liquids inside of containers, without needing to open or manipulate the containers.",
        "primary_area": "",
        "author": "Nathaniel Hanson;Wesley Lewis;Kavya Puthuveetil;Donelle Furline;Akhil Padmanabha;Ta\u015flan Padir;Zackory Erickson;Nathaniel Hanson;Wesley Lewis;Kavya Puthuveetil;Donelle Furline;Akhil Padmanabha;Ta\u015flan Padir;Zackory Erickson",
        "authorids": "/37089372587;/37089895536;/37089257794;/37089892725;/37088507364;/38496444600;/37085785366;/37089372587;/37089895536;/37089257794;/37089892725;/37088507364;/38496444600;/37085785366",
        "aff": "Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Institute for Experiential Robotics, Northeastern University, Boston, Massachusetts, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161084/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5522164520636085201&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;1;0;1",
        "aff_unique_norm": "Northeastern University;Carnegie Mellon University",
        "aff_unique_dep": "Institute for Experiential Robotics;Robotics Institute",
        "aff_unique_url": "https://www.northeastern.edu;https://www.cmu.edu",
        "aff_unique_abbr": "NU;CMU",
        "aff_campus_unique_index": "0;1;1;0;1;0;1",
        "aff_campus_unique": "Boston;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161407",
        "title": "SM/VIO: Robust Underwater State Estimation Switching Between Model-based and Visual Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the robustness problem of visual-inertial state estimation for underwater operations. Underwater robots operating in a challenging environment are required to know their pose at all times. All vision-based localization schemes are prone to failure due to poor visibility conditions, color loss, and lack of features. The proposed approach utilizes a model of the robot's kinematics together with proprioceptive sensors to maintain the pose estimate during visual-inertial odometry (VIO) failures. Furthermore, the trajectories from successful VIO and the ones from the model-driven odometry are integrated in a coherent set that maintains a consistent pose at all times. Health-monitoring tracks the VIO process ensuring timely switches between the two estimators. Finally, loop closure is implemented on the overall trajectory. The resulting framework is a robust estimator switching between model-based and visual-inertial odometry (SM/VIO). Experimental results from numerous deployments of the Aqua2 vehicle demonstrate the robustness of our approach over coral reefs and a shipwreck.",
        "primary_area": "",
        "author": "Bharat Joshi;Hunter Damron;Sharmin Rahman;Ioannis Rekleitis;Bharat Joshi;Hunter Damron;Sharmin Rahman;Ioannis Rekleitis",
        "authorids": "/37087324582;/37086573954;/37085989996;/37281356300;/37087324582;/37086573954;/37085989996;/37281356300",
        "aff": "University of South Carolina, Columbia, SC, USA; Epic Systems Corporation, Madison, WI, USA; University of South Carolina, Columbia, SC, USA; University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161407/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3267515582679931715&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of South Carolina;Epic Systems Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sc.edu;https://www.epicsystems.com",
        "aff_unique_abbr": "USC;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Columbia;Madison",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161085",
        "title": "SRI-Graph: A Novel Scene-Robot Interaction Graph for Robust Scene Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel scene-robot interaction graph (SRI-Graph) that exploits the known position of a mobile manipulator for robust and accurate scene understanding. Compared to the state-of-the-art scene graph approaches, the proposed SRI-Graph captures not only the relationships between the objects, but also the relationships between the robot manipulator and objects with which it interacts. To improve the detection accuracy of spatial relationships, we leverage the 3D position of the mobile manipulator in addition to RGB images. The manipulator's ego information is crucial for a successful scene understanding when the relationships are visually uncertain. The proposed model is validated for a real-world 3D robot-assisted feeding task. We release a new dataset named 3DRF-Pos for training and validation. We also develop a tool, named LabelImg-Rel, as an extension of the open-sourced image annotation tool LabelImg for a convenient annotation in robot-environment interaction scenarios*. Our experimental results using the Movo platform show that SRI-Graph outperforms the state-of-the-art approach and improves detection accuracy by up to 9.83%.",
        "primary_area": "",
        "author": "Dong Yang;Xiao Xu;Mengchen Xiong;Edwin Babaians;Eckehard Steinbach;Dong Yang;Xiao Xu;Mengchen Xiong;Edwin Babaians;Eckehard Steinbach",
        "authorids": "/37089660575;/38238310400;/37089697129;/37085653235;/37273225600;/37089660575;/38238310400;/37089697129;/37085653235;/37273225600",
        "aff": "Department of Computer Engineering, School of Computation, Information and Technology, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Department of Computer Engineering, School of Computation, Information and Technology, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Department of Computer Engineering, School of Computation, Information and Technology, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Department of Computer Engineering, School of Computation, Information and Technology, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Department of Computer Engineering, School of Computation, Information and Technology, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161085/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5944489123164071668&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Computer Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160220",
        "title": "STAP: Sequencing Task-Agnostic Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Advances in robotic skill acquisition have made it possible to build general-purpose libraries of learned skills for downstream manipulation tasks. However, naively executing these skills one after the other is unlikely to succeed without accounting for dependencies between actions prevalent in longhorizon plans. We present Sequencing Task-Agnostic Policies (STAP), a scalable framework for training manipulation skills and coordinating their geometric dependencies at planning time to solve long-horizon tasks never seen by any skill during training. Given that Q-functions encode a measure of skill feasibility, we formulate an optimization problem to maximize the joint success of all skills sequenced in a plan, which we estimate by the product of their Q-values. Our experiments indicate that this objective function approximates ground truth plan feasibility and, when used as a planning objective, reduces myopic behavior and thereby promotes long-horizon task success. We further demonstrate how STAP can be used for task and motion planning by estimating the geometric feasibility of skill sequences provided by a task planner. We evaluate our approach in simulation and on a real robot. Qualitative results and code are made available at sites.google.com/stanford.edu/stap.",
        "primary_area": "",
        "author": "Christopher Agia;Toki Migimatsu;Jiajun Wu;Jeannette Bohg;Christopher Agia;Toki Migimatsu;Jiajun Wu;Jeannette Bohg",
        "authorids": "/37088414901;/37086141343;/37085659126;/37591153900;/37088414901;/37086141343;/37085659126;/37591153900",
        "aff": "Stanford University, Stanford, CA, USA; Stanford University, Stanford, CA, USA; Stanford University, Stanford, CA, USA; Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160220/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13901746839100708649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161555",
        "title": "STD-Trees: Spatio-temporal Deformable Trees for Multirotors Kinodynamic Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In constrained solution spaces with a huge number of homotopy classes, standalone sampling-based kinodynamic planners suffer low efficiency in convergence. Local optimization is integrated to alleviate this problem. In this paper, we propose to thrive the trajectory tree growing by optimizing the tree in the forms of deformation units, and each unit contains one tree node and all the edges connecting it. The deforming proceeds both spatially and temporally by optimizing the node state and edge time durations efficiently. Deforming the unit only changes the tree locally yet improves the overall quality of a corresponding subtree. Further, to consider the computation burden and optimizing level, patterns to deform different tree parts in combination of different deformation units are studied and compared, all showing much faster convergence. The proposed deformation can be easily integrated into different RRT-based kinodynamic planning methods, and numerical experiments show that integrating the spatio-temporal deformation greatly accelerates the convergence and outperforms the spatial-only deformation.",
        "primary_area": "",
        "author": "Hongkai Ye;Chao Xu;Fei Gao;Hongkai Ye;Chao Xu;Fei Gao",
        "authorids": "/37086811929;/37404060100;/37086045143;/37086811929;/37404060100;/37086045143",
        "aff": "Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161555/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9473524235979555125&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160413",
        "title": "STD: Stable Triangle Descriptor for 3D place recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a novel global descriptor termed stable triangle descriptor (STD) for 3D place recognition. For a triangle, its shape is uniquely determined by the length of the sides or included angles. Moreover, the shape of triangles is completely invariant to rigid transformations. Based on this property, we first design an algorithm to efficiently extract local key points from the 3D point cloud and encode these key points into triangular descriptors. Then, place recognition is achieved by matching the side lengths (and some other information) of the descriptors between point clouds. The point correspondence obtained from the descriptor matching pair can be further used in geometric verification, which greatly improves the accuracy of place recognition. In our experiments, we extensively compare our proposed system against other state-of-the-art systems (i.e., M2DP, Scan Context) on public datasets (i.e., KITTI, NCLT, and Complex-Urban) and our self-collected dataset (with a non-repetitive scanning solid-state LiDAR). All the quantitative results show that STD has stronger adaptability and a great improvement in precision over its counterparts. To share our findings and make contributions to the community, we open source our code on our GitHub: github.com/hku-mars/STD.",
        "primary_area": "",
        "author": "Chongjian Yuan;Jiarong Lin;Zuhao Zou;Xiaoping Hong;Fu Zhang;Chongjian Yuan;Jiarong Lin;Zuhao Zou;Xiaoping Hong;Fu Zhang",
        "authorids": "/37088939463;/37087012222;/37089895708;/37088942003;/38245883800;/37088939463;/37087012222;/37089895708;/37088942003;/38245883800",
        "aff": "School of System Design and Intelligent Manufacturing, Southern University of Science and Technology, Shenzhen, People's Republic of China; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong Special Administrative Region, People's Republic of China; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong Special Administrative Region, People's Republic of China; School of System Design and Intelligent Manufacturing, Southern University of Science and Technology, Shenzhen, People's Republic of China; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong Special Administrative Region, People's Republic of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160413/",
        "gs_citation": 92,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14434295184635960307&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Southern University of Science and Technology;The University of Hong Kong",
        "aff_unique_dep": "School of System Design and Intelligent Manufacturing;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.hku.hk",
        "aff_unique_abbr": "SUSTech;HKU",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Shenzhen;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160708",
        "title": "STEPS: Joint Self-supervised Nighttime Image Enhancement and Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised depth estimation draws a lot of attention recently as it can promote the 3D sensing capa-bilities of self-driving vehicles. However, it intrinsically relies upon the photometric consistency assumption, which hardly holds during nighttime. Although various supervised night-time image enhancement methods have been proposed, their generalization performance in challenging driving scenarios is not satisfactory. To this end, we propose the first method that jointly learns a nighttime image enhancer and a depth estimator, without using ground truth for either task. Our method tightly entangles two self-supervised tasks using a newly proposed uncertain pixel masking strategy. This strategy originates from the observation that nighttime images not only suffer from underexposed regions but also from overexposed regions. By fitting a bridge-shaped curve to the illumination map distribution, both regions are suppressed and two tasks are bridged naturally. We benchmark the method on two established datasets: nuScenes and RobotCar and demonstrate state-of-the-art performance on both of them. Detailed ablations also reveal the mechanism of our proposal. Last but not least, to mitigate the problem of sparse ground truth of existing datasets, we provide a new photo-realistically enhanced nighttime dataset based upon CARLA. It brings meaningful new challenges to the community. Codes, data, and models are available at https://github.com/ucaszyp/STEPS.",
        "primary_area": "",
        "author": "Yupeng Zheng;Chengliang Zhong;Pengfei Li;Huan-ang Gao;Yuhang Zheng;Bu Jin;Ling Wang;Hao Zhao;Guyue Zhou;Qichao Zhang;Dongbin Zhao;Yupeng Zheng;Chengliang Zhong;Pengfei Li;Huan-ang Gao;Yuhang Zheng;Bu Jin;Ling Wang;Hao Zhao;Guyue Zhou;Qichao Zhang;Dongbin Zhao",
        "authorids": "/37089892258;/37089894032;/37089893178;/37089892178;/37089892228;/37089893311;/37089893580;/37086217629;/37085489402;/37085737334;/37277016800;/37089892258;/37089894032;/37089893178;/37089892178;/37089892228;/37089893311;/37089893580;/37086217629;/37085489402;/37085737334;/37277016800",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, China; Xi'an Research Institute of High-Tech, China; Department of Computer Science and Technology, Tsinghua University, China; Department of Computer Science and Technology, Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Xi'an Research Institute of High-Tech, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute of Automation, Chinese Academy of Sciences, China; Institute of Automation, Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160708/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3354639509478705569&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;1;0;0;0;0;1;0;0;2;2",
        "aff_unique_norm": "Tsinghua University;Xi'an Research Institute of High-Tech;Chinese Academy of Sciences",
        "aff_unique_dep": "Institute for AI Industry Research (AIR);;Institute of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn;;http://www.ia.cas.cn",
        "aff_unique_abbr": "Tsinghua;;CAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160790",
        "title": "STEV: Stretchable Triboelectric E-skin enabled Proprioceptive Vibration Sensing for Soft Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Vibration perception is essential for robotic sensing and dynamic control. Nevertheless, due to the rigorous demand for sensor conformability and stretchability, enabling soft robots with proprioceptive vibration sensing remains challenging. This paper proposes a novel liquid metal-based stretchable e-skin via a kirigami-inspired design to enable soft robot proprioceptive vibration sensing. The e-skin is fabricated into 0.1mm ultrathin thickness, ensuring its negligible influence on the overall stiffness of the soft robot. Moreover, the working mechanism of the e-skin is based on the ubiquitous triboelectrification effect, which transduces mechanical stimuli without external power supply. To demonstrate the practicability of the e-skin, we built a soft gripper consisting of three soft robotic fingers with proprioceptive vibration sensing. Our experiment shows that the gripper can accurately distinguish the grain category (six grains with the same mass, 99.9% accuracy) and the packaging quality (100% accuracy) by simply shaking the gripped bottle. In summary, a soft robotic proprioceptive vibration sensing solution is proposed; it helps soft robots to have a more comprehensive awareness of their self-state and may inspire further research on soft robotics.",
        "primary_area": "",
        "author": "Zihan Wang;Kai-Chong Lei;Huaze Tang;Shoujie Li;Yuan Dai;Wenbo Ding;Xiao-Ping Zhang;Zihan Wang;Kai-Chong Lei;Huaze Tang;Shoujie Li;Yuan Dai;Wenbo Ding;Xiao-Ping Zhang",
        "authorids": "/37089895468;/37089892774;/37089686579;/37089229975;/37089896004;/37889819500;/37279339900;/37089895468;/37089892774;/37089686579;/37089229975;/37089896004;/37889819500;/37279339900",
        "aff": "Tsinghua-Berkeley Shenzhen Institute, Shenzhen International Graduate School, Tsinghua University, China; Tsinghua-Berkeley Shenzhen Institute, Shenzhen International Graduate School, Tsinghua University, China; Tsinghua-Berkeley Shenzhen Institute, Shenzhen International Graduate School, Tsinghua University, China; Tsinghua-Berkeley Shenzhen Institute, Shenzhen International Graduate School, Tsinghua University, China; Tencent Robotics X Lab, Shenzhen, China; RISC-V International Open Source Laboratory, Shenzhen, China; Department of Electrical, Computer and Biomedical Engineering, Ryerson University, Toronto, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160790/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17967820536427730109&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;3",
        "aff_unique_norm": "Tsinghua University;Tencent Robotics X Lab;RISC-V International Open Source Laboratory;Ryerson University",
        "aff_unique_dep": "Tsinghua-Berkeley Shenzhen Institute;Robotics;;Department of Electrical, Computer and Biomedical Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.tencent.com;;https://www.ryerson.ca",
        "aff_unique_abbr": "THU;Tencent;;Ryerson",
        "aff_campus_unique_index": "0;0;0;0;0;0;1",
        "aff_campus_unique": "Shenzhen;Toronto",
        "aff_country_unique_index": "0;0;0;0;0;0;1",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "10160538",
        "title": "STPOTR: Simultaneous Human Trajectory and Pose Prediction Using a Non-Autoregressive Transformer for Robot Follow-Ahead",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we greatly expand the capability of robots to perform the follow-ahead task and variations of this task through development of a neural network model to predict future human motion from an observed human motion history. We propose a non-autoregressive transformer architecture to leverage its parallel nature for easier training and fast, accurate predictions at test time. The proposed architecture divides human motion prediction into two parts: 1) the human trajectory, which is the 3D positions of the hip joint over time, and 2) the human pose which is the 3D positions of all other joints over time with respect to a fixed hip joint. We propose to make the two predictions simultaneously, as the shared representation can improve the model performance. Therefore, the model consists of two sets of encoders and decoders. First, a multi-head attention module applied to encoder outputs improves human trajectory. Second, another multi-head self-attention module applied to encoder outputs concatenated with decoder outputs facilitates the learning of temporal dependencies. Our model is well-suited for robotic applications in terms of test accuracy and speed, and compares favorably with respect to state-of-the-art methods. We demonstrate the real-world applicability of our work via the Robot Follow-Ahead task, a challenging yet practical case study for our proposed model. The human motion predicted by our model enables the robot follow-ahead in scenarios that require taking detailed human motion into account such as sit-to-stand, stand-to-sit. It also enables simple control policies to trivially generalize to many different variations of human following, such as follow-beside. Our code and data are available at the following Github page: https://github.com/mmahdavian/STPOTR",
        "primary_area": "",
        "author": "Mohammad Mahdavian;Payam Nikdel;Mahdi TaherAhmadi;Mo Chen;Mohammad Mahdavian;Payam Nikdel;Mahdi TaherAhmadi;Mo Chen",
        "authorids": "/37085364544;/37086454305;/37089449647;/37085494765;/37085364544;/37086454305;/37089449647;/37085494765",
        "aff": "School of Computing Science, Simon Fraser University (SFU), Burnaby, Canada; School of Computing Science, Simon Fraser University (SFU), Burnaby, Canada; School of Computing Science, Simon Fraser University (SFU), Burnaby, Canada; School of Computing Science, Simon Fraser University (SFU), Burnaby, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160538/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=227531401238351681&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "School of Computing Science",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Burnaby",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160671",
        "title": "Safe Bipedal Path Planning via Control Barrier Functions for Polynomial Shape Obstacles Estimated Using Logistic Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe path planning is critical for bipedal robots to operate in safety-critical environments. Common path planning algorithms, such as RRT or RRT*, typically use geometric or kinematic collision check algorithms to ensure collision-free paths toward the target position. However, such approaches may generate non-smooth paths that do not comply with the dynamics constraints of walking robots. It has been shown that the control barrier function (CBF) can be integrated with RRT/RRT*to synthesize dynamically feasible collision-free paths. Yet, existing work has been limited to simple circular or elliptical shape obstacles due to the challenging nature of constructing appropriate barrier functions to represent irregularly shaped obstacles. In this paper, we present a CBF-based RRT* algorithm for bipedal robots to generate a collision-free path through space with multiple polynomial-shaped obstacles. In particular, we used logistic regression to construct polynomial barrier functions from a grid map of the environment to represent irregularly shaped obstacles. Moreover, we developed a multi-step CBF steering controller to ensure the efficiency of free space exploration. The proposed approach was first validated in simulation for a differential drive model, and then experimentally evaluated with a 3D humanoid robot, Digit, in a lab setting with randomly placed obstacles.",
        "primary_area": "",
        "author": "Chengyang Peng;Octavian Donca;Guillermo Castillo;Ayonga Hereid;Chengyang Peng;Octavian Donca;Guillermo Castillo;Ayonga Hereid",
        "authorids": "/37089891887;/37089893871;/37086936437;/37077055000;/37089891887;/37089893871;/37086936437;/37077055000",
        "aff": "Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA; Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA; Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA; Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160671/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2202863517093919401&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ohio State University",
        "aff_unique_dep": "Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.osu.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Columbus",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160805",
        "title": "Safe Control using Vision-based Control Barrier Function (V-CBF)",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe motion control in unknown environments is one of the challenging tasks in robotics, such as autonomous navigation. Control Barrier Function (CBF), as a strong math-ematical tool, has been widely used in many safety-critical systems to satisfy safety requirements. However, there are only a handful of recent studies on safety controllers with perception inputs. Common assumptions in most of the works are that the CBF is already known and obstacles have predefined shapes. In this work, we introduce a novel Vision-based Control Barrier Function (V-CBF), which enables generalization to new environments and obstacles of arbitrary shapes. We then derive CBF safety conditions over RGB-D space and relate those to actual robot control inputs. To train the CBF function, we introduce a method to generate ground truth with desired properties complying with CBF and a method to generate part of the CBF as an image-to-image translation problem. We finally demonstrate the efficacy of V-CBF on the safe control of an autonomous car in CARLA simulator.",
        "primary_area": "",
        "author": "Hossein Abdi;Golnaz Raja;Reza Ghabcheloo;Hossein Abdi;Golnaz Raja;Reza Ghabcheloo",
        "authorids": "/37088377618;/37089895603;/37298989400;/37088377618;/37089895603;/37298989400",
        "aff": "Faculty of Engineering and Natural Sciences, Tampere University, Finland; Faculty of Engineering and Natural Sciences, Tampere University, Finland; Faculty of Engineering and Natural Sciences, Tampere University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160805/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2323145000103657577&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tampere University",
        "aff_unique_dep": "Faculty of Engineering and Natural Sciences",
        "aff_unique_url": "https://www.tuni.fi",
        "aff_unique_abbr": "Tuni",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "10161201",
        "title": "Safe Model-based Control from Signal Temporal Logic Specifications Using Recurrent Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a policy search approach to learn controllers from specifications given as Signal Temporal Logic (STL) formulae. The system model, which is unknown but assumed to be an affine control system, is learned together with the control policy. The model is implemented as two feedforward neural networks (FNNs) - one for the drift, and one for the control directions. To capture the history dependency of STL specifications, we use a recurrent neural network (RNN) to implement the control policy. In contrast to prevalent model-free methods, the learning approach proposed here takes advantage of the learned model and is more efficient. We use control barrier functions (CBFs) with the learned model to improve the safety of the system. We validate our algorithm via simulations and experiments. The results show that our approach can satisfy the given specification within very few system runs, and can be used for on-line control.",
        "primary_area": "",
        "author": "Wenliang Liu;Mirai Nishioka;Calin Belta;Wenliang Liu;Mirai Nishioka;Calin Belta",
        "authorids": "/37088892880;/37089895930;/37276061600;/37088892880;/37089895930;/37276061600",
        "aff": "Boston University, Boston, MA, USA; Commonwealth School, Boston, MA, USA; Boston University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161201/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7728213154972965594&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Boston University;Commonwealth School",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.bu.edu;",
        "aff_unique_abbr": "BU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161343",
        "title": "Safe Operations of an Aerial Swarm via a Cobot Human Swarm Interface",
        "track": "main",
        "status": "Poster",
        "abstract": "Command and control of an aerial swarm is a complex task. This task increases in difficulty when the flight volume is restricted and the swarm and operator inhabit the same workspace. This work presents a novel method for interacting with and controlling a swarm of quadrotors in a confined space. EMG-based gesture control is used to control the position, orientation, and density of the swarm. Inter-agent as well as agent-operator collisions are prevented through a velocity controller based on a distance-based potential function. State feedback is relayed to the operator via a vibrotactile haptic vest. This cobot human swarm interface prioritizes operator safety while reducing the cognitive load during control of a cobot swarm. This work demonstrates that an operator can safely and intuitively control a swarm of aerial robots in the same workspace.",
        "primary_area": "",
        "author": "Sydrak S. Abdi;Derek A. Paley;Sydrak S. Abdi;Derek A. Paley",
        "authorids": "/37089894014;/37295022600;/37089894014;/37295022600",
        "aff": "Sydrak S. Abdi; Derek A. Paley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161343/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10310235505100118364&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10160992",
        "title": "Safe Real-World Autonomous Driving by Learning to Predict and Plan with a Mixture of Experts",
        "track": "main",
        "status": "Poster",
        "abstract": "The goal of autonomous vehicles is to navigate public roads safely and comfortably. To enforce safety, traditional planning approaches rely on handcrafted rules to generate trajectories. Machine learning-based systems, on the other hand, scale with data and are able to learn more complex behaviors. However, they often ignore that agents and self-driving vehicle trajectory distributions can be leveraged to improve safety. In this paper, we propose modeling a distribution over multiple future trajectories for both the self-driving vehicle and other road agents, using a unified neural network architecture for prediction and planning. During inference, we select the planning trajectory that minimizes a cost taking into account safety and the predicted probabilities. Our approach does not depend on any rule-based planners for trajectory generation or optimization, improves with more training data and is simple to implement. We extensively evaluate our method through a realistic simulator and show that the predicted trajectory distribution corresponds to different driving profiles. We also successfully deploy it on a self-driving vehicle on urban public roads, confirming that it drives safely without compromising comfort. The code for training and testing our model on a public prediction dataset and the video of the road test are available at https://woven.mobi/safepathnet.",
        "primary_area": "",
        "author": "Stefano Pini;Christian S. Perone;Aayush Ahuja;Ana Sofia Rufino Ferreira;Moritz Niendorf;Sergey Zagoruyko;Stefano Pini;Christian S. Perone;Aayush Ahuja;Ana Sofia Rufino Ferreira;Moritz Niendorf;Sergey Zagoruyko",
        "authorids": "/37086497242;/37089892945;/37086938408;/37089448879;/37085486759;/37085692147;/37086497242;/37089892945;/37086938408;/37089448879;/37085486759;/37085692147",
        "aff": "Woven Planet Holdings, Inc.; Woven Planet Holdings, Inc.; Woven Planet Holdings, Inc.; Woven Planet Holdings, Inc.; Woven Planet Holdings, Inc.; Woven Planet Holdings, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160992/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12068917182799326825&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Woven Planet Holdings",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.wovenplanet.com",
        "aff_unique_abbr": "WPH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161548",
        "title": "Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks: Navigation, Manipulation, Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is a fundamental property for the real-world deployment of robotic platforms. Any control policy should avoid dangerous actions that could harm the environment, humans, or the robot itself. In reinforcement learning (RL), safety is crucial when exploring a new environment to learn a new skill. This paper introduces a new formulation of safe exploration for robotic RL in the tangent space of the constraint manifold that effectively transforms the action space of the RL agent for always respecting safety constraints locally. We show how to apply this approach to a wide range of robotic platforms and how to define safety constraints that represent dynamic articulated objects like humans in the context of robotic RL. Our proposed approach achieves state-of-the-art performance in simulated high-dimensional and dynamic tasks while avoiding collisions with the environment. We show safe real-world deployment of our learned controller on a \\text{TIAGo}++\\text{TIAGo}++ robot, achieving remarkable performance in manipulation and human-robot interaction tasks.",
        "primary_area": "",
        "author": "Puze Liu;Kuo Zhang;Davide Tateo;Snehal Jauhri;Zhiyuan Hu;Jan Peters;Georgia Chalvatzaki;Puze Liu;Kuo Zhang;Davide Tateo;Snehal Jauhri;Zhiyuan Hu;Jan Peters;Georgia Chalvatzaki",
        "authorids": "/37089195561;/37089660048;/37086271891;/37089448523;/37089892717;/37533077600;/37085353493;/37089195561;/37089660048;/37086271891;/37089448523;/37089892717;/37533077600;/37085353493",
        "aff": "Computer Science Department, Technical University Darmstadt; Computer Science Department, Technical University Darmstadt; Computer Science Department, Technical University Darmstadt; Computer Science Department, Technical University Darmstadt; Computer Science Department, Technical University Darmstadt; Centre for Cognitive Science; Hessian.AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161548/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7222470401584456867&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;2",
        "aff_unique_norm": "Technical University Darmstadt;Centre for Cognitive Science;Hessian.AI",
        "aff_unique_dep": "Computer Science Department;Cognitive Science;",
        "aff_unique_url": "https://www.tu-darmstadt.de;;https://www.hessian.ai",
        "aff_unique_abbr": "TUD;;Hessian.AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;2",
        "aff_country_unique": "Germany;;China"
    },
    {
        "id": "10160763",
        "title": "Safe Self-Supervised Learning in Real of Visuo-Tactile Feedback Policies for Industrial Insertion",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial insertion tasks are often performed repetitively with parts that are subject to tight tolerances and prone to breakage. Learning an industrial insertion policy in real is challenging as the collision between the parts and the environment can cause slippage or breakage of the part. In this paper, we present a safe self-supervised method to learn a visuo-tactile insertion policy that is robust to grasp pose variations. The method reduces human input and collisions between the part and the receptacle. The method divides the insertion task into two phases. In the first align phase, a tactile-based grasp pose estimation model is learned to align the insertion part with the receptacle. In the second insert phase, a vision-based policy is learned to guide the part into the receptacle. The robot uses force-torque sensing to achieve a safe self-supervised data collection pipeline. Physical experiments on the USB insertion task from the NIST Assembly Taskboard suggest that the resulting policies can achieve 45/45 insertion successes on 45 different initial grasp poses, improving on two baselines: (1) a behavior cloning agent trained on 50 human insertion demonstrations (1/45) and (2) an online RL policy (TD3) trained in real (0/45).",
        "primary_area": "",
        "author": "Letian Fu;Huang Huang;Lars Berscheid;Hui Li;Ken Goldberg;Sachin Chitta;Letian Fu;Huang Huang;Lars Berscheid;Hui Li;Ken Goldberg;Sachin Chitta",
        "authorids": "/37089449079;/37088985585;/37085380166;/37089894545;/37273026700;/37279717300;/37089449079;/37088985585;/37085380166;/37089894545;/37273026700;/37279717300",
        "aff": "The AUTOLab at UC Berkeley; The AUTOLab at UC Berkeley; Karlsruhe Institute of Technology; Autodesk Research; The AUTOLab at UC Berkeley; Autodesk Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160763/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1948351375242586824&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;2",
        "aff_unique_norm": "University of California, Berkeley;Karlsruhe Institute of Technology;Autodesk",
        "aff_unique_dep": "The AUTOLab;;Autodesk Research",
        "aff_unique_url": "https://www.berkeley.edu;https://www.kit.edu;https://research.autodesk.com",
        "aff_unique_abbr": "UC Berkeley;KIT;Autodesk",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "10160280",
        "title": "Safe and Distributed Multi-Agent Motion Planning under Minimum Speed Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "The motion planning problem for multiple unstop-pable agents is of interest in many robotics applications, for example, autonomous traffic management for multiple fixed-wing aircraft. Unfortunately, many of the existing algorithms cannot provide safety for such agents, because they require the agents to be able to brake to a complete stop for safety and feasibility insurance. In this paper, we present a distributed multi-agent motion planner that guarantees collision avoidance and persistent feasibility, which can be applied to a team of homogeneous mobile vehicles that cannot stop. The planner is built on top of the idea that a collision-free trajectory in form of a loop can safely accommodate multiple unstoppable agents, while avoiding collisions among them and static obstacles. At every time step, in a distributed manner, the agents generate trajectory-manipulating actions that preserve the loop structure. Then, a deconfliction process selects a conflict-free subset of the generated actions, which are applied at the next time step. Through simulation using an unstoppable Dubins car model, we show that the proposed motion planner is able to provide persistent safety guarantees for such agents in obstacle-cluttered space in real-time.",
        "primary_area": "",
        "author": "Inkyu Jang;Jungwon Park;H. Jin Kim;Inkyu Jang;Jungwon Park;H. Jin Kim",
        "authorids": "/37087499137;/37087323909;/37599626400;/37087499137;/37087323909;/37599626400",
        "aff": "Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Institute of Advanced Aerospace Technology (IAAT), Seoul National University, Seoul, Korea; Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Institute of Advanced Aerospace Technology (IAAT), Seoul National University, Seoul, Korea; Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Institute of Advanced Aerospace Technology (IAAT), Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160280/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11542907194094656538&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161056",
        "title": "Safe and Efficient Navigation in Extreme Environments using Semantic Belief Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "To achieve autonomy in unknown and unstruc-tured environments, we propose a method for semantic-based planning under perceptual uncertainty. This capability is cru-cial for safe and efficient robot navigation in environment with mobility-stressing elements that require terrain-specific locomotion policies. We propose the Semantic Belief Graph (SBG), a geometric- and semantic-based representation of a robot's probabilistic roadmap in the environment. The SBG nodes comprise of the robot geometric state and the semantic-knowledge of the terrains in the environment. The SBG edges represent local semantic-based controllers that drive the robot between the nodes or invoke an information gathering action to reduce semantic belief uncertainty. We formulate a semantic-based planning problem on SBG that produces a policy for the robot to safely navigate to the target location with min-imal traversal time. We analyze our method in simulation and present real-world results with a legged robotic platform navigating multi-level outdoor environments.",
        "primary_area": "",
        "author": "Muhammad Fadhil Ginting;Sung-Kyun Kim;Oriana Peltzer;Joshua Ott;Sunggoo Jung;Mykel J. Kochenderfer;Ali-akbar Agha-mohammadi;Muhammad Fadhil Ginting;Sung-Kyun Kim;Oriana Peltzer;Joshua Ott;Sunggoo Jung;Mykel J. Kochenderfer;Ali-akbar Agha-mohammadi",
        "authorids": "/37086345435;/37598024600;/37088505805;/37089662054;/37086354519;/37596929200;/38274170800;/37086345435;/37598024600;/37088505805;/37089662054;/37086354519;/37596929200;/38274170800",
        "aff": "Department of Aeronautics & Astronautics, Stanford University, Stanford, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Aeronautics & Astronautics, Stanford University, Stanford, CA, USA; Department of Aeronautics & Astronautics, Stanford University, Stanford, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Aeronautics & Astronautics, Stanford University, Stanford, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161056/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7266640830827520082&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;1;0;1",
        "aff_unique_norm": "Stanford University;California Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics & Astronautics;NASA Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.stanford.edu;https://www.caltech.edu",
        "aff_unique_abbr": "Stanford;Caltech",
        "aff_campus_unique_index": "0;1;0;0;1;0;1",
        "aff_campus_unique": "Stanford;Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160457",
        "title": "Safeguarding Learning-Based Planners Under Motion and Sensing Uncertainties Using Reachability Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based trajectory planners in robotics have attracted growing interest given their ability to plan for complex tasks. These planners are typically trained in simulation under nominal conditions before being implemented on real robots. However, in real settings, the presence of motion and sensing uncertainties causes the robot to deviate from planned reference trajectories potentially leading to unsafe outcomes such as collisions. In this paper we present a reachability analysis to predict such deviations and to evaluate robot safety along reference trajectories. We then use the reachability analysis to safeguard a learning-based planner. Finally, we demonstrate the applicability of our safeguarding algorithm for learning-based planners via multiple simulations and real robot experiments.",
        "primary_area": "",
        "author": "Akshay Shetty;Adam Dai;Alexandros Tzikas;Grace Gao;Akshay Shetty;Adam Dai;Alexandros Tzikas;Grace Gao",
        "authorids": "/37086935306;/37089850076;/37089895946;/38257269700;/37086935306;/37089850076;/37089895946;/38257269700",
        "aff": "Department of Aeronautics and Astronautics, Stanford University, CA, USA; Department of Electrical Engineering, Stanford University, CA, USA; Department of Aeronautics and Astronautics, Stanford University, CA, USA; Department of Aeronautics and Astronautics, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160457/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10478438465568190994&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160598",
        "title": "Safety Evaluation of Robot Systems via Uncertainty Quantification",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an approach for quantifying the propagated uncertainty of robot systems in an online and data-driven manner. Especially in Human-Robot Collaboration, keeping track of the safety compliance during run time is essential: Misclassifying dangerous situations as safe might result in severe accidents. According to official regulations (e.g., ISO standards), safety in industrial robot applications depends on critical parameters, such as the distance and relative velocity between humans and robots. However, safety can only be assured given a measure for the reliability of these parameters. While different risk detection and mitigation approaches exist in literature, a measure that can be used to evaluate safety limits online, and succinctly implies whether a situation is safe or dangerous, is missing to date. Motivated by this, we introduce a generalizable method for calculating the propagated measurement uncertainty of arbitrary parameters, that captures the accumulated uncertainty originating from sensory devices and environmental disturbances of the system. To show that our approach delivers correct results, we perform validation experiments in simulation. In addition, we employ our method in two real-world settings and demonstrate how quantifying the propagated uncertainty of critical parameters facilitates assessing safety online in Human-Robot Collaboration.",
        "primary_area": "",
        "author": "Woo-Jeong Baek;Torsten Kr\u00f6ger;Woo-Jeong Baek;Torsten Kr\u00f6ger",
        "authorids": "/37089677272;/37283223400;/37089677272;/37283223400",
        "aff": "Institute for Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT); Institute for Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160598/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10429267092967978035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161379",
        "title": "Safety Under Uncertainty: Tight Bounds with Risk-Aware Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel class of risk-aware control barrier functions (RA-CBFs) for the control of stochastic safety-critical systems. Leveraging a result from the stochastic level-crossing literature, we deviate from the martingale theory that is currently used in stochastic CBF techniques and prove that a RA-CBF based control synthesis confers a tighter upper bound on the probability of the system becoming unsafe within a finite time interval than existing approaches. We highlight the advantages of our proposed approach over the state-of-the-art via a comparative study on an mobile-robot example, and further demonstrate its viability on an autonomous vehicle highway merging problem in dense traffic.",
        "primary_area": "",
        "author": "Mitchell Black;Georgios Fainekos;Bardh Hoxha;Danil Prokhorov;Dimitra Panagou;Mitchell Black;Georgios Fainekos;Bardh Hoxha;Danil Prokhorov;Dimitra Panagou",
        "authorids": "/37088650811;/38529834400;/37085547165;/37298522000;/37403362000;/37088650811;/38529834400;/37085547165;/37298522000;/37403362000",
        "aff": "Dept. of Aerospace Engineering, Univ. of Michigan, Ann Arbor, MI, USA; Toyota North America Research & Development, Ann Arbor, MI, USA; Toyota North America Research & Development, Ann Arbor, MI, USA; Toyota North America Research & Development, Ann Arbor, MI, USA; Dept. of Aerospace Engineering, Univ. of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161379/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=531567702390985337&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Michigan;Toyota North America Research & Development",
        "aff_unique_dep": "Department of Aerospace Engineering;",
        "aff_unique_url": "https://www.umich.edu;https://www.toyota.com",
        "aff_unique_abbr": "UM;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160985",
        "title": "Safety-Aware Unsupervised Skill Discovery",
        "track": "main",
        "status": "Poster",
        "abstract": "Programming manipulation behaviors can become increasingly difficult with a growing number and complexity of manipulation tasks, particularly in a dynamic and unstructured environment. Recent progress in unsupervised skill discovery algorithms has shown great promise in learning an extensive collection of behaviors without extrinsic supervision. On the other hand, safety is one of the most critical factors for real- world robot applications. As skill discovery methods typically encourage exploratory and dynamic behaviors, it can often be the case that a large portion of learned skills remain too dangerous and unsafe. In this paper, we introduce the novel problem of Safety-Aware Skill Discovery, which aims to learn, in a task-agnostic fashion, a repertoire of reusable skills that are inherently safe to be composed for solving downstream tasks. We present a computationally tractable algorithm that learns a latent-conditioned skill policy that maximizes intrinsic rewards regularized with a safety-critic that can model any user-defined safety constraints. Using the pretrained safe skill repertoire, hierarchical reinforcement learning can solve multiple downstream tasks without the need for explicit consideration of safety during training and testing. We evaluate our algorithm on a collection of force-controlled robotic manipulation tasks in simulation and show promising downstream task performance while satisfying safety constraints.",
        "primary_area": "",
        "author": "Sunin Kim;Jaewoon Kwon;Taeyoon Lee;Younghyo Park;Julien Perez;Sunin Kim;Jaewoon Kwon;Taeyoon Lee;Younghyo Park;Julien Perez",
        "authorids": "/37089895056;/37086578281;/37086353797;/37089570261;/37088998752;/37089895056;/37086578281;/37086353797;/37089570261;/37088998752",
        "aff": "NAVER LABS, Gyeonggi-do, South Korea; NAVER LABS, Gyeonggi-do, South Korea; NAVER LABS, Gyeonggi-do, South Korea; NAVER LABS, Gyeonggi-do, South Korea; NAVER LABS Europe, Meylan, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160985/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16744070663034958972&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "NAVER LABS;NAVER LABS Europe",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.naverlabs.com;https://labs.naver.com",
        "aff_unique_abbr": "NAVER LABS;NAVER LABS Europe",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Meylan",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "South Korea;France"
    },
    {
        "id": "10161256",
        "title": "Safety-Constrained Policy Transfer with Successor Features",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we focus on the problem of safe policy transfer in reinforcement learning: we seek to leverage existing policies when learning a new task with specified constraints. This problem is important for safety-critical applications where interactions are costly and unconstrained exploration can lead to undesirable or dangerous outcomes, e.g., with physical robots that interact with humans. We propose a Constrained Markov Decision Process (CMDP) formulation that simultaneously enables the transfer of policies and adherence to safety constraints. Our formulation cleanly separates task goals from safety considerations and permits the specification of a wide variety of constraints. Our approach relies on a novel extension of generalized policy improvement to constrained settings via a Lagrangian formulation. We devise a dual optimization algorithm that estimates the optimal dual variable of a target task, thus enabling safe transfer of policies derived from successor features learned on source tasks. Our experiments in simulated domains show that our approach is effective; it visits unsafe states less frequently and outperforms alternative state-of-the-art methods when taking safety constraints into account.",
        "primary_area": "",
        "author": "Zeyu Feng;Bowen Zhang;Jianxin Bi;Harold Soh;Zeyu Feng;Bowen Zhang;Jianxin Bi;Harold Soh",
        "authorids": "/37089893011;/37089892092;/37089893771;/37684942300;/37089893011;/37089892092;/37089893771;/37684942300",
        "aff": "Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore; Smart Systems Institute (SSI), NUS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161256/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8504139158075539926&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10161126",
        "title": "Safety-Critical Controller Verification via Sim2Real Gap Quantification",
        "track": "main",
        "status": "Poster",
        "abstract": "The well-known quote from George Box states that: \u201cAll models are wrong, but some are useful.\u201d To develop more useful models, we quantify the inaccuracy with which a given model represents a system of interest, so that we may leverage this quantity to facilitate controller synthesis and verification. Specifically, we develop a procedure that identifies a sim2real gap that holds with a minimum probability. Augmenting the nominal model with our identified sim2real gap produces an uncertain model which we prove is an accurate representor of system behavior. We leverage this uncertain model to synthesize and verify a controller in simulation using a probabilistic verification approach. This pipeline produces controllers with an arbitrarily high probability of realizing desired safe behavior on system hardware without requiring hardware testing except for those required for sim2real gap identification. We also showcase our procedure working on two hardware platforms - the Robotarium and a quadruped.",
        "primary_area": "",
        "author": "Prithvi Akella;Wyatt Ubellacker;Aaron D. Ames;Prithvi Akella;Wyatt Ubellacker;Aaron D. Ames",
        "authorids": "/37088643745;/37077831700;/37300877900;/37088643745;/37077831700;/37300877900",
        "aff": "California Institute of Technology; California Institute of Technology; California Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161126/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4290132988818639435&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161032",
        "title": "Safety-Critical Ergodic Exploration in Cluttered Environments via Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the problem of safe trajectory planning for autonomous search and exploration in constrained, cluttered environments. Guaranteeing safe (collision-free) trajectories is a challenging problem that has garnered significant due to its importance in the successful utilization of robots in search and exploration tasks. This work contributes a method that generates guaranteed safety-critical search trajectories in a cluttered environment. Our approach integrates safety-critical constraints using discrete control barrier functions (DCBFs) with ergodic trajectory optimization to enable safe exploration. Ergodic trajectory optimization plans continuous exploratory trajectories that guarantee complete coverage of a space. We demonstrate through simulated and experimental results on a drone that our approach is able to generate trajectories that enable safe and effective exploration. Furthermore, we show the efficacy of our approach for safe exploration using real-world single- and multi- drone platforms.",
        "primary_area": "",
        "author": "Cameron Lerch;Dayi Dong;Ian Abraham;Cameron Lerch;Dayi Dong;Ian Abraham",
        "authorids": "/37089894145;/37089892980;/37085549466;/37089894145;/37089892980;/37085549466",
        "aff": "Department of Mechanical Engineering and Materials Science, Yale University, New Haven, USA; Department of Mechanical Engineering and Materials Science, Yale University, New Haven, USA; Department of Mechanical Engineering and Materials Science, Yale University, New Haven, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161032/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7916494049936317983&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Yale University",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science",
        "aff_unique_url": "https://www.yale.edu",
        "aff_unique_abbr": "Yale",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Haven",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160959",
        "title": "Sample Efficient Dynamics Learning for Symmetrical Legged Robots: Leveraging Physics Invariance and Geometric Symmetries",
        "track": "main",
        "status": "Poster",
        "abstract": "Model generalization of the underlying dynamics is critical for achieving data efficiency when learning for robot control. This paper proposes a novel approach for learning dynamics leveraging the symmetry in the underlying robotic system, which allows for robust extrapolation from fewer samples. Existing frameworks that represent all data in vector space fail to consider the structured information of the robot, such as leg symmetry, rotational symmetry, and physics invariance. As a result, these schemes require vast amounts of training data to learn the system's redundant elements because they are learned independently. Instead, we propose considering the geometric prior by representing the system in symmetrical object groups and designing neural network architecture to assess invariance and equivariance between the objects. Finally, we demonstrate the effectiveness of our approach by comparing the generalization to unseen data of the proposed model and the existing models. We also implement a controller of a climbing robot based on learned inverse dynamics models. The results show that our method generates accurate control inputs that help the robot reach the desired state while requiring less training data than existing methods.",
        "primary_area": "",
        "author": "Jee-eun Lee;Jaemin Lee;Tirthankar Bandyopadhyay;Luis Sentis;Jee-eun Lee;Jaemin Lee;Tirthankar Bandyopadhyay;Luis Sentis",
        "authorids": "/37086921263;/37089938907;/37562167000;/37426747500;/37086921263;/37089938907;/37562167000;/37426747500",
        "aff": "Department of Aerospace Engineering and Engineering Mechanics, Human Centered Robotics Laboratory, The University of Texas at Austin, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Robotics and Autonomous Systems Group, Data61, CSIRO, QLD, Australia; Faculty of Department of Aerospace Engineering and Engineering Mechanics, The University of Texas at Austin, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160959/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1985721032161272489&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "The University of Texas at Austin;California Institute of Technology;CSIRO",
        "aff_unique_dep": "Department of Aerospace Engineering and Engineering Mechanics;Department of Mechanical and Civil Engineering;Robotics and Autonomous Systems Group, Data61",
        "aff_unique_url": "https://www.utexas.edu;https://www.caltech.edu;https://www.csiro.au",
        "aff_unique_abbr": "UT Austin;Caltech;CSIRO",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Austin;Pasadena;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "10160980",
        "title": "Sample, Crop, Track: Self-Supervised Mobile 3D Object Detection for Urban Driving LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning has led to great progress in the detection of mobile (i.e. movement-capable) objects in urban driving scenes in recent years. Supervised approaches typically require the annotation of large training sets; there has thus been great interest in leveraging weakly, semi- or self- supervised methods to avoid this, with much success. Whilst weakly and semi-supervised methods require some annotation, self-supervised methods have used cues such as motion to relieve the need for annotation altogether. However, a complete absence of annotation typically degrades their performance, and ambiguities that arise during motion grouping can inhibit their ability to find accurate object boundaries. In this paper, we propose a new self-supervised mobile object detection approach called SCT. This uses both motion cues and expected object sizes to improve detection performance, and predicts a dense grid of 3DD oriented bounding boxes to improve object discovery. We significantly outperform the state-of-the-art self-supervised mobile object detection method TCR on the KITTI tracking benchmark, and achieve performance that is within 30 % of the fully supervised PV-RCNN++ method for IoUs \\leq\\leq 0.5. Our source code will be made available online.",
        "primary_area": "",
        "author": "Sangyun Shin;Stuart Golodetz;Madhu Vankadari;Kaichen Zhou;Andrew Markham;Niki Trigoni;Sangyun Shin;Stuart Golodetz;Madhu Vankadari;Kaichen Zhou;Andrew Markham;Niki Trigoni",
        "authorids": "/37089658497;/37938271700;/37086448149;/37089239732;/37410667900;/37297514400;/37089658497;/37938271700;/37086448149;/37089239732;/37410667900;/37297514400",
        "aff": "University of Oxford, UK; University of Oxford, UK; University of Oxford, UK; University of Oxford, UK; University of Oxford, UK; University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160980/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17050539363242591330&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161339",
        "title": "Sample-Driven Connectivity Learning for Motion Planning in Narrow Passages",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based motion planning works well in many cases but is less effective if the configuration space has narrow passages. In this paper, we propose a learning-based strategy to sample in these narrow passages, which improves overall planning time. Our algorithm first learns from the configuration space planning graphs and then uses the learned information to effectively generate narrow passage samples. We perform experiments in various 6D and 7D scenes. The algorithm offers one order of magnitude speed-up compared to baseline planners in some of these scenes.",
        "primary_area": "",
        "author": "Sihui Li;Neil T. Dantam;Sihui Li;Neil T. Dantam",
        "authorids": "/37087060752;/37546520000;/37087060752;/37546520000",
        "aff": "Department of Computer Science, Colorado School of Mines, USA; Department of Computer Science, Colorado School of Mines, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161339/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12276932939164004132&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "CSM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161213",
        "title": "Sample-Efficient Goal-Conditioned Reinforcement Learning via Predictive Information Bottleneck for Goal Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose Predictive Information bottleneck for Goal representation learning (PI-Goal), a self-supervised method for sample-efficient goal-conditioned reinforcement learning (RL). Goal-conditioned RL learns to reach commanded goals with reward signals. A goal could be given in a noisy or abstract form, and thus jeopardizes sample efficiency. Previous methods usually assume that the agent can map a state to an achievable goal. In this work, we consider a setting in which the goal space is unknown to the agent and the agent cannot recognize a goal in a specific state (referred to as a goal state) until the goal is commanded. Our PI-Goal learns a goal representation which contains only the predictive information of a goal state, i.e., the mutual information between a current state and a future state, and guarantees the optimality of the learned policy. Experimental results show that PI-Goal consistently outperforms the baseline methods in tasks with unknown goal spaces, e.g., object manipulation, object search, and embodied question answering.",
        "primary_area": "",
        "author": "Qiming Zou;Einoshin Suzuki;Qiming Zou;Einoshin Suzuki",
        "authorids": "/37087106444;/37593849900;/37087106444;/37593849900",
        "aff": "Graduate School of Systems Life Sciences, Kyushu University, Fukuoka, Japan; Graduate School and Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161213/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:5KLMHCwh83sJ:scholar.google.com/&scioq=Sample-Efficient+Goal-Conditioned+Reinforcement+Learning+via+Predictive+Information+Bottleneck+for+Goal+Representation+Learning&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kyushu University",
        "aff_unique_dep": "Graduate School of Systems Life Sciences",
        "aff_unique_url": "https://www.kyushu-u.ac.jp",
        "aff_unique_abbr": "Kyushu U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Fukuoka",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10161266",
        "title": "Sampling-based path planning under temporal logic constraints with real-time adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Replanning in temporal logic tasks is extremely difficult during the online execution of robots. This study introduces an effective path planner that computes solutions for temporal logic goals and instantly adapts to non-static and partially unknown environments. Given prior knowledge and a task specification, the planner first identifies an initial feasible solution by growing a sampling-based search tree. While carrying out the computed plan, the robot maintains a solution library to continuously enhance the unfinished part of the plan and store backup plans. The planner updates existing plans when meeting unexpected obstacles or recognizing flaws in prior knowledge. Upon a high-level path is obtained, a trajectory generator tracks the path by dividing it into segments of motion primitives. Our planner is integrated into an autonomous mobile robot system, further deployed on a multicopter with limited onboard processing power. In simulation and real-world experiments, our planner is demonstrated to swiftly and effectively adjust to environmental uncertainties.",
        "primary_area": "",
        "author": "Yizhou Chen;Ruoyu Wang;Xinyi Wang;Ben M. Chen;Yizhou Chen;Ruoyu Wang;Xinyi Wang;Ben M. Chen",
        "authorids": "/37088954139;/37089464862;/37089284770;/38520079900;/37088954139;/37089464862;/37089284770;/38520079900",
        "aff": "Chinese University of Hong Kong, Hong Kong; Chinese University of Hong Kong, Hong Kong; Chinese University of Hong Kong, Hong Kong; Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161266/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4424664076382298354&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161527",
        "title": "Satellite Image Based Cross-view Localization for Autonomous Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing spatial localization techniques for au-tonomous vehicles mostly use a pre-built 3D-HD map, often constructed using a survey-grade 3D mapping vehicle, which is not only expensive but also laborious. This paper shows that by using an off-the-shelf high-definition satellite image as a ready-to-use map, we are able to achieve cross-view vehicle localization up to a satisfactory accuracy, providing a cheaper and more practical way for localization. While the utilization of satellite imagery for cross-view localization is an established concept, the conventional methodology focuses primarily on image re-trieval. This paper introduces a novel approach to cross-view localization that departs from the conventional image retrieval method. Specifically, our method develops (1) a Geometric-align Feature Extractor (GaFE) that leverages measured 3D points to bridge the geometric gap between ground and overhead views, (2) a Pose Aware Branch (PAB) adopting a triplet loss to encourage pose-aware feature extraction, and (3) a Recursive Pose Refine Branch (RPRB) using the Levenberg-Marquardt (LM) algorithm to align the initial pose towards the true vehicle pose iteratively. Our method is validated on KITTI and Ford Multi-AV Seasonal datasets as ground view and Google Maps as the satellite view. The results demonstrate the superiority of our method in cross-view localization with median spatial and angular errors within 1 meter and 1\u00b0, respectively.",
        "primary_area": "",
        "author": "Shan Wang;Yanhao Zhang;Ankit Vora;Akhil Perincherry;Hengdong Li;Shan Wang;Yanhao Zhang;Ankit Vora;Akhil Perincherry;Hengdong Li",
        "authorids": "/37089894529;/37088452302;/37087325085;/37086754652;/37089894376;/37089894529;/37088452302;/37087325085;/37086754652;/37089894376",
        "aff": "Data61, CSIRO, Australia; Australian National University; Ford Motor Company, Dearborn, USA; Ford Motor Company, Dearborn, USA; Australian National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161527/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4232535869601003480&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;1",
        "aff_unique_norm": "CSIRO;Australian National University;Ford Motor Company",
        "aff_unique_dep": "Data61;;",
        "aff_unique_url": "https://www.csiro.au;https://www.anu.edu.au;https://www.ford.com",
        "aff_unique_abbr": "CSIRO;ANU;Ford",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Dearborn",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "10161498",
        "title": "Scalable Task-Driven Robotic Swarm Control via Collision Avoidance and Learning Mean-Field Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, reinforcement learning and its multi-agent analogue have achieved great success in solving various complex control problems. However, multi-agent rein-forcement learning remains challenging both in its theoretical analysis and empirical design of algorithms, especially for large swarms of embodied robotic agents where a definitive toolchain remains part of active research. We use emerging state-of-the-art mean-field control techniques in order to convert many-agent swarm control into more classical single-agent control of distributions. This allows profiting from advances in single-agent reinforcement learning at the cost of assuming weak interaction between agents. However, the mean-field model is violated by the nature of real systems with embodied, physically colliding agents. Thus, we combine collision avoidance and learning of mean-field control into a unified framework for tractably designing intelligent robotic swarm behavior. On the theoretical side, we provide novel approximation guarantees for general mean-field control both in continuous spaces and with collision avoidance. On the practical side, we show that our approach outperforms multi-agent reinforcement learning and allows for decentralized open-loop application while avoiding collisions, both in simulation and real UAV swarms. Overall, we propose a framework for the design of swarm behavior that is both mathematically well-founded and practically useful, enabling the solution of otherwise intractable swarm problems.",
        "primary_area": "",
        "author": "Kai Cui;Mengguang Li;Christian Fabian;Heinz Koeppl;Kai Cui;Mengguang Li;Christian Fabian;Heinz Koeppl",
        "authorids": "/37089280554;/37089894115;/37089648188;/37285057700;/37089280554;/37089894115;/37089648188;/37285057700",
        "aff": "Department of Electrical Engineering and Information Technology, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Department of Electrical Engineering and Information Technology, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Department of Electrical Engineering and Information Technology, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Department of Electrical Engineering and Information Technology, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161498/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3039633943122565064&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Department of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Darmstadt",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161469",
        "title": "Scene-level Point Cloud Colorization with Semantics-and-geometry-aware Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In robotic applications, we often obtain tons of 3D point cloud data without color information, and it is difficult to visualize point clouds in a meaningful and colorful way. Can we colorize 3D point clouds for better visualization? Existing deep learning-based colorization methods usually only take simple 3D objects as input, and their performance for complex scenes with multiple objects is limited. To this end, this paper proposes a novel semantics-and-geometry-aware colorization network, termed SGNet, for vivid scene-level point cloud colorization. Specifically, we propose a novel pipeline that explores geometric and semantic cues from point clouds containing only coordinates for color prediction. We also design two novel losses, including a colorfulness metric loss and a pairwise consistency loss, to constrain model training for genuine colorization. To the best of our knowledge, our work is the first to generate realistic colors for point clouds of large-scale indoor scenes. Extensive experiments on the widely used ScanNet benchmarks demonstrate that the proposed method achieves state-of-the-art performance on point cloud colorization.",
        "primary_area": "",
        "author": "Rongrong Gao;Tian-Zhu Xiang;Chenyang Lei;Jaesik Park;Qifeng Chen;Rongrong Gao;Tian-Zhu Xiang;Chenyang Lei;Jaesik Park;Qifeng Chen",
        "authorids": "/37088457529;/37089538296;/37087231184;/38240904400;/37087230927;/37088457529;/37089538296;/37087231184;/38240904400;/37087230927",
        "aff": "Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; POSTECH; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161469/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17979475112831892615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Inception Institute of Artificial Intelligence;Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering;;",
        "aff_unique_url": "https://www.ust.hk;;https://www.postech.ac.kr",
        "aff_unique_abbr": "HKUST;;POSTECH",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "Hong Kong;Abu Dhabi;Pohang",
        "aff_country_unique_index": "0;1;0;2;0",
        "aff_country_unique": "China;United Arab Emirates;South Korea"
    },
    {
        "id": "10161316",
        "title": "SceneCalib: Automatic Targetless Calibration of Cameras and Lidars in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate camera-to-lidar calibration is a requirement for sensor data fusion in many 3D perception tasks. In this paper, we present SceneCalib, a novel method for simultaneous self-calibration of extrinsic and intrinsic parameters in a system containing multiple cameras and a lidar sensor. Existing methods typically require specially designed calibration targets and human operators, or they only attempt to solve for a subset of calibration parameters. We resolve these issues with a fully automatic method that requires no explicit correspondences between camera images and lidar point clouds, allowing for robustness to many outdoor environments. Furthermore, the full system is jointly calibrated with explicit cross-camera constraints to ensure that camera-to-camera and camera-to-lidar extrinsic parameters are consistent.",
        "primary_area": "",
        "author": "Ayon Sen;Gang Pan;Anton Mitrokhin;Ashraful Islam;Ayon Sen;Gang Pan;Anton Mitrokhin;Ashraful Islam",
        "authorids": "/37089896098;/37089894599;/37086581371;/37089894076;/37089896098;/37089894599;/37086581371;/37089894076",
        "aff": "NVIDIA Corporation, Santa Clara, CA, USA; NVIDIA Corporation, Santa Clara, CA, USA; NVIDIA Corporation, Santa Clara, CA, USA; NVIDIA Corporation, Santa Clara, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161316/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12947751035246343415&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NVIDIA Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Santa Clara",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160864",
        "title": "Search Algorithms for Multi-Agent Teamwise Cooperative Path Finding",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-Agent Path Finding (MA-PF) computes a set of collision-free paths for multiple agents from their respective starting locations to destinations. This paper considers a generalization of MA-PF called Multi-Agent Teamwise Cooperative Path Finding (MA-TC-PF), where agents are grouped as multiple teams and each team has its own objective to be minimized. For example, an objective can be the sum or max of individual arrival times of the agents. In general, there is more than one team, and MA-TC-PF is thus a multi-objective planning problem with the goal of finding the entire Pareto-optimal front that represents all possible trade-offs among the objectives of the teams. To solve MA-TC-PF, we propose two algorithms TC-CBS and TC-M*, which leverage the existing CBS and M* for conventional MA-PF. We discuss the conditions under which the proposed algorithms are complete and are guaranteed to find the Pareto-optimal front. We present numerical results for several types of MA-TC-PF problems.",
        "primary_area": "",
        "author": "Zhongqiang Ren;Chaoran Zhang;Sivakumar Rathinam;Howie Choset;Zhongqiang Ren;Chaoran Zhang;Sivakumar Rathinam;Howie Choset",
        "authorids": "/37086293378;/37089893114;/37268809800;/37281322200;/37086293378;/37089893114;/37268809800;/37281322200",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160864/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8884970561545356172&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Texas A&M University",
        "aff_unique_dep": ";Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.tamu.edu",
        "aff_unique_abbr": "CMU;TAMU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Pittsburgh;College Station",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160753",
        "title": "Security-Aware Reinforcement Learning under Linear Temporal Logic Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate the problem of reinforcement learning under linear temporal logic (LTL) specifications for Markov decision processes (MDPs) with security constraints. We consider an outside passive intruder (observer) that can observe the external output behavior of the system through an output projection. We assume that the secret of the system is a subset of the initial states. The security constraint requires that the observer can never infer for sure that the agent was initiated from a secret state. Our objective is to learn a control policy that achieves the LTL task while ensuring security. To solve the problem of shaping the reward for reinforcement learning, we propose an approach based on the initial-state estimator and the limit deterministic B\u00fcchi automata. We illustrate the proposed approach by a case study of mobile robot example.",
        "primary_area": "",
        "author": "Bohan Cui;Keyi Zhu;Shaoyuan Li;Xiang Yin;Bohan Cui;Keyi Zhu;Shaoyuan Li;Xiang Yin",
        "authorids": "/37089893132;/37088997733;/37279612700;/37085401374;/37089893132;/37088997733;/37279612700;/37085401374",
        "aff": "Ministry of Education of China, Key Laboratory of System Control and Information Processing, Shanghai, China; Ministry of Education of China, Key Laboratory of System Control and Information Processing, Shanghai, China; Ministry of Education of China, Key Laboratory of System Control and Information Processing, Shanghai, China; Ministry of Education of China, Key Laboratory of System Control and Information Processing, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160753/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15455111767306903083&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ministry of Education of China",
        "aff_unique_dep": "Key Laboratory of System Control and Information Processing",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160798",
        "title": "Segregator: Global Point Cloud Registration with Semantic and Geometric Cues",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents Segregator, a global point cloud registration framework that exploits both semantic information and geometric distribution to efficiently build up outlier-robust correspondences and search for inliers. Current state-of-the-art algorithms rely on point features to set up putative correspondences and refine them by employing pair-wise distance consistency checks. However, such a scheme suffers from degenerate cases, where the descriptive capability of local point features downgrades, and unconstrained cases, where length-preserving (1-TRIMs)-based checks cannot sufficiently constrain whether the current observation is consistent with others, resulting in a complexified NP-complete problem to solve. To tackle these problems, on the one hand, we propose a novel degeneracy-robust and efficient corresponding procedure consisting of both instance-level semantic clusters and geometric-level point features. On the other hand, Gaussian distribution-based translation and rotation invariant measurements (G-TRIMs) are proposed to conduct the consistency check and further constrain the problem size. We validated our proposed algorithm on extensive real-world data-based experiments. The code is available: https://github.com/Pamphlett/Segregator.",
        "primary_area": "",
        "author": "Pengyu Yin;Shenghai Yuan;Haozhi Cao;Xingyu Ji;Shuyang Zhang;Lihua Xie;Pengyu Yin;Shenghai Yuan;Haozhi Cao;Xingyu Ji;Shuyang Zhang;Lihua Xie",
        "authorids": "/37089894950;/37085527198;/37089316921;/37089894179;/37088507304;/37274139300;/37089894950;/37085527198;/37089316921;/37089894179;/37088507304;/37274139300",
        "aff": "Centre for Advanced Robotics Technology Innovation (CARTIN), School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Centre for Advanced Robotics Technology Innovation (CARTIN), School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Centre for Advanced Robotics Technology Innovation (CARTIN), School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Centre for Advanced Robotics Technology Innovation (CARTIN), School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong SAR, China; Centre for Advanced Robotics Technology Innovation (CARTIN), School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160798/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17932640506055195227&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Nanyang Technological University;Hong Kong University of Science and Technology",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.ust.hk",
        "aff_unique_abbr": "NTU;HKUST",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Kowloon",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "10161368",
        "title": "Self-Adaptive Driving in Nonstationary Environments through Conjectural Online Lookahead Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Powered by deep representation learning, re-inforcement learning (RL) provides an end-to-end learning framework capable of solving self-driving (SD) tasks without manual designs. However, time-varying nonstationary environments cause proficient but specialized RL policies to fail at execution time. For example, an RL-based SD policy trained under sunny days does not generalize well to rainy weather. Even though meta learning enables the RL agent to adapt to new tasks/environments, its offline operation fails to equip the agent with online adaptation ability when facing nonstationary environments. This work proposes an online meta reinforcement learning algorithm based on the conjectural online lookahead adaptation (COLA). COLA determines the online adaptation at every step by maximizing the agent's conjecture of the future performance in a lookahead horizon. Experimental results demonstrate that under dynamically changing weather and lighting conditions, the COLA-based self-adaptive driving outperforms the baseline policies regarding online adaptability. A demo video, source code, and appendixes are available at https://github.com/Panshark/COLA",
        "primary_area": "",
        "author": "Tao Li;Haozhe Lei;Quanyan Zhu;Tao Li;Haozhe Lei;Quanyan Zhu",
        "authorids": "/37087116188;/37089895773;/37085449829;/37087116188;/37089895773;/37085449829",
        "aff": "Department of Electrical and Computer Engineering, New York University, Brooklyn, NY, USA; Department of Electrical and Computer Engineering, New York University, Brooklyn, NY, USA; Department of Electrical and Computer Engineering, New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161368/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4785556641014313076&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160549",
        "title": "Self-Entanglement-Free Tethered Path Planning for Non-Particle Differential-Driven Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel mechanism to derive self-entanglement-free path for tethered differential-driven robots is proposed in this work. The problem is tailored to the applications of tethered robots without an omni-directional tether re-tractor which is often encountered when an omni-directional tether retracting mechanism is incapable of being jointly equipped with other geometrically complex devices (e.g. a manipulator), for instance the disaster recovery, spatial exploration, etc. Without a special consideration on the spatial relation between the pose of the mobile base and the tether, self-entanglement appears when the robot moves, resulting in unsafe motion of the robot and potential damage to the tether. In this paper, the self-entanglement-free constraint is modelled as the admissible orientation of the tether anchoring on the robot with respect to the robot's heading orientation. A searching-based path planning algorithm is then proposed to generate a near optimal path solution with guaranteed null of tether self-entanglement. The effectiveness of the proposed algorithm is compared with the motions without considering self-entanglement-free constraint, illustrated in challenging planning cases, and validated in realworld scenes. An open-source implementation has also been provided for the benefit of the robotics community.",
        "primary_area": "",
        "author": "Tong Yang;Jiangpin Liu;Yue Wang;Rong Xiong;Tong Yang;Jiangpin Liu;Yue Wang;Rong Xiong",
        "authorids": "/37089400737;/37089320234;/37072299700;/37271511300;/37089400737;/37089320234;/37072299700;/37271511300",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, P.R., China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, P.R., China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, P.R., China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, P.R., China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160549/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=164616724693518850&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160883",
        "title": "Self-Improving Safety Performance of Reinforcement Learning Based Driving with Black-Box Verification Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a self-improving artificial intelligence system to enhance the safety performance of reinforcement learning (RL)-based autonomous driving (AD) agents using black-box verification methods. RL algorithms have become popular in AD applications in recent years. However, the performance of existing RL algorithms heavily depends on the diversity of training scenarios. A lack of safety-critical scenarios during the training phase could result in poor generalization performance in real-world driving applications. We propose a novel framework in which the weaknesses of the training set are explored through black-box verification methods. After discovering AD failure scenarios, the RL agent's training is re-initiated via transfer learning to improve the performance of previously unsafe scenarios. Simulation results demonstrate that our approach efficiently discovers safety failures of action decisions in RL-based adaptive cruise control (ACC) applications and significantly reduces the number of vehicle collisions through iterative applications of our method. The source code is publicly available at https://github.com/data-and-decision-lab/self-improving-RL.",
        "primary_area": "",
        "author": "Resul Dagdanov;Halil Durmus;Nazim Kemal Ure;Resul Dagdanov;Halil Durmus;Nazim Kemal Ure",
        "authorids": "/37089235182;/37085828306;/38189666100;/37089235182;/37085828306;/38189666100",
        "aff": "Department of Aeronautical Engineering, ITU Artificial Intelligence and Data Science Research Center, Istanbul Technical University, Turkey; Department of Electronics and Communication Engineering, Eatron Technologies, Istanbul Technical University, Turkey; Department of Computer Engineering, ITU Artificial Intelligence and Data Science Application and Research Center, Istanbul Technical University, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160883/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15789619217304305797&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Istanbul Technical University",
        "aff_unique_dep": "Department of Aeronautical Engineering",
        "aff_unique_url": "https://www.itu.edu.tr",
        "aff_unique_abbr": "ITU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Istanbul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Turkey"
    },
    {
        "id": "10161371",
        "title": "Self-Supervised Learning of Action Affordances as Interaction Modes",
        "track": "main",
        "status": "Poster",
        "abstract": "When humans perform a task with an articulated object, they interact with the object only in a handful of ways, while the space of all possible interactions is nearly endless. This is because humans have prior knowledge about what interactions are likely to be successful, i.e., to open a new door we first try the handle. While learning such priors without supervision is easy for humans, it is notoriously hard for machines. In this work, we tackle unsupervised learning of priors of useful interactions with articulated objects, which we call interaction modes. In contrast to the prior art, we use no supervision or privileged information; we only assume access to the depth sensor in the simulator to learn the interaction modes. More precisely, we define a successful interaction as the one changing the visual environment substantially and learn a generative model of such interactions, that can be conditioned on the desired goal state of the object. In our experiments, we show that our model covers most of the human interaction modes, outperforms existing state-of-the-art methods for affordance learning, and can generalize to objects never seen during training. Additionally, we show promising results in the goal-conditional setup, where our model can be quickly fine-tuned to perform a given task. We show in the experiments that such affordance learning predicts interaction which covers most modes of interaction for the querying articulated object and can be fine-tuned to a goal-conditional model. For supplementary: https://actaim.github.io/.",
        "primary_area": "",
        "author": "Liquan Wang;Nikita Dvornik;Rafael Dubeau;Mayank Mittal;Animesh Garg;Liquan Wang;Nikita Dvornik;Rafael Dubeau;Mayank Mittal;Animesh Garg",
        "authorids": "/37089893409;/37086332289;/37089893145;/37089654860;/37086330576;/37089893409;/37086332289;/37089893145;/37089654860;/37086330576",
        "aff": "University of Toronto & Vector Institute, Canada; Nvidia, United States; University of Toronto & Vector Institute, Canada; Samsung, India; Samsung, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161371/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6515945494464384691&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "University of Toronto;NVIDIA Corporation;Samsung",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.utoronto.ca;https://www.nvidia.com;https://www.samsung.com/in/",
        "aff_unique_abbr": "U of T;NVIDIA;Samsung",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;2;2",
        "aff_country_unique": "Canada;United States;India"
    },
    {
        "id": "10160786",
        "title": "Self-Supervised Learning of Object Segmentation from Unlabeled RGB-D Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a self-supervised learning system for segmenting rigid objects in RGB images. The proposed pipeline is trained on unlabeled RGB-D videos of static objects, which can be captured with a camera carried by a mobile robot. A key feature of the self-supervised training process is a graph-matching algorithm that operates on the over-segmentation output of the point cloud that is reconstructed from each video. The graph matching, along with point cloud registration, is able to find reoccurring object patterns across videos and combine them into 3D object pseudo labels, even under occlusions or different viewing angles. Projected 2D object masks from 3D pseudo labels are used to train a pixel-wise feature extractor through contrastive learning. During online inference, a clustering method uses the learned features to cluster foreground pixels into object segments. Experiments highlight the method's effectiveness on both real and synthetic video datasets, which include cluttered scenes of tabletop objects. The proposed method outperforms existing unsupervised methods for object segmentation by a large margin.",
        "primary_area": "",
        "author": "Shiyang Lu;Yunfu Deng;Abdeslam Boularias;Kostas Bekris;Shiyang Lu;Yunfu Deng;Abdeslam Boularias;Kostas Bekris",
        "authorids": "/37086579739;/37089894452;/37542596800;/37282424700;/37086579739;/37089894452;/37542596800;/37282424700",
        "aff": "Department of Computer Science, Rutgers University, New Brunswick, NJ, USA; Department of Electrical and Computer Engineering, Rutgers University, New Brunswick, NJ; Department of Computer Science, Rutgers University, New Brunswick, NJ, USA; Department of Computer Science, Rutgers University, New Brunswick, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160786/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:vrurS6xO9yUJ:scholar.google.com/&scioq=Self-Supervised+Learning+of+Object+Segmentation+from+Unlabeled+RGB-D+Videos&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161161",
        "title": "Self-Supervised Monocular Depth Underwater",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth estimation is critical for any robotic system. In the past years, the estimation of depth from monocular images has shown great improvement. However, in the underwater environment results are still lagging behind due to appearance changes caused by the medium. So far little effort has been invested in overcoming this. Moreover, underwater, there are more limitations to using high-resolution depth sensors, which is a serious obstacle to generating ground truth. So far unsupervised methods that tried to solve this have achieved limited success as they relied on domain transfer from a dataset in the air. We suggest network training using subsequent frames, self-supervised by a reprojection loss, as was demonstrated successfully above water. We propose several additions to the self-supervised framework to cope with the underwater environment and achieve state-of-the-art results on a challenging forward-looking underwater dataset.",
        "primary_area": "",
        "author": "Shlomi Amitai;Itzik Klein;Tali Treibitz;Shlomi Amitai;Itzik Klein;Tali Treibitz",
        "authorids": "/37089895248;/38235426400;/37546832000;/37089895248;/38235426400;/37546832000",
        "aff": "The Hatter Dept. of Marine Technologies, Charney School of Marine Sciences, University of Haifa, Haifa, Israel; The Hatter Dept. of Marine Technologies, Charney School of Marine Sciences, University of Haifa, Haifa, Israel; The Hatter Dept. of Marine Technologies, Charney School of Marine Sciences, University of Haifa, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161161/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11864984451842416225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Haifa",
        "aff_unique_dep": "Hatter Dept. of Marine Technologies",
        "aff_unique_url": "https://www.haifa.ac.il",
        "aff_unique_abbr": "UoH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "10160442",
        "title": "Self-adaptive Teaching-learning-based Optimizer with Improved RBF and Sparse Autoencoder for Complex Optimization Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "Evolutionary algorithms are commonly used to solve many complex optimization problems in such fields as robotics, industrial automation, and complex system design. Yet, their performance is limited when dealing with high-dimensional complex problems because they often require enormous computational resources to yield desired solutions, and they may easily trap into local optima. To solve this problem, this work proposes a Self-adaptive Teaching-learning-based Optimizer with an improved Radial basis function model and a sparse Autoencoder (STORA). In STORA, a Self-adaptive Teaching-learning-based Optimizer is designed to dynamically adjust parameters for balancing exploration and exploitation during its solution process. Then, a sparse autoencoder (SAE) is adopted as a dimension reduction method to compress search space into lower-dimensional one for more efficiently guiding population to converge towards global optima. Besides, an Improved Radial Basis Function model (IRBF) is designed as a surrogate model to balance training time and prediction accuracy. It is adopted to save computational resources for improving overall performance. In addition, a dynamic population allocation strategy is adopted to well integrate SAE and IRBF in STORA. We evaluate it by comparing it with several state-of-the-art algorithms through six benchmark functions. We further test it by applying it to solve a real-world computational offloading problem.",
        "primary_area": "",
        "author": "Jing Bi;Ziqi Wang;Haitao Yuan;Junfei Qiao;Jia Zhang;MengChu Zhou;Jing Bi;Ziqi Wang;Haitao Yuan;Junfei Qiao;Jia Zhang;MengChu Zhou",
        "authorids": "/37530385000;/37088771177;/37592390300;/37273179900;/37281461700;/37273591600;/37530385000;/37088771177;/37592390300;/37273179900;/37281461700;/37273591600",
        "aff": "Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Department of Computer Science, Lyle School of Engineering at Southern Methodist University, Dallas, TX, USA; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160442/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7727058621066462317&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;2;3",
        "aff_unique_norm": "Beijing University of Technology;Beihang University;Southern Methodist University;New Jersey Institute of Technology",
        "aff_unique_dep": "Faculty of Information Technology;School of Automation Science and Electrical Engineering;Department of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.bit.edu.cn;http://www.buaa.edu.cn;https://www.smu.edu;https://www.njit.edu",
        "aff_unique_abbr": "BIT;BUAA;SMU;NJIT",
        "aff_campus_unique_index": "0;0;0;0;1;2",
        "aff_campus_unique": "Beijing;Dallas;Newark",
        "aff_country_unique_index": "0;0;0;0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10160653",
        "title": "Self-supervised Cloth Reconstruction via Action-conditioned Cloth Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "State estimation is one of the greatest challenges for cloth manipulation due to cloth's high dimensionality and self-occlusion. Prior works propose to identify the full state of crumpled clothes by training a mesh reconstruction model in simulation. However, such models are prone to suffer from a sim-to-real gap due to differences between cloth simulation and the real world. In this work, we propose a self-supervised method to finetune a mesh reconstruction model in the real world. Since the full mesh of crumpled cloth is difficult to obtain in the real world, we design a special data collection scheme and an action-conditioned model-based cloth tracking method to generate pseudo-labels for self-supervised learning. By finetuning the pretrained mesh reconstruction model on this pseudo-labeled dataset, we show that we can improve the quality of the reconstructed mesh without requiring human annotations, and improve the performance of downstream manipulation task. More visualizations and results can be found on our project website.",
        "primary_area": "",
        "author": "Zixuan Huang;Xingyu Lin;David Held;Zixuan Huang;Xingyu Lin;David Held",
        "authorids": "/37089893157;/37089447209;/37408101800;/37089893157;/37089447209;/37408101800",
        "aff": "Robotics Institute, Carnegie Mellon University, USA; Robotics Institute, Carnegie Mellon University, USA; Robotics Institute, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160653/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7008322045390891771&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160391",
        "title": "Self-supervised Multi-frame Monocular Depth Estimation with Pseudo-LiDAR Pose Enhancement",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth estimation is one of the most important tasks in scene understanding. In the existing joint self-supervised learning approaches of depth-pose estimation, depth estimation and pose estimation networks are independent of each other. They only use the adjacent image frames for pose estimation and lack the use of the estimated geometric information. To enhance the depth-pose association, we propose a monocular multi-frame unsupervised depth estimation framework, named PLPE-Depth. There are a depth estimation network and two pose estimation networks with image input and pseudo-LiDAR input. The main idea of our approach is to use the pseudo-LiDAR reconstructed from the depth map to estimate the pose of adjacent frames. We propose depth re-estimation with a better pose between the image pose and the pseudo-LiDAR pose to improve the accuracy of estimation. Besides, we improve the reconstruction loss and design a pseudo-LiDAR pose enhancement loss to facilitate the joint learning. Our approach enhances the use of the estimated depth information and strengthens the coupling between depth estimation and pose estimation. Experiments on the KITTI dataset show that our depth estimation achieves state-of-the-art performance at low resolution. Our source codes will be released on https://github.com/IRMVLabIPLPE-Depth.",
        "primary_area": "",
        "author": "Wenhua Wu;Guangming Wang;Jiquan Zhong;Hesheng Wang;Zhe Liu;Wenhua Wu;Guangming Wang;Jiquan Zhong;Hesheng Wang;Zhe Liu",
        "authorids": "/37089798189;/37086937116;/37089797740;/37292567100;/38505849700;/37089798189;/37086937116;/37089797740;/37292567100;/38505849700",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Insititute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Insititute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Insititute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160391/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11193957623699852657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "AI Institute",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160307",
        "title": "Semantic Keypoint Extraction for Scanned Animals using Multi-Depth-Camera Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Keypoint annotation in pointclouds is an important task for 3D reconstruction, object tracking and alignment, in particular in deformable or moving scenes. In the context of agriculture robotics, it is a critical task for livestock automation to work toward condition assessment or behaviour recognition. In this work, we propose a novel approach for semantic keypoint annotation in pointclouds, by reformulating the keypoint extraction as a regression problem of the distance between the keypoints and the rest of the pointcloud. We use the distance on the pointcloud manifold mapped into a radial basis function (RBF), which is then learned using an encoder-decoder architecture. Special consideration is given to the data augmentation specific to multi-depth-camera systems by considering noise over the extrinsic calibration and camera frame dropout. Additionally, we investigate computationally efficient non-rigid deformation methods that can be applied to animal pointclouds. Our method is tested on data collected in the field, on moving beef cattle, with a calibrated system of multiple hardware-synchronised RGB-D cameras.",
        "primary_area": "",
        "author": "Raphael Falque;Teresa Vidal-Calleja;Alen Alempijevic;Raphael Falque;Teresa Vidal-Calleja;Alen Alempijevic",
        "authorids": "/37085688432;/37085384801;/37296706500;/37085688432;/37085384801;/37296706500",
        "aff": "Robotics Institute, University of Technology, Sidney, Australia; Robotics Institute, University of Technology, Sidney, Australia; Robotics Institute, University of Technology, Sidney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160307/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11047298433784655575&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10161342",
        "title": "Semantic Mapping with Confidence Scores through Metric Embeddings and Gaussian Process Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in robotic mapping enable robots to use both semantic and geometric understanding of their surroundings to perform complex tasks. Current methods are optimized for reconstruction quality, but they do not provide a measure of how certain they are of their outputs. Therefore, algorithms that use these maps do not have a way of assessing how much they can trust the outputs. We present a mapping approach that unifies semantic information and shape completion inferred from RGBD images and computes confidence scores for its predictions. We use a Gaussian Process (GP) classification model to merge confidence scores (if available) for the given information. A novel aspect of our method is that we lift the measurement to a learned metric space over which the GP parameters are learned. After training, we can evaluate the uncertainty of objects' completed shapes with their semantic information. We show that our approach can achieve more accurate predictions than a classic GP model and provide robots with the flexibility to decide whether they can trust the estimate at a given location using the confidence scores.",
        "primary_area": "",
        "author": "Jungseok Hong;Suveer Garg;Volkan Isler;Jungseok Hong;Suveer Garg;Volkan Isler",
        "authorids": "/37088505608;/37088809621;/37298487800;/37088505608;/37088809621;/37298487800",
        "aff": "Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, United States; Samsung AI Center New York, New York, NY, United States; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161342/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:5ONM4Ab-3eoJ:scholar.google.com/&scioq=Semantic+Mapping+with+Confidence+Scores+through+Metric+Embeddings+and+Gaussian+Process+Classification&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Minnesota;Samsung AI Center",
        "aff_unique_dep": "Department of Computer Science and Engineering;AI Center",
        "aff_unique_url": "https://www.umn.edu;https://www.samsung.com/us/",
        "aff_unique_abbr": "UMN;Samsung AI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Minneapolis;New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160746",
        "title": "Semantic-SuPer: A Semantic-aware Surgical Perception Framework for Endoscopic Tissue Identification, Reconstruction, and Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and robust tracking and reconstruction of the surgical scene is a critical enabling technology toward autonomous robotic surgery. Existing algorithms for 3D perception in surgery mainly rely on geometric information, while we propose to also leverage semantic information inferred from the endoscopic video using image segmentation algorithms. In this paper, we present a novel, comprehensive surgical per-ception framework, Semantic-SuPer, that integrates geometric and semantic information to facilitate data association, 3D reconstruction, and tracking of endoscopic scenes, benefiting downstream tasks like surgical navigation. The proposed frame-work is demonstrated on challenging endoscopic data with deforming tissue, showing its advantages over our baseline and several other state-of-the-art approaches. Our code and dataset are available at https://github.com/ucsdarclab/Python-SuPer.",
        "primary_area": "",
        "author": "Shan Lin;Albert J. Miao;Jingpei Lu;Shunkai Yu;Zih-Yun Chiu;Florian Richter;Michael C. Yip;Shan Lin;Albert J. Miao;Jingpei Lu;Shunkai Yu;Zih-Yun Chiu;Florian Richter;Michael C. Yip",
        "authorids": "/37088473733;/37089892509;/37088071646;/37089891965;/37086357053;/37086936752;/37085382768;/37088473733;/37089892509;/37088071646;/37089891965;/37086357053;/37086936752;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160746/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1076186695723018096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160469",
        "title": "Semantics-aware Exploration and Inspection Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper contributes a novel strategy for semantics-aware autonomous exploration and inspection path planning. Attuned to the fact that environments that need to be explored often involve a sparse set of semantic entities of particular interest, the proposed method offers volumetric exploration combined with two new planning behaviors that together ensure that a complete mesh model is reconstructed for each semantic, while its surfaces are observed at appropriate resolution and through suitable viewing angles. Evaluated in extensive simulation studies and experimental results using a flying robot, the planner delivers efficient combined exploration and high-fidelity inspection planning that is focused on the semantics of interest. Comparisons against relevant methods of the state-of-the-art are further presented.",
        "primary_area": "",
        "author": "Mihir Dharmadhikari;Kostas Alexis;Mihir Dharmadhikari;Kostas Alexis",
        "authorids": "/37088504973;/37546514600;/37088504973;/37546514600",
        "aff": "Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160469/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17809689930412959516&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Norwegian University of Science and Technology",
        "aff_unique_dep": "Autonomous Robots Lab",
        "aff_unique_url": "https://www.ntnu.edu",
        "aff_unique_abbr": "NTNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Trondheim",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "10161565",
        "title": "Semi-autonomous robotic control of a self-shaping cochlear implant",
        "track": "main",
        "status": "Poster",
        "abstract": "Cochlear implants (CIs) can improve hearing in patients suffering from sensorineural hearing loss via an electrode array (EA) carefully inserted in the scala tympani. Current EAs can cause trauma during insertion, threatening hearing preservation; hence we proposed a pre-curved thermally drawn EA that curls into the cochlea under the influence of body temperature. However, the additional surgical skill required to insert pre-curved EAs usually produces worse surgical outcomes. Medical robots can offer an effective solution to assist surgeons in improving surgical outcomes and reducing outliers. This work proposes a collaborative approach to insert our EA where manageable tasks are automated using a vision-based system. The insertion strategy presented allowed us to insert our EA successfully. The feasibility study showed that we can insert EAs following the defined control strategy while keeping the exerted contact forces within safe levels. The teleoperated robotic system and robotic vision approach to control a self-shaping CI has thus shown potential to provide the tools for a more delicate and atraumatic approach.",
        "primary_area": "",
        "author": "Daniel Bautista-Salinas;Conor Kirby;Mohamed E. M. K. Abdelaziz;Burak Temelkuran;Charlie T. Huins;Ferdinando Rodriguez y Baena;Daniel Bautista-Salinas;Conor Kirby;Mohamed E. M. K. Abdelaziz;Burak Temelkuran;Charlie T. Huins;Ferdinando Rodriguez y Baena",
        "authorids": "/37087031023;/37089894124;/37086453351;/37086563609;/37089892819;/37085615495;/37087031023;/37089894124;/37086453351;/37086563609;/37089892819;/37085615495",
        "aff": "Department of Mechanical Engineering, Mechatronics in Medicine Lab, Imperial College London, UK; Department of Mechanical Engineering, Mechatronics in Medicine Lab, Imperial College London, UK; The Hamlyn Centre for Robotic Surgery, Institute of Global Health Innovation, Imperial College London, London, UK; Department of Metabolism, Digestion and Reproduction, Imperial College London, UK; Queen Elizabeth Hospital Birmingham, UK; Department of Mechanical Engineering, Mechatronics in Medicine Lab, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161565/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3690725390930361705&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Imperial College London;Queen Elizabeth Hospital",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.imperial.ac.uk;https://wwwQEHB.org.uk",
        "aff_unique_abbr": "ICL;",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";London;Birmingham",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160553",
        "title": "Sensor Localization by Few Distance Measurements via the Intersection of Implicit Manifolds",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a general approach for determining the unknown (or uncertain) position and orientation of a sensor mounted on a robot in a known environment, using only a few distance measurements (between 2 to 6 typically), which is advantageous, among others, in sensor cost, and storage and information-communication resources. In-between the measurements, the robot can perform predetermined local motions in its workspace, which are useful for narrowing down the candidate poses of the sensor. We demonstrate our approach for planar workspaces, and show that, under mild transversality assumptions, already two measurements are sufficient to reduce the set of possible poses to a set of curves (one-dimensional objects) in the three-dimensional configuration space of the sensor \\mathbb{R}^{2}\\times \\mathbb{S}^{1},\\mathbb{R}^{2}\\times \\mathbb{S}^{1}, and three or more measurements reduce the set of possible poses to a finite collection of points. However, analytically computing these potential poses for non-trivial intermediate motions between measurements raises substantial hardships and thus we resort to numerical approximation. We reduce the localization problem to a carefully tailored procedure of intersecting two or more implicitly defined two-manifolds, which we carry out to any desired accuracy, proving guarantees on the quality of the approximation. We demonstrate the real-time effectiveness of our method even at high accuracy on various scenarios and different allowable intermediate motions. We also present experiments with a physical robot. Our open-source software and supplementary materials are available at https://bitbucket.org/taucgl/vb-fdml-public.",
        "primary_area": "",
        "author": "Michael M. Bilevich;Steven M. LaValle;Dan Halperin;Michael M. Bilevich;Steven M. LaValle;Dan Halperin",
        "authorids": "/37089892090;/37280522300;/37355669200;/37089892090;/37280522300;/37355669200",
        "aff": "Blavatnik School of Computer Science, Tel-Aviv University, Israel; Center for Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland; Blavatnik School of Computer Science, Tel-Aviv University, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160553/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14997809641357501199&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Tel-Aviv University;University of Oulu",
        "aff_unique_dep": "Blavatnik School of Computer Science;Center for Ubiquitous Computing",
        "aff_unique_url": "https://www.tau.ac.il;https://www.oulu.fi",
        "aff_unique_abbr": "TAU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tel-Aviv;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Israel;Finland"
    },
    {
        "id": "10161145",
        "title": "Seq2Seq Imitation Learning for Tactile Feedback-based Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot control for tactile feedback based manip-ulation can be difficult due to modeling of physical contacts, partial observability of the environment, and noise in perception and control. This work focuses on solving partial observability of contact-rich manipulation tasks as a Sequence-to-Sequence (Seq2Seq) Imitation Learning (IL) problem. The proposed Seq2Seq model first produces a robot-environment interaction sequence to estimate the partially observable environment state variables, and then, the observed interaction sequence is transformed to a control sequence for the task itself. The proposed Seq2Seq IL for tactile feedback based manipulation is experimentally validated on a door-open task in a simulated environment and a snap-on insertion task with a real robot. The model is able to learn both tasks from only 50 expert demonstrations while state-of-the-art reinforcement learning and imitation learning methods fail.",
        "primary_area": "",
        "author": "Wenyan Yang;Alexandre Angleraud;Roel S. Pieters;Joni Pajarinen;Joni-Kristian K\u00e4m\u00e4r\u00e4inen;Wenyan Yang;Alexandre Angleraud;Roel S. Pieters;Joni Pajarinen;Joni-Kristian K\u00e4m\u00e4r\u00e4inen",
        "authorids": "/37088505300;/37086512332;/37086512826;/37398592200;/37268498700;/37088505300;/37086512332;/37086512826;/37398592200;/37268498700",
        "aff": "Tampere University, Finland; Tampere University, Finland; Tampere University, Finland; Aalto University, Finland; Tampere University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161145/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=741436194087677918&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Tampere University;Aalto University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tuni.fi;https://www.aalto.fi",
        "aff_unique_abbr": "Tuni;Aalto",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "10160259",
        "title": "Sequence-Agnostic Multi-Object Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "The Multi-Object Navigation (MultiON) task requires a robot to localize an instance (each) of multiple object classes. It is a fundamental task for an assistive robot in a home or a factory. Existing methods for MultiON have viewed this as a direct extension of Object Navigation (ON), the task of localising an instance of one object class, and are pre-sequenced, i.e., the sequence in which the object classes are to be explored is provided in advance. This is a strong limitation in practical applications characterized by dynamic changes. This paper describes a deep reinforcement learning framework for sequence-agnostic MultiON based on an actor-critic architecture and a suitable reward specification. Our framework leverages past experiences and seeks to reward progress toward individual as well as multiple target object classes. We use photo-realistic scenes from the Gibson benchmark dataset in the AI Habitat 3D simulation environment to experimentally show that our method performs better than a pre-sequenced approach and a state of the art ON method extended to MultiON.",
        "primary_area": "",
        "author": "Nandiraju Gireesh;Ayush Agrawal;Ahana Datta;Snehasis Banerjee;Mohan Sridharan;Brojeshwar Bhowmick;Madhava Krishna;Nandiraju Gireesh;Ayush Agrawal;Ahana Datta;Snehasis Banerjee;Mohan Sridharan;Brojeshwar Bhowmick;Madhava Krishna",
        "authorids": "/37089238309;/37089893419;/37089894840;/37960481000;/37269573500;/37571664300;/37089108874;/37089238309;/37089893419;/37089894840;/37960481000;/37269573500;/37571664300;/37089108874",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160259/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8496808183730892346&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14
    },
    {
        "id": "10160859",
        "title": "Sequential Bayesian Optimization for Adaptive Informative Path Planning with Multimodal Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Adaptive Informative Path Planning with Multi-modal Sensing (AIPPMS) considers the problem of an agent equipped with multiple sensors, each with different sensing accuracy and energy costs. The agent's goal is to explore the environment and gather information subject to its resource constraints in unknown, partially observable environments. Previous work has focused on the less general Adaptive Informative Path Planning (AIPP) problem, which considers only the effect of the agent's movement on received observations. The AIPPMS problem adds additional complexity by requiring that the agent reasons jointly about the effects of sensing and movement while balancing resource constraints with information objectives. We formulate the AIPPMS problem as a belief Markov decision process with Gaussian process beliefs and solve it using a sequential Bayesian optimization approach with online planning. Our approach consistently outperforms previous AIPPMS solutions by more than doubling the average reward received in almost every experiment while also reducing the root-mean-square error in the environment belief by 50%. We completely open-source our implementation to aid in further development and comparison.11https://github.com/sisl/SBO_AIPPMS",
        "primary_area": "",
        "author": "Joshua Ott;Edward Balaban;Mykel J. Kochenderfer;Joshua Ott;Edward Balaban;Mykel J. Kochenderfer",
        "authorids": "/37089662054;/37295483600;/37596929200;/37089662054;/37295483600;/37596929200",
        "aff": "Department of Aeronautics & Astronautics, Stanford University; NASA Ames Research Center; Department of Aeronautics & Astronautics, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160859/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2150619489372671729&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;NASA Ames Research Center",
        "aff_unique_dep": "Department of Aeronautics & Astronautics;",
        "aff_unique_url": "https://www.stanford.edu;https://ames.nasa.gov",
        "aff_unique_abbr": "Stanford;NASA Ames",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161094",
        "title": "Sequential Stochastic Multi-Task Assignment for Multi-Robot Deployment Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time sequential decision making under uncertainty is a challenging task for autonomous robots. Such problems are even more challenging when making decisions involving heterogeneous teams of robots completing multiple tasks. Deploying autonomous taxi cabs and utilizing drones for package delivery represent relevant examples of these types of problems. In this paper, we present an effective solution to a multi-robot multi-task sequential stochastic assignment problem using a simulation-based optimization algorithm (MARP). Our algorithm employs a novel approach that uses Monte Carlo simulation to seek the deployment with the highest probability of being optimal. To demonstrate MARP's performance and robustness, we performed more than 2,000 numerical experiments in two different problem domains, evaluating MARP's performance against three different comparison algorithms. These numerical studies show that MARP significantly outperforms the comparison methods, achieving results within 5% of the maximum possible reward.",
        "primary_area": "",
        "author": "Colin Mitchell;Graeme Best;Geoffrey Hollinger;Colin Mitchell;Graeme Best;Geoffrey Hollinger",
        "authorids": "/37089895109;/37085672100;/37543482700;/37089895109;/37085672100;/37543482700",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; School of Mechanical and Mechatronic Engineering, University of Technology, Sydney, NSW, Australia; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161094/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5497037728556878145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Oregon State University;University of Technology, Sydney",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute;School of Mechanical and Mechatronic Engineering",
        "aff_unique_url": "https://oregonstate.edu;https://www.uts.edu.au",
        "aff_unique_abbr": "OSU;UTS",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Corvallis;Sydney",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "10161101",
        "title": "Shape visual servoing of a tether cable from parabolic features",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a visual servoing approach that controls the deformation of a suspended tether cable subject to gravity from visual data provided by a RGB-D camera. The cable shape is modelled with a parabolic curve together with the orientation of the plane containing the tether. The visual features considered are the parabolic coefficients and the yaw angle of that plane. We derive the analytical expression of the interaction matrix that relates the variation of the visual features to the velocities of the cable extremities. Singularities are demonstrated to occur if and only if the cable is taut horizontally or vertically. An image processing algorithm is also developed to extract in real-time the current features fitting the parabola to the cable from the observed point cloud. Simulations and experimental results demonstrate the efficiency of our visual servoing approach to deform the tether cable toward a desired shape configuration.",
        "primary_area": "",
        "author": "Lev Smolentsev;Alexandre Krupa;Fran\u00e7ois Chaumette;Lev Smolentsev;Alexandre Krupa;Fran\u00e7ois Chaumette",
        "authorids": "/37089895770;/37329643400;/37265186700;/37089895770;/37329643400;/37265186700",
        "aff": "Inria, Univ Rennes, CNRS, IRISA, Rennes, France; Inria, Univ Rennes, CNRS, IRISA, Rennes, France; Inria, Univ Rennes, CNRS, IRISA, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161101/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4608757513873257677&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Inria",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Rennes",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10161509",
        "title": "Shared Control of Assistive Robots through User-intent Prediction and Hyperdimensional Recall of Reactive Behavior",
        "track": "main",
        "status": "Poster",
        "abstract": "There is increasing interest in shared control for assistive robotics with adaptable levels of supervised autonomy. In this work, we present a user-adaptive multi-layer shared control scheme for control of assistive devices. The system leverages the advantages of brain-inspired hyperdimensional computing (HDC) for classification & recall of reactive robotic behavior including high performance, computational efficiency and intelligent sensor fusion, to execute actuation based on the user's goal while alleviating the burden of fine control. Using a multi-modal dataset of activities of daily living, we first recognize the user's most recent behaviors, then predict the user's next action based on their habitual action sequences, and finally, determine actuation through HDC recall-based shared control which intelligently deliberates between the predicted action and sensor feedback-based autonomy. In this work, we independently implement each layer to achieve >92% accuracy and then integrate the layers and discuss the combined performance and methods to reduce accumulated error.",
        "primary_area": "",
        "author": "Alisha Menon;Laura I. Galindez Olascoaga;Vamshi Balanaga;Anirudh Natarajan;Jennifer Ruffing;Ryan Ardalan;Jan M. Rabaey;Alisha Menon;Laura I. Galindez Olascoaga;Vamshi Balanaga;Anirudh Natarajan;Jennifer Ruffing;Ryan Ardalan;Jan M. Rabaey",
        "authorids": "/37088811286;/37086952031;/37089597079;/37089447142;/37089600292;/37089893264;/37276611300;/37088811286;/37086952031;/37089597079;/37089447142;/37089600292;/37089893264;/37276611300",
        "aff": "EECS Department, The Berkeley Wireless Research Center, University of California, Berkeley; EECS Department, The Berkeley Wireless Research Center, University of California, Berkeley; EECS Department, The Berkeley Wireless Research Center, University of California, Berkeley; EECS Department, The Berkeley Wireless Research Center, University of California, Berkeley; EECS Department, The Berkeley Wireless Research Center, University of California, Berkeley; EECS Department, The Berkeley Wireless Research Center, University of California, Berkeley; EECS Department, The Berkeley Wireless Research Center, University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161509/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7033854599892933053&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "EECS Department",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160947",
        "title": "Show me What you want: Inverse Reinforcement Learning to Automatically Design Robot Swarms by Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic design is a promising approach to generating control software for robot swarms. So far, automatic design has relied on mission-specific objective functions to specify the desired collective behavior. In this paper, we explore the possibility to specify the desired collective behavior via demonstrations. We develop Demo-Cho, an automatic design method that combines inverse reinforcement learning with automatic modular design of control software for robot swarms. We show that, only on the basis of demonstrations and without the need to be provided with an explicit objective function, Demo-Cho successfully generated control software to perform four missions. We present results obtained in simulation and with physical robots.",
        "primary_area": "",
        "author": "Ilyes Gharbi;Jonas Kuckling;David Garz\u00f3n Ramos;Mauro Birattari;Ilyes Gharbi;Jonas Kuckling;David Garz\u00f3n Ramos;Mauro Birattari",
        "authorids": "/37089894009;/37089894418;/37089893789;/37299118400;/37089894009;/37089894418;/37089893789;/37299118400",
        "aff": "IRIDIA, Universit\u00e9 libre de Bruxelles, Brussels, Belgium; Department of Computer and Information Science, University of Konstanz, Germany; IRIDIA, Universit\u00e9 libre de Bruxelles, Brussels, Belgium; IRIDIA, Universit\u00e9 libre de Bruxelles, Brussels, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160947/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7121119679041706741&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Universit\u00e9 libre de Bruxelles;University of Konstanz",
        "aff_unique_dep": "IRIDIA;Department of Computer and Information Science",
        "aff_unique_url": "https://www.ulb.ac.be;https://www.uni-konstanz.de",
        "aff_unique_abbr": "ULB;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brussels;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Belgium;Germany"
    },
    {
        "id": "10160979",
        "title": "Shunted Collision Avoidance for Multi-UAV Motion Planning with Posture Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the problem of fixed-wing unmanned aerial vehicles (UAV s) motion planning with posture constraints and the problem of the more general symmetrical situations where UAVs have more than one optimal solution. In this paper, the posture constraints are formulated in the 3D Dubins method, and the symmetrical situations are overcome by a more collaborative strategy called the shunted strategy. The effectiveness of the proposed method has been validated by conducting extensive simulation experiments. Meanwhile, we compared the proposed method with the other state-of-the-art methods, and the comparison results show that the proposed method advances the previous works. Finally, the practicability of the proposed algorithm was analyzed by the statistic in computational cost. The source code of our method can be available at https://github.com/wuuya1/SCA.",
        "primary_area": "",
        "author": "Gang Xu;Deye Zhu;Junjie Cao;Yong Liu;Jian Yang;Gang Xu;Deye Zhu;Junjie Cao;Yong Liu;Jian Yang",
        "authorids": "/37089483356;/37089487474;/37088457540;/37066946100;/37088458819;/37089483356;/37089487474;/37088457540;/37066946100;/37088458819",
        "aff": "Taizhou Institute of Zhejiang University, Taizhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Research and Development Academy of Machinery Equipment, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160979/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15879414358940553445&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Zhejiang University;Research and Development Academy of Machinery Equipment",
        "aff_unique_dep": "Taizhou Institute;",
        "aff_unique_url": "http://www.zju.edu.cn;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Taizhou;Hangzhou;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161062",
        "title": "Sim-and-Real Reinforcement Learning for Manipulation: A Consensus-based Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Sim-and-real training is a promising alternative to sim-to-real training for robot manipulations. However, the current sim-and-real training is neither efficient, i.e., slow con-vergence to the optimal policy, nor effective, i.e., sizeable real-world robot data. Given limited time and hardware budgets, the performance of sim-and-real training is not satisfactory. In this paper, we propose a Consensus-based Sim-And-Real deep reinforcement learning algorithm (CSAR) for manipulator pick-and-place tasks, which shows comparable performance in both sim-and- real worlds. In this algorithm, we train the agents in simulators and the real world to get the optimal policies for both sim-and-real worlds. We found two interesting phenomenons: (1) Best policy in simulation is not the best for sim-and-real training. (2) The more simulation agents, the better sim-and-real training. The experimental video is available at: https://youtu.be/mcHJtNIsTEQ.",
        "primary_area": "",
        "author": "Wenxing Liu;Hanlin Niu;Wei Pan;Guido Herrmann;Joaquin Carrasco;Wenxing Liu;Hanlin Niu;Wei Pan;Guido Herrmann;Joaquin Carrasco",
        "authorids": "/37089210601;/37088654909;/37088467306;/37284937100;/37596217000;/37089210601;/37088654909;/37088467306;/37284937100;/37596217000",
        "aff": "the Department of Electrical & Electronic Engineering, The University of Manchester, Manchester, UK; the Department of Electrical & Electronic Engineering, The University of Manchester, Manchester, UK; the Department of Computer Science, The University of Manchester, Manchester, UK; the Department of Electrical & Electronic Engineering, The University of Manchester, Manchester, UK; the Department of Electrical & Electronic Engineering, The University of Manchester, Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161062/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15149677328751692986&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "The University of Manchester",
        "aff_unique_dep": "Department of Electrical & Electronic Engineering",
        "aff_unique_url": "https://www.manchester.ac.uk",
        "aff_unique_abbr": "UoM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Manchester",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161298",
        "title": "Sim-to-Real Policy and Reward Transfer with Adaptive Forward Dynamics Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning has shown promise in learning robust skills for robot control, but typically requires a large amount of samples to achieve good performance. Sim-to-real transfer learning has been developed to solve this problem, but the policy trained in simulation usually has unsatisfactory performance in the real world because simulators inevitably model the dynamics of reality imperfectly. To enable sample-efficient learning in the real world, we proposed progressive policy transfer with adaptive dynamics model (PPTADM). PPTADM assumes the dynamics of simulation and real world do not match but the state space is the same, transfers policy from simulation via progressive neural network (PNN) and further improves the policy with a learned forward dynamics model in reality. In addition, for real-world tasks in which reward functions are difficult or even impossible to define and verify the effectiveness, PPTADM can learn in real world solely from a transferred reward function that is estimated from simulation even though their dynamics do not match. Our results in five simulated tasks and on a real robot arm show that with PPTADM, the robot's learning efficiency and performance in the real world can be significantly improved.",
        "primary_area": "",
        "author": "Rongshun Juan;Hao Ju;Jie Huang;Randy Gomez;Keisuke Nakamura;Guangliang Li;Rongshun Juan;Hao Ju;Jie Huang;Randy Gomez;Keisuke Nakamura;Guangliang Li",
        "authorids": "/37089195007;/37089895549;/37089196244;/37979526500;/37534198900;/37086047680;/37089195007;/37089895549;/37089196244;/37979526500;/37534198900;/37086047680",
        "aff": "College of Information Science and Engineering, Ocean University of China; College of Information Science and Engineering, Ocean University of China; College of Information Science and Engineering, Ocean University of China; Honda Research Institute Japan Co., Ltd, Wako, Japan; Honda Research Institute Japan Co., Ltd, Wako, Japan; College of Information Science and Engineering, Ocean University of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161298/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1272987777832443164&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Ocean University of China;Honda Research Institute Japan Co., Ltd",
        "aff_unique_dep": "College of Information Science and Engineering;",
        "aff_unique_url": "http://www.ouc.edu.cn;https://www.honda-ri.jp/english/",
        "aff_unique_abbr": ";HRI-JP",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Wako",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "10160497",
        "title": "Sim-to-Real Transfer for Quadrupedal Locomotion via Terrain Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning has recently emerged as an appealing alternative for legged locomotion over multiple terrains by training a policy in physical simulation and then transferring it to the real world (i.e., sim-to-real transfer). Despite considerable progress, the capacity and scalability of traditional neural networks are still limited, which may hinder their applications in more complex environments. In contrast, the Transformer architecture has shown its superiority in a wide range of large-scale sequence modeling tasks, including natural language processing and decision-making problems. In this paper, we propose Terrain Transformer (TERT), a high-capacity Transformer model for quadrupedal locomotion control on various terrains. Furthermore, to better leverage Transformer in sim-to-real scenarios, we present a novel two-stage training framework consisting of an offline pretraining stage and an online correction stage, which can naturally integrate Transformer with privileged training. Extensive experiments in simulation demonstrate that TERT outperforms state-of-the-art baselines on different terrains in terms of return, energy consumption and control smoothness. In further real-world validation, TERT successfully traverses nine challenging terrains, including sand pit and stair down, which can not be accomplished by strong baselines.",
        "primary_area": "",
        "author": "Hang Lai;Weinan Zhang;Xialin He;Chen Yu;Zheng Tian;Yong Yu;Jun Wang;Hang Lai;Weinan Zhang;Xialin He;Chen Yu;Zheng Tian;Yong Yu;Jun Wang",
        "authorids": "/37089895145;/37086030166;/37089892422;/37089472108;/37089892778;/37089896019;/37086377041;/37089895145;/37086030166;/37089892422;/37089472108;/37089892778;/37089896019;/37086377041",
        "aff": "Digital Brain Lab, Shanghai, China; Dept. of Computer Sci. and Eng., Shanghai Jiao Tong University, China; Dept. of Computer Sci. and Eng., Shanghai Jiao Tong University, China; School of Info. Sci. and Tech., ShanghaiTech University, China; School of Creativity and Art, ShanghaiTech University, China; Dept. of Computer Sci. and Eng., Shanghai Jiao Tong University, China; Centre for Artificial Intelligence, University College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160497/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=596349686508529727&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;2;2;1;3",
        "aff_unique_norm": "Digital Brain Lab;Shanghai Jiao Tong University;ShanghaiTech University;University College London",
        "aff_unique_dep": ";Dept. of Computer Sci. and Eng.;School of Info. Sci. and Tech.;Centre for Artificial Intelligence",
        "aff_unique_url": ";https://www.sjtu.edu.cn;http://www.shanghaitech.edu.cn;https://www.ucl.ac.uk",
        "aff_unique_abbr": ";SJTU;ShanghaiTech;UCL",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Shanghai;;London",
        "aff_country_unique_index": "0;0;0;0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "10160370",
        "title": "Sim2Real2: Actively Building Explicit Physics Model for Precise Articulated Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately manipulating articulated objects is a challenging yet important task for real robot applications. In this paper, we present a novel framework called Sim2Real2 to enable the robot to manipulate an unseen articulated object to the desired state precisely in the real world with no human demonstrations. We leverage recent advances in physics simulation and learning-based perception to build the interactive explicit physics model of the object and use it to plan a long-horizon manipulation trajectory to accomplish the task. However, the interactive model cannot be correctly estimated from a static observation. Therefore, we learn to predict the object affordance from a single-frame point cloud, control the robot to actively interact with the object with a one-step action, and capture another point cloud. Further, the physics model is constructed from the two point clouds. Experimental results show that our framework achieves about 70% manipulations with < 30% relative error for common articulated objects, and 30% manipulations for difficult objects. Our proposed framework also enables advanced manipulation strategies, such as manipulating with different tools. Code and videos are available on our project webpage: https://ttimelord.github.io/Sim2Real2-site/",
        "primary_area": "",
        "author": "Liqian Ma;Jiaojiao Meng;Shuntao Liu;Weihang Chen;Jing Xu;Rui Chen;Liqian Ma;Jiaojiao Meng;Shuntao Liu;Weihang Chen;Jing Xu;Rui Chen",
        "authorids": "/37089894310;/37089894400;/37089869408;/37087031864;/37537287500;/37085699353;/37089894310;/37089894400;/37089869408;/37087031864;/37537287500;/37085699353",
        "aff": "Department of Mechanical Engineering, State Key Laboratory of Tribology, the Beijing Key Laboratory of Precision/Ultra-Precision Manufacturing Equipment Control, Tsinghua University, Beijing, China; School of Modern Post, Beijing University of Posts and Telecommunications, Beijing, China; AVIC Chengdu Aircraft Industrial (Group) Co., Ltd, Chengdu, Sichuan, China; Department of Mechanical Engineering, State Key Laboratory of Tribology, the Beijing Key Laboratory of Precision/Ultra-Precision Manufacturing Equipment Control, Tsinghua University, Beijing, China; Department of Mechanical Engineering, State Key Laboratory of Tribology, the Beijing Key Laboratory of Precision/Ultra-Precision Manufacturing Equipment Control, Tsinghua University, Beijing, China; Department of Mechanical Engineering, State Key Laboratory of Tribology, the Beijing Key Laboratory of Precision/Ultra-Precision Manufacturing Equipment Control, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160370/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16216452670929122739&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;0",
        "aff_unique_norm": "Tsinghua University;Beijing University of Posts and Telecommunications;AVIC Chengdu Aircraft Industrial (Group) Co., Ltd",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Modern Post;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://www.bupt.edu.cn/;",
        "aff_unique_abbr": "Tsinghua;BUPT;",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Beijing;Chengdu",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160831",
        "title": "Simple-BEV: What Really Matters for Multi-Sensor BEV Perception?",
        "track": "main",
        "status": "Poster",
        "abstract": "Building 3D perception systems for autonomous vehicles that do not rely on high-density LiDAR is a critical research problem because of the expense of LiDAR systems compared to cameras and other sensors. Recent research has developed a variety of camera-only methods, where features are differentiably \u201clifted\u201d from the multi-camera images onto the 2D ground plane, yielding a \u201cbird's eye view\u201d (BEV) feature representation of the 3D space around the vehicle. This line of work has produced a variety of novel \u201clifting\u201d methods, but we observe that other details in the training setups have shifted at the same time, making it unclear what really matters in top-performing methods. We also observe that using cameras alone is not a real-world constraint, considering that additional sensors like radar have been integrated into real vehicles for years already. In this paper, we first of all attempt to elucidate the high-impact factors in the design and training protocol of BEV perception models. We find that batch size and input resolution greatly affect performance, while lifting strategies have a more modest effect-even a simple parameter-free lifter works well. Second, we demonstrate that radar data can provide a substantial boost to performance, helping to close the gap between camera-only and LiDAR-enabled systems. We analyze the radar usage details that lead to good performance, and invite the community to re-consider this commonly-neglected part of the sensor platform.",
        "primary_area": "",
        "author": "Adam W. Harley;Zhaoyuan Fang;Jie Li;Rares Ambrus;Katerina Fragkiadaki;Adam W. Harley;Zhaoyuan Fang;Jie Li;Rares Ambrus;Katerina Fragkiadaki",
        "authorids": "/37078301800;/37089893273;/37089895272;/37871304500;/37944899600;/37078301800;/37089893273;/37089895272;/37871304500;/37944899600",
        "aff": "Stanford University; Carnegie Mellon University; Toyota Research Institute; Toyota Research Institute; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160831/",
        "gs_citation": 143,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12620386158938173118&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;1",
        "aff_unique_norm": "Stanford University;Carnegie Mellon University;Toyota Research Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.cmu.edu;https://www.tri.global",
        "aff_unique_abbr": "Stanford;CMU;TRI",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160837",
        "title": "Simplified Motor Primitives for Gait Symmetrization: Pilot Study with an Active Hip Orthosis",
        "track": "main",
        "status": "Poster",
        "abstract": "Lower-limb exoskeletons are wearable devices whose main purposes are human rehabilitation and bilateral locomotion assistance. In particular, there is a growing interest for their use to symmetrize the gait of hemiparetic patients. This often consists in using the kinematics of the less affected side as a reference for the most affected one. In this work, we followed this approach to design a symmetrization algorithm using the formalism of motor primitives, i.e. a low-dimensional set of signals that provide the desired assistance through their combination. The amount of variables to be stored in memory is thus intrinsically limited, and this framework is particularly adapted to include other modes of assistance and/or transitions between locomotion tasks. In this paper, we report the preliminary validation of this newly developed algorithm with a hip exoskeleton and a single participant replicating hemiparetic walking. Results show that the algorithm effectively managed to reduce both temporal and spatial gait asymmetry.",
        "primary_area": "",
        "author": "Henri Laloyaux;Chiara Livolsi;Andrea Pergolini;Simona Crea;Nicola Vitiello;Renaud Ronsse;Henri Laloyaux;Chiara Livolsi;Andrea Pergolini;Simona Crea;Nicola Vitiello;Renaud Ronsse",
        "authorids": "/37088420572;/37088535286;/37088533356;/38557457700;/38506597800;/37299789300;/37088420572;/37088535286;/37088533356;/38557457700;/38506597800;/37299789300",
        "aff": "Institute of Mechanics, Materials, and Civil Engineering (iMMC), the Institute of NeuroScience (IoNS) and the Louvain Bionics of UCLouvain, Louvain-la-Neuve, Belgium; Department of Excellence in Robotics and AI, BioRobotics Institute, Scuola Superiore Sant'Anna, Pisa, Italy; Department of Excellence in Robotics and AI, BioRobotics Institute, Scuola Superiore Sant'Anna, Pisa, Italy; IUVO S.r.l., the company that owns the IP rights of the APO technology; IUVO S.r.l., the company that owns the IP rights of the APO technology; Institute of Mechanics, Materials, and Civil Engineering (iMMC), the Institute of NeuroScience (IoNS) and the Louvain Bionics of UCLouvain, Louvain-la-Neuve, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160837/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1965105995994744535&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;2;0",
        "aff_unique_norm": "UCLouvain;Scuola Superiore Sant'Anna;IUVO S.r.l.",
        "aff_unique_dep": "Institute of Mechanics, Materials, and Civil Engineering (iMMC);Department of Excellence in Robotics and AI;",
        "aff_unique_url": "https://www.uclouvain.be;https://www.sssup.it;",
        "aff_unique_abbr": "UCL;SSSA;",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Louvain-la-Neuve;Pisa;",
        "aff_country_unique_index": "0;1;1;1;1;0",
        "aff_country_unique": "Belgium;Italy"
    },
    {
        "id": "10161462",
        "title": "Simplifying Aerial Manipulation Using Intentional Collisions",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial manipulation describes a process that includes physical interaction between an unmanned aircraft system (UAS) and its environment. We aim to apply aerial manipulation to sample leaves and small branches from rain forest trees. Current approaches to aerial manipulation involve extended periods of UAS-environment interaction, during which forces and moments can lead to a loss in attitude or position control in underactuated multicopters. By adapting intelligent foot placement strategies found in dynamically stable hopping robots, this work proposes a strategy involving carefully managed intentional collisions between the UAS and its environment. We designed an attitude controller denoted a Velocity Matching controller that aligns a UAS-mounted pogo-stick foot with the center of mass velocity vector during collision approach to maximize UAS ability to recover a hover state after collision. We propose the use of a flight envelope involving altitude and horizontal speed states to assess recoverability prior to initiating each approach to collision. We identify this flight envelope from a simulation study built on a model of flight in Conventional Waypoint Following and Velocity Matching control modes as well as a model of collision response. Experimental flight testing evaluates the simulation-based envelope resulting in an actual envelope that is somewhat smaller but similarly shaped to the envelope identified in simulation.",
        "primary_area": "",
        "author": "Mark Nail;Nick J\u00e4nne;Olivia Ma;Gabriel Arellano;Ella Atkins;R. Brent Gillespie;Mark Nail;Nick J\u00e4nne;Olivia Ma;Gabriel Arellano;Ella Atkins;R. Brent Gillespie",
        "authorids": "/37086576858;/37089894834;/37089892476;/37089893847;/37299901300;/38558668400;/37086576858;/37089894834;/37089892476;/37089893847;/37299901300;/38558668400",
        "aff": "Robotics Department, University of Michigan, Ann Arbor, MI, USA; Department of Electrical and Computer Engineering, University of Michigan, Ann Arbor, MI, USA; Robotics Department, University of Michigan, Ann Arbor, MI, USA; Department of Ecology and Evolutionary Biology, University of Michigan, Ann Arbor, MI, USA; Department of Aerospace and Ocean Engineering, Virginia Tech, Blacksburg, VA, USA; Robotics Department, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161462/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4761068353767159258&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Michigan;Virginia Tech",
        "aff_unique_dep": "Robotics Department;Department of Aerospace and Ocean Engineering",
        "aff_unique_url": "https://www.umich.edu;https://www.vt.edu",
        "aff_unique_abbr": "UM;VT",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Ann Arbor;Blacksburg",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161158",
        "title": "Simultaneous Tactile Estimation and Control of Extrinsic Contact",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method that simultaneously estimates and controls extrinsic contact with tactile feedback. The method enables challenging manipulation tasks that require controlling light forces and accurate motions in contact, such as balancing an unknown object on a thin rod standing upright. A factor graph-based framework fuses a sequence of tactile and kinematic measurements to estimate and control the interaction between gripper-object-environment, including the location and wrench at the extrinsic contact between the grasped object and the environment and the grasp wrench transferred from the gripper to the object. The same framework simultaneously plans the gripper motions that make it possible to estimate the state while satisfying regularizing control objectives to prevent slip, such as minimizing the grasp wrench and minimizing frictional force at the extrinsic contact. We show results with sub-millimeter contact localization error and good slip prevention even on slippery environments, for multiple contact formations (point, line, patch contact) and transitions between them. See supplementary video and results at https://sites.google.com/view/sim-tact.",
        "primary_area": "",
        "author": "Sangwoon Kim;Devesh K. Jha;Diego Romeres;Parag Patre;Alberto Rodriguez;Sangwoon Kim;Devesh K. Jha;Diego Romeres;Parag Patre;Alberto Rodriguez",
        "authorids": "/37088997798;/37072717800;/37086098761;/37089919081;/38194796600;/37088997798;/37072717800;/37086098761;/37089919081;/38194796600",
        "aff": "MIT; Mitsubishi Electric Research Laboratories; Mitsubishi Electric Research Laboratories; Magna International Inc.; MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161158/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7263552624889810324&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Mitsubishi Electric Research Laboratories;Magna International Inc.",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://web.mit.edu;https://www.merl.com;https://www.magna.com",
        "aff_unique_abbr": "MIT;MERL;Magna",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "10161095",
        "title": "Skill-based Robot Programming in Mixed Reality with Ad-hoc Validation Using a Force-enabled Digital Twin",
        "track": "main",
        "status": "Poster",
        "abstract": "Skill-based programming has proven to be advantageous for assembly tasks, but still requires expert knowledge, especially for force-controlled applications. However, it is error-prone due to the multitude of parameters, e.g. different coordinate frames and either position-, velocity- or force-controlled motions on the axes of a frame. We propose a mixed reality based solution, which systematically visualizes the geometric constraints of advanced high-level skills directly in the real-world robotic environment and provides a user interface to create applications efficiently and safely in mixed reality. Therefore, state-machine information is also visualized, and a holographic digital twin allows the user to ad-hoc validate the program via force-enabled simulation. The approach is evaluated on a top hat rail mounting task, proving the capability of the system to handle advanced assembly programming tasks efficiently and tangibly.",
        "primary_area": "",
        "author": "Jan Krieglstein;Gesche Held;Bal\u00e1zs A. B\u00e1lint;Frank N\u00e4gele;Werner Kraus;Jan Krieglstein;Gesche Held;Bal\u00e1zs A. B\u00e1lint;Frank N\u00e4gele;Werner Kraus",
        "authorids": "/37088562104;/37089894470;/37089658788;/37086454281;/37357181400;/37088562104;/37089894470;/37089658788;/37086454281;/37357181400",
        "aff": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161095/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13426944953553663172&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ipa.fraunhofer.de",
        "aff_unique_abbr": "Fraunhofer IPA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161128",
        "title": "Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "Precise localization is critical for autonomous vehicles. We present a self-supervised learning method that employs transformers for the first time for the task of outdoor localization using LiDAR data. We propose a pre-text task that reorganizes the slices of a 360\u00b0 LiDAR scan to leverage its axial properties. Our model, called Slice Transformer, employs multi-head attention while systematically processing the slices. To the best of our knowledge, this is the first instance of leveraging multi-head attention for outdoor point clouds. We additionally introduce the Perth-Wadataset, which provides a large-scale LiDAR map of Perth city in Western Australia, covering ~4km2area. Localization annotations are provided for Perth - Wa.The proposed localization method is thoroughly evaluated on Perth-WA and Appollo-SouthBay datasets. We also establish the efficacy of our self-supervised learning approach for the common downstream task of object classification using ModelNet40 and ScanNN datasets. The code and Perth-WA data will be publicly released.",
        "primary_area": "",
        "author": "Muhammad Ibrahim;Naveed Akhtar;Saeed Anwar;Michael Wise;Ajmal Mian;Muhammad Ibrahim;Naveed Akhtar;Saeed Anwar;Michael Wise;Ajmal Mian",
        "authorids": "/37089260113;/38242687700;/37085684311;/37088773463;/37283914600;/37089260113;/38242687700;/37085684311;/37088773463;/37283914600",
        "aff": "Department of Computer Science, The University of Western Australia; Department of Computer Science, The University of Western Australia; King Fahad University of Petroleum and Minerals (KFUPM), Dhahran, KSA; Department of Computer Science, The University of Western Australia; Department of Computer Science, The University of Western Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161128/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13546520281370909259&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "The University of Western Australia;King Fahad University of Petroleum and Minerals",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.uwa.edu.au;https://www.kfupm.edu.sa",
        "aff_unique_abbr": "UWA;KFUPM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Dhahran",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Australia;Saudi Arabia"
    },
    {
        "id": "10160803",
        "title": "Small-shot Multi-modal Distillation for Vision-based Autonomous Steering",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel learning framework for autonomous systems that uses a small amount of \u201cauxiliary information\u201d that complements the learning of the main modality, called \u201csmall-shot auxiliary modality distillation network (AMD-S-Net)\u201d. The AMD-S-Net contains a two-stream framework design that can fully extract information from different types of data (i.e., paired/unpaired multi-modality data) to distill knowledge more effectively. We also propose a novel training paradigm based on the \u201creset operation\u201d that enables the teacher to explore the local loss landscape near the student domain iteratively, providing local landscape information and potential directions to discover better solutions by the student, thus achieving higher learning performance. Our experiments show that AMD-S-Net and our training paradigm outperform other SOTA methods by up to 12.7% and 18.1% improvement in autonomous steering, respectively.",
        "primary_area": "",
        "author": "Yu Shen;Luyu Yang;Xijun Wang;Ming C. Lin;Yu Shen;Luyu Yang;Xijun Wang;Ming C. Lin",
        "authorids": "/37088996267;/37089894382;/37089893476;/37278387400;/37088996267;/37089894382;/37089893476;/37278387400",
        "aff": "Department of Computer Science, University of Maryland at College Park, United States; Department of Computer Science, University of Maryland at College Park, United States; Department of Computer Science, University of Maryland at College Park, United States; Department of Computer Science, University of Maryland at College Park, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160803/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3000947057792974710&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160874",
        "title": "SmartRainNet: Uncertainty Estimation For Laser Measurement in Rain",
        "track": "main",
        "status": "Poster",
        "abstract": "Adverse weather has raised a big challenge for autonomous vehicles. Unreliable measurements due to sensor degradation could seriously affect the performance of autonomous driving tasks, such as perception and localization. In this work, we study sensor degradation in rainy weather and present a novel method that evaluates the uncertainty for each laser measurement from a 3D LiDAR. With uncertainty estimation, downstream tasks that rely on LiDAR input (e.g., perception or localization) can increase their reliability by adjusting their reliance on laser measurements with varying fidelity. Alternatively, uncertainty estimation can be used for sensor performance evaluation. Our proposed method, SmartRainNet, uses an attention-based Mixture Density Network to model the dependence between neighboring laser measurements and then calculate the probability density for each laser measurement as an uncertainty score. We evaluate SmartRainNet on synthetic and naturalistic sensor degradation datasets and provide qualitative and quantitative results to demonstrate the effectiveness of our method in evaluating uncertainty. Finally, we demonstrate three practical applications of uncertainty estimation to address autonomous driving challenges in rainy weather.",
        "primary_area": "",
        "author": "Chen Zhang;Zefan Huang;Beatrix Xue Lin Tung;Marcelo H. Ang;Daniela Rus;Chen Zhang;Zefan Huang;Beatrix Xue Lin Tung;Marcelo H. Ang;Daniela Rus",
        "authorids": "/37089258978;/37087323099;/37089896100;/37279138700;/37279652300;/37089258978;/37087323099;/37089896100;/37279138700;/37279652300",
        "aff": "National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160874/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17340316675270425199&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "National University of Singapore;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.mit.edu",
        "aff_unique_abbr": "NUS;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "10160536",
        "title": "SoLo T-DIRL: Socially-Aware Dynamic Local Planner based on Trajectory-Ranked Deep Inverse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a novel framework for socially-aware robot navigation in dynamic, crowded environments using a Deep Inverse Reinforcement Learning. To address the social navigation problem, our multi-modal learning based planner explicitly considers social interaction factors, as well as social-awareness factors, into the DIRL pipeline to learn a reward function from human demonstrations. Moreover, we propose a novel trajectory ranking score using the sudden velocity change of pedestrians around the robot to address the sub-optimality in human demonstrations. Our evaluation shows that this method can successfully make a robot navigate in a crowded social environment and outperforms the state-of-art social navigation methods in terms of the success rate, navigation time, and invasion rate.",
        "primary_area": "",
        "author": "Yifan Xu;Theodor Chakhachiro;Tribhi Kathuria;Maani Ghaffari;Yifan Xu;Theodor Chakhachiro;Tribhi Kathuria;Maani Ghaffari",
        "authorids": "/37089549968;/37088946398;/37086183739;/37087056400;/37089549968;/37088946398;/37086183739;/37087056400",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160536/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3230747161817773015&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160988",
        "title": "Socially Fair Coverage Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate and develop algorithms for social fairness in coverage control problems. Existing coverage control methods are efficient, optimizing the average expected distance from any event to the nearest robot. However, in societal applications like disaster response or transportation, these conventional objectives lead to disparate coverage costs with respect to different groups within a population. We formulate social fairness for coverage control as the minimization of the maximum coverage cost among a set of groups within a population. Our approach uses Voronoi iteration to solve this novel problem by approximating the non-differentiable objective with the log-sum-exp and defining a gradient based controller that prioritizes fairness while also optimizing average performance when disparities between groups are low. We show convergence properties of this proposed control law and demonstrate the approach in simulations of randomly generated population densities as well as environments generated from U.S. census data on population rates and demographics. Our approach provides greater fairness than existing methods while maintaining similar computational time and convergence properties.",
        "primary_area": "",
        "author": "Matthew Malencia;George Pappas;Vijay Kumar;Matthew Malencia;George Pappas;Vijay Kumar",
        "authorids": "/37088506525;/37281547100;/37280341400;/37088506525;/37281547100;/37280341400",
        "aff": "GRASP Laboratory, Levine Hall 4th floor, Uni-versity of Pennsylvania, Philadelphia, PA; GRASP Laboratory, Levine Hall 4th floor, Uni-versity of Pennsylvania, Philadelphia, PA; GRASP Laboratory, Levine Hall 4th floor, Uni-versity of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160988/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17364105058754614162&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161344",
        "title": "Soft Sensing Skins for Arbitrary Objects: An Automatic Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensors are becoming more prevalent in numerous research domains, including robotics, human-robot interaction, and grasping. As the development of customized soft tactile skin for various applications continues to gain momentum, there is an increasing demand for the automation of design and manufacturing processes based on user specifications. Our work presents a partially automated framework for designing and customizing silicone-based skin-like sensors for objects of arbitrary shapes. We assess the performance of stretch and contact sensors featuring custom patterns on complex surfaces, subjecting them to position control, grasping, and manipulation scenarios. Our study's findings demonstrate the feasibility of fabricating skin-like sensors effectively within a semi-automated framework, with potential applications in the aforementioned research domains.",
        "primary_area": "",
        "author": "Sonja Gro\u00df;Diego Hidalgo-Carvajal;Silija Breimann;Nicolai Stein;Amartya Ganguly;Abdeldjallil Naceri;Sami Haddadin;Sonja Gro\u00df;Diego Hidalgo-Carvajal;Silija Breimann;Nicolai Stein;Amartya Ganguly;Abdeldjallil Naceri;Sami Haddadin",
        "authorids": "/37089895682;/37089475417;/37089895967;/37089896085;/37088234990;/37546043900;/37542865300;/37089895682;/37089475417;/37089895967;/37089896085;/37088234990;/37546043900;/37542865300",
        "aff": "Centre for Tactile Internet with Human-in-the-Loop (CeTI), Germany; Centre for Tactile Internet with Human-in-the-Loop (CeTI), Germany; Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany; Centre for Tactile Internet with Human-in-the-Loop (CeTI), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161344/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12557958149194192966&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;1;0",
        "aff_unique_norm": "Centre for Tactile Internet with Human-in-the-Loop;Technical University of Munich",
        "aff_unique_dep": ";Chair of Robotics and Systems Intelligence",
        "aff_unique_url": ";https://www.tum.de",
        "aff_unique_abbr": "CeTI;TUM",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161074",
        "title": "SonicFinger: Pre-touch and Contact Detection Tactile Sensor for Reactive Pregrasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot end effectors with proximity detection and contact sensing capabilities can reactively position the gripper to align objects and ensure successful grasps. In this paper, we introduce SonicFinger, an acoustic aura based sensing system capable of full-surface pre-touch and contact sensing. A single piezoelectric transducer embedded within a novel 3D printed finger is excited using a monotone to create an acoustic aura encompassing the finger; this enables pre-touch sensing and gripper alignment, while changes in finger-transducer acoustic coupling indicate contact. SonicFinger is low-cost, compact, and easy to manufacture and assemble. Sensing capabilities are evaluated using a set of objects with various physical properties such as optical reflectivity, dielectric constants, mechanical properties, and acoustic absorption. A dataset with over 8,000 proximity and contact events is collected. Our system shows a pre-touch detection true positive rate (TPR) of 92.4% and a true negative rate (TNR) of 95.3%. Contact detection experiments show a TPR of 93.7% and a TNR of 98.7%. Furthermore, pretouch detection information from Sonic Finger is used to adjust the robot grippers pose to align a target object at the center of both fingers.",
        "primary_area": "",
        "author": "Siddharth Rupavatharam;Caleb Escobedo;Daewon Lee;Colin Prepscius;Larry Jackel;Richard Howard;Volkan Isler;Siddharth Rupavatharam;Caleb Escobedo;Daewon Lee;Colin Prepscius;Larry Jackel;Richard Howard;Volkan Isler",
        "authorids": "/37086478326;/37089195404;/37599980600;/37088686982;/37089466321;/37089405964;/37298487800;/37086478326;/37089195404;/37599980600;/37088686982;/37089466321;/37089405964;/37298487800",
        "aff": "Samsung AI Center New York, NY; Samsung AI Center New York, NY; Samsung AI Center New York, NY; Samsung AI Center New York, NY; Samsung AI Center New York, NY; Samsung AI Center New York, NY; Samsung AI Center New York, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161074/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13556290314424583609&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Samsung AI Center",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "Samsung AI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160461",
        "title": "Sonicverse: A Multisensory Simulation Platform for Embodied Household Agents that See and Hear",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing embodied agents in simulation has been a key research topic in recent years. Exciting new tasks, algorithms, and benchmarks have been developed in various simulators. However, most of them assume deaf agents in silent environments, while we humans perceive the world with multiple senses. We introduce Sonicverse, a multisensory simulation platform with integrated audio-visual simulation for training household agents that can both see and hear. Sonicverse models realistic continuous audio rendering in 3D environments in real-time. Together with a new audio-visual VR interface that allows humans to interact with agents with audio, Sonicverse enables a series of embodied AI tasks that need audio-visual perception. For semantic audio-visual navigation in particular, we also propose a new multi-task learning model that achieves state-of-the-art performance. In addition, we demonstrate Sonicverse's realism via sim-to-real transfer, which has not been achieved by other simulators: an agent trained in Sonicverse can successfully perform audio-visual navigation in real-world environments. Sonicverse is available at: https://github.com/StanfordVL/Sonicverse.",
        "primary_area": "",
        "author": "Ruohan Gao;Hao Li;Gokul Dharan;Zhuzhu Wang;Chengshu Li;Fei Xia;Silvio Savarese;Li Fei-Fei;Jiajun Wu;Ruohan Gao;Hao Li;Gokul Dharan;Zhuzhu Wang;Chengshu Li;Fei Xia;Silvio Savarese;Li Fei-Fei;Jiajun Wu",
        "authorids": "/37087234277;/37089894471;/37089893414;/37089895310;/37087318952;/37086564490;/37298502600;/38273560700;/37085659126;/37087234277;/37089894471;/37089893414;/37089895310;/37087318952;/37086564490;/37298502600;/38273560700;/37085659126",
        "aff": "Stanford University; Stanford University; Stanford University; Stanford University; Stanford University; Stanford University; Stanford University; Stanford University; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160461/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=701386277381549760&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161341",
        "title": "Source-free Unsupervised Domain Adaptation for 3D Object Detection in Adverse Weather",
        "track": "main",
        "status": "Poster",
        "abstract": "A domain shift exists between the distributions of large scale, outdoor lidar datasets due to being captured using different types of lidar sensors, in different locations, and under varying weather conditions. Inclement weather in particular affects the quality of lidar data, adding artifacts such as scattered and missed points, leading to a drop in performance of 3D object detection networks trained on standard lidar datasets. Domain adaptation methods seek to adapt source-trained neural networks to a target domain. Pseudo-label based self training approaches are popular methods for source-free unsupervised domain adaptation. However, their efficacy depends on the quality of the labels generated by the source trained model. These labels may be incorrect with high confidence, rendering thresholding methods ineffective. In order to avoid reinforcing errors caused by label noise, we propose an uncertainty-aware mean teacher framework which implicitly filters incorrect pseudo-labels during training. Leveraging model uncertainty allows the mean teacher network to perform implicit filtering by down-weighing losses corresponding to uncertain pseudo-labels. Effectively, we perform automatic soft-sampling of pseudo-labeled data while aligning predictions from the student and teacher networks. We demonstrate our domain adaptation method on an adverse weather dataset created by augmenting lidar scenes from KITTI with rain, snow, and fog and show that it out-performs current domain adaptation frameworks. We make our code publicly available 11https://github.com/deeptibhegde/UncertaintyAwareMeanTeacher.",
        "primary_area": "",
        "author": "Deepti Hegde;Velat Kilic;Vishwanath Sindagi;A Brinton Cooper;Mark Foster;Vishal M Patel;Deepti Hegde;Velat Kilic;Vishwanath Sindagi;A Brinton Cooper;Mark Foster;Vishal M Patel",
        "authorids": "/37089892112;/37086874014;/37085595649;/38232219900;/37267753800;/37391395200;/37089892112;/37086874014;/37085595649;/38232219900;/37267753800;/37391395200",
        "aff": "Johns Hopkins University, United States; Johns Hopkins University, United States; Johns Hopkins University, United States; Johns Hopkins University, United States; Johns Hopkins University, United States; Johns Hopkins University, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161341/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15152098937042722440&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161216",
        "title": "Spatial-Temporal-Aware Safe Multi-Agent Reinforcement Learning of Connected Autonomous Vehicles in Challenging Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Communication technologies enable coordination among connected and autonomous vehicles (CAVs). However, it remains unclear how to utilize shared information to improve the safety and efficiency of the CAV system in dynamic and complicated driving scenarios. In this work, we propose a framework of constrained multi-agent reinforcement learning (MARL) with a parallel Safety Shield for CAVs in challenging driving scenarios that includes unconnected hazard vehicles. The coordination mechanisms of the proposed MARL include information sharing and cooperative policy learning, with Graph Convolutional Network (GCN)-Transformer as a spatial-temporal encoder that enhances the agent's environment awareness. The Safety Shield module with Control Barrier Functions (CBF)-based safety checking protects the agents from taking unsafe actions. We design a constrained multi-agent advantage actor-critic (CMAA2C) algorithm to train safe and cooperative policies for CAVs. With the experiment deployed in the CARLA simulator, we verify the performance of the safety checking, spatial-temporal encoder, and coordination mechanisms designed in our method by comparative experiments in several challenging scenarios with unconnected hazard vehicles. Results show that our proposed methodology significantly increases system safety and efficiency in challenging scenarios.",
        "primary_area": "",
        "author": "Zhili Zhang;Songyang Han;Jiangwei Wang;Fei Miao;Zhili Zhang;Songyang Han;Jiangwei Wang;Fei Miao",
        "authorids": "/37089831818;/37088333832;/37088601466;/37072758500;/37089831818;/37088333832;/37088601466;/37072758500",
        "aff": "Department of Computer Science and Engineering; Department of Computer Science and Engineering; Department of Electrical and Computer Engineering, University of Connecticut, Storrs Mansfield, CT, USA; Department of Computer Science and Engineering",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161216/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10166447413169382199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, San Diego;University of Connecticut",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://cse.ucsd.edu;https://www.uconn.edu",
        "aff_unique_abbr": "UCSD CSE;UConn",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Storrs Mansfield",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160920",
        "title": "Speeding Up Assembly Sequence Planning Through Learning Removability Probabilities",
        "track": "main",
        "status": "Poster",
        "abstract": "Industry 4.0 facilitates a high number of product variants, posing significant challenges for modern manufacturing. One of them is the automatic creation of assembly sequences. This can be achieved with the assembly-by-disassembly (AbD) approach, which is currently highly inefficient. We aim at speeding up AbD by leveraging deep learning. AbD relies on iteratively testing parts for removal, which makes the order in which parts are tested highly relevant for its run-time. We optimize this order by training a graph neural network (GNN) based on the shape of parts and the shape of local part connections. For each part, it predicts a removability probability. We use these probabilities to optimize the order in which parts are tested for removal. This reduces the number of parts tested by approximately 64%-90%, depending on the tested product. Further improvements are achieved by combining our approach with bookkeeping, another approach for speeding up AbD. Finally, we separately analyze the impact of the parts and their connections on the removability probabilities predicted by the GNN. We found that most of the important information regarding a part's removability can be derived from its connections alone.",
        "primary_area": "",
        "author": "Alexander Cebulla;Tamim Asfour;Torsten Kr\u00f6ger;Alexander Cebulla;Tamim Asfour;Torsten Kr\u00f6ger",
        "authorids": "/37089817208;/37295529100;/37283223400;/37089817208;/37295529100;/37283223400",
        "aff": "Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics Lab (IAR-IPR), Karlsruhe Institute of Technology (KIT); Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics Lab (IAR-IPR), Karlsruhe Institute of Technology (KIT); Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics Lab (IAR-IPR), Karlsruhe Institute of Technology (KIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160920/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4216946413208258045&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160412",
        "title": "SphNet: A Spherical Network for Semantic Pointcloud Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic segmentation for robotic systems can enable a wide range of applications, from self-driving cars and augmented reality systems to domestic robots. We argue that a spherical representation is a natural one for egocentric pointclouds. Thus, in this work, we present a novel framework exploiting such a representation of LiDAR pointclouds for the task of semantic segmentation. Our approach is based on a spherical convolutional neural network that can seamlessly handle observations from various sensor systems (e.g., different LiDAR systems) and provides an accurate segmentation of the environment. We operate in two distinct stages: First, we encode the projected input pointclouds to spherical features. Second, we decode and back-project the spherical features to achieve an accurate semantic segmentation of the pointcloud. We evaluate our method with respect to state-of-the-art projection-based semantic segmentation approaches using well-known public datasets. We demonstrate that the spherical representation enables us to provide more accurate segmentation and to have a better generalization to sensors with different field-of-view and number of beams than what was seen during training.",
        "primary_area": "",
        "author": "Lukas Bernreiter;Lionel Ott;Roland Siegwart;Cesar Cadena;Lukas Bernreiter;Lionel Ott;Roland Siegwart;Cesar Cadena",
        "authorids": "/37086451179;/38251784400;/37281398300;/37593590400;/37086451179;/38251784400;/37281398300;/37593590400",
        "aff": "Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160412/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13519055847866690325&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161346",
        "title": "Spherical Cubic Blends: $\\mathcal{C}^{2}$-Continuous, Zero-Clamped, and Time-Optimized Interpolation of Quaternions",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern collaborative robotic applications require robot motions that are predictable for human coworkers. Therefore, trajectories often need to be planned in task space rather than configuration space (\\mathcal{C}\\mathcal{C}-space). While the interpolation of translations in Euclidean space is straightforward, the interpolation of rotations in SO(3)SO(3) is more complex. Most approaches originating from computer graphics do not exhibit the often desired \\mathcal{C}^{2}\\mathcal{C}^{2}-continuity in robotics. Our main contribution is a \\mathcal{C}^{2}\\mathcal{C}^{2}-continuous, zero-clamped interpolation scheme for quaternions that computes a fast synchronized motion given a set of waypoints. As a second contribution, we present modifications to two state-of-the-art quaternion interpolation schemes, Spherical Quadrangle Interpolation (SQUAD) and Spherical Parabolic Blends (SPB), to enable them to compute \\mathcal{C}^{2}\\mathcal{C}^{2}-continuous, zero-clamped trajectories. In experiments, we demonstrate that for the time optimization of trajectories, our approach is computationally efficient and at the same time computes smooth trajectory profiles.",
        "primary_area": "",
        "author": "Jonas Wittmann;Lukas Cha;Marco Kappertz;Philipp Seiwald;Daniel J. Rixen;Jonas Wittmann;Lukas Cha;Marco Kappertz;Philipp Seiwald;Daniel J. Rixen",
        "authorids": "/37088531141;/37089893249;/37089892563;/37086126925;/37393325300;/37088531141;/37089893249;/37089892563;/37086126925;/37393325300",
        "aff": "Department of Mechanical Engineering, Technical University of Munich, TUM School of Engineering and Design, Munich Institute of Robotics and Machine Intelligence (MIRMI), Garching, Germany; Department of Mechanical Engineering, Technical University of Munich, TUM School of Engineering and Design, Munich Institute of Robotics and Machine Intelligence (MIRMI), Garching, Germany; Department of Mechanical Engineering, Technical University of Munich, TUM School of Engineering and Design, Munich Institute of Robotics and Machine Intelligence (MIRMI), Garching, Germany; Department of Mechanical Engineering, Technical University of Munich, TUM School of Engineering and Design, Munich Institute of Robotics and Machine Intelligence (MIRMI), Garching, Germany; Department of Mechanical Engineering, Technical University of Munich, TUM School of Engineering and Design, Munich Institute of Robotics and Machine Intelligence (MIRMI), Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161346/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12890308344362053933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161172",
        "title": "Stable Contact Guaranteeing Motion/Force Control for an Aerial Manipulator on an Arbitrarily Tilted Surface",
        "track": "main",
        "status": "Poster",
        "abstract": "This study aims to design a motion/force controller for an aerial manipulator which guarantees the tracking of time-varying motion/force trajectories as well as the stability during the transition between free and contact motions. To this end, we model the force exerted on the end-effector as the Kelvin-Voigt linear model and estimate its parameters by recursive least-squares estimator. Then, the gains of the disturbance-observer (DOB)-based motion/force controller are calculated based on the stability conditions considering both the model uncertainties in the dynamic equation and switching between the free and contact motions. To validate the proposed controller, we conducted the time-varying motion/force tracking experiments with different approach speeds and orientations of the surface. The results show that our controller enables the aerial manipulator to track the time-varying motion/force trajectories.",
        "primary_area": "",
        "author": "Jeonghyun Byun;Byeongjun Kim;Changhyeon Kim;Donggeon David Oh;H. Jin Kim;Jeonghyun Byun;Byeongjun Kim;Changhyeon Kim;Donggeon David Oh;H. Jin Kim",
        "authorids": "/37089194964;/37089895267;/37086041943;/37089680346;/37599626400;/37089194964;/37089895267;/37086041943;/37089680346;/37599626400",
        "aff": "Department of Aerospace Engineering, Automation and System Research Institute(ASRI) and Institute of Advanced Aerospace Technology(IAAT), Seoul National University, Seoul, South Korea; Department of Aerospace Engineering, Automation and System Research Institute(ASRI) and Institute of Advanced Aerospace Technology(IAAT), Seoul National University, Seoul, South Korea; Department of Aerospace Engineering, Automation and System Research Institute(ASRI) and Institute of Advanced Aerospace Technology(IAAT), Seoul National University, Seoul, South Korea; Department of Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Aerospace Engineering, Automation and System Research Institute(ASRI) and Institute of Advanced Aerospace Technology(IAAT), Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161172/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12836669476045641187&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161437",
        "title": "Stable Station Keeping of Autonomous Sailing Robots via the Switched Systems Approach for Ocean Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "Ocean observation is an emerging field, and sailing robots have several promising features (e.g., long-range sailing, environmental friendliness, energy-saving and low-noise) to perform tasks. In this paper, we define an ocean observation mission in a restricted target area as a station keeping problem. Inspired by an orientation-restricted Dubins path method, the robot keeps sailing and collecting data in a smooth reciprocation, where the trajectories consist of sailing against wind segments and turning downwind parts divided by a goal area and an acceptable area. The upwind sailing segments are of interest for data acquisition. However, the system stability can not be guaranteed during the whole reciprocation especially for sailing outside the goal area. Hereby, we refer to a switched systems approach and propose a desired heading generation scheme to realize safe and stable control in both areas. The stability for subsystems is proved with Lyapunov-like functions. The stable station keeping scheme is verified in both simulation and real experiments. Finally, we completed continuous and effective observation within 50 minutes in the goal area with a radius of 50 meters by a catamaran robot named OceanVoy460.",
        "primary_area": "",
        "author": "Weimin Qi;Qinbo Sun;Yu Cao;Huihuan Qian;Weimin Qi;Qinbo Sun;Yu Cao;Huihuan Qian",
        "authorids": "/37087243921;/37086608896;/37089893318;/37549401900;/37087243921;/37086608896;/37089893318;/37549401900",
        "aff": "Shenzhen Institute of Artificial Intelligent and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligent and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Huawei Technologies Co., Ltd, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligent and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161437/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15701125805455327577&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "The Chinese University of Hong Kong;Huawei Technologies Co., Ltd",
        "aff_unique_dep": "Shenzhen Institute of Artificial Intelligent and Robotics for Society;",
        "aff_unique_url": "https://www.cuhk.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "CUHK;Huawei",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160875",
        "title": "Stackelberg Games for Learning Emergent Behaviors During Competitive Autocurricula",
        "track": "main",
        "status": "Poster",
        "abstract": "Autocurricular training is an important sub-area of multi-agent reinforcement learning (MARL) that allows multiple agents to learn emergent skills in an unsupervised co-evolving scheme. The robotics community has experimented auto-curricular training with physically grounded problems, such as robust control and interactive manipulation tasks. However, the asymmetric nature of these tasks makes the generation of sophisticated policies challenging. Indeed, the asymmetry in the environment may implicitly or explicitly provide an advantage to a subset of agents which could, in turn, lead to a low-quality equilibrium. This paper proposes a novel game-theoretic algorithm, Stackelberg Multi-Agent Deep Deterministic Policy Gradient (ST-MADDPG), which formulates a two-player MARL problem as a Stackelberg game with one player as the \u2018leader\u2019 and the other as the \u2018follower\u2019 in a hierarchical interaction structure wherein the leader has an advantage. We first demonstrate that the leader's advantage from ST-MADDPG can be used to alleviate the inherent asymmetry in the environment. By exploiting the leader's advantage, ST-MADDPG improves the quality of a co-evolution process and results in more sophisticated and complex strategies that work well even against an unseen strong opponent.",
        "primary_area": "",
        "author": "Boling Yang;Liyuan Zheng;Lillian J. Ratliff;Byron Boots;Joshua R. Smith;Boling Yang;Liyuan Zheng;Lillian J. Ratliff;Byron Boots;Joshua R. Smith",
        "authorids": "/37086136690;/37086425353;/37072945600;/37085459219;/37290693300;/37086136690;/37086425353;/37072945600;/37085459219;/37290693300",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; Electrical and Computer Engineering Department, University of Washington; Electrical and Computer Engineering Department, University of Washington; Paul G. Allen School of Computer Science & Engineering, University of Washington; Electrical and Computer Engineering Department, University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160875/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3715511067456317205&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Paul G. Allen School of Computer Science & Engineering",
        "aff_unique_url": "https://www.cs.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160978",
        "title": "Start State Selection for Control Policy Learning from Optimal Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "Combination of optimal control methods and machine learning approaches allows to profit from complementary benefits of each field in control of robotic systems. Data from optimal trajectories provides valuable information that can be used to learn a near-optimal state-dependent feedback control policy. To obtain high-quality learning data, careful selection of optimal trajectories, determined by a set of start states, is essential to achieve a good learning performance. In this paper, we extend previous work with new comple-menting strategies to generate start points. These methods complement the existing approach, as they introduce new criteria to identify relevant regions in joint state space that need coverage by new trajectories. It is demonstrated that the extensions significantly improve the overall performance of the previous method in simulation on full nonlinear dynamics model of the industrial Manutec r3 robot arm. Further, it is demonstrated that it suffices to learn a policy that reaches the proximity of the goal state, from where a PI controller can be used for stable control reaching the final system state.",
        "primary_area": "",
        "author": "Christoph Zelch;Jan Peters;Oskar von Stryk;Christoph Zelch;Jan Peters;Oskar von Stryk",
        "authorids": "/37088507215;/37533077600;/37293900600;/37088507215;/37533077600;/37293900600",
        "aff": "Department of Computer Science TU Darmstadt, Simulation, Systems, Optimization and Robotics Group, Darmstadt, Germany; Department of Computer Science, Intelligent Autonomous Systems Group, TU Darmstadt, Darmstadt, Germany; Department of Computer Science TU Darmstadt, Simulation, Systems, Optimization and Robotics Group, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160978/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11268886443009278634&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TU Darmstadt",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Darmstadt",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161001",
        "title": "Statistical Safety and Robustness Guarantees for Feedback Motion Planning of Unknown Underactuated Stochastic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for providing statistical guarantees on runtime safety and goal reachability for integrated planning and control of a class of systems with unknown nonlinear stochastic underactuated dynamics. Specifically, given a dynamics dataset, our method jointly learns a mean dynamics model, a spatially-varying disturbance bound that captures the effect of noise and model mismatch, and a feedback controller based on contraction theory that stabilizes the learned dynamics. We propose a sampling-based planner that uses the mean dynamics model and simultaneously bounds the closed-loop tracking error via a learned disturbance bound. We employ techniques from Extreme Value Theory (EVT) to estimate, to a specified level of confidence, several constants which characterize the learned components and govern the size of the tracking error bound. This ensures plans are guaranteed to be safely tracked at runtime. We validate that our guarantees translate to empirical safety in simulation on a 10D quadrotor, and in the real world on a physical CrazyFlie quadrotor and Clearpath Jackal robot, whereas baselines that ignore the model error and stochasticity are unsafe.",
        "primary_area": "",
        "author": "Craig Knuth;Glen Chou;Jamie Reese;Joseph Moore;Craig Knuth;Glen Chou;Jamie Reese;Joseph Moore",
        "authorids": "/37088851710;/37086482625;/37089893669;/37086037338;/37088851710;/37086482625;/37089893669;/37086037338",
        "aff": "Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA; University of Michigann, Ann Arbor, MI, USA; Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161001/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15241597499209907878&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Johns Hopkins University;University of Michigan",
        "aff_unique_dep": "Applied Physics Laboratory;",
        "aff_unique_url": "https://www.jhuapl.edu;https://www.umich.edu",
        "aff_unique_abbr": "JHU APL;UM",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Laurel;Ann Arbor;Baltimore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160709",
        "title": "Statistical shape representations for temporal registration of plant components in 3D",
        "track": "main",
        "status": "Poster",
        "abstract": "Plants are dynamic organisms and understanding temporal variations in vegetation is an essential problem for robots in the wild. However, associating repeated 3D scans of plants across time is challenging. A key step in this process is re-identifying and tracking the same individual plant components over time. Previously, this has been achieved by comparing their global spatial or topological location. In this work, we demonstrate how using shape features improves temporal organ matching. We present a landmark-free shape compression algorithm, which allows for the extraction of 3D shape features of leaves, characterises leaf shape and curvature efficiently in few parameters, and makes the association of individual leaves in feature space possible. The approach combines 3D contour extraction and further compression using Principal Component Analysis (PCA) to produce a shape space encoding, which is entirely learned from data and retains information about edge contours and 3D curvature. Our evaluation on temporal scan sequences of tomato plants shows, that incorporating shape features improves temporal leaf-matching. A combination of shape, location, and rotation information proves most informative for recognition of leaves over time and yields a true positive rate of 75%, a 15% improvement on sate-of-the-art methods. This is essential for robotic crop monitoring, which enables whole-of-lifecycle phenotyping.",
        "primary_area": "",
        "author": "Karoline Heiwolt;Cengiz \u00d6ztireli;Grzegorz Cielniak;Karoline Heiwolt;Cengiz \u00d6ztireli;Grzegorz Cielniak",
        "authorids": "/37086921532;/37085690751;/37550177700;/37086921532;/37085690751;/37550177700",
        "aff": "Lincoln Centre for Autonomous Systems, University of Lincoln, Lincoln, United Kingdom; Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom; Lincoln Centre for Autonomous Systems, University of Lincoln, Lincoln, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160709/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4196623532147935588&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Lincoln;University of Cambridge",
        "aff_unique_dep": "Lincoln Centre for Autonomous Systems;Department of Computer Science and Technology",
        "aff_unique_url": "https://www.lincoln.ac.uk;https://www.cam.ac.uk",
        "aff_unique_abbr": ";Cambridge",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Lincoln;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160900",
        "title": "Stealthy Perception-based Attacks on Unmanned Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we study vulnerability of unmanned aerial vehicles (UAVs) to stealthy attacks on perception-based control. To guide our analysis, we consider two specific missions: (ii) ground vehicle tracking (GVT), and (ii) vertical take-off and landing (VTOL) of a quadcopter on a moving ground vehicle. Specifically, we introduce a method to consistently attack both the sensors measurements and camera images over time, in order to cause control performance degradation (e.g., by failing the mission) while remaining stealthy (i.e., undetected by the deployed anomaly detector). Unlike existing attacks that mainly rely on vulnerability of deep neural networks to small input perturbations (e.g., by adding small patches and/or noise to the images), we show that stealthy yet effective attacks can be designed by changing images of the ground vehicle's landing markers as well as suitably falsifying sensing data. We illustrate the effectiveness of our attacks in Gazebo 3D robotics simulator.",
        "primary_area": "",
        "author": "Amir Khazraei;Haocheng Meng;Miroslav Pajic;Amir Khazraei;Haocheng Meng;Miroslav Pajic",
        "authorids": "/37086157289;/37089892333;/37294788600;/37086157289;/37089892333;/37294788600",
        "aff": "Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160900/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16242210676595840641&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160780",
        "title": "StereoPose: Category-Level 6D Transparent Object Pose Estimation from Stereo Images via Back-View NOCS",
        "track": "main",
        "status": "Poster",
        "abstract": "Most existing methods for category-level pose estimation rely on object point clouds. However, when considering transparent objects, depth cameras are usually not able to capture high-quality data, resulting in point clouds with severe artifacts. Without a complete point cloud, existing methods are not applicable to challenging transparent objects. To tackle this problem, we present StereoPose, a novel stereo image based framework for category-level object pose estimation, ideally suited for transparent objects. For a robust estimation from pure stereo images, we develop a pipeline that decouples category-level pose estimation into object size estimation, initial pose estimation, and pose refinement. StereoPose then estimates object pose based on representation in the normalized object coordinate space (NOCS). To address the issue of image content aliasing, we further define a back-view NOCS map for the transparent object. The back-view NOCS aims to reduce the network learning ambiguity caused by content aliasing, and leverage informative cues on the back of the transparent object for more accurate pose estimation. To further improve the performance of the stereo framework, StereoPose is equipped with a parallax attention module for stereo feature fusion and an epipolar loss for improving the stereo-view consistency of network predictions. Extensive experiments on the public TOD dataset demonstrate the superiority of the proposed StereoPose framework for category-level 6D transparent object pose estimation. Code and demos will be available on the project homepage: www.cse.cuhk.edu.hk/~kaichen/stereopose.html.",
        "primary_area": "",
        "author": "Kai Chen;Stephen James;Congying Sui;Yun-Hui Liu;Pieter Abbeel;Qi Dou;Kai Chen;Stephen James;Congying Sui;Yun-Hui Liu;Pieter Abbeel;Qi Dou",
        "authorids": "/37404002500;/37089815931;/37086578213;/37279412600;/37542877900;/37085465414;/37404002500;/37089815931;/37086578213;/37279412600;/37542877900;/37085465414",
        "aff": "The Chinese University of Hong Kong; Dyson Robot Learning Lab.; Hong Kong Centre for Logistics Robotics; The Chinese University of Hong Kong; University of California, Berkeley; The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160780/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17237261398295737960&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;0",
        "aff_unique_norm": "The Chinese University of Hong Kong;Dyson;Hong Kong Centre for Logistics Robotics;University of California, Berkeley",
        "aff_unique_dep": ";Robot Learning Lab;Centre for Logistics Robotics;",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.dyson.com;;https://www.berkeley.edu",
        "aff_unique_abbr": "CUHK;Dyson;;UC Berkeley",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "Hong Kong SAR;;Berkeley",
        "aff_country_unique_index": "0;1;0;0;2;0",
        "aff_country_unique": "China;United Kingdom;United States"
    },
    {
        "id": "10160441",
        "title": "StereoVAE: A lightweight stereo-matching system using embedded GPUs",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a lightweight system for stereo-matching using embedded graphic processing units (GPUs). The proposed system overcomes the trade-off between accuracy and processing speed in stereo matching, thus further improving the matching accuracy while ensuring real-time processing. The basic idea is to construct a tiny neural network based on a variational autoencoder (VAE) to achieve the upscaling and refinement a small size of coarse disparity map. This map is initially generated using a traditional matching method. The proposed hybrid structure maintains the advantage of low computational complexity found in traditional methods. Additionally, it achieves matching accuracy with the help of a neural network. Extensive experiments on the KITTI 2015 benchmark dataset demonstrate that our tiny system exhibits high robustness in improving the accuracy of coarse disparity maps generated by different algorithms, while running in real-time on embedded GPUs.",
        "primary_area": "",
        "author": "Qiong Chang;Xiang Li;Xin Xu;Xin Liu;Yun Li;Jun Miyazaki;Qiong Chang;Xiang Li;Xin Xu;Xin Liu;Yun Li;Jun Miyazaki",
        "authorids": "/37086434274;/37089892704;/37089893980;/37086305539;/38467214600;/37374174800;/37086434274;/37089892704;/37089893980;/37086305539;/38467214600;/37374174800",
        "aff": "School of Computing, Tokyo Institute of Technology, Tokyo, Japan; School of Electronic Science & Engineering, Nanjing University, Nanjing, China; School of Electronic Science & Engineering, Nanjing University, Nanjing, China; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; School of Electronic Science & Engineering, Nanjing University, Nanjing, China; School of Computing, Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160441/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2222981716997924883&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;1;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Nanjing University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "School of Computing;School of Electronic Science & Engineering;Artificial Intelligence Research Center",
        "aff_unique_url": "https://www.titech.ac.jp;http://www.nju.edu.cn;https://www.aist.go.jp",
        "aff_unique_abbr": "Titech;Nanjing U;AIST",
        "aff_campus_unique_index": "0;1;1;0;1;0",
        "aff_campus_unique": "Tokyo;Nanjing",
        "aff_country_unique_index": "0;1;1;0;1;0",
        "aff_country_unique": "Japan;China"
    },
    {
        "id": "10160924",
        "title": "StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels from a Stereo Camera Using Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Obstacle detection is a safety-critical problem in robot navigation, where stereo matching is a popular vision-based approach. While deep neural networks have shown impressive results in computer vision, most of the previous obstacle detection works only leverage traditional stereo matching techniques to meet the computational constraints for real-time feedback. This paper proposes a computationally efficient method that employs a deep neural network to detect occupancy from stereo images directly. Instead of learning the point cloud correspondence from the stereo data, our approach extracts the compact obstacle distribution based on volumetric representations. In addition, we prune the computation of safety irrelevant spaces in a coarse-to-fine manner based on octrees generated by the decoder. As a result, we achieve real-time performance on the onboard computer (NVIDIA Jetson TX2). Our approach detects obstacles accurately in the range of 32 meters and achieves better IoU (Intersection over Union) and CD (Chamfer Distance) scores with only 2% of the computation cost of the state-of-the-art stereo model. Furthermore, we validate our method's robustness and real-world feasibility through autonomous navigation experiments with a real robot. Hence, our work contributes toward closing the gap between the stereo-based system in robot perception and state-of-the-art stereo models in computer vision. To counter the scarcity of high-quality real-world indoor stereo datasets, we collect a 1.36 hours stereo dataset with a mobile robot which is used to fine-tune our model. The dataset, the code, and further details including additional visualizations are available at https://lhy.xyz/stereovoxelnet/.",
        "primary_area": "",
        "author": "Hongyu Li;Zhengang Li;Ne\u015fet \u00dcnver Akmandor;Huaizu Jiang;Yanzhi Wang;Ta\u015fk\u0131n Pad\u0131r;Hongyu Li;Zhengang Li;Ne\u015fet \u00dcnver Akmandor;Huaizu Jiang;Yanzhi Wang;Ta\u015fk\u0131n Pad\u0131r",
        "authorids": "/37089621661;/37088389898;/37088594588;/37085553878;/37966617700;/38496444600;/37089621661;/37088389898;/37088594588;/37085553878;/37966617700;/38496444600",
        "aff": "Khoury College of Computer Sciences, Northeastern University; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Khoury College of Computer Sciences, Northeastern University; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160924/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16224651848932016719&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Khoury College of Computer Sciences",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Boston",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160894",
        "title": "Stochastic Planning for ASV Navigation Using Satellite Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous surface vessels (ASV) represent a promising technology to automate water-quality monitoring of lakes. In this work, we use satellite images as a coarse map and plan sampling routes for the robot. However, inconsistency between the satellite images and the actual lake, as well as environmental disturbances such as wind, aquatic vegetation, and changing water levels can make it difficult for robots to visit places suggested by the prior map. This paper presents a robust route-planning algorithm that minimizes the expected total travel distance given these environmental disturbances, which induce uncertainties in the map. We verify the efficacy of our algorithm in simulations of over a thousand Canadian lakes and demonstrate an application of our algorithm in a 3.7 km-long real-world robot experiment on a lake in Northern Ontario, Canada.",
        "primary_area": "",
        "author": "Yizhou Huang;Hamza Dugmag;Timothy D. Barfoot;Florian Shkurti;Yizhou Huang;Hamza Dugmag;Timothy D. Barfoot;Florian Shkurti",
        "authorids": "/37089894521;/37089893744;/37283734000;/37706697200;/37089894521;/37089893744;/37283734000;/37706697200",
        "aff": "Department of Computer Science, University of Toronto, Toronto, Canada; University of Toronto Institute for Aerospace Studies, Toronto, Canada; University of Toronto Institute for Aerospace Studies, Toronto, Canada; Department of Computer Science, University of Toronto, Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160894/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3088529339117038355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161409",
        "title": "Stochastic Robustness Interval for Motion Planning with Signal Temporal Logic",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a novel robustness measure for continuous-time stochastic trajectories with respect to Signal Temporal Logic (STL) specifications. We show the soundness of the measure and develop a monitor for reasoning about partial trajectories. Using this monitor, we introduce an STL sampling-based motion planning algorithm for robots under uncertainty. Given a minimum robustness requirement, this algorithm finds satisfying motion plans; alternatively, the algorithm also optimizes for the measure. We prove probabilistic completeness and asymptotic optimality of the motion planner with respect to the measure, and demonstrate the effectiveness of our approach on several case studies.",
        "primary_area": "",
        "author": "Roland B. Ilyes;Qi Heng Ho;Morteza Lahijanian;Roland B. Ilyes;Qi Heng Ho;Morteza Lahijanian",
        "authorids": "/37089678587;/37087321977;/37398443600;/37089678587;/37087321977;/37398443600",
        "aff": "Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161409/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18178445489651611868&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161120",
        "title": "Stochastic Traveling Salesperson Problem with Neighborhoods for Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a new route-finding problem which considers perception and travel costs simultaneously. Specifically, we consider the problem of finding the shortest tour such that all objects of interest can be detected successfully. To represent a viable detection region for each object, we propose to use an entropy-based viewing score that generates a diameter-bounded region as a viewing neighborhood. We formulate the detection-based trajectory planning problem as a stochastic traveling salesperson problem with neighborhoods and propose a center-visit method that obtains an approximation ratio of O(\\frac{D_{max}}{D_{min}})O(\\frac{D_{max}}{D_{min}}) for disjoint regions. For non-disjoint regions, our method -provides a novel finite detour in 3D, which utilizes the region's minimum curvature property. Finally, we show that our method can generate efficient trajectories compared to a baseline method in a photo-realistic simulation environment.",
        "primary_area": "",
        "author": "Cheng Peng;Minghan Wei;Volkan Isler;Cheng Peng;Minghan Wei;Volkan Isler",
        "authorids": "/37085820317;/37086455365;/37298487800;/37085820317;/37086455365;/37298487800",
        "aff": "Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, US; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, US; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, US",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161120/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:2H408Yd9oDcJ:scholar.google.com/&scioq=Stochastic+Traveling+Salesperson+Problem+with+Neighborhoods+for+Object+Detection&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160299",
        "title": "Strained Elastic Surfaces with Adjustable-Modulus Edges (SESAMEs) for Soft Robotic Actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "For robots to interact safely with humans and travel with minimal weight, low-density packable actuators are sought. Electronically-driven active materials like shape memory wire and other artificial muscle fibers offer solutions, but these materials need a restoring force. Moreover, if joint bending is required, the actuators must exert a bending moment around the joint. In this paper, we model the three-dimensional shapes of strained elastic surfaces with adjustable-modulus edges (SESAMEs), then implement SESAMEs by machine embroidering shape memory alloy wire onto stretched elastic fabric, showing a path to lightweight actuators that exert bending forces and have built-in restoring forces. SESAMEs start out planar, and upon release from the plane take on three-dimensional shapes thanks to the balance between bending energy in the boundary and strain energy in the elastic surface. The elastic creates both a restoring force to bring the boundary back to its original shape after actuation, and an out-of-plane structure for applying a bending moment. We demonstrate SESAMEs' properties as soft robotic actuators individually and in arrays, and coupled to flexible plastic frames during the planar fabrication process as bending actuators to switch bistable mechanical structures.",
        "primary_area": "",
        "author": "Christopher J. Kimmer;Michael Seokyoung Han;Cindy K. Harnett;Christopher J. Kimmer;Michael Seokyoung Han;Cindy K. Harnett",
        "authorids": "/37063303900;/37089836042;/37322827000;/37063303900;/37089836042;/37322827000",
        "aff": "Informatics, School of Natural Science, Indiana University Southeast, New Albany, IN, US; Department of Mechanical Engineering, University of Louisville, Louisville, KY, USA; Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160299/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5325226036153562630&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Indiana University Southeast;University of Louisville",
        "aff_unique_dep": "School of Natural Science;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ius.edu;https://www.louisville.edu",
        "aff_unique_abbr": "IUS;UofL",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "New Albany;Louisville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160358",
        "title": "Streaming LifeLong Learning With Any-Time Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Soumya Banerjee;Vinay Kumar Verma;Vinay P. Namboodiri;Soumya Banerjee;Vinay Kumar Verma;Vinay P. Namboodiri",
        "authorids": "/37089893806;/312464228661373;/37427828700;/37089893806;/312464228661373;/37427828700",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160358/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=258765475297546783&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "10161313",
        "title": "Structural Design and Frequency Tuning of Piezoelectric Energy Harvesters Based on Topology Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Vibrational piezoelectric energy harvesters (vPEH) are of great interest in several fields such as autonomous sensors and wireless sensor networks, bird tracking devices, or autonomous miniaturized robotic systems. They capture energy from mechanical vibrations available in the ambient environment and convert it into electrical one to power those systems. Basically, a vPEH is composed of three main parts: the transducer mechanical structure, an electronic interface and the storage unit. In this paper, we focus on the optimization of the mechanical structure of the harvester. To this end, an optimization framework based on topology optimization is proposed. It consists to combine the Solid Isotropic Material with Penalization (SIMP) approach and frequency tuning technique to further increase the efficiency of the harvesters. The fundamental frequency of the design is tuned by considering the mass of the attachment as an optimization variable in addition to the classical density and polarity variables. Two numerical examples, including a new piezoelectric energy harvester configuration, are investigated to demonstrate the effectiveness of the topology optimization framework.",
        "primary_area": "",
        "author": "Abbas Homayouni-Amlashi;Micky Rakotondrabe;Abdenbi Mohand-Ousaid;Abbas Homayouni-Amlashi;Micky Rakotondrabe;Abdenbi Mohand-Ousaid",
        "authorids": "/37087237408;/37296164300;/37085718337;/37087237408;/37296164300;/37085718337",
        "aff": "Universit\u00e9 de Franche-Comt\u00e9, SUPMICROTECH, CNRS, institut FEMTO-ST, Besan\u00e7on, France; LGP laboratory, National School of Engineering in Tarbes (ENIT-INPT), University of Toulouse, Tarbes, France; Universit\u00e9 de Franche-Comt\u00e9, SUPMICROTECH, CNRS, institut FEMTO-ST, Besan\u00e7on, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161313/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11314938183232062810&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universit\u00e9 de Franche-Comt\u00e9;University of Toulouse",
        "aff_unique_dep": "SUPMICROTECH;LGP laboratory",
        "aff_unique_url": ";https://www.univ-toulouse.fr",
        "aff_unique_abbr": ";UT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Besan\u00e7on;Tarbes",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160452",
        "title": "Structure PLP-SLAM: Efficient Sparse Mapping and Localization using Point, Line and Plane for Monocular, RGB-D and Stereo Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a visual SLAM system that uses both points and lines for robust camera localization, and simultaneously performs a piece-wise planar reconstruction (PPR) of the environment to provide a structural map in real-time. One of the biggest challenges in parallel tracking and mapping with a monocular camera is to keep the scale consistent when reconstructing the geometric primitives. This further introduces difficulties in graph optimization of the bundle adjustment (BA) step. We solve these problems by proposing several run-time optimizations on the reconstructed lines and planes. Our system is able to run with depth and stereo sensors in addition to the monocular setting. Our proposed SLAM tightly incorporates the semantic and geometric features to boost both frontend pose tracking and backend map optimization. We evaluate our system exhaustively on various datasets, and show that we outperform state-of-the-art methods in terms of trajectory precision. The code of PLP-SLAM has been made available in open-source for the research community (https://github.com/PeterFWS/Structure-PLP-SLAM).",
        "primary_area": "",
        "author": "Fangwen Shu;Jiaxuan Wang;Alain Pagani;Didier Stricker;Fangwen Shu;Jiaxuan Wang;Alain Pagani;Didier Stricker",
        "authorids": "/37088887024;/37089896142;/37398285300;/37326112700;/37088887024;/37089896142;/37398285300;/37326112700",
        "aff": "DFKI - German Research Center for Artificial Intelligence; DFKI - German Research Center for Artificial Intelligence; DFKI - German Research Center for Artificial Intelligence; DFKI - German Research Center for Artificial Intelligence",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160452/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1585175503512867447&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "German Research Center for Artificial Intelligence",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.dFKI.de",
        "aff_unique_abbr": "DFKI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161046",
        "title": "Structured Motion Generation with Predictive Learning: Proposing Subgoal for Long-Horizon Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "For assisting humans in their daily lives, robots need to perform long-horizon tasks, such as tidying up a room or preparing a meal. One effective strategy for handling a long-horizon task is to break it down into short-horizon subgoals, that the robot can execute sequentially. In this paper, we propose extending a predictive learning model using deep neural networks (DNN) with a Subgoal Proposal Module (SPM), with the goal of making such tasks realizable. We evaluate our proposed model in a case-study of a long-horizon task, consisting of cutting and arranging a pizza. This task requires the robot to consider: (1) the order of the subtasks, (2) multiple subtask selection, (3) coordination of dual-arm, and (4) variations within a subtask. The results confirm that the model is able to generalize motion generation to unseen tools and objects arrangement combinations. Furthermore, it significantly reduces the prediction error of the generated motions compared to without the proposed SPM. Finally, we validate the generated motions on the dual-arm robot Nextage Open. See our accompanying video here: https://youtu.be/3hYS2knRm50",
        "primary_area": "",
        "author": "Namiko Saito;Jo\u00e3o Moura;Tetsuya Ogata;Marina Y. Aoyama;Shingo Murata;Shigeki Sugano;Sethu Vijayakumar;Namiko Saito;Jo\u00e3o Moura;Tetsuya Ogata;Marina Y. Aoyama;Shingo Murata;Shigeki Sugano;Sethu Vijayakumar",
        "authorids": "/37086597961;/37086411872;/37273829100;/37089894839;/37085384128;/37274050800;/37295595500;/37086597961;/37086411872;/37273829100;/37089894839;/37085384128;/37274050800;/37295595500",
        "aff": "Department of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; The Alan Turing Institute, London, U.K.; the National Institute of Advanced Science and Technology, Tokyo, Japan; School of Informatics, The University of Edin-burgh, Edinburgh, U.K.; Department of Electronics and Electrical Engineering, Keio University, Kanagawa, Japan; Department of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; The Alan Turing Institute, London, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161046/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15215497589394603706&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;4;0;1",
        "aff_unique_norm": "Waseda University;The Alan Turing Institute;National Institute of Advanced Science and Technology;The University of Edinburgh;Keio University",
        "aff_unique_dep": "Department of Modern Mechanical Engineering;;;School of Informatics;Department of Electronics and Electrical Engineering",
        "aff_unique_url": "https://www.waseda.jp/top;https://www.turing.ac.uk;https://www.nict.go.jp/;https://www.ed.ac.uk;https://www.keio.ac.jp",
        "aff_unique_abbr": "Waseda;ATI;NICT;Edinburgh;Keio",
        "aff_campus_unique_index": "0;1;0;2;3;0;1",
        "aff_campus_unique": "Tokyo;London;Edinburgh;Kanagawa",
        "aff_country_unique_index": "0;1;0;1;0;0;1",
        "aff_country_unique": "Japan;United Kingdom"
    },
    {
        "id": "10161579",
        "title": "Supernumerary Robotic Limbs for Next Generation Space Suit Technology",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper discusses the incorporation of a pair of Supernumerary Robotic Limbs (SuperLimbs) onto the next generation of NASA space suits. The wearable robots attached to the space suit assist an astronaut in performing Extra-Vehicular Activities (EVAs). The SuperLimbs grab handrails fixed to the outside of a space vehicle to securely hold the astronaut body. The astronaut can use both hands for performing an EVA task, rather than using one hand for securing the body or operating a tether. The SuperLimbs can also assist an astronaut in repositioning the body and stabilizing it during an EVA mission. A control algorithm based on Admittance Control is developed for a) virtually reducing the inertial load of the entire body so that an astronaut can reposition his/her body with reduced effort, and b) bracing the body stably despite reaction forces and disturbances acting on the astronaut during an EVA operation. A full-scale prototype of Space Suit SuperLimbs was constructed and tested. Results from the experimentation indicated that with the aid of SuperLimbs, energy consumption during EVAs is reduced significantly.",
        "primary_area": "",
        "author": "Erik Ballesteros;Brandon Man;H. Harry Asada;Erik Ballesteros;Brandon Man;H. Harry Asada",
        "authorids": "/37089893136;/37089895734;/37279023100;/37089893136;/37089895734;/37279023100",
        "aff": "Department of Mechanical Engineering, The Massachusetts Institute of Technology; Department of Computer Science, Cornell University; Department of Mechanical Engineering, The Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161579/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14591339785437402417&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "The Massachusetts Institute of Technology;Cornell University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Computer Science",
        "aff_unique_url": "https://web.mit.edu;https://www.cornell.edu",
        "aff_unique_abbr": "MIT;Cornell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161432",
        "title": "Support Generation for Robot-Assisted 3D Printing with Curved Layers",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-assisted 3D printing has drawn a lot of attention by its capability to fabricate curved layers that are optimized according to different objectives. However, the support generation algorithm based on a fixed printing direction for planar layers cannot be directly applied for curved layers as the orientation of material accumulation is dynamically varied. In this paper, we propose a skeleton-based support generation method for robot-assisted 3D printing with curved layers. The support is represented as an implicit solid so that the problems of numerical robustness can be effectively avoided. The effectiveness of our algorithm is verified on a dual-material printing platform that consists of a robotic arm and a newly designed dual-material extruder. Experiments have been successfully conducted on our system to fabricate a variety of freeform models.",
        "primary_area": "",
        "author": "Tianyu Zhang;Yuming Huang;Piotr Kukulski;Neelotpal Dutta;Guoxin Fang;Charlie C.L. Wang;Tianyu Zhang;Yuming Huang;Piotr Kukulski;Neelotpal Dutta;Guoxin Fang;Charlie C.L. Wang",
        "authorids": "/37088907738;/37089894392;/37089893224;/37089895604;/37086103358;/37538386600;/37088907738;/37089894392;/37089893224;/37089895604;/37086103358;/37538386600",
        "aff": "Department of Mechanical, Aerospace and Civil Engineering, University of Manchester, Manchester; Department of Mechanical, Aerospace and Civil Engineering, University of Manchester, Manchester; Department of Mechanical, Aerospace and Civil Engineering, University of Manchester, Manchester; Department of Mechanical, Aerospace and Civil Engineering, University of Manchester, Manchester; Department of Mechanical, Aerospace and Civil Engineering, University of Manchester, Manchester; Department of Mechanical, Aerospace and Civil Engineering, University of Manchester, Manchester",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161432/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16466912124892360435&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Manchester",
        "aff_unique_dep": "Department of Mechanical, Aerospace and Civil Engineering",
        "aff_unique_url": "https://www.manchester.ac.uk",
        "aff_unique_abbr": "UoM",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Manchester",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160403",
        "title": "Surgical-VQLA:Transformer with Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the availability of computer-aided simulators and recorded videos of surgical procedures, junior residents still heavily rely on experts to answer their queries. However, expert surgeons are often overloaded with clinical and academic workloads and limit their time in answering. For this purpose, we develop a surgical question-answering system to facilitate robot-assisted surgical scene and activity understanding from recorded videos. Most of the existing visual question answering (VQA) methods require an object detector and regions based feature extractor to extract visual features and fuse them with the embedded text of the question for answer generation. However, (i) surgical object detection model is scarce due to smaller datasets and lack of bounding box annotation; (ii) current fusion strategy of heterogeneous modalities like text and image is naive; (iii) the localized answering is missing, which is crucial in complex surgical scenarios. In this paper, we propose Visual Question Localized-Answering in Robotic Surgery (Surgical-VQLA) to localize the specific surgical area during the answer prediction. To deal with the fusion of the heterogeneous modalities, we design gated vision-language embedding (GVLE) to build input patches for the Language Vision Transformer (LViT) to predict the answer. To get localization, we add the detection head in parallel with the prediction head of the LViT. We also integrate generalized intersection over union (GIoU) loss to boost localization performance by preserving the accuracy of the question-answering model. We annotate two datasets of VQLA by utilizing publicly available surgical videos from EndoVis-17 and 18 of the MICCAI challenges. Our validation results suggest that Surgical-VQLA can better understand the surgical scene and localized the specific area related to the question-answering. GVLE presents an efficient language-vision embedding technique by showing superior performance over the existing benchmarks. Show More",
        "primary_area": "",
        "author": "Long Bai;Mobarakol Islam;Lalithkumar Seenivasan;Hongliang Ren;Long Bai;Mobarakol Islam;Lalithkumar Seenivasan;Hongliang Ren",
        "authorids": "/37089689279;/37086799020;/37088703624;/37287561300;/37089689279;/37086799020;/37088703624;/37287561300",
        "aff": "Dept. of Electronic Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College, London, UK; Dept. of Biomedical Engineering, National University of Singapore, Singapore; Shun Hing Institute of Advanced Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160403/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10168567297079520070&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "The Chinese University of Hong Kong;University College London;National University of Singapore",
        "aff_unique_dep": "Dept. of Electronic Engineering;Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS);Dept. of Biomedical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.ucl.ac.uk;https://www.nus.edu.sg",
        "aff_unique_abbr": "CUHK;UCL;NUS",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Hong Kong;London;",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "China;United Kingdom;Singapore"
    },
    {
        "id": "10161539",
        "title": "Suture Thread Spline Reconstruction from Endoscopic Images for Robotic Surgery with Reliability-driven Keypoint Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Automating the process of manipulating and delivering sutures during robotic surgery is a prominent problem at the frontier of surgical robotics, as automating this task can significantly reduce surgeons' fatigue during tele-operated surgery and allow them to spend more time addressing higher-level clinical decision making. Accomplishing autonomous suturing and suture manipulation in the real world requires accurate suture thread localization and reconstruction, the process of creating a 3D shape representation of suture thread from 2D stereo camera surgical image pairs. This is a very challenging problem due to how limited pixel information is available for the threads, as well as their sensitivity to lighting and specular reflection. We present a suture thread reconstruction work that uses reliable keypoints and a Minimum Variation Spline (MVS) smoothing optimization to construct a 3D centerline from a segmented surgical image pair. This method is comparable to previous suture thread reconstruction works, with the possible benefit of increased accuracy of grasping point estimation. Our code and datasets will be available at: https://github.com/ucsdarclab/thread-reconstruction.",
        "primary_area": "",
        "author": "Neelay Joglekar;Fei Liu;Ryan Orosco;Michael Yip;Neelay Joglekar;Fei Liu;Ryan Orosco;Michael Yip",
        "authorids": "/37089893816;/37088689503;/38580551800;/37085382768;/37089893816;/37088689503;/38580551800;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California, San Diego, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, CA, USA; Department of Surgery, University of New Mexico, Albuquerque, NM, USA; Department of Electrical and Computer Engineering, University of California, San Diego, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161539/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13358159339311832046&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, San Diego;University of New Mexico",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Surgery",
        "aff_unique_url": "https://www.ucsd.edu;https://www.unm.edu",
        "aff_unique_abbr": "UCSD;UNM",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "San Diego;Albuquerque",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161039",
        "title": "Swarm Robotics Search and Rescue: A Bee-Inspired Swarm Cooperation Approach without Information Exchange",
        "track": "main",
        "status": "Poster",
        "abstract": "Swarm robotics plays a non-negligible role in actual practice because of its scalability and robustness. Besides some specific studies, there is still a lack of overall approaches to solving the search and rescue problem in a communication-denied environment. This paper presents a bee-inspired swarm cooperation approach without information exchange, including a target grouping method suitable for multi-objective and multi-robot, a finite behavior state machine, and the corresponding control law. Finally, the effectiveness of the proposed approach is shown via simulation. The overall approach proposed in this paper does not require two-way information exchange, and it is robust against relative and own position errors, making swarm robotics search and rescue in a communication-denied environment possible.",
        "primary_area": "",
        "author": "Yue Li;Yan Gao;Sijie Yang;Quan Quan;Yue Li;Yan Gao;Sijie Yang;Quan Quan",
        "authorids": "/37088984614;/37088986380;/37089894735;/37406014700;/37088984614;/37088986380;/37089894735;/37406014700",
        "aff": "School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161039/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12767143151686653373&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Automation Science and Electrical Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161355",
        "title": "Swarm-LIO: Decentralized Swarm LiDAR-inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate self and relative state estimation are the critical preconditions for completing swarm tasks, e.g., collaborative autonomous exploration, target tracking, search and rescue. This paper proposes Swarm-LIO: a fully decentralized state estimation method for aerial swarm systems, in which each drone performs precise ego-state estimation, exchanges ego-state and mutual observation information by wireless communication, and estimates relative state with respect to (w.r.t.) the rest of UAVs, all in real-time and only based on LiDAR-inertial measurements. A novel 3D LiDAR-based drone detection, identification and tracking method is proposed to obtain observations of teammate drones. The mutual observation measurements are then tightly-coupled with IMU and LiDAR measurements to perform real-time and accurate estimation of ego-state and relative state jointly. Extensive real-world experiments show the broad adaptability to complicated scenarios, including GPS-denied scenes, degenerate scenes for camera (dark night) or LiDAR (facing a single wall). Compared with ground-truth provided by motion capture system, the result shows the centimeter-level localization accuracy which outperforms other state-of-the-art LiDAR-inertial odometry for single UAV system.",
        "primary_area": "",
        "author": "Fangcheng Zhu;Yunfan Ren;Fanze Kong;Huajie Wu;Siqi Liang;Nan Chen;Wei Xu;Fu Zhang;Fangcheng Zhu;Yunfan Ren;Fanze Kong;Huajie Wu;Siqi Liang;Nan Chen;Wei Xu;Fu Zhang",
        "authorids": "/37089661744;/37087243712;/37088939160;/37089895885;/37089895082;/37086298779;/37086942915;/38245883800;/37089661744;/37087243712;/37088939160;/37089895885;/37089895082;/37086298779;/37086942915;/38245883800",
        "aff": "Department of Mechanical Engineering, The University of Hong Kong, China; Department of Mechanical Engineering, The University of Hong Kong, China; Department of Mechanical Engineering, The University of Hong Kong, China; Department of Mechanical Engineering, The University of Hong Kong, China; Harbin Institute of Technology, Shenzhen, China; Nan Chen; Wei Xu; Department of Mechanical Engineering, The University of Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161355/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4089955866377695170&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "The University of Hong Kong;Harbin Institute of Technology;",
        "aff_unique_dep": "Department of Mechanical Engineering;;",
        "aff_unique_url": "https://www.hku.hk;http://en.hhit.edu.cn/;",
        "aff_unique_abbr": "HKU;HIT;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "10160657",
        "title": "SwinDepth: Unsupervised Depth Estimation using Monocular Sequences via Swin Transformer and Densely Cascaded Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular depth estimation plays a critical role in various computer vision and robotics applications such as localization, mapping, and 3D object detection. Recently, learning-based algorithms achieve huge success in depth estimation by training models with a large amount of data in a supervised manner. However, it is challenging to acquire dense ground truth depth labels for supervised training, and the unsupervised depth estimation using monocular sequences emerges as a promising alternative. Unfortunately, most studies on unsupervised depth estimation explore loss functions or occlusion masks, and there is little change in model architecture in that ConvNet-based encoder-decoder structure becomes a de-facto standard for depth estimation. In this paper, we employ a convolution-free Swin Transformer as an image feature extractor so that the network can capture both local geometric features and global semantic features for depth estimation. Also, we propose a Densely Cascaded Multi-scale Network (DCMNet) that connects every feature map directly with another from different scales via a top-down cascade pathway. This densely cascaded connectivity reinforces the interconnection between decoding layers and produces high-quality multi-scale depth outputs. The experiments on two different datasets, KITTI and Make3D, demonstrate that our proposed method outperforms existing state-of-the-art unsupervised algorithms.",
        "primary_area": "",
        "author": "Dongseok Shim;H. Jin Kim;Dongseok Shim;H. Jin Kim",
        "authorids": "/37088567748;/37599626400;/37088567748;/37599626400",
        "aff": "Interdisciplinary Program in Artificial Intelligence (IPAI), Seoul National University; Interdisciplinary Program in Artificial Intelligence (IPAI), Seoul National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160657/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15749511608360334408&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Interdisciplinary Program in Artificial Intelligence (IPAI)",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161533",
        "title": "Switching Attention in Time-Varying Environments via Bayesian Inference of Abstractions",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the goal of endowing robots with a means for focusing attention in order to operate reliably in complex, uncertain, and time-varying environments, we consider how a robot can (i) determine which portions of its environment to pay attention to at any given point in time, (ii) infer changes in context (e.g., task or environment dynamics), and (iii) switch its attention accordingly. In this work, we tackle these questions by modeling context switches in a time-varying Markov decision process (MDP) framework. We utilize the theory of bisimulation-based state abstractions in order to synthesize mechanisms for paying attention to context-relevant information. We then present an algorithm based on Bayesian inference for detecting changes in the robot's context (task or environment dynamics) as it operates online, and use this to trigger switches between different abstraction-based attention mechanisms. Our approach is demonstrated on two examples: (i) an illustrative discrete-state tracking problem, and (ii) a continuous-state tracking problem implemented on a quadrupedal hardware platform. These examples demonstrate the ability of our approach to detect context switches online and robustly ignore task-irrelevant distractors by paying attention to context-relevant information.",
        "primary_area": "",
        "author": "Meghan Booker;Anirudha Majumdar;Meghan Booker;Anirudha Majumdar",
        "authorids": "/37089894148;/37086027485;/37089894148;/37086027485",
        "aff": "Mechanical and Aerospace Engineering, Princeton University, NJ, USA; Mechanical and Aerospace Engineering, Princeton University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161533/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11013650335728179865&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160841",
        "title": "Synthesizing Reactive Test Environments for Autonomous Systems: Testing Reach-Avoid Specifications with Multi-Commodity Flows",
        "track": "main",
        "status": "Poster",
        "abstract": "We study automated test generation for testing discrete decision-making modules in autonomous systems. Linear temporal logic is used to encode the system specification - requirements of the system under test - and the test specification, which is unknown to the system and describes the desired test behavior. The reactive test synthesis problem is to find constraints on system actions such that in a test execution, both the system and test specifications are satisfied. To do this, we use the specifications and their corresponding B\u00fcchi automata to construct the specification product automaton. Then, a virtual product graph representing all possible test executions of the system is constructed from the transition system and the specification product automaton. The main result of this paper is framing the test synthesis problem as a multi-commodity network flow optimization. This optimization is used to derive reactive constraints on system actions, which constitute the test environment. The resulting test environment ensures that the system meets the test specification while also satisfying the system specification. We illustrate this framework in simulation using grid world examples and demonstrate it on hardware with the Unitree A1 quadruped, where we test dynamic locomotion behaviors reactively.",
        "primary_area": "",
        "author": "Apurva Badithela;Josefine B. Graebener;Wyatt Ubellacker;Eric V. Mazumdar;Aaron D. Ames;Richard M. Murray;Apurva Badithela;Josefine B. Graebener;Wyatt Ubellacker;Eric V. Mazumdar;Aaron D. Ames;Richard M. Murray",
        "authorids": "/37086957229;/37089894720;/37077831700;/37086145019;/37300877900;/37267068200;/37086957229;/37089894720;/37077831700;/37086145019;/37300877900;/37267068200",
        "aff": "Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Graduate Aerospace Laboratories, California Institute of Technology, Pasadena, CA, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160841/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10531161459593982095&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Computing and Mathematical Sciences",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160416",
        "title": "Synthetic-to-Real Domain Adaptation for Action Recognition: A Dataset and Baseline Performances",
        "track": "main",
        "status": "Poster",
        "abstract": "Human action recognition is a challenging problem, particularly when there is high variability in factors such as subject appearance, backgrounds and viewpoint. While deep neural networks (DNNs) have been shown to perform well on action recognition tasks, they typically require large amounts of high-quality labeled data to achieve robust performance across a variety of conditions. Synthetic data has shown promise as a way to avoid the substantial costs and potential ethical concerns associated with collecting and labeling enormous amounts of data in the real-world. However, synthetic data may differ from real data in important ways. This phenomenon, known as domain shift, can limit the utility of synthetic data in robotics applications. To mitigate the effects of domain shift, substantial effort is being dedicated to the development of domain adaptation (DA) techniques. Yet, much remains to be understood about how best to develop these techniques. In this paper, we introduce a new dataset called Robot Control Gestures (RoCoG-v2). The dataset is composed of both real and synthetic videos from seven gesture classes, and is intended to support the study of synthetic-to-real domain shift for video-based action recognition. Our work expands upon existing datasets by focusing the action classes on gestures for human-robot teaming, as well as by enabling investigation of domain shift in both ground and aerial views. We present baseline results using state-of-the-art action recognition and domain adaptation algorithms and offer initial insight on tackling the synthetic-to-real and ground-to-air domain shifts. Instructions on accessing the dataset can be found at https://github.com/reddyav1/RoCoG-v2.",
        "primary_area": "",
        "author": "Arun V. Reddy;Ketul Shah;William Paul;Rohita Mocharla;Judy Hoffman;Kapil D. Katyal;Dinesh Manocha;Celso M. de Melo;Rama Chellappa;Arun V. Reddy;Ketul Shah;William Paul;Rohita Mocharla;Judy Hoffman;Kapil D. Katyal;Dinesh Manocha;Celso M. de Melo;Rama Chellappa",
        "authorids": "/37089485004;/37088646731;/37089451594;/37089893688;/38236676800;/38228973900;/37267825600;/37683411800;/37274537000;/37089485004;/37088646731;/37089451594;/37089893688;/38236676800;/38228973900;/37267825600;/37683411800;/37274537000",
        "aff": "Johns Hopkins University Applied Physics Lab, Laurel, MD, USA; Dept. of Electrical & Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University Applied Physics Lab, Laurel, MD, USA; Johns Hopkins University Applied Physics Lab, Laurel, MD, USA; Georgia Institute of Technology, Atlanta, GA, USA; Johns Hopkins University Applied Physics Lab, Laurel, MD, USA; University of Maryland, College Park, MD, USA; Army Research Lab, Adelphi, MD, USA; Dept. of Electrical & Computer Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160416/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6846196744602301303&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;1;0;2;3;0",
        "aff_unique_norm": "Johns Hopkins University;Georgia Institute of Technology;University of Maryland;Army Research Lab",
        "aff_unique_dep": "Applied Physics Lab;;;",
        "aff_unique_url": "https://www.jhuapl.edu;https://www.gatech.edu;https://www/umd.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "JHU APL;Georgia Tech;UMD;ARL",
        "aff_campus_unique_index": "0;1;0;0;2;0;3;4;1",
        "aff_campus_unique": "Laurel;Baltimore;Atlanta;College Park;Adelphi",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161531",
        "title": "SyreaNet: A Physically Guided Underwater Image Enhancement Framework Integrating Synthetic and Real Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater image enhancement (UIE) is vital for high-level vision-related underwater tasks. Although learning-based UIE methods have made remarkable achievements in recent years, it's still challenging for them to consistently deal with various underwater conditions, which could be caused by: 1) the use of the simplified atmospheric image formation model in UIE may result in severe errors; 2) the network trained solely with synthetic images might have difficulty in generalizing well to real underwater images. In this work, we, for the first time, propose a framework SyreaNet for UIE that integrates both synthetic and real data under the guidance of the revised underwater image formation model and novel domain adaptation (DA) strategies. First, an underwater image synthesis module based on the revised model is proposed. Then, a physically guided disentangled network is designed to predict the clear images by combining both synthetic and real underwater images. The intra- and inter-domain gaps are abridged by fully exchanging the domain knowledge. Extensive experiments demonstrate the superiority of our framework over other state-of-the-art (SOTA) learning-based UIE methods qualitatively and quantitatively. The code and dataset are publicly available at https://github.com/RockWenJJ/SyreaNet.git.",
        "primary_area": "",
        "author": "Junjie Wen;Jinqiang Cui;Zhenjun Zhao;Ruixin Yan;Zhi Gao;Lihua Dou;Ben M. Chen;Junjie Wen;Jinqiang Cui;Zhenjun Zhao;Ruixin Yan;Zhi Gao;Lihua Dou;Ben M. Chen",
        "authorids": "/37089893127;/37072144400;/37090000825;/37089893949;/37085495662;/37324043000;/38520079900;/37089893127;/37072144400;/37090000825;/37089893949;/37085495662;/37324043000;/38520079900",
        "aff": "Department of Mathematics and Theories, Peng Cheng Laboratory, Shen-zhen, China; Department of Mathematics and Theories, Peng Cheng Laboratory, Shen-zhen, China; Department of Mathematics and Theories, Peng Cheng Laboratory, Shen-zhen, China; Department of Mathematics and Theories, Peng Cheng Laboratory, Shen-zhen, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Automation, Beijing Institute of Technology, Beijing, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Shatin, N.T., Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161531/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6639186511282650811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;3",
        "aff_unique_norm": "Peng Cheng Laboratory;Wuhan University;Beijing Institute of Technology;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mathematics and Theories;School of Remote Sensing and Information Engineering;School of Automation;Department of Mechanical and Automation Engineering",
        "aff_unique_url": ";http://www.whu.edu.cn/;http://www.bit.edu.cn;https://www.cuhk.edu.hk",
        "aff_unique_abbr": ";WHU;BIT;CUHK",
        "aff_campus_unique_index": "0;0;0;0;1;2;3",
        "aff_campus_unique": "Shen-zhen;Wuhan;Beijing;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160573",
        "title": "System Configuration and Navigation of a Guide Dog Robot: Toward Animal Guide Dog-Level Guiding Work",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot guide dog has compelling advantages over animal guide dogs for its cost-effectiveness, the potential for mass production, and low maintenance burden. However, despite the long history of guide dog robot research, previous studies were conducted with little or no consideration of how the guide dog handler and the guide dog work as a team for navigation. To develop a robotic guiding system that genuinely benefits blind or visually impaired individuals, we performed qualitative research, including interviews with guide dog handlers, trainers, and first-hand blindfold walking experiences with various guide dogs. We build a collaborative indoor navigation scheme for a guide dog robot that includes preferred features such as speed and directional control. For collaborative navigation, we propose a semantic-aware local path planner that enables safe and efficient guiding work by utilizing semantic information about the environment and considering the handler's position and directional cues to determine the collision-free path. We evaluate our integrated robotic system by testing blindfolded walking in indoor settings and demonstrate guide dog-like navigation behavior by avoiding obstacles at typical gait speed (0.7m/s). The following demonstration video link includes an audio description: https://youtu.be/YxlcMeaL7GA",
        "primary_area": "",
        "author": "Hochul Hwang;Tim Xia;Ibrahima Keita;Ken Suzuki;Joydeep Biswas;Sunghoon I. Lee;Donghyun Kim;Hochul Hwang;Tim Xia;Ibrahima Keita;Ken Suzuki;Joydeep Biswas;Sunghoon I. Lee;Donghyun Kim",
        "authorids": "/37089895441;/37089893236;/37089892802;/37089892085;/37538259200;/37089894684;/37085554176;/37089895441;/37089893236;/37089892802;/37089892085;/37538259200;/37089894684;/37085554176",
        "aff": "University of Texas at Austin; University of Texas at Austin; University of Texas at Austin; University of Texas at Austin; University of Texas at Austin; University of Texas at Austin; University of Massachusetts Amherst, U.S.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160573/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5100110537773605699&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "University of Texas at Austin;University of Massachusetts Amherst",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.umass.edu",
        "aff_unique_abbr": "UT Austin;UMass Amherst",
        "aff_campus_unique_index": "0;0;0;0;0;0;1",
        "aff_campus_unique": "Austin;Amherst",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161091",
        "title": "TANDEM3D: Active Tactile Exploration for 3D Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile recognition of 3D objects remains a challenging task. Compared to 2D shapes, the complex geometry of 3D surfaces requires richer tactile signals, more dexterous actions, and more advanced encoding techniques. In this work, we propose TANDEM3D, a method that applies a co-training framework for exploration and decision making to 3D object recognition with tactile signals. Starting with our previous work, which introduced a co-training paradigm for 2D recognition problems, we introduce a number of advances that enable us to scale up to 3D. TANDEM3D is based on a novel encoder that builds 3D object representation from contact positions and normals using PointNet++. Furthermore, by enabling 6DOF movement, TANDEM3D explores and collects discriminative touch information with high efficiency. Our method is trained entirely in simulation and validated with real-world experiments. Compared to state-of-the-art baselines, TANDEM3D achieves higher accuracy and a lower number of actions in recognizing 3D objects and is also shown to be more robust to different types and amounts of sensor noise.",
        "primary_area": "",
        "author": "Jingxi Xu;Han Lin;Shuran Song;Matei Ciocarlie;Jingxi Xu;Han Lin;Shuran Song;Matei Ciocarlie",
        "authorids": "/37088507340;/37089892754;/37085613509;/37297485500;/37088507340;/37089892754;/37085613509;/37297485500",
        "aff": "Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161091/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1359571154095250773&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160899",
        "title": "TJ-FlyingFish: Design and Implementation of an Aerial-Aquatic Quadrotor with Tiltable Propulsion Units",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial-aquatic vehicles are capable to move in the two most dominant fluids, making them more promising for a wide range of applications. We propose a prototype with special designs for propulsion and thruster configuration to cope with the vast differences in the fluid properties of water and air. For propulsion, the operating range is switched for the different mediums by the dual-speed propulsion unit, providing sufficient thrust and also ensuring output efficiency. For thruster configuration, thrust vectoring is realized by the rotation of the propulsion unit around the mount arm, thus enhancing the underwater maneuverability. This paper presents a quadrotor prototype of this concept and the design details and realization in practice.",
        "primary_area": "",
        "author": "Xuchen Liu;Minghao Dou;Dongyue Huang;Songqun Gao;Ruixin Yan;Biao Wang;Jinqiang Cui;Qinyuan Ren;Lihua Dou;Zhi Gao;Jie Chen;Ben M. Chen;Xuchen Liu;Minghao Dou;Dongyue Huang;Songqun Gao;Ruixin Yan;Biao Wang;Jinqiang Cui;Qinyuan Ren;Lihua Dou;Zhi Gao;Jie Chen;Ben M. Chen",
        "authorids": "/37089892530;/37089892257;/37089895414;/37089896062;/37089893949;/37538973200;/37072144400;/38264350700;/37324043000;/37085495662;/38107663500;/38520079900;/37089892530;/37089892257;/37089895414;/37089896062;/37089893949;/37538973200;/37072144400;/38264350700;/37324043000;/37085495662;/38107663500;/38520079900",
        "aff": "Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China; Peng Cheng Laboratory, Shenzhen, Guangdong, China; Peng Cheng Laboratory, Shenzhen, Guangdong, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, Zhejiang, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, China; Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University, Shanghai, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160899/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5879934431391864583&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;0;0;1;1;2;3;4;5;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Peng Cheng Laboratory;Zhejiang University;Beijing Institute of Technology;Wuhan University;Tongji University",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;;College of Control Science and Engineering;School of Automation;School of Remote Sensing and Information Engineering;Shanghai Research Institute for Intelligent Autonomous Systems",
        "aff_unique_url": "https://www.cuhk.edu.hk;;http://www.zju.edu.cn;http://www.bit.edu.cn;http://www.whu.edu.cn/;https://www.tongji.edu.cn",
        "aff_unique_abbr": "CUHK;;ZJU;BIT;WHU;Tongji",
        "aff_campus_unique_index": "0;0;0;0;0;1;1;2;3;4;5;0",
        "aff_campus_unique": "Hong Kong;Shenzhen;Hangzhou;Beijing;Wuhan;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160537",
        "title": "TODE-Trans: Transparent Object Depth Estimation with Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "Transparent objects are widely used in industrial automation and daily life. However, robust visual recognition and perception of transparent objects have always been a major challenge. Currently, most commercial-grade depth cameras are still not good at sensing the surfaces of transparent objects due to the refraction and reflection of light. In this work, we present a transformer-based transparent object depth estimation approach from a single RGB-D input. We observe that the global characteristics of the transformer make it easier to extract contextual information to perform depth estimation of transparent areas. In addition, to better enhance the fine-grained features, a feature fusion module (FFM) is designed to assist coherent prediction. Our empirical evidence demonstrates that our model delivers significant improvements in recent popular datasets, e.g., 25% gain on RMSE and 21% gain on REL compared to previous state-of-the-art convolutional-based counterparts in ClearGrasp dataset. Extensive results show that our transformer-based model enables better aggregation of the object's RGB and inaccurate depth information to obtain a better depth representation. Our code and the pre-trained model are available at https://github.com/yuchendoudou/TODE.",
        "primary_area": "",
        "author": "Kang Chen;Shaochen Wang;Beihao Xia;Dongxu Li;Zhen Kan;Bin Li;Kang Chen;Shaochen Wang;Beihao Xia;Dongxu Li;Zhen Kan;Bin Li",
        "authorids": "/37088474386;/37088518790;/37088978874;/37089894335;/37545883400;/37089893795;/37088474386;/37088518790;/37088978874;/37089894335;/37545883400;/37089893795",
        "aff": "University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; Huazhong University of Science and Technology, Wuhan, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160537/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2176553703327777376&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China;Huazhong University of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.ustc.edu.cn;http://www.hust.edu.cn",
        "aff_unique_abbr": "USTC;HUST",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Hefei;Wuhan",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160476",
        "title": "TOFG: A Unified and Fine-Grained Environment Representation in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "In autonomous driving, an accurate understanding of environment, e.g., the vehicle-to-vehicle and vehicle-to-lane interactions, plays a critical role in many driving tasks such as trajectory prediction and motion planning. Environment information comes from high-definition (HD) map and historical trajectories of vehicles. Due to the heterogeneity of the map data and trajectory data, many data-driven models for trajectory prediction and motion planning extract vehicle-to-vehicle and vehicle-to-lane interactions in a separate and sequential manner. However, such a manner may capture biased interpretation of interactions, causing lower prediction and planning accuracy. Moreover, separate extraction leads to a complicated model structure and hence the overall efficiency and scalability are sacrificed. To address the above issues, we propose an environment representation, Temporal Occupancy Flow Graph (TOFG). Specifically, the occupancy flow-based representation unifies the map information and vehicle trajectories into a homogeneous data format and enables a consistent prediction. The temporal dependencies among vehicles can help capture the change of occupancy flow timely to further promote model performance. To demonstrate that TOFG is capable of simplifying the model architecture, we incorporate TOFG with a simple graph attention (GAT) based neural network and propose TOFG-GAT, which can be used for both trajectory prediction and motion planning. Experiment results show that TOFG-GAT achieves better or competitive performance than all the SOTA baselines with less training time.",
        "primary_area": "",
        "author": "Zihao Wen;Yifan Zhang;Xinhong Chen;Jianping Wang;Zihao Wen;Yifan Zhang;Xinhong Chen;Jianping Wang",
        "authorids": "/37089893735;/37088388333;/37088761517;/37406463900;/37089893735;/37088388333;/37088761517;/37406463900",
        "aff": "City University of Hong Kong Shenzhen Research Institute, Shenzhen, China; City University of Hong Kong Shenzhen Research Institute, Shenzhen, China; City University of Hong Kong Shenzhen Research Institute, Shenzhen, China; City University of Hong Kong Shenzhen Research Institute, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160476/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16875341044812717609&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "City University of Hong Kong",
        "aff_unique_dep": "Shenzhen Research Institute",
        "aff_unique_url": "https://www.cityu.edu.hk",
        "aff_unique_abbr": "CityU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160488",
        "title": "TOP-JAM: A bio-inspired topology-based model of joint attention for human-robot interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Coexisting with others and interacting in society implies sharing knowledge and attention about world objects, events, features, episodes, and even imagination or abstract ideas in time and space. Inspired by human phenomenological, cognitive and behavioral research, this work focuses on the study of joint attention (JA) for human-robot interaction (HRI), based on two main assumptions: a) the perception and representation of attention jointness constitute an isomorphic relation, and b) inspiration on dynamic neural fields (DNF) theory is a promising way to investigate contextual and non-linear spatio-temporal relations underlying attention and knowledge sharing in HRI. Taking into account the previous considerations, we propose a topology-based model for JA named TOP-JAM, which is able to represent and track in real-time JA states, from observations of behavioral data. More importantly, the model consists in a representation that can be directly understood by human beings, which conforms to robo-ethical principles in social robotics. This study evaluates computational properties of the model in simulation. Through a real experiment with the robot Pepper, the study shows that TOP-JAM is able to track JA in a triad interaction scenario.",
        "primary_area": "",
        "author": "Hendry Ferreira Chame;Aur\u00e9lie Clodic;Rachid Alami;Hendry Ferreira Chame;Aur\u00e9lie Clodic;Rachid Alami",
        "authorids": "/37085491688;/37296056000;/37278643600;/37085491688;/37296056000;/37278643600",
        "aff": "Team NeuroRhythms, LORIA-CNRS, Vand\u0153uvre-l\u00e8s-Nancy; Team Robotics and InteractionS (RIS), LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; Team Robotics and InteractionS (RIS), LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160488/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2874801494513503597&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "LORIA-CNRS;Universit\u00e9 de Toulouse",
        "aff_unique_dep": "Team NeuroRhythms;Team Robotics and InteractionS (RIS)",
        "aff_unique_url": "https://www.loria.fr;https://www.univ-toulouse.fr",
        "aff_unique_abbr": ";UT",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Vand\u0153uvre-l\u00e8s-Nancy;Toulouse",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10161192",
        "title": "TRADE: Object Tracking with 3D Trajectory and Ground Depth Estimates for UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose TRADE for robust tracking and 3D localization of a moving target in complex environments, from UAVs equipped with a single camera. Ultimately TRADE enables 3d-aware target following. Tracking-by-detection approaches are vulnerable to target switching, especially between similar objects. Thus, TRADE predicts and incorporates the target 3D trajectory to select the right target from the tracker's response map. Unlike static environments, depth estimation of a moving target from a single camera is an ill-posed problem. Therefore we propose a novel 3D localization method for ground targets on complex terrain. It reasons about scene geometry by combining ground plane segmentation, depth-from-motion and single-image depth estimation. The benefits of using TRADE are demonstrated as tracking robustness and depth accuracy on several dynamic scenes simulated in this work. Additionally, we demonstrate autonomous target following using a thermal camera by running TRADE on a quadcopter's board computer.",
        "primary_area": "",
        "author": "Pedro F. Proen\u00e7a;Patrick Spieler;Robert A. Hewitt;Jeff Delaune;Pedro F. Proen\u00e7a;Patrick Spieler;Robert A. Hewitt;Jeff Delaune",
        "authorids": "/37086315258;/37088504609;/37073604800;/37086592626;/37086315258;/37088504609;/37073604800;/37086592626",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161192/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2183997495628182569&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160683",
        "title": "TTCDist: Fast Distance Estimation From an Active Monocular Camera Using Time-to-Contact",
        "track": "main",
        "status": "Poster",
        "abstract": "Distance estimation from vision is fundamental for a myriad of robotic applications such as navigation, manipu-lation, and planning. Inspired by the mammal's visual system, which gazes at specific objects, we develop two novel constraints relating time-to-contact, acceleration, and distance that we call the \\tau\\tau -constraint and \\Phi\\Phi -constraint. They allow an active (moving) camera to estimate depth efficiently and accurately while using only a small portion of the image. The constraints are applicable to range sensing, sensor fusion, and visual servoing. We successfully validate the proposed constraints with two experiments. The first applies both constraints in a trajectory estimation task with a monocular camera and an Inertial Measurement Unit (IMU). Our methods achieve 30-70% less average trajectory error while running 25\\times25\\times and 6.2\\times6.2\\times faster than the popular Visual-Inertial Odometry methods VINS-Mono and ROVIO respectively. The second experiment demonstrates that when the constraints are used for feedback with efference copies the resulting closed loop system's eigenvalues are invariant to scaling of the applied control signal. We believe these results indicate the \\tau\\tau and \\Phi\\Phi constraint's potential as the basis of robust and efficient algorithms for a multitude of robotic applications.",
        "primary_area": "",
        "author": "Levi Burner;Nitin J. Sanket;Cornelia Ferm\u00fcller;Yiannis Aloimonos;Levi Burner;Nitin J. Sanket;Cornelia Ferm\u00fcller;Yiannis Aloimonos",
        "authorids": "/37089892191;/37086390746;/37269887600;/37282631400;/37089892191;/37086390746;/37269887600;/37282631400",
        "aff": "Perception and Robotics Group, Electrical and Computer Engineering, University of Maryland, College Park; Robotics Engineering, Worcester Polytechnic Institute; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160683/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13343210599525040302&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "University of Maryland, College Park;Worcester Polytechnic Institute;University of Maryland",
        "aff_unique_dep": "Electrical and Computer Engineering;Robotics Engineering;Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies",
        "aff_unique_url": "https://www.umd.edu;https://www.wpi.edu;https://www.umd.edu",
        "aff_unique_abbr": "UMD;WPI;UMD",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "College Park;Worcester",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160288",
        "title": "Tac-VGNN: A Voronoi Graph Neural Network for Pose-Based Tactile Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile pose estimation and tactile servoing are fundamental capabilities of robot touch. Reliable and precise pose estimation can be provided by applying deep learning models to high-resolution optical tactile sensors. Given the recent successes of Graph Neural Network (GNN) and the effectiveness of Voronoi features, we developed a Tactile Voronoi Graph Neural Network (Tac-VGNN) to achieve reliable pose-based tactile servoing relying on a biomimetic optical tactile sensor (TacTip). The GNN is well suited to modeling the distribution relationship between shear motions of the tactile markers, while the Voronoi diagram supplements this with area-based tactile features related to contact depth. The experiment results showed that the Tac-VGNN model can help enhance data interpretability during graph generation and model training efficiency significantly than CNN-based methods. It also improved pose estimation accuracy along vertical depth by 28.57% over vanilla GNN without Voronoi features and achieved better performance on the real surface following tasks with smoother robot control trajectories. For more project details, please view our website: https://sites.google.com/view/tac-vgnn/home",
        "primary_area": "",
        "author": "Wen Fan;Max Yang;Yifan Xing;Nathan F. Lepora;Dandan Zhang;Wen Fan;Max Yang;Yifan Xing;Nathan F. Lepora;Dandan Zhang",
        "authorids": "/37089561448;/37089892957;/37089560540;/37399610200;/37086595836;/37089561448;/37089892957;/37089560540;/37399610200;/37086595836",
        "aff": "Department of Engineering Mathematics and Bristol, Robotics Laboratory, University of Bristol, U.K.; Department of Engineering Mathematics and Bristol, Robotics Laboratory, University of Bristol, U.K.; Department of Computer Science, University of Bristol, U.K.; Department of Engineering Mathematics and Bristol, Robotics Laboratory, University of Bristol, U.K.; Department of Engineering Mathematics and Bristol, Robotics Laboratory, University of Bristol, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160288/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3812630446382165581&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Engineering Mathematics",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Bristol;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160222",
        "title": "Tackling Clutter in Radar Data - Label Generation and Detection Using PointNet++",
        "track": "main",
        "status": "Poster",
        "abstract": "Radar sensors employed for environment perception, e.g. in autonomous vehicles, output a lot of unwanted clutter. These points, for which no corresponding real objects exist, are a major source of errors in following processing steps like object detection or tracking. We therefore present two novel neural network setups for identifying clutter. The input data, network architectures and training configuration are adjusted specifically for this task. Special attention is paid to the downsampling of point clouds composed of multiple sensor scans. In an extensive evaluation, the new setups display substantially better performance than existing approaches. Because there is no suitable public data set in which clutter is annotated, we design a method to automatically generate the respective labels. By applying it to existing data with object annotations and releasing its code, we effectively create the first freely available radar clutter data set representing realworld driving scenarios. Code and instructions are accessible at www.github.com/kopp-j/clutter-ds.",
        "primary_area": "",
        "author": "Johannes Kopp;Dominik Kellner;Aldi Piroli;Klaus Dietmayer;Johannes Kopp;Dominik Kellner;Aldi Piroli;Klaus Dietmayer",
        "authorids": "/37089006114;/38251951000;/37088540711;/37283417900;/37089006114;/38251951000;/37088540711;/37283417900",
        "aff": "Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany; BMW AG, Munich, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160222/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4656193735078515065&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Ulm University;BMW AG",
        "aff_unique_dep": "Institute of Measurement, Control and Microtechnology;",
        "aff_unique_url": "https://www.uni-ulm.de;https://www.bmw.com",
        "aff_unique_abbr": "Ulm U;BMW",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Ulm;Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160975",
        "title": "Tactile Identification of Object Shapes via In-Hand Manipulation with A Minimalistic Barometric Tactile Sensor Array",
        "track": "main",
        "status": "Poster",
        "abstract": "With the goal of providing an alternative to optical and other tactile sensors, we set out to stress test the object shape identification capabilities of barometric tactile arrays in robotic manipulation tasks. These sensors are superior to optical devices in terms of form factor, ease of fabrication, and data reading/processing speeds, but lack the necessary spatial resolution to identify surface shapes via a single contact. To compensate, we utilize in-hand-manipulation, specifically in- hand-rolling to identify object shapes via a spatiotemporal approach. To increase task difficulty, we only use three neighboring barometric sensors and designed strict experiment requirements with the purpose of creating a set of extremely confusable test objects. The E- TRoll robotic hand, equipped with a barometric tactile array on one finger, was used to roll test objects within its grasp, taking just under 3.4 seconds for data collection under the fastest tested speed setting, compared to 33 seconds in our previous work. We also designed and implemented a feature extraction algorithm, based and improved upon our recently published algorithm. This captures enough information from the collected spatiotemporal data samples for successful classification with only 13 features. Finally, a bagged tree classification algorithm was trained and optimized with data from 1,164 trials of rolling 9 prismatic test objects, leading to a five-fold cross validation accuracy of 90.5% for identifying the 9 object classes.",
        "primary_area": "",
        "author": "Xin Zhou;Adam J. Spiers;Xin Zhou;Adam J. Spiers",
        "authorids": "/37089663070;/38514763300;/37089663070;/38514763300",
        "aff": "Both authors are with Imperial College, London; Both authors are with Imperial College, London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160975/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17234352348560983021&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160480",
        "title": "Tactile Tool Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans can effortlessly perform very complex, dexterous manipulation tasks by reacting to sensor observations. In contrast, robots can not perform reactive manipulation and they mostly operate in open-loop while interacting with their environment. Consequently, the current manipulation algorithms either are inefficient in performance or can only work in highly structured environments. In this paper, we present closed-loop control of a complex manipulation task where a robot uses a tool to interact with objects. Manipulation using a tool leads to complex kinematics and contact constraints that need to be satisfied for generating feasible manipulation trajectories. We first present an open-loop controller design using Non-Linear Programming (NLP) that satisfies these constraints. In order to design a closed-loop controller, we present a pose estimator of objects and tools using tactile sensors. Using our tactile estimator, we design a closed-loop controller based on Model Predictive Control (MPC). The proposed algorithm is verified using a 6 DoF manipulator on tasks using a variety of objects and tools. We verify that our closed-loop controller can successfully perform tool manipulation under several unexpected contacts.",
        "primary_area": "",
        "author": "Yuki Shirai;Devesh K. Jha;Arvind U. Raghunathan;Dennis Hong;Yuki Shirai;Devesh K. Jha;Arvind U. Raghunathan;Dennis Hong",
        "authorids": "/37086344073;/37072717800;/37401365500;/37575333900;/37086344073;/37072717800;/37401365500;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160480/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5976934065324057451&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of California, Los Angeles;Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;",
        "aff_unique_url": "https://www.ucla.edu;https://www.merl.com",
        "aff_unique_abbr": "UCLA;MERL",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Los Angeles;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160729",
        "title": "Tactile based robotic skills for cable routing operations",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a set of tactile based skills to perform robotic cable routing operations for deformable linear objects (DLOs) characterized by considerable stiffness and constrained at both ends. In particular, tactile data are exploited to reconstruct the shape of the grasped portion of the DLO and to estimate the future local one. This information is exploited to obtain a grasping configuration aligned to the local shape of the DLO, starting from a rough initial grasping pose, and to follow the DLO's contour in the three-dimensional space. Taking into account the distance travelled along the arc length of the DLO, the robot can detect the cable segments that must be firmly grasped and inserted in intermediate clips, continuing then to slide along the contour until the next DLO's portion, that has to be clipped, is reached. The proposed skills are experimentally validated with an industrial robot on different DLOs in several configurations and on a cable routing use case.",
        "primary_area": "",
        "author": "Andrea Monguzzi;Martina Pelosi;Andrea Maria Zanchettin;Paolo Rocco;Andrea Monguzzi;Martina Pelosi;Andrea Maria Zanchettin;Paolo Rocco",
        "authorids": "/37089552135;/37089893222;/37546427600;/37274178600;/37089552135;/37089893222;/37546427600;/37274178600",
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160729/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12431214056426609839&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB)",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161036",
        "title": "Tactile-Driven Gentle Grasping for Human-Robot Collaborative Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a control scheme for force sensitive, gentle grasping with a Pisa/IIT anthropomorphic SoftHand equipped with a miniaturised version of the TacTip optical tactile sensor on all five fingertips. The tactile sensors provide high-resolution information about a grasp and how the fingers interact with held objects. We first describe a series of hardware developments for performing asynchronous sensor data acquisition and processing, resulting in a fast control loop sufficient for real-time grasp control. We then develop a novel grasp controller that uses tactile feedback from all five fingertip sensors simultaneously to gently and stably grasp 43 objects of varying geometry and stiffness, which is then applied to a human-to-robot handover task. These developments open the door to more advanced manipulation with underactuated hands via fast reflexive control using high-resolution tactile sensing.",
        "primary_area": "",
        "author": "Christopher J. Ford;Haoran Li;John Lloyd;Manuel G. Catalano;Matteo Bianchi;Efi Psomopoulou;Nathan F. Lepora;Christopher J. Ford;Haoran Li;John Lloyd;Manuel G. Catalano;Matteo Bianchi;Efi Psomopoulou;Nathan F. Lepora",
        "authorids": "/37089000013;/37089455846;/37089123940;/37544547800;/37394737700;/38541617100;/37399610200;/37089000013;/37089455846;/37089123940;/37544547800;/37394737700;/38541617100;/37399610200",
        "aff": "Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, UK; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, UK; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, UK; the Department of Soft Robotics for Human Cooperation and Rehabilitation, Istituto Italiano di Tecnologia (IIT), Italy; the Department of Information Engineering, Research Center \u201cE. Piaggio\u201d, University of Pisa, Italy; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, UK; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161036/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16432424223891506374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;2;0;0",
        "aff_unique_norm": "University of Bristol;Istituto Italiano di Tecnologia;University of Pisa",
        "aff_unique_dep": "Department of Engineering Mathematics;Department of Soft Robotics for Human Cooperation and Rehabilitation;Department of Information Engineering",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.iit.it;https://www.unipi.it",
        "aff_unique_abbr": "UoB;IIT;UNIPi",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Bristol;",
        "aff_country_unique_index": "0;0;0;1;1;0;0",
        "aff_country_unique": "United Kingdom;Italy"
    },
    {
        "id": "10160289",
        "title": "TactoFind: A Tactile Only System for Object Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of object retrieval in scenarios where visual sensing is absent, object shapes are unknown beforehand and objects can move freely, like grabbing objects out of a drawer. Successful solutions require localizing free objects, identifying specific object instances, and then grasping the identified objects, only using touch feedback. Unlike vision, where cameras can observe the entire scene, touch sensors are local and only observe parts of the scene that are in contact with the manipulator. Moreover, information gathering via touch sensors necessitates applying forces on the touched surface which may disturb the scene itself. Reasoning with touch, therefore, requires careful exploration and integration of information over time - a challenge we tackle. We present a system capable of using sparse tactile feedback from fingertip touch sensors on a dexterous hand to localize, identify and grasp novel objects without any visual feedback. Videos are available at https://sites.google.com/view/tactofind.",
        "primary_area": "",
        "author": "Sameer Pai;Tao Chen;Megha Tippur;Edward Adelson;Abhishek Gupta;Pulkit Agrawal;Sameer Pai;Tao Chen;Megha Tippur;Edward Adelson;Abhishek Gupta;Pulkit Agrawal",
        "authorids": "/37089892356;/37089892750;/37088911188;/37349732300;/37089892518;/37085611190;/37089892356;/37089892750;/37088911188;/37349732300;/37089892518;/37085611190",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; University of Washington; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160289/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13153344710933317652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Washington",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.washington.edu",
        "aff_unique_abbr": "MIT;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160487",
        "title": "Target-Aware Implicit Mapping for Agricultural Crop Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "Crop inspection is a critical part of modern agricultural practices that helps farmers assess the current status of a field and then make crop management decisions. Current crop inspection methods are labour-intensive tasks, which makes them rather slow and expensive to apply. In this paper, we exploit recent advancements in implicit mapping to tackle the challenging context of agricultural environments to create dense maps of crop rows with high enough fidelity to be useful for automated crop inspection. Specifically, we map strawberry and sweet pepper crop rows using RGB images captured by a wheeled mobile field robot inside a greenhouse and then use this data to build 3D maps to document the development of plants and fruits. Our Target-Aware Implicit Mapping system (TAIM) uses a SLAM-based pose initialization strategy for robust pose convergence, an efficient information-guided training sample selection framework for faster loss reduction, and focuses on exploiting training samples for fruit regions of the scene, which are critical for crop inspection tasks, to create more accurate maps in less time.",
        "primary_area": "",
        "author": "Shane Kelly;Alessandro Riccardi;Elias Marks;Federico Magistri;Tiziano Guadagnino;Margarita Chli;Cyrill Stachniss;Shane Kelly;Alessandro Riccardi;Elias Marks;Federico Magistri;Tiziano Guadagnino;Margarita Chli;Cyrill Stachniss",
        "authorids": "/37089893367;/37089894973;/37089447007;/37086805350;/37087324270;/37546501900;/37329668600;/37089893367;/37089894973;/37089447007;/37086805350;/37087324270;/37546501900;/37329668600",
        "aff": "Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany; Lamarr Institute for Machine Learning and Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160487/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=271047807655075421&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Lamarr Institute for Machine Learning and Artificial Intelligence",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160306",
        "title": "Task-Directed Exploration in Continuous POMDPs for Robotic Manipulation of Articulated Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Representing and reasoning about uncertainty is crucial for autonomous agents acting in partially observable environments with noisy sensors. Partially observable Markov decision processes (POMDPs) serve as a general framework for representing problems in which uncertainty is an important factor. Online sample-based POMDP methods have emerged as efficient approaches to solving large POMDPs and have been shown to extend to continuous domains. However, these solutions struggle to find long-horizon plans in problems with significant uncertainty. Exploration heuristics can help guide planning, but many real-world settings contain significant task-irrelevant uncertainty that might distract from the task objective. In this paper, we propose STRUG, an online POMDP solver capable of handling domains that require long-horizon planning with significant task-relevant and task-irrelevant uncertainty. We demonstrate our solution on several temporally extended versions of toy POMDP problems as well as robotic manipulation of articulated objects using a neural perception frontend to construct a distribution of possible models. Our results show that STRUG outperforms the current sample-based online POMDP solvers on several tasks.",
        "primary_area": "",
        "author": "Aidan Curtis;Leslie Kaelbling;Siddarth Jain;Aidan Curtis;Leslie Kaelbling;Siddarth Jain",
        "authorids": "/37089450030;/37269373600;/37088688017;/37089450030;/37269373600;/37088688017",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160306/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2119767389544006489&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://www.mit.edu;https://www.merl.com",
        "aff_unique_abbr": "MIT;MERL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161157",
        "title": "Task-Driven Graph Attention for Hierarchical Relational Object Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Embodied AI agents in large scenes often need to navigate to find objects. In this work, we study a naturally emerging variant of the object navigation task, hierarchical relational object navigation (HRON), where the goal is to find objects specified by logical predicates organized in a hierarchical structure-objects related to furniture and then to rooms-such as finding an apple on top of a table in the kitchen. Solving such a task requires an efficient representation to reason about object relations and correlate the relations in the environment and in the task goal. HRON in large scenes (e.g. homes) is particularly challenging due to its partial observability and long horizon, which invites solutions that can compactly store the past information while effectively exploring the scene. We demonstrate experimentally that scene graphs are the best-suited representation compared to conventional representations such as images or 2D maps. We propose a solution that uses scene graphs as part of its input and integrates graph neural networks as its backbone, with an integrated task-driven attention mechanism, and demonstrate its better scalability and learning efficiency than state-of-the-art baselines.",
        "primary_area": "",
        "author": "Michael Lingelbach;Chengshu Li;Minjune Hwang;Andrey Kurenkov;Alan Lou;Roberto Mart\u00edn-Mart\u00edn;Ruohan Zhang;Li Fei-Fei;Jiajun Wu;Michael Lingelbach;Chengshu Li;Minjune Hwang;Andrey Kurenkov;Alan Lou;Roberto Mart\u00edn-Mart\u00edn;Ruohan Zhang;Li Fei-Fei;Jiajun Wu",
        "authorids": "/37089893502;/37087318952;/37089891864;/37085704818;/37089895510;/37085788640;/37088230763;/38273560700;/37085659126;/37089893502;/37087318952;/37089891864;/37085704818;/37089895510;/37085788640;/37088230763;/38273560700;/37085659126",
        "aff": "Department of Computer Science, Stanford University, CA, USA; Department of Computer Science, Stanford University, CA, USA; Department of Computer Science, Stanford University, CA, USA; Department of Computer Science, Stanford University, CA, USA; Department of Computer Science, Stanford University, CA, USA; University of Texas at Austin, TX, USA; Department of Computer Science, Stanford University, CA, USA; Department of Computer Science, Stanford University, CA, USA; Department of Computer Science, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161157/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1322739415223404115&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;0;0;0",
        "aff_unique_norm": "Stanford University;University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.stanford.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Stanford;UT Austin",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;0;0",
        "aff_campus_unique": "Stanford;Austin",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161053",
        "title": "Task-Oriented Stiffness Setting for a Variable Stiffness Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "The integration of variable stiffness actuators (VSA) in robotic systems endows them with intrinsic flexibility and therefore robustness to unknown disturbances. However, this characteristic presents a challenge: choosing the best intrinsic stiffness setting guaranteeing the required force ap-plication capability while keeping the system as adaptable to uncertainties as possible. This paper proposes a method to set the optimal stiffness for a multi-finger VSA hand to perform a desired manipulation task. The task is generically represented as a force (with unknown magnitude) applied along a reference direction. According to the force application's direction and the hand's kinematic state, the fingers assume a certain role to split the collective force application. We employ the endpoint stiffness ellipsoid to analyze the required finger stiffness to fulfill the task. We evaluate the optimized stiffness settings in a door opening application with an iterative adaption of the stiffness behavior to handle the unknown force requirement. The results show a successful collective behavior of the fingers, where the stiffness setting considers a task-oriented force-adaptability trade-off and effective use of independent VSA fingers.",
        "primary_area": "",
        "author": "Ana Elvira H. Martin;Ashok M. Sundaram;Werner Friedl;Virginia Ruiz Garate;M\u00e1ximo A. Roa;Ana Elvira H. Martin;Ashok M. Sundaram;Werner Friedl;Virginia Ruiz Garate;M\u00e1ximo A. Roa",
        "authorids": "/37088507433;/37086134571;/37295467000;/38251628900;/37628512100;/37088507433;/37086134571;/37295467000;/38251628900;/37628512100",
        "aff": "DLR, the Institute of Robotics and Mechatronics, German Aerospace Center, Wessling, Germany; DLR, the Institute of Robotics and Mechatronics, German Aerospace Center, Wessling, Germany; DLR, the Institute of Robotics and Mechatronics, German Aerospace Center, Wessling, Germany; Bristol Robotics Laboratory, University of the West of England, Bristol, United Kingdom; DLR, the Institute of Robotics and Mechatronics, German Aerospace Center, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161053/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14898900112031125427&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "German Aerospace Center;University of the West of England",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;Bristol Robotics Laboratory",
        "aff_unique_url": "https://www.dlr.de;https://www.uwe.ac.uk",
        "aff_unique_abbr": "DLR;UWE",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Wessling;Bristol",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "10161293",
        "title": "Task-Space Clustering for Mobile Manipulator Task Sequencing",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile manipulators have gained attention for the potential in performing large-scale tasks which are beyond the reach of fixed-base manipulators. The Robotic Task Sequencing Problem for mobile manipulators often requires optimizing the motion sequence of the robot to visit multiple targets while reducing the number of base placements. A two-step approach to this problem is clustering the task-space into clusters of targets before sequencing the robot motion. In this paper, we propose a task-space clustering method which formulates the clustering step as a Set Cover Problem using bipartite graph and reachability analysis, then solves it to obtain the minimum number of target clusters with corresponding base placements. We demonstrated the practical usage of our method in a mobile drilling experiment containing hundreds of targets. Multiple simulations were conducted to benchmark the algorithm and also showed that our proposed method found, in practical time, better solutions than the existing state-of-the-art methods.",
        "primary_area": "",
        "author": "Quang-Nam Nguyen;Nicholas Adrian;Quang-Cuong Pham;Quang-Nam Nguyen;Nicholas Adrian;Quang-Cuong Pham",
        "authorids": "/37089894805;/37088506189;/38191381800;/37089894805;/37088506189;/38191381800",
        "aff": "Singapore Centre for 3D Printing (SC3DP), Nanyang Technological University (NTU), Singapore; HP-NTU Digital Manufacturing Corporate Lab, Nanyang Technological University (NTU), Singapore; Eureka Robotics, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161293/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=680933570287022356&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Nanyang Technological University;Eureka Robotics",
        "aff_unique_dep": "Singapore Centre for 3D Printing (SC3DP);",
        "aff_unique_url": "https://www.ntu.edu.sg;",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "10160509",
        "title": "Telerobot operators can account for varying transmission dynamics in a visuo-haptic object tracking task",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans possess an innate ability to incorporate tools into our body schema to perform a myriad of tasks not possible with our natural limbs. Human-in-the-loop telerobotic systems (HiLTS) are tools that extend human manipulation capabilities to remote and virtual environments. Unlike most hand-held tools, however, HiLTS often possess complex electromechanical architectures that introduce non-trivial transmission dynamics between the robot's leader and follower, which alter or obfuscate the environment's dynamics. While considerable research has focused on negating or circumventing these dynamics, it is not well understood how capable human operators are at incorporating these transmission dynamics into their sensorimotor control scheme. To begin answering this question, we recruited \\mathrm{N}=12\\mathrm{N}=12 participants to use a novel reconfigurable teleoperator with varying transmission dynamics to perform a visuo-haptic tracking task. Contrary to our original hypothesis, our findings demonstrate that humans can account for substantial differences in teleoperator transmission dynamics and produce the compensatory strategies necessary to adequately control the teleoperator. These findings suggest that advances in transparency algorithms and haptic feedback approaches must be coupled with control designs that leverage the unique capabilities of the human operator in the loop.",
        "primary_area": "",
        "author": "Mohit Singhala;Jeremy D. Brown;Mohit Singhala;Jeremy D. Brown",
        "authorids": "/37088396940;/38556961200;/37088396940;/38556961200",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160509/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5584899278844890659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160335",
        "title": "Temporal Logic Swarm Control with Splitting and Merging",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an agent-agnostic framework to control swarms of robots tasked with temporal and logical missions expressed as Metric Temporal Logic (MTL) formulas. We consider agents that can receive global commands from a high-level planner, but no inter-agent communication. Moreover, agents are grouped into sub-swarms whose number can vary over the mission time horizon due to splitting and merging. However, a strict upper bound on the maximum number of sub-swarms is imposed to ensure their safe operation in the environment. We propose a two-phase approach. In the first phase, we compute the trajectories of the sub-swarms, splitting, and merging actions using a Mixed Integer Linear Programming approach that ensures the satisfaction of the MTL specification with minimal swarm division over the mission time horizon. Moreover, it enforces the upper bound on the number of sub-swarms. In the second phase, splitting fractions for sub-swarms resulting from splitting actions are computed. A distributed randomized protocol with no interagent communication ensures agent assignments matching the splitting fractions. Finally, we show the operation and performance of the approach in simulations with multiple tasks that require swarm splitting or merging.",
        "primary_area": "",
        "author": "Gustavo A. Cardona;Kevin Leahy;Cristian-Ioan Vasile;Gustavo A. Cardona;Kevin Leahy;Cristian-Ioan Vasile",
        "authorids": "/37085799776;/37085596244;/37085532895;/37085799776;/37085596244;/37085532895",
        "aff": "Dept. of Mechanical Engineering and Mechanics, Lehigh University, Bethlehem, PA, USA; Lincoln Laboratory, Massachusetts Institute of Technology, Lexington, MA, USA; Dept. of Mechanical Engineering and Mechanics, Lehigh University, Bethlehem, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160335/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4351965738940230913&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Lehigh University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Dept. of Mechanical Engineering and Mechanics;Lincoln Laboratory",
        "aff_unique_url": "https://www.lehigh.edu;https://web.mit.edu",
        "aff_unique_abbr": "Lehigh;MIT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Bethlehem;Lexington",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160893",
        "title": "Tendon-Driven Soft Robotic Gripper with Integrated Ripeness Sensing for Blackberry Harvesting",
        "track": "main",
        "status": "Poster",
        "abstract": "Growing global demand for food, coupled with continuing labor shortages, motivate the need for automated agricultural harvesting. While some specialty crops (e.g., apples, peaches, blueberries) can be harvested via existing harvesting modalities, fruits such as blackberries and raspberries require delicate handling to mitigate fruit damage that could significantly impact marketability. This motivates the development of soft robotic solutions that enable efficient, delicate harvesting. This paper presents the design, fabrication, and feasibility testing of a tendon-driven soft gripping system focused on blackberries, which are a fragile fruit susceptible to post-harvest damage. The gripper is low-cost and small form factor, allowing for the integration of a micro-servo for tendon retraction, a near-infrared (NIR) based blackberry ripeness sensor utilizing the reflectance modality for identifying fully ripe blackberries, and an endoscopic camera for visual servoing. The gripper was used to harvest 139 berries with manual positioning in two separate field tests. Field testing found an average retention force of 2.06 N and 6.08 N for ripe and unripe blackberries, respectively. Sensor tests identified an average reflectance of 16.78 and 21.70 for ripe and unripe blackberries, respectively, indicating a clear distinction between the two ripeness levels. Finally, the soft robotic gripper was integrated onto a UR5 robot arm and successfully harvested fifteen artificial blackberries in a lab setting using visual servoing.",
        "primary_area": "",
        "author": "Alex Qiu;Claire Young;Anthony L. Gunderman;Milad Azizkhani;Yue Chen;Ai-Ping Hu;Alex Qiu;Claire Young;Anthony L. Gunderman;Milad Azizkhani;Yue Chen;Ai-Ping Hu",
        "authorids": "/37089892464;/37089896110;/37088647691;/37089295973;/37085574910;/37073227200;/37089892464;/37089896110;/37088647691;/37089295973;/37085574910;/37073227200",
        "aff": "School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, USA; Biomedical Engineering Department, Georgia Institute of Technology/Emory, Atlanta, USA; School of Electronics and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, USA; Biomedical Engineering Department, Georgia Institute of Technology/Emory, Atlanta, USA; Intelligent Sustainable Technologies Division, Georgia Tech Research Institute, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160893/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12075531808363061491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Georgia Institute of Technology;Georgia Tech Research Institute",
        "aff_unique_dep": "School of Mechanical Engineering;Intelligent Sustainable Technologies Division",
        "aff_unique_url": "https://www.gatech.edu;https://www.gtri.gatech.edu",
        "aff_unique_abbr": "Georgia Tech;GTRI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160352",
        "title": "Tentacle-Based Shape Shifting of Metamorphic Robots Using Fast Inverse Kinematics",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new approach to tackle the problem of metamorphic robots' reconfiguration. Given the chain-type metamorphic robot's initial and target configuration, we compute a reconfiguration plan that is provably physically collision-free. Our solution employs a specific heuristic. The robot initially reconfigures to a shape that resembles an octopus with many tentacles. After that, the tentacles gradually reconnect to each other using inverse kinematics, separating one tentacle from the body and keeping the other one connected. This strategy eventually leads to a snake-like structure of the robot. For the target configuration, we compute the reconfiguration plan with the same procedure, however, we reverse the plan to reconfigure the robot from the snake-like structure to the target shape. According to our experimental evaluation, our newly introduced strategy for finding reconfiguration plans is successful. It efficiently finds collision-free plans even for robots consisting of hundreds of modules.",
        "primary_area": "",
        "author": "Jan Mr\u00e1zek;Patrick Ondika;Ivana \u010cern\u00e1;Ji\u0159\u00ed Barnat;Jan Mr\u00e1zek;Patrick Ondika;Ivana \u010cern\u00e1;Ji\u0159\u00ed Barnat",
        "authorids": "/37085536357;/37089893468;/38547110900;/37063396900;/37085536357;/37089893468;/38547110900;/37063396900",
        "aff": "Faculty of Informatics, Masaryk University, Czechia; Faculty of Informatics, Masaryk University, Czechia; Faculty of Informatics, Masaryk University, Czechia; Faculty of Informatics, Masaryk University, Czechia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160352/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3780549295996036644&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Masaryk University",
        "aff_unique_dep": "Faculty of Informatics",
        "aff_unique_url": "https://www.muni.cz",
        "aff_unique_abbr": "MU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Czechia"
    },
    {
        "id": "10160773",
        "title": "Test-Time Synthetic-to-Real Adaptive Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Is it possible for a synthetic to realistic domain adapted neural network in single image depth estimation to truly generalize on real world data? The resultant, adapted model will only generalize on the realistic domain dataset, which only reflects a small portion of the true, real world. As a result, the network still has to cope with the potential danger of domain shift between the realistic domain dataset and the real world data. Instead, a viable solution is to design the model to be capable of continuously adapting to the distribution of data it receives at test-time. In this paper, we propose a depth estimation method that is capable of adapting to the domain shift at test-time. Our method adapts to the unseen test-time domain, by updating the network using our proposed objective functions. Following former work, we reduce the entropy of the current prediction for refinement and adaptation. We propose a Logit Order Enforcement loss that can prevent the network from deviating into wrong solutions, which can result from the mere reduction of the aforementioned entropy. Qualitative and quantitative results show the effectiveness of our method. Our method reduces the dependency on training data by 5.8\u00d7 on average, while achieving comparable performance to state-of-the-art unsupervised domain adaptation (UDA) and domain generalization methods (DG) on the KITTI dataset.",
        "primary_area": "",
        "author": "Eojindl Yi;Junmo Kim;Eojindl Yi;Junmo Kim",
        "authorids": "/37088689760;/37407301400;/37088689760;/37407301400",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST), Korea; Korea Advanced Institute of Science and Technology (KAIST), Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160773/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6788726374481848570&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "10161304",
        "title": "Test-time Domain Adaptation for Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Test-time domain adaptation, i.e. adapting source-pretrained models to the test data on-the-fly in a source-free, unsupervised manner, is a highly practical yet very challenging task. Due to the domain gap between source and target data, inference quality on the target domain can drop drastically especially in terms of absolute scale of depth. In addition, unsupervised adaptation can degrade the model performance due to inaccurate pseudo labels. Furthermore, the model can suffer from catastrophic forgetting when errors are accumulated over time. We propose a test-time domain adaptation framework for monocular depth estimation which achieves both stability and adaptation performance by benefiting from both self-training of the supervised branch and pseudo labels from self-supervised branch, and is able to tackle the above problems: our scale alignment scheme aligns the input features between source and target data, correcting the absolute scale inference on the target domain; with pseudo label consistency check, we select confident pixels thus improve pseudo label quality; regularisation and self-training schemes are applied to help avoid catastrophic forgetting. Without requirement of further supervisions on the target domain, our method adapts the source-trained models to the test data with significant improvements over the direct inference results, providing scale-aware depth map outputs that outperform the state-of-the-arts. Code is available at https://github.com/Malefikus/ada-depth.",
        "primary_area": "",
        "author": "Zhi Li;Shaoshuai Shi;Bernt Schiele;Dengxin Dai;Zhi Li;Shaoshuai Shi;Bernt Schiele;Dengxin Dai",
        "authorids": "/37089739278;/37856500200;/37265607300;/37531409100;/37089739278;/37856500200;/37265607300;/37531409100",
        "aff": "Saarland University Campus; Max Planck Institute for Informatics; Max Planck Institute for Informatics; Max Planck Institute for Informatics",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161304/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5280976909205858061&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Saarland University;Max Planck Institute for Informatics",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-saarland.de;https://mpi-inf.mpg.de",
        "aff_unique_abbr": "UdS;MPII",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Campus;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161501",
        "title": "Testing Rare Downstream Safety Violations via Upstream Adaptive Sampling of Perception Error Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Testing black-box perceptual-control systems in simulation faces two difficulties. Firstly, perceptual inputs in simulation lack the fidelity of real-world sensor inputs. Secondly, for a reasonably accurate perception system, encountering a rare failure trajectory may require running infeasibly many simulations. This paper combines perception error models-surrogates for a sensor-based detection system-with state-dependent adaptive importance sampling. This allows us to efficiently assess the rare failure probabilities for real-world perceptual control systems within simulation. Our experiments with an autonomous braking system equipped with an RGB obstacle-detector show that our method can calculate accurate failure probabilities with an inexpensive number of simulations. Further, we show how choice of safety metric can influence the process of learning proposal distributions capable of reliably sampling high-probability failures.",
        "primary_area": "",
        "author": "Craig Innes;Subramanian Ramamoorthy;Craig Innes;Subramanian Ramamoorthy",
        "authorids": "/37088996171;/37529920500;/37088996171;/37529920500",
        "aff": "School of Informaticsm, University of Edinburgh, Edinburgh, United Kingdom; School of Informaticsm, University of Edinburgh, Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161501/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7990676914145434496&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10161222",
        "title": "The Human Gaze Helps Robots Run Bravely and Efficiently in Crowds",
        "track": "main",
        "status": "Poster",
        "abstract": "In human-aware navigation, the robot tacitly games with humans, balancing safety and efficiency according to human intentions. Poor balance or bad intent recognition causes the robot to stop conservatively or advance rashly, resulting in a deadlock or even a collision respectively. To address the issue, this paper proposes an improved limit cycle for collaboratively parameterizing human intentions and planning robot motions. The human-robot interaction is modeled as a dynamic chicken game with incomplete information, where the human gaze is introduced to depict the unique characteristics of each person, allowing the robot to approach with different safety margins. Our method is tested in challenging indoor scenarios and outperforms traditional methods in both safety and efficiency. We enable robots to utilize human wisdom to solve problems that cannot be solved on their own. The robot bravely goes through oncoming crowds by getting closer to people with higher attention on it and has the foresight to stably cross in front or behind people.",
        "primary_area": "",
        "author": "Qianyi Zhang;Zhengxi Hu;Yinuo Song;Jiayi Pei;Jingtai Liu;Qianyi Zhang;Zhengxi Hu;Yinuo Song;Jiayi Pei;Jingtai Liu",
        "authorids": "/37088525936;/37089166249;/37089892612;/37089895057;/37405237000;/37088525936;/37089166249;/37089892612;/37089895057;/37405237000",
        "aff": "Institute of Robotics and Automatic Information System, Nankai University, Tianjin, China; Institute of Robotics and Automatic Information System, Nankai University, Tianjin, China; Institute of Robotics and Automatic Information System, Nankai University, Tianjin, China; Institute of Robotics and Automatic Information System, Nankai University, Tianjin, China; Institute of Robotics and Automatic Information System, Nankai University, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161222/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17043249737416052848&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Nankai University",
        "aff_unique_dep": "Institute of Robotics and Automatic Information System",
        "aff_unique_url": "http://www.nankai.edu.cn",
        "aff_unique_abbr": "Nankai",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tianjin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161369",
        "title": "The New Dexterity Adaptive Humanlike Robot Hand: Employing a Reconfigurable Palm for Robust Grasping and Dexterous Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots have predominantly been used in automating tasks in structured industrial environments, however, with the advances in technology they are starting to take part in roles in dynamic everyday life scenarios. As a result, the tasks executed by robotic systems will also grow in sophistication. Grasping and dexterous manipulation are critical aspects that allow humans to execute these sophisticated tasks, enabling them to interact with their environment. As such, emulating the human hand can be advantageous for interacting with a world designed for humans. However, directly replicating the anatomical structure of the hand produces designs that are fully actuated, expensive, and which require sophisticated controls and sensing to operate efficiently. In this paper, we present two different versions of the New Dexterity adaptive, humanlike robot hand that is capable of executing robust caging grasps under a wide range of environmental uncertainties (e.g., object pose uncertainties). One of the versions has a classic, fixed thumb base while the second one incorporates an additional degree of freedom at the thumb base, which enables a translational motion for repositioning the thumb and adjusting the aperture. This design choice enhances the inhand manipulation capabilities of the robot hand, improving also the power grasping capabilities for larger objects. The performances of the proposed robot hand designs are experimentally validated and compared through three different tests: i) grasping experiments involving everyday-life objects, ii) force experiments that evaluate their force exertion capabilities, and iii) in-hand manipulation experiments that demonstrate and compare their dexterity.",
        "primary_area": "",
        "author": "Geng Gao;Anany Dwivedi;Minas Liarokapis;Geng Gao;Anany Dwivedi;Minas Liarokapis",
        "authorids": "/37087027460;/37086133073;/38558084100;/37087027460;/37086133073;/38558084100",
        "aff": "Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161369/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2560958054209182038&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Auckland",
        "aff_unique_dep": "Department of Mechanical and Mechatronics Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "10161520",
        "title": "The Reflectance Field Map: Mapping Glass and Specular Surfaces in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the Reflectance Field Map, a reliable real-time method for detecting shiny surfaces, like glass, metal, and mirrors, with lidar. The Reflectance Field Map combines the theory developed for Light Field Mapping, common in computer graphics, with occupancy grid mapping. Like early methods for sonar-based robot mapping, we show how the addition of angular viewpoint information to a standard 2D grid map enables robust mapping in the presence of specular reflections. However unlike previous approaches, our method works in dynamic environments. Additionally, unlike recent approaches for lidar-based mapping of specular surfaces, our approach is sensor-agnostic and has no reliance on either intensity or multi-return measurements. We demonstrate the ability of the Reflectance Field Map to accurately map a campus environment containing numerous pedestrians and significant plate glass, both straight and curved. The algorithm runs in real-time (75+Hz) on a single core of a standard desktop processor. An open source implementation of the algorithm is available at https://github.com/collinej/reflectance_field_map.",
        "primary_area": "",
        "author": "Paul Foster;Collin Johnson;Benjamin Kuipers;Paul Foster;Collin Johnson;Benjamin Kuipers",
        "authorids": "/37077891100;/38540370800;/38532726400;/37077891100;/38540370800;/38532726400",
        "aff": "Cruise Automation, San Francisco, CA, USA; May Mobility, Ann Arbor, MI, USA; Computer Science and Engineering, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161520/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16434120723474618751&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Cruise Automation;May Mobility;University of Michigan",
        "aff_unique_dep": ";;Computer Science and Engineering",
        "aff_unique_url": "https://www.cruise.com;;https://www.umich.edu",
        "aff_unique_abbr": "Cruise;;UM",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "San Francisco;Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160628",
        "title": "The Role of Symmetry in Constructing Geometric Flat Outputs for Free-Flying Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Mechanical systems naturally evolve on principal bundles describing their inherent symmetries. The ensuing factorization of the configuration manifold into a symmetry group and an internal shape space has provided deep insights into the locomotion of many robotic and biological systems. On the other hand, the property of differential flatness has enabled efficient, effective planning and control algorithms for various robotic systems. Yet, a practical means of finding a flat output for an arbitrary robotic system remains an open question. In this work, we demonstrate surprising new connections between these two domains, for the first time employing symmetry directly to construct a flat output. We provide sufficient conditions for the existence of a trivialization of the bundle in which the group variables themselves are a flat output. We call this a geometric flat output, since it is equivariant (i.e. it preserves the symmetry) and often global or almost global, properties not typically enjoyed by other flat outputs. In such a trivialization, the motion planning problem is easily solved, since a given trajectory for the group variables will fully determine the trajectory for the shape variables that exactly achieves this motion. We provide a partial catalog of robotic systems with geometric flat outputs and worked examples for the planar rocket, planar aerial manipulator, and quadrotor.",
        "primary_area": "",
        "author": "Jake Welde;Matthew D. Kvalheim;Vijay Kumar;Jake Welde;Matthew D. Kvalheim;Vijay Kumar",
        "authorids": "/37086067619;/37089457036;/37280341400;/37086067619;/37089457036;/37280341400",
        "aff": "GRASP Laboratory, University of Pennsylvania; Department of Mathematics, University of Michigan; GRASP Laboratory, University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160628/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17934256081673629389&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Pennsylvania;University of Michigan",
        "aff_unique_dep": "GRASP Laboratory;Department of Mathematics",
        "aff_unique_url": "https://www.upenn.edu;https://www.umich.edu",
        "aff_unique_abbr": "UPenn;UM",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Philadelphia;Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160302",
        "title": "The SLAM Hive Benchmarking Suite",
        "track": "main",
        "status": "Poster",
        "abstract": "Benchmarking Simultaneous Localization and Mapping (SLAM) algorithms is important to scientists and users of robotic systems alike. But through their many configuration options in hardware and software, SLAM systems feature a vast parameter space that scientists up to now were not able to explore. The proposed SLAM Hive Benchmarking Suite is able to analyze SLAM algorithms in 1000's of mapping runs, through its utilization of container technology and deployment in a cluster. This paper presents the architecture and open source implementation of SLAM Hive and compares it to existing efforts on SLAM evaluation. Furthermore, we highlight the function of SLAM Hive by exploring some open source algorithms on public datasets in terms of accuracy. We compare the algorithms against each other and evaluate how parameters effect not only accuracy but also CPU and memory usage. Through this we show that SLAM Hive can become an essential tool for proper comparisons and evaluations of SLAM algorithms and thus drive the scientific development in the research on SLAM.",
        "primary_area": "",
        "author": "Yuanyuan Yang;Bowen Xu;Yinjie Li;S\u00f6ren Schwertfeger;Yuanyuan Yang;Bowen Xu;Yinjie Li;S\u00f6ren Schwertfeger",
        "authorids": "/37089328496;/37089893016;/37089892510;/37391715800;/37089328496;/37089893016;/37089892510;/37391715800",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160302/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17761330055526563765&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ShanghaiTech University",
        "aff_unique_dep": "School of Information Science and Technology",
        "aff_unique_url": "https://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "ShanghaiTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160394",
        "title": "The Sum of Its Parts: Visual Part Segmentation for Inertial Parameter Identification of Manipulated Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "To operate safely and efficiently alongside human workers, collaborative robots (cobots) require the ability to quickly understand the dynamics of manipulated objects. However, traditional methods for estimating the full set of inertial parameters rely on motions that are necessarily fast and unsafe (to achieve a sufficient signal-to-noise ratio). In this work, we take an alternative approach: by combining visual and force-torque measurements, we develop an inertial parameter identification algorithm that requires slow or \u201cstop-and-go\u201d motions only, and hence is ideally tailored for use around humans. Our technique, called Homogeneous Part Segmentation (HPS), leverages the observation that man-made objects are often composed of distinct, homogeneous parts. We combine a surface-based point clustering method with a volumetric shape segmentation algorithm to quickly produce a part-level segmentation of a manipulated object; the segmented representation is then used by HPS to accurately estimate the object's inertial parameters. To benchmark our algorithm, we create and utilize a novel dataset consisting of realistic meshes, segmented point clouds, and inertial parameters for 20 common workshop tools. Finally, we demonstrate the real-world performance and accuracy of HPS by performing an intricate \u2018hammer balancing act\u2019 autonomously and online with a low-cost collaborative robotic arm. Our code and dataset are open source and freely available.",
        "primary_area": "",
        "author": "Philippe Nadeau;Matthew Giamou;Jonathan Kelly;Philippe Nadeau;Matthew Giamou;Jonathan Kelly",
        "authorids": "/37088507489;/37085674428;/37085364182;/37088507489;/37085674428;/37085364182",
        "aff": "STARS Laboratory, University of Toronto Institute for Aerospace Studies, Toronto, Ontario, Canada; STARS Laboratory, University of Toronto Institute for Aerospace Studies, Toronto, Ontario, Canada; Vector Institute Faculty Affiliate",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160394/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5421384141488550269&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies;Vector Institute",
        "aff_unique_dep": "STARS Laboratory;Faculty Affiliate",
        "aff_unique_url": "https://www.ias.uToronto.ca;https://vectorinstitute.ai",
        "aff_unique_abbr": ";VI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161337",
        "title": "The Third Generation (G3) Dual-Modal and Dual Sensing Mechanisms (DMDSM) Pretouch Sensor for Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Fingertip-mounted pretouch sensors are very useful for robotic grasping. In this paper, we report a new (G3) dual-modal and dual sensing mechanisms (DMDSM) pretouch sensor for near-distance ranging and material sensing, which is based on pulse-echo ultrasound (US) and optoacoustics (OA). Different from previously reported versions, the G3 sensor utilizes a self-focused US/OA transceiver, thereby eliminating the need of a bulky parabolic reflective mirror for focusing the ultrasound and laser beams. The self-focused laser and ultrasound beams can be easily steered by a (flat) scanning mirror which expands from single-point ranging and detection to areal mapping or imaging. To verify the new design, a prototype G3 DMDSM sensor with a scanning mirror is fabricated. The US and OA ranging performances are tested in experiments. Together with the scanning mirror, thin wire targets made of same or different materials at different positions are scanned and imaged. The ranging and imaging results show that the G3 DMDSM sensor can provide new and better pretouch mapping and imaging capabilities for robotic grasping than its predecessors.",
        "primary_area": "",
        "author": "Cheng Fang;Shuangliang Li;Di Wang;Fengzhi Guo;Dezhen Song;Jun Zou;Cheng Fang;Shuangliang Li;Di Wang;Fengzhi Guo;Dezhen Song;Jun Zou",
        "authorids": "/37085893142;/37088593265;/37086453325;/37089578129;/37275586600;/37576103200;/37085893142;/37088593265;/37086453325;/37089578129;/37275586600;/37576103200",
        "aff": "Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA; Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161337/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11637098228932648412&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160478",
        "title": "The new exhibition Blind machines, a large 3D printing machine",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the further developments and preliminary results of a large 3D printing machine based on a 3 d.o.f cable-driven parallel robot (CDPR) that is used for an artistic exhibition. The printing material is a powder constituted of glass micro-beads that is deposited on a fixed trajectory so that the resulting structure collapses with time. A first exhibition has been held during the summer of 2019 and another one was scheduled to take place during ICRA 2020, that was canceled because of the Covid. The current exhibition has started on 07/09/2022 and will end on 10/14/2019. We describe in this paper the improvements of the current prototype, both on hardware and software, compared to the 2019 and 2020 versions. Between 7/9/2022 and 16/10/2022 the CDPR has run for 126 hours and has traveled on a total distance of 9km. During the period 142 layers have been deposited, representing a mass of 2.56 tons of glass powder.",
        "primary_area": "",
        "author": "J-P. Merlet;Y. Papegay;J-P. Merlet;Y. Papegay",
        "authorids": "/37277013900;/37273442000;/37277013900;/37273442000",
        "aff": "HEPHAISTOS project, Inria Sophia-Antipolis, France; HEPHAISTOS project, Inria Sophia-Antipolis, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160478/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7498737901809534128&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Inria Sophia-Antipolis",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sophia-Antipolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160215",
        "title": "Throwing Objects into A Moving Basket While Avoiding Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "The capabilities of a robot will be increased significantly by exploiting throwing behavior. In particular, throwing will enable robots to rapidly place the object into the target basket, located outside its feasible kinematic space, without traveling to the desired location. In previous approaches, the robot often learned a parameterized throwing kernel through analytical approaches, imitation learning, or hand-coding. There are many situations in which such approaches do not work/generalize well due to various object shapes, heterogeneous mass distribution, and also obstacles that might be presented in the environment. It is obvious that a method is needed to modulate the throwing kernel through its meta-parameters. In this paper, we tackle object throwing problem through a deep reinforcement learning approach that enables robots to precisely throw objects into a moving basket while there is an obstacle obstructing the path. To the best of our knowledge, we are the first group that addresses throwing objects with obstacle avoidance. Such a throwing skill not only increases the physical reachability of a robotic arm but also improves the execution time. In particular, the robot detects the pose of the target object, basket, and obstacle at each time step, predicts the proper grasp configuration for the target object, and then infers appropriate parameters to throw the object into the basket. Due to safety constraints, we develop a simulation environment in Gazebo to train the robot and then use the learned policy in real-robot directly. To assess the performers of the proposed approach, we perform extensive sets of experiments in both simulation and real-robot in three scenarios. Experimental results showed that the robot could precisely throw a target object into the basket outside its kinematic range and generalize well to new locations and objects without colliding with obstacles. The video of our experiments can be found at https://youtu.be/VmIFF__c_84. Show More",
        "primary_area": "",
        "author": "Hamidreza Kasaei;Mohammadreza Kasaei;Hamidreza Kasaei;Mohammadreza Kasaei",
        "authorids": "/37088515518;/37089894512;/37088515518;/37089894512",
        "aff": "Department of Artificial Intelligence, Faculty of Science and Engineering, Bernoulli Institute, University of Groningen, The Netherlands; School of Informatics, University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160215/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16624049927823343210&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Groningen;University of Edinburgh",
        "aff_unique_dep": "Department of Artificial Intelligence;School of Informatics",
        "aff_unique_url": "https://www.rug.nl;https://www.ed.ac.uk",
        "aff_unique_abbr": "RUG;Edinburgh",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Edinburgh",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Netherlands;United Kingdom"
    },
    {
        "id": "10160250",
        "title": "Topological Trajectory Prediction with Homotopy Classes",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory prediction in a cluttered environment is key to many important robotics tasks such as autonomous navigation. However, there are an infinite number of possible trajectories to consider. To simplify the space of trajectories under consideration, we utilise homotopy classes to partition the space into countably many mathematically equivalent classes. All members within a class demonstrate identical high-level motion with respect to the environment, i.e., travelling above or below an obstacle. This allows high-level prediction of a trajectory in terms of a sparse label identifying its homotopy class. We therefore present a light-weight learning framework based on variable-order Markov processes to learn and predict homotopy classes and thus high-level agent motion. By informing a Gaussian mixture model (GMM) with our homotopy class predictions, we see great improvements in low-level trajectory prediction compared to a naive GMM on a real dataset.",
        "primary_area": "",
        "author": "Jennifer Wakulicz;Ki Myung Brian Lee;Teresa Vidal-Calleja;Robert Fitch;Jennifer Wakulicz;Ki Myung Brian Lee;Teresa Vidal-Calleja;Robert Fitch",
        "authorids": "/37088996209;/37088506983;/37085384801;/38466367800;/37088996209;/37088506983;/37085384801;/38466367800",
        "aff": "Jennifer Wakulicz; Ki Myung Brian Lee; Teresa Vidal-Calleja; Robert Fitch",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160250/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9507310845204812732&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "10161483",
        "title": "Topology Matching of Branched Deformable Linear Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new method for correspondence estimation between a previously known topology of a branched deformable linear object and an image representation from a 3D stereo camera. Although frequently encountered in production, robotic deformable linear object manipulation still lacks reliable sensor feedback. Especially for branched deformable linear objects, such as wire harnesses, correspondence estimation is very challenging. Due to their flexible nature, they have an infinite-dimensional configuration space, such that visual appearances of the same object can vary strongly. Knowing the correspondence is vital for various applications, e.g., estimating valid grasping positions for robotic wire routing or augmented reality support for workers. Therefore, this paper presents a method for matching the topology of a branched deformable linear object to camera sensor data. Asymmetries in the wire harness design reduce the solution space by comparing the known topology of a model to the topology extracted from sensor data. The problem of finding the most likely solution to the matching problem requires features extracted from camera images. These features are used to construct a graph-based topology representation, which can then be matched to a graph-based topology representation of the known branched deformable linear object. The presented method is evaluated using multiple different non-overlapping configurations of a wire harness, showing the effectiveness of a graph-based segment matching approach.",
        "primary_area": "",
        "author": "Manuel Z\u00fcrn;Markus Wnuk;Armin Lechler;Alexander Verl;Manuel Z\u00fcrn;Markus Wnuk;Armin Lechler;Alexander Verl",
        "authorids": "/37088557582;/37086333039;/37085362328;/37370221100;/37088557582;/37086333039;/37085362328;/37370221100",
        "aff": "Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany; Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany; Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany; Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161483/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8534701868766233058&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Stuttgart",
        "aff_unique_dep": "Institute for Control Engineering of Machine Tools and Manufacturing Units",
        "aff_unique_url": "https://www.uni-stuttgart.de",
        "aff_unique_abbr": "Uni Stuttgart",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160333",
        "title": "Topology-Based MPC for Automatic Footstep Placement and Contact Surface Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art approaches to footstep planning assume reduced-order dynamics when solving the combinatorial problem of selecting contact surfaces in real time. However, in exchange for computational efficiency, these approaches ignore joint torque limits and limb dynamics. In this work, we address these limitations by presenting a topology-based approach that enables model predictive control (MPC) to simultaneously plan full-body motions, torque commands, footstep placements, and contact surfaces in real time. To determine if a robot's foot is inside a contact surface, we borrow the winding number concept from topology. We then use this winding number and potential field to create a contact-surface penalty function. By using this penalty function, MPC can select a contact surface from all candidate surfaces in the vicinity and determine footstep placements within it. We demonstrate the benefits of our approach by showing the impact of considering full-body dynamics, which includes joint torque limits and limb dynamics, on the selection of footstep placements and contact surfaces. Furthermore, we validate the feasibility of deploying our topology-based approach in an MPC scheme and explore its potential capabilities through a series of experimental and simulation trials.",
        "primary_area": "",
        "author": "Jaehyun Shim;Carlos Mastalli;Thomas Corb\u00e8res;Steve Tonneau;Vladimir Ivan;Sethu Vijayakumar;Jaehyun Shim;Carlos Mastalli;Thomas Corb\u00e8res;Steve Tonneau;Vladimir Ivan;Sethu Vijayakumar",
        "authorids": "/37089891999;/37085537096;/37088997400;/37085790049;/37085552022;/37295595500;/37089891999;/37085537096;/37088997400;/37085790049;/37085552022;/37295595500",
        "aff": "School of Informatics, University of Edinburgh, U.K.; Institute of Sensors, Signals and Systems, School of Engineering and Physical Sciences, Heriot-Watt University, U.K.; School of Informatics, University of Edinburgh, U.K.; School of Informatics, University of Edinburgh, U.K.; Touchlab Limited, U.K.; School of Informatics, University of Edinburgh, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160333/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15162852146243885041&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;0",
        "aff_unique_norm": "University of Edinburgh;Heriot-Watt University;Touchlab Limited",
        "aff_unique_dep": "School of Informatics;Institute of Sensors, Signals and Systems;",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.hw.ac.uk;",
        "aff_unique_abbr": "Edinburgh;HWU;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160693",
        "title": "Torque Control with Joints Position and Velocity Limits Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "The design of a control architecture for providing the desired motion along with the realization of the joint limitation of a robotic system is still an open challenge in control and robotics. This paper presents a torque control architecture for fully actuated manipulators for tracking the desired time-varying trajectory while ensuring the joints position and velocity limits. The presented architecture stems from the parametrization of the feasible joints position and velocity space by exogenous states. The proposed parametrization transforms the control problem with constrained states to an un-constrained one by replacing the joints position and velocity with the exogenous states. With the help of Lyapunov-based arguments, we prove that the proposed control architecture ensures the stability and convergence of the desired joint trajectory along with the joints position and velocity limits avoidance. We validate the performance of proposed architecture through various simulations on a simple two-degree-of-freedom manipulator and the humanoid robot iCub.",
        "primary_area": "",
        "author": "Venus Pasandi;Daniele Pucci;Venus Pasandi;Daniele Pucci",
        "authorids": "/37088338487;/37706167200;/37088338487;/37706167200",
        "aff": "Artificial and Mechanical Intelligence, Italian Institute of Technology, Genoa, Italy; Artificial and Mechanical Intelligence, Italian Institute of Technology, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160693/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3301053764412593124&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Italian Institute of Technology",
        "aff_unique_dep": "Artificial and Mechanical Intelligence",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "10161297",
        "title": "Torque-Limited Manipulation Planning through Contact by Interleaving Graph Search and Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots often have to perform manipulation tasks in close proximity to people (Fig 1). As such, it is desirable to use a robot arm that has limited joint torques so as to not injure the nearby person. Unfortunately, these limited torques then limit the payload capability of the arm. By using contact with the environment, robots can expand their reachable workspace that, otherwise, would be inaccessible due to exceeding actuator torque limits. We adapt our recently developed INSAT algorithm [1] to tackle the problem of torque-limited whole arm manipulation planning through contact. INSAT requires no prior over contact mode sequence and no initial template or seed for trajectory optimization. INSAT achieves this by interleaving graph search to explore the manipulator joint configuration space with incremental trajectory optimizations seeded by neighborhood solutions to find a dynamically feasible trajectory through contact. We demonstrate our results on a variety of manipulators and scenarios in simulation. We also experimentally show our planner exploiting robot-environment contact for the pick and place of a payload using a Kinova Gen3 robot. In comparison to the same trajectory running in free space, we experimentally show that the utilization of bracing contacts reduces the overall torque required to execute the trajectory.",
        "primary_area": "",
        "author": "Ramkumar Natarajan;Garrison L.H. Johnston;Nabil Simaan;Maxim Likhachev;Howie Choset;Ramkumar Natarajan;Garrison L.H. Johnston;Nabil Simaan;Maxim Likhachev;Howie Choset",
        "authorids": "/37086335184;/37086937947;/37282380300;/37309318800;/37281322200;/37086335184;/37086937947;/37282380300;/37309318800;/37281322200",
        "aff": "The Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Department of Mechanical Engineering, Vanderbilt University; Department of Mechanical Engineering, Vanderbilt University; The Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute at Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161297/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5361985034818393382&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Vanderbilt University",
        "aff_unique_dep": "The Robotics Institute;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.vanderbilt.edu",
        "aff_unique_abbr": "CMU;Vanderbilt",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160400",
        "title": "Touch Classification on Robotic Skin using Multimodal Tactile Sensing Modules",
        "track": "main",
        "status": "Poster",
        "abstract": "Human employs different touch patterns to convey diverse social messages; for example, a stroke is an encouragement, whereas a hit is an offense. Various tactile sensors have been developed to grant an intuitive physical interaction with a robotic system, yet many encountered limitations in achieving broad sensibility or fabricating into a large skin. This paper presents a robotic skin with multimodal tactile sensing modules to achieve broad spatiotemporal sensibility with a few sensing elements. The multimodal module is composed of a microphone and a vented screw installed on a conductive sensory domain. A multilayered fabric with a textured surface covers the sensory domain and forms a piezoresistive structure. High and low temporal components of touch elicit a micro-vibration and a conductivity change on the skin, where both are measured with multimodal modules. The measurements are each processed with short-time Fourier transform (STFT) and electrical resistance tomography (ERT) to encode two spatiotemporal feature maps, which are classified into ten touch classes using a convolutional neural network. Due to a sensibility to both high and low temporal components of touch, the skin classifies touches with an accuracy of 97.0 %, whereas only 84.7 % and 90.6 % are achieved when one type of feature map is used. Also, the skin is robust and beneficial in power consumption and fabrication since the multimodal modules are not exposed to an external stimulus and are sparsely distributed.",
        "primary_area": "",
        "author": "Min Jin Yang;Junhwi Cho;Hyunjo Chung;Kyungseo Park;Jung Kim;Min Jin Yang;Junhwi Cho;Hyunjo Chung;Kyungseo Park;Jung Kim",
        "authorids": "/37088997191;/37088356121;/37089894007;/37067235600;/37407273800;/37088997191;/37088356121;/37089894007;/37067235600;/37407273800",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, University of Illinois Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160400/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15329693516944726416&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;https://illinois.edu",
        "aff_unique_abbr": "KAIST;UIUC",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Daejeon;Urbana",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "10160714",
        "title": "Toward Cooperative 3D Object Reconstruction with Multi-agent",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of object reconstruction in a multi-agent collaboration scenario. Specifically, we focus on the reconstruction of specific goals through several cooperative agents equipped with vision sensors to achieve higher efficiency than single agents. Our main insight is that a complete 3D object can be split into several local 3D models and assigned to different agents. In addition, we can use the salient characteristics of the collaboration agent itself to help realize the integration of local models. We develop a novel pipeline that first restores local 3D models from the images obtained from different agents, then the relative poses between collaborative agents are estimated by aligning intrinsic features. After that, all local models are integrated using the estimated parameters. Extensive experiments show that our proposed method is capable of accurately reconstructing 3D objects in the real world in a multi-agent collaborative manner. The full reconstruction pipeline is released to the public as an open-source project.",
        "primary_area": "",
        "author": "Xiong Li;Zhenyu Wen;Leiqiang Zhou;Chenwei Li;Yejian Zhou;Taotao Li;Zhen Hong;Xiong Li;Zhenyu Wen;Leiqiang Zhou;Chenwei Li;Yejian Zhou;Taotao Li;Zhen Hong",
        "authorids": "/37089576136;/37085432604;/37089573525;/37089818071;/37086271035;/37089895263;/37088662643;/37089576136;/37085432604;/37089573525;/37089818071;/37086271035;/37089895263;/37088662643",
        "aff": "Institute of Cyberspace Security and the College of Engineering, Zhejiang University of Technology; Institute of Cyberspace Security and the College of Engineering, Zhejiang University of Technology; Institute of Cyberspace Security and the College of Engineering, Zhejiang University of Technology; Institute of Cyberspace Security and the College of Engineering, Zhejiang University of Technology; Institute of Cyberspace Security and the College of Engineering, Zhejiang University of Technology; Institute of Cyberspace Security and the College of Engineering, Zhejiang University of Technology; Institute of Cyberspace Security and the College of Engineering, Zhejiang University of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160714/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7722725255438984465&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University of Technology",
        "aff_unique_dep": "Institute of Cyberspace Security and the College of Engineering",
        "aff_unique_url": "https://www.zjut.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160351",
        "title": "Toward Efficient Physical and Algorithmic Design of Automated Garages",
        "track": "main",
        "status": "Poster",
        "abstract": "Parking in large metropolitan areas is often a time-consuming task with further implications for traffic patterns that affect urban landscaping. Reducing the premium space needed for parking has led to the development of automated mechanical parking systems. Compared to regular garages having one or two rows of vehicles on each island, automated garages can have multiple rows of vehicles stacked together to support higher parking demands. Although this multi-row layout reduces parking space, it makes parking and retrieval more complicated. In this work, we propose an automated garage design that supports nearly 100% parking density. Modeling the problem of parking and retrieving multiple vehicles as a special class of multi-robot path planning problem, we propose associated algorithms for handling all common operations of the automated garage, including (1) optimal algorithm and near-optimal methods that find feasible and efficient solutions for simultaneous parking/retrieval and (2) a novel shuffling mechanism to rearrange vehicles to facilitate scheduled retrieval at rush hours. We conduct thorough simulation studies showing the proposed methods are promising for large and high-density real-world parking applications.",
        "primary_area": "",
        "author": "Teng Guo;Jingjin Yu;Teng Guo;Jingjin Yu",
        "authorids": "/37088998158;/37536570700;/37088998158;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160351/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13145110257884043350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161224",
        "title": "Toward Fine Contact Interactions: Learning to Control Normal Contact Force with Limited Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Dexterous manipulation of objects through fine control of physical contacts is essential for many important tasks of daily living. A fundamental ability underlying fine contact control is compliant control, i.e., controlling the contact forces while moving. For robots, the most widely explored approaches heavily depend on models of manipulated objects and expensive sensors to gather contact location and force information needed for real-time control. The models are difficult to obtain, and the sensors are costly, hindering personal robots' adoption in our homes and businesses. This study performs model-free reinforcement learning of a normal contact force controller on a robotic manipulation system built with a low-cost, information-poor tactile sensor. Despite the limited sensing capability, our force controller can be combined with a motion controller to enable fine contact interactions during object manipulation. Promising results are demonstrated in non-prehensile, dexterous manipulation experiments.",
        "primary_area": "",
        "author": "Jinda Cui;Jiawei Xu;David Saldana;Jeff Trinkle;Jinda Cui;Jiawei Xu;David Saldana;Jeff Trinkle",
        "authorids": "/37089893726;/37088996257;/38543033800;/37281356500;/37089893726;/37088996257;/38543033800;/37281356500",
        "aff": "Lehigh AIRLab, Honda Research Institute USA, San Jose, CA, USA; Department of Computer Science and Engineering, Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, Bethleham, PA, USA; Department of Computer Science and Engineering, Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, Bethleham, PA, USA; Department of Computer Science and Engineering, Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, Bethleham, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161224/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7119019073121696301&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Honda Research Institute USA;Lehigh University",
        "aff_unique_dep": "Honda Research Institute;Department of Computer Science and Engineering",
        "aff_unique_url": "https://honda-ri.com;https://www.lehigh.edu",
        "aff_unique_abbr": "HRI;Lehigh",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "San Jose;Bethlehem",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160384",
        "title": "Toward Zero-Shot Sim-to-Real Transfer Learning for Pneumatic Soft Robot 3D Proprioceptive Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Pneumatic soft robots present many advantages in manipulation tasks. Notably, their inherent compliance makes them safe and reliable in unstructured and fragile environments. However, full-body shape sensing for pneumatic soft robots is challenging because of their high degrees of freedom and complex deformation behaviors. Vision-based proprioception sensing methods relying on embedded cameras and deep learning provide a good solution to proprioception sensing by extracting the full-body shape information from the high-dimensional sensing data. But the current training data collection process makes it difficult for many applications. To address this challenge, we propose and demonstrate a robust sim-to-real pipeline that allows the collection of the soft robot's shape information in high-fidelity point cloud representation. The model trained on simulated data was evaluated with real internal camera images. The results show that the model performed with averaged Chamfer distance of 8.85 mm and tip position error of 10.12 mm even with external perturbation for a pneumatic soft robot with a length of 100.0 mm. We also demonstrated the sim-to-real pipeline's potential for exploring different configurations of visual patterns to improve vision-based reconstruction results. The code and dataset are available at https://github.com/DeepSoRo/DeepSoRoSim2Real.",
        "primary_area": "",
        "author": "Uksang Yoo;Hanwen Zhao;Alvaro Altamirano;Wenzhen Yuan;Chen Feng;Uksang Yoo;Hanwen Zhao;Alvaro Altamirano;Wenzhen Yuan;Chen Feng",
        "authorids": "/37088939475;/37089895412;/37089895789;/37085486405;/37086391326;/37088939475;/37089895412;/37089895789;/37085486405;/37086391326",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160384/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11304362269071643226&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Carnegie Mellon University;New York University",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.nyu.edu",
        "aff_unique_abbr": "CMU;NYU",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Pittsburgh;Brooklyn",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161506",
        "title": "Towards Autonomous UAV Railway DC Line Recharging: Design and Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomously recharging UAVs from existing infrastructure has enormous potential for various applications, such as infrastructure inspection, surveillance, and search and rescue. While it is an active area of research, most related work focuses on alternating current (AC) infrastructure while very little work has been done on investigating the potential of recharging UAVs from direct current (DC) infrastructure. This work proposes a UAV system designed to autonomously recharge from existing DC infrastructure. Two onboard powerline grippers and a motorized cable drum enable the UAV to perform a two-stage landing on railway DC lines where a wire is connected between them through the UAV for recharging. Light-weight electronics designed to be carried by the UAV are developed to harvest energy from up to 3kV DC railway lines. The recharge mission is autonomously executed using fully onboard and real-time perception and trajectory planning and tracking algorithms. The potential of the system is shown in lab setting validation, with hardware-in-the-loop simulation, and partly in a real overhead powerline environment, verifying the functionality of the sub-components.",
        "primary_area": "",
        "author": "Frederik Falk Nyboe;Nicolaj Haarh\u00f8j Malle;Gerd vom B\u00f6gel;Linda Cousin;Thomas Heckel;Konstantin Troidl;Anders Schack Madsen;Emad Ebeid;Frederik Falk Nyboe;Nicolaj Haarh\u00f8j Malle;Gerd vom B\u00f6gel;Linda Cousin;Thomas Heckel;Konstantin Troidl;Anders Schack Madsen;Emad Ebeid",
        "authorids": "/37088919143;/37088919032;/37396840900;/37088526864;/37085730726;/37089894755;/37089895176;/38233264800;/37088919143;/37088919032;/37396840900;/37088526864;/37085730726;/37089894755;/37089895176;/38233264800",
        "aff": "Drone Infrastructure Inspection and Interaction (DIII), University of Southern Denmark (SDU); Drone Infrastructure Inspection and Interaction (DIII), University of Southern Denmark (SDU); Fraunhofer IMS; Fraunhofer IMS; Fraunhofer IISB; Fraunhofer IISB; Drone Infrastructure Inspection and Interaction (DIII), University of Southern Denmark (SDU); Drone Infrastructure Inspection and Interaction (DIII), University of Southern Denmark (SDU)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161506/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10248226654386728722&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;1;1;1;0;0",
        "aff_unique_norm": "University of Southern Denmark;Fraunhofer Institute for Integrated Systems and Device Technology",
        "aff_unique_dep": "Drone Infrastructure Inspection and Interaction (DIII);",
        "aff_unique_url": "https://www.sdu.dk;https://www.ims.fraunhofer.de/",
        "aff_unique_abbr": "SDU;Fraunhofer IMS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;1;1;1;0;0",
        "aff_country_unique": "Denmark;Germany"
    },
    {
        "id": "10160531",
        "title": "Towards Bridging the Space Domain Gap for Satellite Pose Estimation using Event Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep models trained using synthetic data require domain adaptation to bridge the gap between the simulation and target environments. State-of-the-art domain adaptation methods often demand sufficient amounts of (unlabelled) data from the target domain. However, this need is difficult to fulfil when the target domain is an extreme environment, such as space. In this paper, our target problem is close proximity satellite pose estimation, where it is costly to obtain images of satellites from actual rendezvous missions. We demonstrate that event sensing offers a promising solution to generalise from the simulation to the target domain under stark illumination differences. Our main contribution is an event-based satellite pose estimation technique, trained purely on synthetic event data with basic data augmentation to improve robustness against practical (noisy) event sensors. Underpinning our method is a novel dataset with carefully calibrated ground truth, comprising of real event data obtained by emulating satellite rendezvous scenarios in the lab under drastic lighting conditions. Results on the dataset showed that our event-based satellite pose estimation method, trained only on synthetic data without adaptation, could generalise to the target domain effectively.",
        "primary_area": "",
        "author": "Mohsi Jawaid;Ethan Elms;Yasir Latif;Tat-Jun Chin;Mohsi Jawaid;Ethan Elms;Yasir Latif;Tat-Jun Chin",
        "authorids": "/37089892292;/37089892251;/38541523400;/37411757200;/37089892292;/37089892251;/38541523400;/37411757200",
        "aff": "Sentient Satellites Laboratory (SSL), Australian Institute for Machine Learning (AIML), Adelaide, Australia; Sentient Satellites Laboratory (SSL), Australian Institute for Machine Learning (AIML), Adelaide, Australia; Sentient Satellites Laboratory (SSL), Australian Institute for Machine Learning (AIML), Adelaide, Australia; Sentient Satellites Laboratory (SSL), Australian Institute for Machine Learning (AIML), Adelaide, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160531/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2889441800295239861&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Australian Institute for Machine Learning",
        "aff_unique_dep": "Sentient Satellites Laboratory",
        "aff_unique_url": "https://www.aiml.edu.au",
        "aff_unique_abbr": "AIML",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Adelaide",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160257",
        "title": "Towards Consistent Batch State Estimation Using a Time-Correlated Measurement Noise Model",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an algorithm for learning time-correlated measurement covariances for application in batch state estimation. We parameterize the inverse measurement covariance matrix to be block-banded, which conveniently factorizes and results in a computationally efficient approach for correlating measurements across the entire trajectory. We train our covariance model through supervised learning using the groundtruth trajectory. In applications where the measurements are time-correlated, we demonstrate improved performance in both the mean posterior estimate and the covariance (i.e., improved estimator consistency). We use an experimental dataset collected using a mobile robot equipped with a laser rangefinder to demonstrate the improvement in performance. We also verify estimator consistency in a controlled simulation using a statistical test over several trials.",
        "primary_area": "",
        "author": "David J. Yoon;Timothy D. Barfoot;David J. Yoon;Timothy D. Barfoot",
        "authorids": "/37086573785;/37283734000;/37086573785;/37283734000",
        "aff": "University of Toronto Institute for Aerospace Studies (UTIAS), Dufferin St, Ontario, Canada; University of Toronto Institute for Aerospace Studies (UTIAS), Dufferin St, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160257/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5559743140523480257&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies",
        "aff_unique_dep": "Institute for Aerospace Studies",
        "aff_unique_url": "https://utias.utoronto.ca",
        "aff_unique_abbr": "UTIAS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160816",
        "title": "Towards Efficient Gas Leak Detection in Built Environments: Data-Driven Plume Modeling for Gas Sensing Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The deployment of robots for Gas Source Localization (GSL) tasks in hazardous scenarios significantly reduces the risk to humans and animals. Gas sensing using mobile robots focuses primarily on simplified scenarios, due to the complexity of gas dispersion, with a current trend towards tackling more complex environments. However, most state-of-art GSL algorithms for environments with obstacles only depend on local information, leading to low efficiency in large and more structured spaces. The efficiency of GSL can be improved dramatically by coupling it with a global knowledge of gas distribution in the environment. However, since gas dispersion in a built environment is difficult to model analytically, most previous work incorporating a gas dispersion model was tested under simplified assumptions, which do not take into consideration the impact of the presence of obstacles to the airflow and gas plume. In this paper, we propose a probabilistic algorithm that enables a robot to efficiently localize gas sources in built environments, by combining a state-of-the-art probabilistic GSL algorithm, Source Term Estimation (STE) with a learned plume model. The pipeline of generating gas dispersion datasets from realistic simulations, the training and validation of the model, as well as the integration of the learned model with the STE framework are presented. The performance of the algorithm is validated both in high-fidelity simulations and real experiments, with promising results obtained under various obstacle configurations.",
        "primary_area": "",
        "author": "Wanting Jin;Faezeh Rahbar;Chiara Ercolani;Alcherio Martinoli;Wanting Jin;Faezeh Rahbar;Chiara Ercolani;Alcherio Martinoli",
        "authorids": "/37089892336;/37085499491;/37086574560;/37325252600;/37089892336;/37085499491;/37086574560;/37325252600",
        "aff": "Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160816/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1242860186341020228&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL)",
        "aff_unique_dep": "School of Architecture, Civil and Environmental Engineering",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10160330",
        "title": "Towards Efficient Trajectory Generation for Ground Robots beyond 2D Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "With the development of robotics, ground robots are no longer limited to planar motion. Passive height variation due to complex terrain and active height control provided by special structures on robots require a more general navigation planning framework beyond 2D. Existing methods rarely considers both simultaneously, limiting the capabilities and applications of ground robots. In this paper, we proposed an optimization-based planning framework for ground robots considering both active and passive height changes on the z-axis. The proposed planner first constructs a penalty field for chassis motion constraints defined in \\mathbb{R}^{3}\\mathbb{R}^{3} such that the optimal solution space of the trajectory is continuous, resulting in a high-quality smooth chassis trajectory. Also, by constructing custom constraints in the z-axis direction, it is possible to plan trajectories for different types of ground robots which have z-axis degree of freedom. We performed simulations and real-world experiments to verify the efficiency and trajectory quality of our algorithm.",
        "primary_area": "",
        "author": "Jingping Wang;Long Xu;Haoran Fu;Zehui Meng;Chao Xu;Yanjun Cao;Ximin Lyu;Fei Gao;Jingping Wang;Long Xu;Haoran Fu;Zehui Meng;Chao Xu;Yanjun Cao;Ximin Lyu;Fei Gao",
        "authorids": "/37089895912;/37089894518;/37089895328;/37089894954;/37404060100;/37086452719;/37086000704;/37086045143;/37089895912;/37089894518;/37089895328;/37089894954;/37404060100;/37086452719;/37086000704;/37086045143",
        "aff": "Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; School of Intelligent Systems Engineering, Sun Yat-sen University, Shenzhen, China; Applicaion Innovation Laboratory, Huawei Technologies Co., Ltd.; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; School of Intelligent Systems Engineering, Sun Yat-sen University, Shenzhen, China; Huzhou Institute of Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160330/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10197847348375268584&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;2;0;0;1;0",
        "aff_unique_norm": "Zhejiang University;Sun Yat-sen University;Huawei Technologies Co., Ltd.",
        "aff_unique_dep": ";School of Intelligent Systems Engineering;Applicaion Innovation Laboratory",
        "aff_unique_url": "http://www.zju.edu.cn;http://www.sysu.edu.cn/;https://www.huawei.com",
        "aff_unique_abbr": "ZJU;SYSU;Huawei",
        "aff_campus_unique_index": "0;0;1;0;0;1;0",
        "aff_campus_unique": "Huzhou;Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160835",
        "title": "Towards Exact Interaction Force Control for Underactuated Quadrupedal Systems with Orthogonal Projection and Quadratic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Projected Inverse Dynamics Control (PIDC) is commonly used in robots subject to contact, especially in quadrupedal systems. Many methods based on such dynamics have been developed for quadrupedal locomotion tasks, and only a few works studied simple interactions between the robot and environment, such as pressing an E-stop button. To facilitate the interaction requiring exact force control for safety, we propose a novel interaction force control scheme for under-actuated quadrupedal systems relying on projection techniques and Quadratic Programming (QP). This algorithm allows the robot to apply a desired interaction force to the environment without using force sensors while satisfying physical constraints and inducing minimal base motion. Unlike previous projection-based methods, the QP design uses two selection matrices in its hierarchical structure, facilitating the decoupling between force and motion control. The proposed algorithm is verified with a quadrupedal robot in a high-fidelity simulator. Compared to the QP designs without the strategy of using two selection matrices and the PIDC method for contact force control, our method provided more accurate contact force tracking performance with minimal base movement, paving the way to approach the exact interaction force control for underactuated quadrupedal systems.",
        "primary_area": "",
        "author": "Shengzhi Wang;Xiangyu Chu;K. W. Samuel Au;Shengzhi Wang;Xiangyu Chu;K. W. Samuel Au",
        "authorids": "/37089894730;/37086437251;/37435246800;/37089894730;/37086437251;/37435246800",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160835/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12387487039566612651&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161073",
        "title": "Towards Generalized Robot Assembly through Compliance-Enabled Contact Formations",
        "track": "main",
        "status": "Poster",
        "abstract": "Contact can be conceptualized as a set of constraints imposed on two bodies that are interacting with one another in some way. The nature of a contact, whether a point, line, or surface, dictates how these bodies are able to move with respect to one another given a force, and a set of contacts can provide either partial or full constraint on a body's motion. Decades of work have explored how to explicitly estimate the location of a contact and its dynamics, e.g., frictional properties, but investigated methods have been computationally expensive and there often exists significant uncertainty in the final calculation. This has affected further advancements in contact-rich tasks that are seemingly simple to humans, such as generalized peg-in-hole insertions. In this work, instead of explicitly estimating the individual contact dynamics between an object and its hole, we approach this problem by investigating compliance-enabled contact formations. More formally, contact formations are defined according to the constraints imposed on an object's available degrees-of-freedom. Rather than estimating individual contact positions, we abstract out this calculation to an implicit representation, allowing the robot to either acquire, maintain, or release constraints on the object during the insertion process, by monitoring forces enacted on the end effector through time. Using a compliant robot, our method is desirable in that we are able to complete industry-relevant insertion tasks of tolerances <0.25mm without prior knowledge of the exact hole location or its orientation. We showcase our method on more generalized insertion tasks, such as commercially available non-cylindrical objects and open world plug tasks.",
        "primary_area": "",
        "author": "Andrew S. Morgan;Quentin Bateux;Mei Hao;Aaron M. Dollar;Andrew S. Morgan;Quentin Bateux;Mei Hao;Aaron M. Dollar",
        "authorids": "/37086455182;/37085358020;/37089895202;/37604732600;/37086455182;/37085358020;/37089895202;/37604732600",
        "aff": "Department of Mechanical Engineering and Materials Science, Yale University, USA; Department of Mechanical Engineering and Materials Science, Yale University, USA; Department of Mechanical Engineering and Materials Science, Yale University, USA; Department of Mechanical Engineering and Materials Science, Yale University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161073/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4392572968909215677&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Yale University",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science",
        "aff_unique_url": "https://www.yale.edu",
        "aff_unique_abbr": "Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161217",
        "title": "Towards Human-Robot Collaboration with Parallel Robots by Kinetostatic Analysis, Impedance Control and Contact Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Parallel robots provide the potential to be lever-aged for human-robot collaboration (HRC) due to low collision energies even at high speeds resulting from their reduced moving masses. However, the risk of unintended contact with the leg chains increases compared to the structure of serial robots. As a first step towards HRC, contact cases on the whole parallel robot structure are investigated and a disturbance observer based on generalized momenta and measurements of motor current is applied. In addition, a Kalman filter and a second-order sliding-mode observer based on generalized momenta are compared in terms of error and detection time. Gearless direct drives with low friction improve external force estimation and enable low impedance. The experimental validation is performed with two force-torque sensors and a kinetostatic model. This allows a new identification method of the motor torque constant of an assembled parallel robot to estimate external forces from the motor current and via a dynamics model. A Cartesian impedance control scheme for compliant robot-environmental dynamics with stiffness from 0.1-2N/mm and the force observation for low forces over the entire structure are validated. The observers are used for collisions and clamping at velocities of 0.4-0.9 m/s for detection within 9\u201358 ms and a reaction in the form of a zero-g mode.",
        "primary_area": "",
        "author": "Aran Mohammad;Moritz Schappler;Tobias Ortmaier;Aran Mohammad;Moritz Schappler;Tobias Ortmaier",
        "authorids": "/37089893042;/37086131932;/37294250600;/37089893042;/37086131932;/37294250600",
        "aff": "Leibniz University Hannover, Institute of Mechatronic Systems, Garbsen, Germany; Leibniz University Hannover, Institute of Mechatronic Systems, Garbsen, Germany; Leibniz University Hannover, Institute of Mechatronic Systems, Garbsen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161217/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4659591280312082030&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Leibniz University Hannover",
        "aff_unique_dep": "Institute of Mechatronic Systems",
        "aff_unique_url": "https://www.uni-hannover.de",
        "aff_unique_abbr": "LUH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Garbsen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161014",
        "title": "Towards Multi-Day Field Deployment Autonomy: A Long-Term Self-Sustainable Micro Aerial Vehicle Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This works deals with the problem of long-term autonomy in the context of multi-day field deployments of Micro Aerial Vehicle (MAV) systems. To truly depart from the necessity for human intervention for the crucial task of providing battery recharging, and to liberate from the need to operate in a confined range around specially installed infrastructure such as recharging pods, the MAV robot is required to harvest power on its own, but equally importantly also sustain prolonged periods of ambient power scarcity. This implies being able to sustain the battery charge overnight when using solar recharging, or even during multiple days of illumination inadequacy (e.g., due to degraded atmospheric lucidity and heavy overcast). We address this by presenting a Self-Sustainable Autonomous System architecture for MAVs centered around a specially tailored Power Management Stack, which is capable of achieving deep system hibernation, a feature that facilitates the aforementioned functionalities. We present a) continuous, b) multi-day successive, and c) externally-powered recharging that uses a legged robot-mounted Mobile Recharging Station. We conclude by demonstrating a challenging zero-intervention multi-day field deployment mission in the N.Nevada region.",
        "primary_area": "",
        "author": "Stephen J. Carlson;Prateek Arora;Tolga Karakurt;Brandon Moore;Christos Papachristos;Stephen J. Carlson;Prateek Arora;Tolga Karakurt;Brandon Moore;Christos Papachristos",
        "authorids": "/37088919008;/37085797792;/37085760611;/37089839264;/37681703400;/37088919008;/37085797792;/37085760611;/37089839264;/37681703400",
        "aff": "University of Nevada, Reno, NV, USA; University of Nevada, Reno, NV, USA; University of Nevada, Reno, NV, USA; University of Nevada, Reno, NV, USA; University of Nevada, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161014/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1404685405741118348&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161108",
        "title": "Towards Open-Set Material Recognition using Robot Tactile Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "The texture recognition can provide clues for robots to interact with the external environment. The traditional tactile material recognition task is studied under the close-set assumption, which means that all types of materials are included in the training set. However, the open-set materials recognition for robots is of much greater significance because in the real-world applications, there is usually something that doesn't belong to any known class. Up to now, there is no researcher to further the discussion of this problem. To cope with unknown classes, this study proposes the Open set Material Recognition (OpenMR) based on General Convolutional Prototype Learning (GCPL). To handle the open space risk for GCPL caused by the lack of unknown samples in the training stage, we use Generative Adversarial Networks (GAN) to synthesize open-set samples as unknowns. The proposed framework is implemented and tested on two batches of tactile data collected in different exploratory motions on 8 material textures using the electronic skin. Compared with other open-set classifiers, experiments reveal that the proposed framework achieves competitive performance in both known classification and unknown detection.",
        "primary_area": "",
        "author": "Kunhong Liu;Qianhui Yang;Yu Xie;Xiangyi Huang;Kunhong Liu;Qianhui Yang;Yu Xie;Xiangyi Huang",
        "authorids": "/37086310614;/37089591163;/37085705083;/37089739776;/37086310614;/37089591163;/37085705083;/37089739776",
        "aff": "School of Film, Xiamen University, China; School of Informatics, Xiamen University, China; School of Aerospace Engineering, Xiamen University, China; School of Aerospace Engineering, Xiamen University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161108/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12918832265884076207&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Xiamen University",
        "aff_unique_dep": "School of Film",
        "aff_unique_url": "https://www.xmu.edu.cn",
        "aff_unique_abbr": "XMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161333",
        "title": "Towards Open-World Interactive Disambiguation for Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Language-based communications are essential in human-robot interaction, especially for the majority of non-expert users. In this paper, we present SeeAsk, an open-world interactive visual grounding system to grasp specified targets with ambiguous natural language instructions. The main contribution of SeeAsk is that it can robustly handle open-world scenes in terms of both open-set objects and open-vocabulary interactions. Specifically, our SeeAsk is built upon modern large-scale vision-language pre-trained models and traditional decision-making process, and shows promising results to be deployed in real-world scenarios. SeeAsk outperforms previous state-of-the-art algorithms with a clear margin in terms of not only success rate but also asking smarter and more informative questions. User studies also demonstrate its advantages over previous works.",
        "primary_area": "",
        "author": "Yuchen Mo;Hanbo Zhang;Tao Kong;Yuchen Mo;Hanbo Zhang;Tao Kong",
        "authorids": "/37089892007;/37086441588;/37085802024;/37089892007;/37086441588;/37085802024",
        "aff": "ByteDance Research, China; ByteDance Research, China; ByteDance Research, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161333/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5482781431302444205&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ByteDance Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.bytedance.com",
        "aff_unique_abbr": "ByteDance",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160601",
        "title": "Towards Predicting Fine Finger Motions from Ultrasound Images via Kinematic Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "A central challenge in building robotic prostheses is the creation of a sensor-based system able to read physiological signals from the lower limb and instruct a robotic hand to perform various tasks. Existing systems typically perform discrete gestures such as pointing or grasping, by employing electromyography (EMG) or ultrasound (US) technologies to analyze muscle states. While estimating finger gestures has been done in the past by detecting prominent gestures, we are interested in detection, or inference, done in the context of fine motions that evolve over time. Examples include motions occurring when performing fine and dexterous tasks such as keyboard typing or piano playing. We consider this task as an important step towards higher adoption rates of robotic prostheses among arm amputees, as it has the potential to dramatically increase functionality in performing daily tasks. To this end, we present an end-to-end robotic system, which can successfully infer fine finger motions. This is achieved by modeling the hand as a robotic manipulator and using it as an intermediate representation to encode muscles' dynamics from a sequence of US images. We evaluated our method by collecting data from a group of subjects and demonstrating how it can be used to replay music played or text typed. To the best of our knowledge, this is the first study demonstrating these downstream tasks within an end-to-end system.",
        "primary_area": "",
        "author": "Dean Zadok;Oren Salzman;Alon Wolf;Alex M. Bronstein;Dean Zadok;Oren Salzman;Alon Wolf;Alex M. Bronstein",
        "authorids": "/37087246375;/37077497700;/37279108200;/37327099600;/37087246375;/37077497700;/37279108200;/37327099600",
        "aff": "Department of Computer Science, Technion, Haifa, Israel; Department of Computer Science, Technion, Haifa, Israel; Department of Mechanical Engineering, Technion, Haifa, Israel; Department of Computer Science, Technion, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160601/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17254291988609964684&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technion",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "10160321",
        "title": "Towards Robots that Influence Humans over Long-Term Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "When humans interact with robots influence is inevitable. Consider an autonomous car driving near a human: the speed and steering of the autonomous car will affect how the human drives. Prior works have developed frameworks that enable robots to influence humans towards desired behaviors. But while these approaches are effective in the short-term (i.e., the first few human-robot interactions), here we explore long-term influence (i.e., repeated interactions between the same human and robot). Our central insight is that humans are dynamic: people adapt to robots, and behaviors which are influential now may fall short once the human learns to anticipate the robot's actions. With this insight, we experimentally demonstrate that a prevalent game-theoretic formalism for generating influential robot behaviors becomes less effective over repeated interactions. Next, we propose three modifications to Stackelberg games that make the robot's policy both influential and unpredictable. We finally test these modifications across simulations and user studies: our results suggest that robots which purposely make their actions harder to anticipate are better able to maintain influence over long-term interaction. See videos here: https://youtu.be/ydO83cgjZ2Q",
        "primary_area": "",
        "author": "Shahabedin Sagheb;Ye-Ji Mun;Neema Ahmadian;Benjamin A. Christie;Andrea Bajcsy;Katherine Driggs-Campbell;Dylan P. Losey;Shahabedin Sagheb;Ye-Ji Mun;Neema Ahmadian;Benjamin A. Christie;Andrea Bajcsy;Katherine Driggs-Campbell;Dylan P. Losey",
        "authorids": "/37089892482;/37089449010;/37089894088;/37089892938;/37086934087;/37085509519;/37085812055;/37089892482;/37089449010;/37089894088;/37089892938;/37086934087;/37085509519;/37085812055",
        "aff": "Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Electrical and Computer Engineering, Human-Centered Autonomy Lab (HCAL), University of Illinois, Urbana-Champaign, IL; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Electrical Engineering and Computer Science, UC Berkeley, CA; Dept. of Electrical and Computer Engineering, Human-Centered Autonomy Lab (HCAL), University of Illinois, Urbana-Champaign, IL; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160321/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6690604335142781963&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;2;1;0",
        "aff_unique_norm": "Virginia Tech;University of Illinois;University of California, Berkeley",
        "aff_unique_dep": "Dept. of Mechanical Engineering;Dept. of Electrical and Computer Engineering;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.vt.edu;https://illinois.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "VT;UIUC;UC Berkeley",
        "aff_campus_unique_index": "0;1;0;0;2;1;0",
        "aff_campus_unique": "Blacksburg;Urbana-Champaign;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160930",
        "title": "Towards Robust Autonomous Grasping with Reflexes Using High-Bandwidth Sensing and Actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern robotic manipulation systems fall short of human manipulation skills partly because they rely on closing feedback loops exclusively around vision data, which reduces system bandwidth and speed. By developing autonomous grasping reflexes that rely on high-bandwidth force, contact, and proximity data, the overall system speed and robustness can be increased while reducing reliance on vision data. We are developing a new system built around a low-inertia, high-speed arm with nimble fingers that combines a high-level trajectory planner operating at less than 1 Hz with low-level autonomous reflex controllers running upwards of 300 Hz. We characterize the reflex system by comparing the volume of the set of successful grasps for a naive baseline controller and variations of our reflexive grasping controller, finding that our controller expands the set of successful grasps by 55% relative to the baseline. We also deploy our reflexive grasping controller with a simple vision-based planner in an autonomous clutter clearing task, achieving a grasp success rate above 90% while clearing over 100 items.",
        "primary_area": "",
        "author": "Andrew SaLoutos;Hongmin Kim;Elijah Stanger-Jones;Menglong Guo;Sangbae Kim;Andrew SaLoutos;Hongmin Kim;Elijah Stanger-Jones;Menglong Guo;Sangbae Kim",
        "authorids": "/37088688960;/37089893288;/37088991680;/37085891920;/37537397200;/37088688960;/37089893288;/37088991680;/37085891920;/37537397200",
        "aff": "Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Mechanical Engineering, Biomimetic Robotics Laboratory, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160930/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8310665825851702675&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160645",
        "title": "Towards Robust Reference System for Autonomous Driving: Rethinking 3D MOT",
        "track": "main",
        "status": "Poster",
        "abstract": "With the rapid development of autonomous driving, the need for auto-labeling reference systems is becoming increasingly urgent. 3D multiple object tracking (MOT) is one of the most critical components of the reference system. In this work, we reviewed and rethought the common failure sources and limitations of the SOTA 3D MOT methods. We propose a set of innovative 3D MOT post-processing modules as a unified framework based on the observation. First, we design a self-learning-based detector to eliminate the outliers in each tracklet. Then a novel post-processing module, GGTrajRec, will recover the breakpoints and ID switches in the trajectories. Finally, a confidence-guided trajectory optimizer is implemented to ensure each trajectory's consistency. Extensive experiments on KITTI and nuScenes show that our method can improve the SOTA methods on most evaluation metrics by a remarkable margin. Currently, our results are second ranking on the KITTI tracking leaderboard. Specifically, our method offers the lowest FPs, highest DetRe, and AssRe values among all methods, which can significantly contribute to a stable and robust reference system for ADAS.",
        "primary_area": "",
        "author": "Leichen Wang;Jiadi Zhang;Pei Cai;Xinrun Li;Leichen Wang;Jiadi Zhang;Pei Cai;Xinrun Li",
        "authorids": "/37088649555;/37089895919;/471496456987023;/37089584009;/37088649555;/37089895919;/471496456987023;/37089584009",
        "aff": "Robert Bosch CN; TongJi University, China; Nanyang Technological University, Singapore; Robert Bosch CN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160645/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16025045625240665753&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Robert Bosch GmbH;TongJi University;Nanyang Technological University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.bosch.com;https://www.tongji.edu.cn;https://www.ntu.edu.sg",
        "aff_unique_abbr": "Bosch;TongJi;NTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Germany;China;Singapore"
    },
    {
        "id": "10161422",
        "title": "Towards Safe Landing of Falling Quadruped Robots Using a 3-DoF Morphable Inertial Tail",
        "track": "main",
        "status": "Poster",
        "abstract": "Falling cat problem is well-known where cats show their super aerial reorientation capability and can land safely. For their robotic counterparts, a similar falling quadruped robot problem, has not been fully addressed, although achieving safe landing as the cats has been increasingly investigated. Unlike imposing the burden on landing control, we approach to safe landing of falling quadruped robots by effective flight phase control. Different from existing work like swinging legs and attaching reaction wheels or simple tails, we propose to deploy a 3-DoF morphable inertial tail on a medium-size quadruped robot. In the flight phase, the tail with its maximum length can self-right the body orientation in 3D effectively; before touch-down, the tail length can be retracted to about 1/4 of its maximum for impressing the tail's side-effect on landing. To enable aerial reorientation for safe landing in the quadruped robots, we design a control architecture, which is verified in a high-fidelity physics simulation environment with different initial conditions. Experimental results on a customized flight-phase test platform with comparable inertial properties are provided and show the tail's effectiveness on 3D body reorientation and its fast retractability before touch-down. An initial falling quadruped robot experiment is shown, where the robot Unitree A1 with the 3-DoF tail can land safely subject to non-negligible initial body angles.",
        "primary_area": "",
        "author": "Yunxi Tang;Jiajun An;Xiangyu Chu;Shengzhi Wang;Ching Yan Wong;K. W. Samuel Au;Yunxi Tang;Jiajun An;Xiangyu Chu;Shengzhi Wang;Ching Yan Wong;K. W. Samuel Au",
        "authorids": "/37088920411;/37088535357;/37086437251;/37089894730;/37089894594;/37088483488;/37088920411;/37088535357;/37086437251;/37089894730;/37089894594;/37088483488",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong SAR, Republic of China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong SAR, Republic of China; Multiscale Medical Robotics Centre, Hong Kong SAR, Republic of China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong SAR, Republic of China; Multiscale Medical Robotics Centre, Hong Kong SAR, Republic of China; Multiscale Medical Robotics Centre, Hong Kong SAR, Republic of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161422/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12894282249936505043&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;1",
        "aff_unique_norm": "The Chinese University of Hong Kong;Multiscale Medical Robotics Centre",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.hk;",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160690",
        "title": "Towards Safe Remote Manipulation: User Command Adjustment based on Risk Prediction for Dynamic Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time remote manipulation requires careful operations by a user to ensure the safety of a robot, which is designed to follow user's commands, against dynamic obstacles. However, a user may give commands to a robot at the risk of collision with dynamic obstacles due to a user's unfamiliar control ability or unexpected situations. In this paper, we propose a risk-aware user command adjustment method to avoid potential collision with dynamic obstacles. Our method consists of a network that predicts the risk of dynamic obstacles and another network that synthesizes commands to avoid obstacles. Based on the predicted risk, our method decides an adjusted command between a user command and a command to avoid collisions. We evaluate our method in problems that face collisions with dynamic obstacles when following given commands and in problems with static obstacles. We show that our method improves safety against the risk of dynamic obstacles or follows user commands when there is no risk. We also demonstrate the feasibility of our method using the real fetch manipulator with seven-degrees-of-freedom.",
        "primary_area": "",
        "author": "Mincheul Kang;Minsung Yoon;Sung-Eui Yoon;Mincheul Kang;Minsung Yoon;Sung-Eui Yoon",
        "authorids": "/37086439291;/37089447491;/37066068100;/37086439291;/37089447491;/37066068100",
        "aff": "School of Computing; School of Computing; Faculty of School of Computing, KAIST, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160690/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2259409747687086950&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "School of Computing;KAIST",
        "aff_unique_dep": "Computing;School of Computing",
        "aff_unique_url": ";https://www.kaist.ac.kr",
        "aff_unique_abbr": ";KAIST",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Daejeon",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";South Korea"
    },
    {
        "id": "10160383",
        "title": "Towards Surgical Context Inference and Translation to Gestures",
        "track": "main",
        "status": "Poster",
        "abstract": "Manual labeling of gestures in robot-assisted surgery is labor intensive, prone to errors, and requires expertise or training. We propose a method for automated and explainable generation of gesture transcripts that leverages the abundance of data for image segmentation. Surgical context is detected using segmentation masks by examining the distances and intersections between the tools and objects. Next, context labels are translated into gesture transcripts using knowledge-based Finite State Machine (FSM) and data-driven Long Short Term Memory (LSTM) models. We evaluate the performance of each stage of our method by comparing the results with the ground truth segmentation masks, the consensus context labels, and the gesture labels in the JIGSAWS dataset. Our results show that our segmentation models achieve state-of-the-art performance in recognizing needle and thread in Suturing and we can automatically detect important surgical states with high agreement with crowd-sourced labels (e.g., contact between graspers and objects in Suturing). We also find that the FSM models are more robust to poor segmentation and labeling performance than LSTMs. Our proposed method can significantly shorten the gesture labeling process (~2.8 times).",
        "primary_area": "",
        "author": "Kay Hutchinson;Zongyu Li;Ian Reyes;Homa Alemzadeh;Kay Hutchinson;Zongyu Li;Ian Reyes;Homa Alemzadeh",
        "authorids": "/37088639509;/37089448451;/37089895703;/37601630800;/37088639509;/37089448451;/37089895703;/37601630800",
        "aff": "Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160383/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3024976602289550185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161322",
        "title": "Towards True Lossless Sparse Communication in Multi-Agent Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Communication enables agents to cooperate to achieve their goals. Learning when to communicate, i.e., sparse (in time) communication, and whom to message is particularly important when bandwidth is limited. However, recent work in learning sparse individualized communication suffers from high variance during training, where decreasing communication comes at the cost of decreased reward, particularly in cooperative tasks. We use the information bottleneck to reframe sparsity as a representation learning problem, which we show naturally enables lossless sparse communication at lower budgets than prior art. In this paper, we propose a method for true lossless sparsity in communication via Information Maximizing Gated Sparse Multi-Agent Communication (IMGS-MAC). Our model uses two individualized regularization objectives, an information maximization autoencoder and sparse communication loss, to create informative and sparse communication. We evaluate the learned communication \u2018language\u2019 through direct causal analysis of messages in non-sparse runs to determine the range of lossless sparse budgets, which allow zero-shot sparsity, and the range of sparse budgets that will inquire a reward loss, which is minimized by our learned gating function with few-shot sparsity. To demonstrate the efficacy of our results, we experiment in cooperative multi-agent tasks where communication is essential for success. We evaluate our model with both continuous and discrete messages. We focus our analysis on a variety of ablations to show the effect of message representations, including their properties, and lossless performance of our model.",
        "primary_area": "",
        "author": "Seth Karten;Mycal Tucker;Siva Kailas;Katia Sycara;Seth Karten;Mycal Tucker;Siva Kailas;Katia Sycara",
        "authorids": "/37086587263;/37089894236;/37089893277;/37268476900;/37086587263;/37089894236;/37089893277;/37268476900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161322/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2926985958139303312&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Robotics Institute;Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.cmu.edu;https://web.mit.edu",
        "aff_unique_abbr": "CMU;MIT",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Pittsburgh;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161274",
        "title": "Towards Unsupervised Filtering of Millimetre-Wave Radar Returns for Autonomous Vehicle Road Following",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning and localization in low-light and inclement weather conditions are critical problems facing autonomous vehicle systems. Our proposed method applies a single modality, millimetre-wave radar perception system for the detection of roadside retro-reflectors. Radar-based perception tasks can be challenging to perform due to the sparse and noisy nature of radar data. We propose the use of an unsupervised learning approach for filtering radar point clouds through Density-Based Spatial Clustering of Applications with Noise (DBSCAN). The DBSCAN algorithm segments retro-reflector points from noise points, thus providing the autonomous vehicle with a predicted path for the road ahead. We tested the approach via indoor experiments that make use of Continental's ARS 408 radar, a mobile Husky A2000 robot, and a Vicon motion capture system for ground truth validation. The experimental results of the proposed system demonstrated a classification accuracy of 84.13 % and F1 score of 83.71 %.",
        "primary_area": "",
        "author": "Dean Sacoransky;Joshua A. Marshall;Keyvan Hashtrudi-Zaad;Dean Sacoransky;Joshua A. Marshall;Keyvan Hashtrudi-Zaad",
        "authorids": "/37089893243;/37269656200;/38277052700;/37089893243;/37269656200;/38277052700",
        "aff": "Department of Electrical & Computer Engineering, Ingenuity Labs, Research Institute, Queen's University, Kingston, ON, Canada; Department of Electrical & Computer Engineering, Ingenuity Labs, Research Institute, Queen's University, Kingston, ON, Canada; Department of Electrical & Computer Engineering, Ingenuity Labs, Research Institute, Queen's University, Kingston, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161274/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18162276007549931087&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queen's University",
        "aff_unique_dep": "Department of Electrical & Computer Engineering",
        "aff_unique_url": "https://www.queensu.ca",
        "aff_unique_abbr": "Queen's U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kingston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10161166",
        "title": "Towards View-invariant and Accurate Loop Detection Based on Scene Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "Loop detection plays a key role in visual Si-multaneous Localization and Mapping (SLAM) by correcting the accumulated pose drift. In indoor scenarios, the richly distributed semantic landmarks are view-point invariant and hold strong descriptive power in loop detection. The current semantic-aided loop detection embeds the topology between semantic instances to search a loop. However, current semantic-aided loop detection methods face challenges in dealing with ambiguous semantic instances and drastic viewpoint differences, which are not fully addressed in the literature. This paper introduces a novel loop detection method based on an incremen-tally created scene graph, targeting the visual SLAM at indoor scenes. It jointly considers the macro-view topology, micro-view topology, and occupancy of semantic instances to find correct correspondences. Experiments using handheld RGB-D sequence show our method is able to accurately detect loops in drastically changed viewpoints. It maintains a high precision in observing objects with similar topology and appearance. Our method also demonstrates that it is robust in changed indoor scenes.",
        "primary_area": "",
        "author": "Chuhao Liu;Shaojie Shen;Chuhao Liu;Shaojie Shen",
        "authorids": "/37086922152;/37954847200;/37086922152;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161166/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4659655826542503548&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161568",
        "title": "Towards Visual Classification Under Class Ambiguity",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual classification under uncertainty is a complex computer vision problem. We present a thorough comparison of several variants of convolutional neural network (CNN) classification techniques in the context of ambiguous image data interpretation. We explore possible improvements in classification accuracy achieved by insertion of prior ambiguity information during the annotation process. This enables us to harness known similarities between individual classes and use them as probability distributions for soft ground-truth labels. We also present an approach based on Bayesian CNNs, offering the possibility of further interpretation of classification results in a problem where the neural network model is often considered as a black box. The presented techniques are verified on a practical spot weld inspection problem.",
        "primary_area": "",
        "author": "Viktor Koz\u00e1k;Jan Mikula;Luk\u00e1\u0161 Bertl;Karel Ko\u0161nar;Libor P\u0159eu\u010dil;Viktor Koz\u00e1k;Jan Mikula;Luk\u00e1\u0161 Bertl;Karel Ko\u0161nar;Libor P\u0159eu\u010dil",
        "authorids": "/37089317632;/37090018696;/37089895607;/38547765500;/37550774800;/37089317632;/37090018696;/37089895607;/38547765500;/37550774800",
        "aff": "Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University in Prague, Praha 2, Czech Republic; Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University in Prague, Praha 2, Czech Republic; Czech Institute of Informatics, Robotics, and Cybernetics, Czech Technical University in Prague, Praha 6, Czech Republic; Czech Institute of Informatics, Robotics, and Cybernetics, Czech Technical University in Prague, Praha 6, Czech Republic; Czech Institute of Informatics, Robotics, and Cybernetics, Czech Technical University in Prague, Praha 6, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161568/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5789598718774784169&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Department of Cybernetics, Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;1;1;1",
        "aff_campus_unique": "Praha 2;Praha 6",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "10161195",
        "title": "Towards a Finned-Swimming Exoskeleton: A Robotic Flutter Kicking Testbed and its Corresponding Thrust Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "While lower limb exoskeletons for above-ground locomotion have been emerging, few attempts have been made to develop an exoskeleton to augment human swimming. Such efforts are hindered by a lack of knowledge surrounding the kinematics and kinetics of human swimming. This paper presents the design of a robotic platform to be used as a finned swimming testbed; describes a controller to generate finned swimming movement; and presents experiments and associated experimental results conducted to explore thrust production resulting from a flutter kick swimming motion.",
        "primary_area": "",
        "author": "Beau P. Johnson;Michael Goldfarb;Beau P. Johnson;Michael Goldfarb",
        "authorids": "/37088533395;/37284476400;/37088533395;/37284476400",
        "aff": "Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161195/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2321416273022797225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161183",
        "title": "Towards a Reliable and Lightweight Onboard Fault Detection in Autonomous Unmanned Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new model for onboard physical fault detection on autonomous unmanned aerial vehicles (UAV) through machine learning (ML) techniques. The proposal performs the detection task with high accuracies and minimal processing requirements while signaling an unreliable ML model to the operator, implemented in two main phases. First, a wrapper-based feature selection is performed to de-crease the feature extraction computational costs, coped with a classification assessment technique to identify ML model unreliability. Second, physical UAV faults are signaled through a multi-view rationale that evaluates a variety of UAV sensors while triggering alerts based on a sliding window scheme. Experiments performed on a real quadcopter UAV with a broken propeller use case shows the proposal's feasibility. Our model can decrease the false-positive rates up to only 0.4%, while also decreasing the computational costs by at least 43 % when compared to traditional techniques. Notwithstanding, it can identify ML model unreliability, signaling the UAV operator when model fine-tuning is needed.",
        "primary_area": "",
        "author": "Sai Srinadhu Katta;Eduardo Kugler Viegas;Sai Srinadhu Katta;Eduardo Kugler Viegas",
        "authorids": "/37089434690;/37072043900;/37089434690;/37072043900",
        "aff": "Secure Systems Research Center (SSRC), Technology Innovation Institute (TII), Abu Dhabi, United Arab Emirates; Graduate Program in Informatics (PPGIa), Pontif\u00edcia Universidade Catolica do Paran\u00e1 (PUCPR), Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161183/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3154503045969351811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Technology Innovation Institute;Pontif\u00edcia Universidade Catolica do Paran\u00e1",
        "aff_unique_dep": "Secure Systems Research Center;Graduate Program in Informatics (PPGIa)",
        "aff_unique_url": ";https://www.pucpr.br",
        "aff_unique_abbr": "TII;PUCPR",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Abu Dhabi;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United Arab Emirates;Brazil"
    },
    {
        "id": "10161408",
        "title": "Traffic-Aware Autonomous Driving with Differentiable Traffic Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "While there have been advancements in autonomous driving control and traffic simulation, there have been little to no works exploring their unification with deep learning. Works in both areas seem to focus on entirely different exclusive problems, yet traffic and driving are inherently related in the real world. In this paper, we present Traffic-Aware Autonomous Driving (TrAAD), a generalizable distillation-style method for traffic-informed imitation learning that directly optimizes for faster traffic flow and lower energy consumption. TrAAD focuses on the supervision of speed control in imitation learning systems, as most driving research focuses on perception and steering. Moreover, our method addresses the lack of co-simulation between traffic and driving simulators and provides a basis for directly involving traffic simulation with autonomous driving in future work. Our results show that, with information from traffic simulation involved in the supervision of imitation learning methods, an autonomous vehicle can learn how to accelerate in a fashion that is beneficial for traffic flow and overall energy consumption for all nearby vehicles.",
        "primary_area": "",
        "author": "Laura Zheng;Sanghyun Son;Ming C. Lin;Laura Zheng;Sanghyun Son;Ming C. Lin",
        "authorids": "/37088690660;/37089894860;/37278387400;/37088690660;/37089894860;/37278387400",
        "aff": "Department of Computer Science, University of Mary-land, College Park, MD, U.S.A.; Department of Computer Science, University of Mary-land, College Park, MD, U.S.A.; Department of Computer Science, University of Mary-land, College Park, MD, U.S.A.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161408/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13822069597346695698&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Maryland, College Park",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161243",
        "title": "TrafficBots: Towards World Models for Autonomous Driving Simulation and Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Data-driven simulation has become a favorable way to train and test autonomous driving algorithms. The idea of replacing the actual environment with a learned simulator has also been explored in model-based reinforcement learning in the context of world models. In this work, we show data-driven traffic simulation can be formulated as a world model. We present TrafficBots, a multi-agent policy built upon motion prediction and end-to-end driving, and based on TrafficBots we obtain a world model tailored for the planning module of autonomous vehicles. Existing data-driven traffic simulators are lacking configurability and scalability. To generate configurable behaviors, for each agent we introduce a destination as nav-igational information, and a time-invariant latent personality that specifies the behavioral style. To improve the scalability, we present a new scheme of positional encoding for angles, allowing all agents to share the same vectorized context and the use of an architecture based on dot-product attention. As a result, we can simulate all traffic participants seen in dense urban scenarios. Experiments on the Waymo open motion dataset show TrafficBots can simulate realistic multi-agent behaviors and achieve good performance on the motion prediction task.",
        "primary_area": "",
        "author": "Zhejun Zhang;Alexander Liniger;Dengxin Dai;Fisher Yu;Luc Van Gool;Zhejun Zhang;Alexander Liniger;Dengxin Dai;Fisher Yu;Luc Van Gool",
        "authorids": "/37089316666;/37085702116;/37531409100;/37086564244;/37277167600;/37089316666;/37085702116;/37531409100;/37086564244;/37277167600",
        "aff": "Computer Vision Lab, ETH Zurich, Switzerland; Computer Vision Lab, ETH Zurich, Switzerland; MPI for Informatics, Germany; Computer Vision Lab, ETH Zurich, Switzerland; PSI, KU Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161243/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14553640722371208232&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "ETH Zurich;Max Planck Institute for Informatics;KU Leuven",
        "aff_unique_dep": "Computer Vision Lab;;PSI",
        "aff_unique_url": "https://www.ethz.ch;https://www.mpi-inf.mpg.de;https://www.kuleuven.be",
        "aff_unique_abbr": "ETHZ;MPII;KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;2",
        "aff_country_unique": "Switzerland;Germany;Belgium"
    },
    {
        "id": "10160296",
        "title": "TrafficGen: Learning to Generate Diverse and Realistic Traffic Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Diverse and realistic traffic scenarios are crucial for evaluating the AI safety of autonomous driving systems in simulation. This work introduces a data-driven method called TrafficGen for traffic scenario generation. It learns from the fragmented human driving data collected in the real world and then generates realistic traffic scenarios. TrafficGen is an autoregressive neural generative model with an encoder-decoder architecture. In each autoregressive iteration, it first encodes the current traffic context with the attention mechanism and then decodes a vehicle's initial state followed by generating its long trajectory. We evaluate the trained model in terms of vehicle placement and trajectories, and the experimental result shows our method has substantial improvements over baselines for generating traffic scenarios. After training, TrafficGen can also augment existing traffic scenarios, by adding new vehicles and extending the fragmented trajectories. We further demonstrate that importing the generated scenarios into a simulator as an interactive training environment improves the performance and safety of a driving agent learned from reinforcement learning. Model and data are available at https://metadriverse.github.io/trafficgen.",
        "primary_area": "",
        "author": "Lan Feng;Quanyi Li;Zhenghao Peng;Shuhan Tan;Bolei Zhou;Lan Feng;Quanyi Li;Zhenghao Peng;Shuhan Tan;Bolei Zhou",
        "authorids": "/37089706657;/37088439980;/37086587832;/37088453938;/37085668760;/37089706657;/37088439980;/37086587832;/37088453938;/37085668760",
        "aff": "ETH Zurich; The University of Edinburgh; University of California, Los Angeles; The University of Texas at Austin; University of California, Los Angeles",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160296/",
        "gs_citation": 119,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17835070967813806754&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;2",
        "aff_unique_norm": "ETH Zurich;University of Edinburgh;University of California, Los Angeles;University of Texas at Austin",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.ethz.ch;https://www.ed.ac.uk;https://www.ucla.edu;https://www.utexas.edu",
        "aff_unique_abbr": "ETHZ;Edinburgh;UCLA;UT Austin",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Los Angeles;Austin",
        "aff_country_unique_index": "0;1;2;2;2",
        "aff_country_unique": "Switzerland;United Kingdom;United States"
    },
    {
        "id": "10160594",
        "title": "Train Offline, Test Online: A Real Robot Learning Benchmark",
        "track": "main",
        "status": "Poster",
        "abstract": "Three challenges limit the progress of robot learning research: robots are expensive (few labs can participate), everyone uses different robots (findings do not generalize across labs), and we lack internet-scale robotics data. We take on these challenges via a new benchmark: Train Offline, Test Online (TOTO). TOTO provides remote users with access to shared robots for evaluating methods on common tasks and an open-source dataset of these tasks for offline training. Its manipulation task suite requires challenging generalization to unseen objects, positions, and lighting. We present initial results on TOTO comparing five pretrained visual representations and four offline policy learning baselines, remotely contributed by five institutions. The real promise of TOTO, however, lies in the future: we release the benchmark for additional submissions from any user, enabling easy, direct comparison to several methods without the need to obtain hardware or collect data.",
        "primary_area": "",
        "author": "Gaoyue Zhou;Victoria Dean;Mohan Kumar Srirama;Aravind Rajeswaran;Jyothish Pari;Kyle Hatch;Aryan Jain;Tianhe Yu;Pieter Abbeel;Lerrel Pinto;Chelsea Finn;Abhinav Gupta;Gaoyue Zhou;Victoria Dean;Mohan Kumar Srirama;Aravind Rajeswaran;Jyothish Pari;Kyle Hatch;Aryan Jain;Tianhe Yu;Pieter Abbeel;Lerrel Pinto;Chelsea Finn;Abhinav Gupta",
        "authorids": "/37089895938;/37089895355;/37089892147;/37085870445;/37089662067;/37089195784;/37089895473;/37087323861;/37542877900;/37085796211;/37085523464;/37291130800;/37089895938;/37089895355;/37089892147;/37085870445;/37089662067;/37089195784;/37089895473;/37087323861;/37542877900;/37085796211;/37085523464;/37291130800",
        "aff": "Carnegie Mellon University Robotics Institute; Carnegie Mellon University Robotics Institute; Carnegie Mellon University Robotics Institute; University of Washington; New York University; Stanford University; University of California, Berkeley; Stanford University; University of California, Berkeley; New York University; Stanford University; Carnegie Mellon University Robotics Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160594/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17791290944543386796&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;1;2;3;4;3;4;2;3;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Washington;New York University;Stanford University;University of California, Berkeley",
        "aff_unique_dep": "Robotics Institute;;;;",
        "aff_unique_url": "https://www.cmu.edu;https://www.washington.edu;https://www.nyu.edu;https://www.stanford.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "CMU;UW;NYU;Stanford;UC Berkeley",
        "aff_campus_unique_index": "1;2;1;2;1",
        "aff_campus_unique": ";Stanford;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161242",
        "title": "Train What You Know \u2013 Precise Pick-and-Place with Transporter Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Precise pick-and-place is essential in robotic applications. To this end, we define an exact training method and an iterative inference method that improve pick-and-place precision with Transporter Networks [1]. We conduct a large scale experiment on 8 simulated tasks. A systematic analysis shows, that the proposed modifications have a significant positive effect on model performance. Considering picking and placing independently, our methods achieve up to 60% lower rotation and translation errors than baselines. For the whole pick-and-place process we observe 50% lower rotation errors for most tasks with slight improvements in terms of translation errors. Furthermore, we propose architectural changes that retain model performance and reduce computational costs and time. We validate our methods with an interactive teaching procedure on real hardware. Supplementary material is available at: https://gergely-soti.github.io/p3",
        "primary_area": "",
        "author": "Gergely S\u00f3ti;Xi Huang;Christian Wurll;Bj\u00f6rn Hein;Gergely S\u00f3ti;Xi Huang;Christian Wurll;Bj\u00f6rn Hein",
        "authorids": "/37089001331;/37089659850;/37370368500;/37604448500;/37089001331;/37089659850;/37370368500;/37604448500",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Robotics and Autonomous Systems, Institute of Applied Research, Karlsruhe University of Applied Sciences, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161242/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14595606317149595574&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Karlsruhe University of Applied Sciences",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics;Robotics and Autonomous Systems, Institute of Applied Research",
        "aff_unique_url": "https://www.kit.edu;https://www.hs-karlsruhe.de",
        "aff_unique_abbr": "KIT;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160581",
        "title": "Training Efficient Controllers via Analytic Policy Gradient",
        "track": "main",
        "status": "Poster",
        "abstract": "Control design for robotic systems is complex and often requires solving an optimization to follow a trajectory accurately. Online optimization approaches like Model Predictive Control (MPC) have been shown to achieve great tracking performance, but require high computing power. Conversely, learning-based offline optimization approaches, such as Reinforcement Learning (RL), allow fast and efficient execution on the robot but hardly match the accuracy of MPC in trajectory tracking tasks. In systems with limited compute, such as aerial vehicles, an accurate controller that is efficient at execution time is imperative. We propose an Analytic Policy Gradient (APG) method to tackle this problem. APG exploits the availability of differentiable simulators by training a controller offline with gradient descent on the tracking error. We address training instabilities that frequently occur with APG through curriculum learning and experiment on a widely used controls benchmark, the CartPole, and two common aerial robots, a quadrotor and a fixed-wing drone. Our proposed method outperforms both model-based and model-free RL methods in terms of tracking error. Concurrently, it achieves similar performance to MPC while requiring more than an order of magnitude less computation time. Our work provides insights into the potential of APG as a promising control method for robotics. To facilitate the exploration of APG, we open-source our code and make it available atgithub.com/lis-epfl/apg_trajectory_tracking.",
        "primary_area": "",
        "author": "Nina Wiedemann;Valentin W\u00fcest;Antonio Loquercio;Matthias M\u00fcller;Dario Floreano;Davide Scaramuzza;Nina Wiedemann;Valentin W\u00fcest;Antonio Loquercio;Matthias M\u00fcller;Dario Floreano;Davide Scaramuzza",
        "authorids": "/37089323749;/37086289200;/37086299855;/37088216388;/37282168700;/37397688400;/37089323749;/37086289200;/37086299855;/37088216388;/37282168700;/37397688400",
        "aff": "Robotics and Perception Group, University of Zurich, Switzerland; Laboratory of Intelligent Systems, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL); Robotics and Perception Group, University of Zurich, Switzerland; Embodied AI Lab, Intel; Laboratory of Intelligent Systems, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL); Robotics and Perception Group, University of Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160581/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=38938098019644829&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;1;0",
        "aff_unique_norm": "University of Zurich;Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne;Intel",
        "aff_unique_dep": "Robotics and Perception Group;Laboratory of Intelligent Systems;Embodied AI Lab",
        "aff_unique_url": "https://www.unizh.ch;https://www.epfl.ch;https://www.intel.com",
        "aff_unique_abbr": "UZH;EPFL;Intel",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Lausanne",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "10161232",
        "title": "Trajectory Generation with Dynamic Programming for End-Effector Sway Damping of Forestry Machine",
        "track": "main",
        "status": "Poster",
        "abstract": "When a robot end-effector is attached to the arm via passive joints, undesirable end-effector sway will occur. In a forestry crane, such as the log-loading or harvesting machine, this sway is problematic as it hinders the efficiency and also can harm the machine and environment. Here, we tackle the sway problem of the forestry forwarder by proposing a methodology for generating anti-sway trajectories in fast maneuvers. We employ the dynamic programming algorithm, combined with a suitable linearization approach, the latter identified through a comparative study. The solution has low computational cost and provides excellent performance for residual sway damping. We demonstrate the dynamic programming solution on the virtual model of the forwarder by using a high-fidelity multibody-dynamics simulator to validate its performance. The results show our optimal trajectories can suppress the residual sway effectively to be, on average, less than 10% of the sway when using fifth order polynomial trajectories, in point-to-point maneuvers starting from rest or from initial sway conditions.",
        "primary_area": "",
        "author": "Iman Jebellat;Inna Sharf;Iman Jebellat;Inna Sharf",
        "authorids": "/37089230522;/37283633500;/37089230522;/37283633500",
        "aff": "Department of Mechanical Engineering, McGill University; Department of Mechanical Engineering, McGill University. She is currently a Lead Researcher at FPInnovations",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161232/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13387163696551046227&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "10160911",
        "title": "Trajectory Optimization for 3D Shape-Changing Robots with Differential Mobile Base",
        "track": "main",
        "status": "Poster",
        "abstract": "Service robots have attracted extensive attention due to specially designed functions, such as mobile manipulators or robots with extra structures. For robots that have changing shapes, autonomous navigation in the real world presents new challenges. In this paper, we propose a trajectory optimization method for differential-drive mobile robots with controllable changing shapes in dense 3D environments. We model the whole-body trajectory as a polynomial trajectory that satisfies the nonholonomic dynamics of the base and dynamics of the extra joints. These constraints are converted into soft constraints, and an activation function for dense sampling is applied to avoid nonlinear mutations. In addition, we guarantee the safety of full shape by limiting the system's distance from obstacles. To comprehensively simulate a large extent of height and width changes, we designed a novel Shape-Changing Robot with a Differential Base (SCR-DB). Our global trajectory optimization gives a smooth and collision-free trajectory for SCR-DB at a low computational cost. We present vast simulations and real-world experiments to validate our performance, including coupled whole-body and independent differential-driven vehicle motion planning.",
        "primary_area": "",
        "author": "Mengke Zhang;Chao Xu;Fei Gao;Yanjun Cao;Mengke Zhang;Chao Xu;Fei Gao;Yanjun Cao",
        "authorids": "/37089893176;/37404060100;/37086045143;/37086452719;/37089893176;/37404060100;/37086045143;/37086452719",
        "aff": "Yunjing Intelligent (Shenzhen) Co. Ltd, Shenzhen, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160911/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17530430131391371458&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Yunjing Intelligent (Shenzhen) Co. Ltd;Zhejiang University",
        "aff_unique_dep": ";Huzhou Institute",
        "aff_unique_url": ";https://www.zju.edu.cn",
        "aff_unique_abbr": ";ZJU",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Huzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160720",
        "title": "Trajectory Optimization for Distributed Manipulation by Shaping a Physical Field",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory optimization is used to solve various planning tasks. In this paper we present a optimization-based method that solves a planning problem for multiple independent objects manipulated by a spatially continuous physical field. The field is generated and controlled (shaped) in real time by an array of actuators. In the paper we first formulate a trajectory optimization problem and a related initialization scheme, and then we demonstrate the proposed method using an experimental platform for distributed magnetic manipulation. The demonstrated task is that of planar reconfiguration of an ensemble of multiple objects, which significantly benefits from the inherent parallelism of the manipulation enabled by the array of actuators shaping the physical field. We show that the system can rearrange up to eight objects simultaneously while avoiding collisions.",
        "primary_area": "",
        "author": "Adam Uchytil;Ji\u00ed Zem\u00e1nek;Adam Uchytil;Ji\u00ed Zem\u00e1nek",
        "authorids": "/37089896091;/37086787801;/37089896091;/37086787801",
        "aff": "Department of Control Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague; Department of Control Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160720/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:SHfUglyWKtUJ:scholar.google.com/&scioq=Trajectory+Optimization+for+Distributed+Manipulation+by+Shaping+a+Physical+Field&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Department of Control Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "10160320",
        "title": "Trajectory Planning for the Bidirectional Quadrotor as a Differentially Flat Hybrid System",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of bidirectional propellers provides quadrotors with greater maneuverability which is advantageous in constrained environments. This paper addresses the development of a trajectory planning algorithm for quadrotors with bidirectional motors. Previous work has shown that the property of differential flatness can be leveraged for efficient trajectory planning. However, planners that leverage flatness for quadrotors fail at points where the acceleration of the center of mass is equal to gravity, i.e., when the vehicle experiences free fall. The central contribution of this paper is a flatness-based trajectory planning method that allows quadrotors to use bidirectional propellers and pass through the so-called free-fall singularity. We model our system as a differentially flat hybrid system with the aid of coordinate charts derived from the Hopf fibration and develop an algorithm that computes forward and reverse thrusts for each propeller, resulting in smooth trajectories everywhere in SE(3). We demonstrate the planner's versatility by planning knife-edge maneuvers and trajectories passing through the free-fall singularity, while transitioning from forward to reverse thrust.",
        "primary_area": "",
        "author": "Katherine Mao;Jake Welde;M. Ani Hsieh;Vijay Kumar;Katherine Mao;Jake Welde;M. Ani Hsieh;Vijay Kumar",
        "authorids": "/37089893466;/37086067619;/38238444800;/37280341400;/37089893466;/37086067619;/38238444800;/37280341400",
        "aff": "Department of Mechanical Engineering and Applied Mechanics, GRASP Laboratory, University of Pennsylvania, PA, USA; Department of Mechanical Engineering and Applied Mechanics, GRASP Laboratory, University of Pennsylvania, PA, USA; Department of Mechanical Engineering and Applied Mechanics, GRASP Laboratory, University of Pennsylvania, PA, USA; Department of Mechanical Engineering and Applied Mechanics, GRASP Laboratory, University of Pennsylvania, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160320/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15838692787414173618&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Mechanical Engineering and Applied Mechanics",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161361",
        "title": "Trajectory and Sway Prediction Towards Fall Prevention",
        "track": "main",
        "status": "Poster",
        "abstract": "Falls are the leading cause of fatal and non-fatal injuries, particularly for older persons. Imbalance can result from the body's internal causes (illness), or external causes (active or passive perturbation). Active perturbation results from applying an external force to a person, while passive perturbation results from human motion interacting with a static obstacle. This work proposes a metric that allows for the monitoring of the persons torso and its correlation to active and passive perturbations. We show that large changes in the torso sway can be strongly correlated to active perturbations. We also show that we can reasonably predict the future path and expected change in torso sway by conditioning the expected path and torso sway on the past trajectory, torso motion, and the surrounding scene. This could have direct future applications to fall prevention. Results demonstrate that the torso sway is strongly correlated with perturbations. And our model is able to make use of the visual cues presented in the panorama and condition the prediction accordingly.",
        "primary_area": "",
        "author": "Weizhuo Wang;Michael Raitor;Steve Collins;C. Karen Liu;Monroe Kennedy;Weizhuo Wang;Michael Raitor;Steve Collins;C. Karen Liu;Monroe Kennedy",
        "authorids": "/37089895169;/37085776120;/37711227200;/38240584300;/37089500447;/37089895169;/37085776120;/37711227200;/38240584300;/37089500447",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161361/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5649087271295829562&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161025",
        "title": "Trajectory error compensation for optimal control of UMA-2 \u2013 a climbing robot executing maintenance operation in harsh environment",
        "track": "main",
        "status": "Poster",
        "abstract": "UMA-2 is a wheeled mobile platform equipped with a vacuum adhesion system, eight actuated joints and four passive ones, designed to climb vertical and curved surfaces. The platform can perform maintenance tasks such as corrosion removal and cleaning with grinding while climbing. The quality of the repairing process is largely affected by grinding process parameters including tool forces, toolpath and the robot trajectory accuracy. The current work introduces a trajectory analysis and adaptation model to control the UMA-2 platform to ensure specific surface quality KPIs and incorporating the effects of robot compliancy. The proposed trajectory analysis has been extensively validated through experimental campaigns representative of maintenance in wind power industry.",
        "primary_area": "",
        "author": "D. Gitardi;S. Sabbadini;A. Valente;D. Gitardi;S. Sabbadini;A. Valente",
        "authorids": "/37089893918;/37089894247;/37585861300;/37089893918;/37089894247;/37585861300",
        "aff": "the Automation Robots and Machines (ARM) Laboratory at SUPSI, University of Applied Science and Arts of Southern Switzerland, Lugano-Viganello, Switzerland; the Automation Robots and Machines (ARM) Laboratory at SUPSI, University of Applied Science and Arts of Southern Switzerland, Lugano-Viganello, Switzerland; the Automation Robots and Machines (ARM) Laboratory at SUPSI, University of Applied Science and Arts of Southern Switzerland, Lugano-Viganello, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161025/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16411226445803111487&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Applied Science and Arts of Southern Switzerland",
        "aff_unique_dep": "Automation Robots and Machines (ARM) Laboratory",
        "aff_unique_url": "https://www.supsi.ch",
        "aff_unique_abbr": "SUPSI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lugano-Viganello",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161444",
        "title": "Trajectory planning issues in cuspidal commercial robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A cuspidal serial robot can travel from one inverse kinematic solution to another without crossing a singularity. Cuspidal robots ask for extra care and caution in trajectory planning, as identifying an aspect related to one unique inverse kinematic solution is not possible. The issues related to motion planning with cuspidal robots are related to the inherent property arising from the geometric design of the robot. The cuspidality property has not been considered in recent industrial 6R robots with a non-spherical wrist. In this work, cuspidality is illustrated with the JACO robot (gen 2, non-spherical wrist), a serial arm by Kinova Robotics which is deployed in various applications and is cuspidal in nature. A nonsingular change of solutions for the robot is provided to highlight the effect of cuspidal robots on the interference with the environment. The pose with multiple inverse kinematic solutions in an aspect is presented. Problems in choosing the initial solution of the path in cuspidal robots, and its consequence, is illustrated with an example path in the workspace of the JACO robot. The paper presents the importance of cuspidality analysis of 6R robots and the implications of neglecting it.",
        "primary_area": "",
        "author": "Durgesh Haribhau Salunkhe;Damien Chablat;Philippe Wenger;Durgesh Haribhau Salunkhe;Damien Chablat;Philippe Wenger",
        "authorids": "/37086014556;/37273551600;/37273555500;/37086014556;/37273551600;/37273555500",
        "aff": "Ecole Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes Universite, Nantes, France; Ecole Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes Universite, Nantes, France; Ecole Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes Universite, Nantes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161444/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1388080705100904585&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ecole Centrale Nantes",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ec-nantes.fr",
        "aff_unique_abbr": "ECN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nantes",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10161200",
        "title": "TransRSS: Transformer-based Radar Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Radar semantic segmentation is a challenging task in environmental understanding, due as the radar data is noisy and suffers measurement ambiguities, which could lead to poor feature learning. To better tackle such difficulties, we present a novel and high-performance Transformer-based Radar Semantic Segmentation method, named TransRSS, to effectively and efficiently feature extraction for radar segmentation. Our approach first introduces the transformer into radar semantic segmentation and deeply integrates the merits of the Convolutional Neural Network (CNN) and transformer to extract more discriminative and global-level semantic features. On the one hand, it takes advantage of the CNN with flexible receptive fields to process images thanks to the shift convolution scheme. On the other hand, it takes advantage of the transformer to model long-range dependency with the self-attention mechanism. Meanwhile, we propose a Dual Position Attention module to aggregate rich context interdependencies between the multi-view features, which achieves an implicit mechanism for adaptively feature aggregation. Extensive experiments on the CARRADA dataset and RADIal dataset demonstrate that our TransRSS surpasses the state-of-the-art (SOTA) radar segmentation methods with remarkable margins.",
        "primary_area": "",
        "author": "Hao Zou;Zhen Xie;Jiarong Ou;Yutao Gao;Hao Zou;Zhen Xie;Jiarong Ou;Yutao Gao",
        "authorids": "/37090022685;/37088479367;/37089894229;/37089498915;/37090022685;/37088479367;/37089894229;/37089498915",
        "aff": "Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161200/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3612133136318094725&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Alibaba Group",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.alibaba.com",
        "aff_unique_abbr": "Alibaba",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161433",
        "title": "TransVisDrone: Spatio-Temporal Transformer for Vision-based Drone-to-Drone Detection in Aerial Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Drone-to-drone detection using visual feed has crucial applications, such as detecting drone collisions, detecting drone attacks, or coordinating flight with other drones. However, existing methods are computationally costly, follow non-end-to-end optimization, and have complex multi-stage pipelines, making them less suitable for real-time deployment on edge devices. In this work, we propose a simple yet effective framework, TransVisDrone, that provides an end-to-end solution with higher computational efficiency. We utilize CSPDarkNet-53 network to learn object-related spatial features and VideoSwin model to improve drone detection in challenging scenarios by learning spatio-temporal dependencies of drone motion. Our method achieves state-of-the-art performance on three challenging real-world datasets (Average Precision@0.5IOU): NPS 0.95, FLDrones 0.75, and AOT 0.80, and a higher throughput than previous methods. We also demonstrate its deployment capability on edge devices and its usefulness in detecting drone-collision (encounter). Project: https://tusharsangam.github.io/TransVisDrone-project-page/",
        "primary_area": "",
        "author": "Tushar Sangam;Ishan Rajendrakumar Dave;Waqas Sultani;Mubarak Shah;Tushar Sangam;Ishan Rajendrakumar Dave;Waqas Sultani;Mubarak Shah",
        "authorids": "/37089891915;/37086076013;/38193476000;/37275509600;/37089891915;/37086076013;/38193476000;/37275509600",
        "aff": "Center for Research in Computer Vision lab (CRCV), University of Central Florida, USA; Center for Research in Computer Vision lab (CRCV), University of Central Florida, USA; Information Technology University of the Punjab, Lahore, Pakistan; Center for Research in Computer Vision lab (CRCV), University of Central Florida, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161433/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=155055904813087979&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Central Florida;Information Technology University of the Punjab",
        "aff_unique_dep": "Center for Research in Computer Vision lab (CRCV);",
        "aff_unique_url": "https://www.ucf.edu;",
        "aff_unique_abbr": "UCF;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Central Florida;Lahore",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Pakistan"
    },
    {
        "id": "10160811",
        "title": "Transferring Implicit Knowledge of Non-Visual Object Properties Across Heterogeneous Robot Morphologies",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans leverage multiple sensor modalities when interacting with objects and discovering their intrinsic properties. Using the visual modality alone is insufficient for deriving intuition behind object properties (e.g., which of two boxes is heavier), making it essential to consider non-visual modalities as well, such as the tactile and auditory. Whereas robots may leverage various modalities to obtain object property understanding via learned exploratory interactions with objects (e.g., grasping, lifting, and shaking behaviors), challenges remain: the implicit knowledge acquired by one robot via object exploration cannot be directly leveraged by another robot with different morphology, because the sensor models, observed data distributions, and interaction capabilities are different across these different robot configurations. To avoid the costly process of learning interactive object perception tasks from scratch, we propose a multi-stage projection framework for each new robot for transferring implicit knowledge of object properties across heterogeneous robot morphologies. We evaluate our approach on the object-property recognition and object-identity recognition tasks, using a dataset containing two heterogeneous robots that perform 7,600 object interactions. Results indicate that knowledge can be transferred across robots, such that a newly-deployed robot can bootstrap its recognition models without exhaustively exploring all objects. We also propose a data augmentation technique and show that this technique improves the generalization of models. We release code, datasets, and additional results, here: https://github.com/gtatiya/Implicit-Knowledge-Transfer.",
        "primary_area": "",
        "author": "Gyan Tatiya;Jonathan Francis;Jivko Sinapov;Gyan Tatiya;Jonathan Francis;Jivko Sinapov",
        "authorids": "/37086934223;/37085992438;/37546531000;/37086934223;/37085992438;/37546531000",
        "aff": "Department of Computer Science, Tufts University, United States; Bosch Center for AI, Germany; Department of Computer Science, Tufts University, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160811/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6114250793553853338&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Tufts University;Bosch Center for AI",
        "aff_unique_dep": "Department of Computer Science;AI",
        "aff_unique_url": "https://www.tufts.edu;https://www.bosch-ai.com",
        "aff_unique_abbr": "Tufts;BCAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "10161385",
        "title": "Transparent Objects: A Corner Case in Stereo Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Stereo matching is a common technique used in 3D perception, but transparent objects such as reflective and penetrable glass pose a challenge as their disparities are often estimated inaccurately. In this paper, we propose transparency-aware stereo (TA-Stereo), an effective solution to tackle this issue. TA-Stereo first utilizes a semantic segmentation or salient object detection network to identify transparent objects, and then homogenizes them to enable stereo matching algorithms to handle them as non-transparent objects. To validate the effectiveness of our proposed TA-Stereo strategy, we collect 260 images containing transparent objects from the KITTI Stereo 2012 and 2015 datasets and manually label pixel-level ground truth. We evaluate our strategy with six deep stereo networks and two types of transparent object detection methods. Our experiments demonstrate that TA-Stereo significantly improves the disparity accuracy of transparent objects. Our project webpage can be accessed at mias.group/TA-Stereo.",
        "primary_area": "",
        "author": "Zhiyuan Wu;Shuai Su;Qijun Chen;Rui Fan;Zhiyuan Wu;Shuai Su;Qijun Chen;Rui Fan",
        "authorids": "/37089894951;/37089703078;/37276133600;/37085892666;/37089894951;/37089703078;/37276133600;/37085892666",
        "aff": "The Robotics & Artificial Intelligence Laboratory (RAIL), the State Key Laboratory of Intelligent Autonomous Systems, Machine Intelligence & Autonomous Systems (MIAS) Group, the College of Electronic & Information Engineering, Tongji University, Frontiers Science Center for Intelligent Autonomous Systems, Shanghai, P. R. China; The Robotics & Artificial Intelligence Laboratory (RAIL), the State Key Laboratory of Intelligent Autonomous Systems, Machine Intelligence & Autonomous Systems (MIAS) Group, the College of Electronic & Information Engineering, Tongji University, Frontiers Science Center for Intelligent Autonomous Systems, Shanghai, P. R. China; The Robotics & Artificial Intelligence Laboratory (RAIL), the State Key Laboratory of Intelligent Autonomous Systems, Machine Intelligence & Autonomous Systems (MIAS) Group, the College of Electronic & Information Engineering, Tongji University, Frontiers Science Center for Intelligent Autonomous Systems, Shanghai, P. R. China; The Robotics & Artificial Intelligence Laboratory (RAIL), the State Key Laboratory of Intelligent Autonomous Systems, Machine Intelligence & Autonomous Systems (MIAS) Group, the College of Electronic & Information Engineering, Tongji University, Frontiers Science Center for Intelligent Autonomous Systems, Shanghai, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161385/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=824900762702302250&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "College of Electronic & Information Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161419",
        "title": "Tree-structured Policy Planning with Learned Behavior Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles (AVs) need to reason about the multimodal behavior of neighboring agents while planning their own motion. Many existing trajectory planners seek a single trajectory that performs well under all plausible futures simultaneously, ignoring bi-directional interactions and thus leading to overly conservative plans. Policy planning, whereby the ego agent plans a policy that reacts to the environment's multimodal behavior, is a promising direction as it can account for the action-reaction interactions between the AV and the environment. However, most existing policy planners do not scale to the complexity of real autonomous vehicle applications: they are either not compatible with modern deep learning prediction models, not interpretable, or not able to generate high quality trajectories. To fill this gap, we propose Tree Policy Planning (TPP), a policy planner that is compatible with state-of-the-art deep learning prediction models, generates multistage motion plans, and accounts for the influence of ego agent on the environment behavior. The key idea of TPP is to reduce the continuous optimization problem into a tractable discrete Markov Decision Process (MDP) through the construction of two tree structures: an ego trajectory tree for ego trajectory options, and a scenario tree for multi-modal ego-conditioned environment predictions. We demonstrate the efficacy of TPP in closed-loop simulations based on real-world nuScenes dataset and results show that TPP scales to realistic AV scenarios and significantly outperforms non-policy baselines.",
        "primary_area": "",
        "author": "Yuxiao Chen;Peter Karkus;Boris Ivanovic;Xinshuo Weng;Marco Pavone;Yuxiao Chen;Peter Karkus;Boris Ivanovic;Xinshuo Weng;Marco Pavone",
        "authorids": "/37088427220;/37085591628;/37086527859;/37086376142;/37307912900;/37088427220;/37085591628;/37086527859;/37086376142;/37307912900",
        "aff": "NVIDIA Research, NVIDIA Corporation, Santa Clara, CA, California; NVIDIA Research, NVIDIA Corporation, Santa Clara, CA, California; NVIDIA Research, NVIDIA Corporation, Santa Clara, CA, California; NVIDIA Research, NVIDIA Corporation, Santa Clara, CA, California; NVIDIA Research, California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161419/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18233624139436263998&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "NVIDIA Corporation;NVIDIA",
        "aff_unique_dep": "NVIDIA Research;NVIDIA Research",
        "aff_unique_url": "https://www.nvidia.com;https://research.nvidia.com",
        "aff_unique_abbr": "NVIDIA;NVIDIA",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Santa Clara;California",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160995",
        "title": "Twist Snake: Plastic table-top cable-driven robotic arm with all motors located at the base link",
        "track": "main",
        "status": "Poster",
        "abstract": "Table-top robotic arms for education and research must be low-cost for availability and lightweight and soft for safety. Therefore, as such a robot, this study focuses on designing a plastic table-top cable-driven robotic arm with all motors located at the base link. However, locating all motors at the base link results in a significant distance between a driving motor and driven joint, increases the number of parts for the force transmission, and increases the risk of a cable loosening and coming off of a pulley. To overcome these issues, this study proposed a novel cable-driven robotic arm named Twist Snake. We designed a joint composition of Twist Snake to minimize the number of parts for the force transmission. In addition, it has a compact cable-pretension/termination-mechanism and covering parts to prevent the cable from loosening and coming off of the pulley. The arm comprised 475 mm long moving links with an 802 g. The feasibility of the arm was experimentally demonstrated by contact rich tasks, the insertion of a toy peg into a hole and swiping a whiteboard with a cleaner. The optimization of the proposed design and the development of a learning method for the arm that leverages contact will be investigated in future work.",
        "primary_area": "",
        "author": "Kazutoshi Tanaka;Masashi Hamaya;Kazutoshi Tanaka;Masashi Hamaya",
        "authorids": "/37088507484;/37085532024;/37088507484;/37085532024",
        "aff": "OMRON SINIC X Corporation, Bunkyo-ku, Tokyo, Japan; OMRON SINIC X Corporation, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160995/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10956486696139190779&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "OMRON SINIC X Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160450",
        "title": "Twisting Spine or Rigid Torso: Exploring Quadrupedal Morphology via Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern legged robot morphologies assign most of their actuated degrees of freedom (DoF's) to the limbs and designs continue to converge to twelve DoF quadrupeds with three actuators per leg and a rigid torso often modeled as a Single Rigid Body (SRB). This is in contrast to the animal kingdom, which provides tantalizing hints that core actuation of a jointed torso confers substantial benefit for efficient agility. Unfortunately, the limited specific power of available actuators continues to hamper roboticists' efforts to capitalize on this bio-inspiration. This paper presents the initial steps in a comparative study of the costs and benefits associated with a traditionally neglected torso degree of freedom: a twisting spine. We use trajectory optimization to explore how a one-DoF, axially twisting spine might help or hinder a set of axially-active (twisting) behaviors: trots, sudden turns while bounding, and parkour-style wall jumps. By optimizing for minimum electrical energy or average power, intuitive cost functions for robots, we avoid hand-tuning the behaviors and explore the activation of the spine. Initial evidence suggests that for lower energy behaviors the spine increases the electrical energy required when compared to the rigid torso, but for higher energy runs the spine trends toward having no effect or reducing the electrical work. These results support future, more bio-inspired versions of the spine with inherent stiffness or dampening built into their mechanical design.",
        "primary_area": "",
        "author": "J. Diego Caporale;Zeyuan Feng;Shane Rozen-Levy;Aja Mia Carter;Daniel E. Koditschek;J. Diego Caporale;Zeyuan Feng;Shane Rozen-Levy;Aja Mia Carter;Daniel E. Koditschek",
        "authorids": "/37088425624;/37089892996;/37088728823;/37089892585;/37275653000;/37088425624;/37089892996;/37088728823;/37089892585;/37275653000",
        "aff": "Mechanical Engineering and Applied Mechanics, University of Pennsylvania, PA, USA; Electrical and Systems Engineering, University of Pennsylvania, PA, USA; Mechanical Engineering and Applied Mechanics, University of Pennsylvania, PA, USA; Electrical and Systems Engineering, University of Pennsylvania, PA, USA; Electrical and Systems Engineering, University of Pennsylvania, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160450/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7501979227145681002&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Mechanical Engineering and Applied Mechanics",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Philadelphia",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160608",
        "title": "Two-Stage Grasping: A New Bin Picking Framework for Small Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel bin picking framework, two-stage grasping, aiming at precise grasping of cluttered small objects. Object density estimation and rough grasping are conducted in the first stage. Fine segmentation, detection, grasping, and pushing are performed in the second stage. A small object bin picking system has been realized to exhibit the concept of two-stage grasping. Experiments have shown the effectiveness of the proposed framework. Unlike traditional bin picking methods focusing on vision-based grasping planning using classic frameworks, the challenges of picking cluttered small objects can be solved by the proposed new framework with simple vision detection and planning.",
        "primary_area": "",
        "author": "Hanwen Cao;Jianshu Zhou;Junda Huang;Yichuan Li;Ng Cheng Meng;Rui Cao;Qi Dou;Yunhui Liu;Hanwen Cao;Jianshu Zhou;Junda Huang;Yichuan Li;Ng Cheng Meng;Rui Cao;Qi Dou;Yunhui Liu",
        "authorids": "/37088951247;/37086011742;/37088953080;/37089195434;/37089892998;/37089307526;/37085465414;/37279412600;/37088951247;/37086011742;/37088953080;/37089195434;/37089892998;/37089307526;/37085465414;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong.; Hong Kong Center for Logistics Robotics (HKCLR); Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong.; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong.; Hong Kong Center for Logistics Robotics (HKCLR); Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong.; Hong Kong Center for Logistics Robotics (HKCLR); Hong Kong Center for Logistics Robotics (HKCLR)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160608/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=858176579846316462&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;1;0;1;1",
        "aff_unique_norm": "The Chinese University of Hong Kong;Hong Kong Center for Logistics Robotics",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.hk;",
        "aff_unique_abbr": "CUHK;HKCLR",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161471",
        "title": "UDepth: Fast Monocular Depth Estimation for Visually-guided Underwater Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a fast monocular depth estimation method for enabling 3D perception capabilities of low-cost underwater robots. We formulate a novel end-to-end deep visual learning pipeline named UDepth, which incorporates domain knowledge of image formation characteristics of natural underwater scenes. First, we adapt a new input space from raw RGB image space by exploiting underwater light attenuation prior, and then devise a least-squared formulation for coarse pixel-wise depth prediction. Subsequently, we extend this into a domain projection loss that guides the end-to-end learning of UDepth on over 9K RGB-D training samples. UDepth is designed with a computationally light MobileNetV2 backbone and a Transformer-based optimizer for ensuring fast inference rates on embedded systems. By domain-aware design choices and through comprehensive experimental analyses, we demonstrate that it is possible to achieve state-of-the-art depth estimation performance while ensuring a small computational footprint. Specifically, with 70 % \u221280 % less network parameters than existing benchmarks, UDepth achieves comparable and often better depth estimation performance. While the full model offers over 66 FPS (13 FPS) inference rates on a single GPU (CPU core), our domain projection for coarse depth prediction runs at 51.5 FPS rates on single-board Jetson TX2s. The inference pipelines are available at https://github.com/uf-robopi/UDepth.",
        "primary_area": "",
        "author": "Boxiao Yu;Jiayi Wu;Md Jahidul Islam;Boxiao Yu;Jiayi Wu;Md Jahidul Islam",
        "authorids": "/37089895924;/37089921337;/37085652546;/37089895924;/37089921337;/37085652546",
        "aff": "Electrical and Computer Engineering (ECE) department, Robot Perception and Intelligence (RoboPI) laboratory, University of Florida, USA; Electrical and Computer Engineering (ECE) department, Robot Perception and Intelligence (RoboPI) laboratory, University of Florida, USA; Electrical and Computer Engineering (ECE) department, Robot Perception and Intelligence (RoboPI) laboratory, University of Florida, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161471/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16502116308109910867&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Florida",
        "aff_unique_dep": "Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ufl.edu",
        "aff_unique_abbr": "UF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161103",
        "title": "UPLIFT: Unsupervised Person Labeling and Identification via Cooperative Learning with Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots are widely used in assisting manual tasks, an interesting challenge is: Can mobile robots help create a labeled knowledge dataset that can be used for efficiently creating deep learning models for other sensors? This paper proposes an Unsupervised Person Labeling and Identification (UPLIFT) framework to automatically enlarge the labeled knowledge dataset. Typically, manual data labeling is very costly, especially when the user population is large and dynamic. To reduce the cost, we use a mobile robot to serve as a knowledge seed and to provide the pseudo-ground-truth for the system so that unlabeled images from other fixed surveillance cameras can be paired with the pseudo-ground-truth. Ultimately, the knowledge dataset can be generated via a system-to-system knowledge transfer process from the former to the latter and gradually expanded as the system operates longer. Experimental results in two environments indicate that UPLIFT achieves an accuracy of 94.1% on average to detect pedestrians' IDs every 10 seconds.",
        "primary_area": "",
        "author": "Yu-Chee Tseng;Ting-Yuan Ke;Fang\u2013Jing Wu;Yu-Chee Tseng;Ting-Yuan Ke;Fang\u2013Jing Wu",
        "authorids": "/37276276400;/37086933439;/37416981900;/37276276400;/37086933439;/37416981900",
        "aff": "Miin Wu School of Computing, National Cheng Kung University, Taiwan; National Yang Ming Chiao Tung University, Taiwan; TU Dortmund University, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161103/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:_el3rvEpbFsJ:scholar.google.com/&scioq=UPLIFT:+Unsupervised+Person+Labeling+and+Identification+via+Cooperative+Learning+with+Mobile+Robots&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "National Cheng Kung University;National Yang Ming Chiao Tung University;TU Dortmund University",
        "aff_unique_dep": "Miin Wu School of Computing;;",
        "aff_unique_url": "https://www.ncku.edu.tw;https://www.nycu.edu.tw;https://www.tu-dortmund.de",
        "aff_unique_abbr": "NCKU;NYCU;TUDO",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "10160631",
        "title": "USEEK: Unsupervised SE(3)-Equivariant 3D Keypoints for Generalizable Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Can a robot manipulate intra-category unseen objects in arbitrary poses with the help of a mere demonstration of grasping pose on a single object instance? In this paper, we try to address this intriguing challenge by using USEEK, an unsupervised SE(3)-equivariant keypoints method that enjoys alignment across instances in a category, to perform generaliz-able manipulation. USEEK follows a teacher-student structure to decouple the unsupervised keypoint discovery and SE(3)-equivariant keypoint detection. With USEEK in hand, the robot can infer the category-level task-relevant object frames in an efficient and explainable manner, enabling manipulation of any intra-category objects from and to any poses. Through extensive experiments, we demonstrate that the keypoints produced by USEEK possess rich semantics, thus successfully transferring the functional knowledge from the demonstration object to the novel ones. Compared with other object representations for manipulation, USEEK is more adaptive in the face of large intra-category shape variance, more robust with limited demonstrations, and more efficient at inference time. Project website: https://sites.google.com/view/useek/.",
        "primary_area": "",
        "author": "Zhengrong Xue;Zhecheng Yuan;Jiashun Wang;Xueqian Wang;Yang Gao;Huazhe Xu;Zhengrong Xue;Zhecheng Yuan;Jiashun Wang;Xueqian Wang;Yang Gao;Huazhe Xu",
        "authorids": "/37089018649;/37089896087;/37088458698;/37085383477;/37089896090;/37086242886;/37089018649;/37089896087;/37088458698;/37085383477;/37089896090;/37086242886",
        "aff": "Shanghai Jiao Tong University; Shanghai Qi Zhi Institute; Carnegie Mellon University; Tsinghua University; Shanghai Qi Zhi Institute; Shanghai Qi Zhi Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160631/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4548547795209603471&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;1;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;Shanghai Qi Zhi Institute;Carnegie Mellon University;Tsinghua University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.qz.io;https://www.cmu.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "SJTU;;CMU;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "10161127",
        "title": "Ultra-low Power Deep Learning-based Monocular Relative Localization Onboard Nano-quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "Precise relative localization is a crucial functional block for swarm robotics. This work presents a novel au-tonomous end-to-end system that addresses the monocular relative localization, through deep neural networks (DNNs), of two peer nano-drones, i.e., sub-40g of weight and sub-100mW processing power. To cope with the ultra-constrained nano-drone platform, we propose a vertically-integrated framework, from the dataset collection to the final in-field deployment, including dataset augmentation, quantization, and system op-timizations. Experimental results show that our DNN can precisely localize a 10 cm-size target nano-drone by employing only low-resolution monochrome images, up to ~2m distance. On a disjoint testing dataset our model yields a mean R2 score of 0.42 and a root mean square error of 18 cm, which results in a mean in-field prediction error of 15 cm and in a closed-loop control error of 17 cm, over a ~60 s-flight test. Ultimately, the proposed system improves the State-of-the-Art by showing long-endurance tracking performance (up to 2 min continuous tracking), generalization capabilities being deployed in a never-seen-before environment, and requiring a minimal power consumption of 95 mW for an onboard real-time inference-rate of 48 Hz.",
        "primary_area": "",
        "author": "S. Bonato;S. C. Lambertenghi;E. Cereda;A. Giusti;D. Palossi;S. Bonato;S. C. Lambertenghi;E. Cereda;A. Giusti;D. Palossi",
        "authorids": "/37089894685;/37089892667;/37086553441;/38498058400;/37073862400;/37089894685;/37089892667;/37086553441;/38498058400;/37073862400",
        "aff": "the Dalle Molle Institute for Artificial Intelligence, USI and SUPSI, Lugano, Switzerland; the Dalle Molle Institute for Artificial Intelligence, USI and SUPSI, Lugano, Switzerland; the Dalle Molle Institute for Artificial Intelligence, USI and SUPSI, Lugano, Switzerland; the Dalle Molle Institute for Artificial Intelligence, USI and SUPSI, Lugano, Switzerland; ETH Z\u00fcrich, Integrated Systems Laboratory, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161127/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7974511765695402701&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Dalle Molle Institute for Artificial Intelligence;ETH Z\u00fcrich",
        "aff_unique_dep": "Institute for Artificial Intelligence;Integrated Systems Laboratory",
        "aff_unique_url": "https://www.dallemolle.ai;https://www.ethz.ch",
        "aff_unique_abbr": "DMI;ETHZ",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Lugano;Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10160367",
        "title": "Uncertainty Quantification of Collaborative Detection for Self-Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Sharing information between connected and autonomous vehicles (CAVs) fundamentally improves the performance of collaborative object detection for self-driving. However, CAVs still have uncertainties on object detection due to practical challenges, which will affect the later modules in self-driving such as planning and control. Hence, uncertainty quantification is crucial for safety-critical systems such as CAVs. Our work is the first to estimate the uncertainty of collaborative object detection. We propose a novel uncertainty quantification method, called Double- M Quantification, which tailors a moving block bootstrap (MBB) algorithm with direct modeling of the multivariant Gaussian distribution of each corner of the bounding box. Our method captures both the epistemic uncertainty and aleatoric uncertainty with one inference pass based on the offline Double- M training process. And it can be used with different collaborative object detectors. Through experiments on the comprehensive collaborative perception dataset, we show that our Double-M method achieves more than 4\u00d7 improvement on uncertainty score and more than 3% accuracy improvement, compared with the state-of-the-art uncertainty quantification methods. Our code is public on https://coperception.github.io/double-m-quantification/.",
        "primary_area": "",
        "author": "Sanbao Su;Yiming Li;Sihong He;Songyang Han;Chen Feng;Caiwen Ding;Fei Miao;Sanbao Su;Yiming Li;Sihong He;Songyang Han;Chen Feng;Caiwen Ding;Fei Miao",
        "authorids": "/37086457798;/37087323806;/37088688721;/37088333832;/37086391326;/37085664380;/37072758500;/37086457798;/37087323806;/37088688721;/37088333832;/37086391326;/37085664380;/37072758500",
        "aff": "Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA; Tandon School of Engineering, New York University, Brooklyn, NY, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA; Tandon School of Engineering, New York University, Brooklyn, NY, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160367/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2253966741251855938&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;1;0;0",
        "aff_unique_norm": "University of Connecticut;New York University",
        "aff_unique_dep": "Department of Computer Science and Engineering;Tandon School of Engineering",
        "aff_unique_url": "https://www.uconn.edu;https://www.nyu.edu",
        "aff_unique_abbr": "UConn;NYU",
        "aff_campus_unique_index": "0;1;0;0;1;0;0",
        "aff_campus_unique": "Storrs Mansfield;Brooklyn",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160686",
        "title": "Uncertainty-Guided Active Reinforcement Learning with Bayesian Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in Reinforcement Learning (RL) have made significant contributions in past years by offering intelligent solutions to solve robotic tasks. However, most RL algorithms, especially the model-free RL, are plagued by low learning efficiency and safety problems. In this paper, we propose using the Bayesian Neural Networks (BNNs) to guide the agent exploring actively to enhance the learning efficiency in RL and investigate the potential of recognizing safety risks in working environments with uncertainty information. We compare two types of uncertainty quantification methods in both action and state spaces. To validate our method, we visualize the quantified uncertainty in robot environments with or without safety hazards. Moreover, we evaluate the learning efficiency and safety performance of the RL agents learned with BNNs on different robotic tasks.",
        "primary_area": "",
        "author": "Xinyang Wu;Mohamed El-Shamouty;Christof Nitsche;Marco F. Huber;Xinyang Wu;Mohamed El-Shamouty;Christof Nitsche;Marco F. Huber",
        "authorids": "/37088506391;/37088504046;/37087148177;/37392400600;/37088506391;/37088504046;/37087148177;/37392400600",
        "aff": "Cyber Cognitive Intelligence Department, Fraunhofer IPA; Robot and Assistive Systems Department, Fraunhofer IPA; Cyber Cognitive Intelligence Department, Fraunhofer IPA; Institute of Industrial Manufacturing and Management IFF, University of Stuttgart",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160686/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=420853090477800009&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Fraunhofer Institute for Production Technology and Automation IPA;Fraunhofer Institute for Manufacturing Engineering and Automation IPA;University of Stuttgart",
        "aff_unique_dep": "Cyber Cognitive Intelligence Department;Robot and Assistive Systems Department;Institute of Industrial Manufacturing and Management IFF",
        "aff_unique_url": "https://www.ipa.fraunhofer.de;https://www.ipa.fraunhofer.de;https://www.uni-stuttgart.de",
        "aff_unique_abbr": "Fraunhofer IPA;Fraunhofer IPA;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160355",
        "title": "Uncertainty-aware LiDAR Panoptic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern autonomous systems often rely on LiDAR scanners, in particular for autonomous driving scenarios. In this context, reliable scene understanding is indispensable. Conventional learning-based methods generally try to achieve maximum performance for this task, while neglecting a proper estimation of the associated uncertainties. In this work, we introduce a novel approach for solving the task of uncertainty- aware panoptic segmentation using LiDAR point clouds. Our proposed EvLPSNet network is the first to solve this task efficiently in a sampling-free manner. It aims to predict per-point semantic and instance segmentations, together with per-point uncertainty estimates. Moreover, it incorporates methods that utilize the uncertainties to improve the segmentation performance. We provide several strong baselines combining state-of- the-art LiDAR panoptic segmentation networks with sampling- free uncertainty estimation techniques. Extensive evaluations show that we achieve the best performance on uncertainty- aware panoptic segmentation quality and calibration compared to these baselines. We make our code available at: https://github.com/kshitij3112/EvLPSNet",
        "primary_area": "",
        "author": "Kshitij Sirohi;Sajad Marvi;Daniel B\u00fcscher;Wolfram Burgard;Kshitij Sirohi;Sajad Marvi;Daniel B\u00fcscher;Wolfram Burgard",
        "authorids": "/37088282357;/37089773351;/37086455193;/37270485300;/37088282357;/37089773351;/37086455193;/37270485300",
        "aff": "Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Engineering, Technical University, N\u00fcrnberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160355/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18085275094061058977&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Freiburg;Technical University of N\u00fcrnberg",
        "aff_unique_dep": "Department of Computer Science;Department of Engineering",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.tu-nuernberg.de",
        "aff_unique_abbr": ";TUN",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";N\u00fcrnberg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161557",
        "title": "Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result. Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.",
        "primary_area": "",
        "author": "Yong Li;Hui Cheng;Yong Li;Hui Cheng",
        "authorids": "/37089892089;/38008557800;/37089892089;/38008557800",
        "aff": "School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161557/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6580963313673022107&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "School of Data and Computer Science",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160742",
        "title": "Unseen Object Instance Segmentation with Fully Test-time RGB-D Embeddings Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Segmenting unseen objects is a crucial ability for the robot since it may encounter new environments during the operation. Recently, a popular solution is leveraging RGB-D features of large-scale synthetic data and directly applying the model to unseen real-world scenarios. However, the domain shift caused by the sim2real gap is inevitable, posing a crucial challenge to the segmentation model. In this paper, we em-phasize the adaptation process across sim2real domains and model it as a learning problem on the BatchNorm param-eters of a simulation-trained model. Specifically, we propose a novel non-parametric entropy objective, which formulates the learning objective for the test-time adaptation in an open-world manner. Then, a cross-modality knowledge distillation objective is further designed to encourage the test-time knowledge transfer for feature enhancement. Our approach can be efficiently implemented with only test images, without requiring annotations or revisiting the large-scale synthetic training data. Besides significant time savings, the proposed method consistently improves segmentation results on the overlap and boundary metrics, achieving state-of-the-art performance on unseen object instance segmentation.",
        "primary_area": "",
        "author": "Lu Zhang;Siqi Zhang;Xu Yang;Hong Qiao;Zhiyong Liu;Lu Zhang;Siqi Zhang;Xu Yang;Hong Qiao;Zhiyong Liu",
        "authorids": "/37089734134;/37089893129;/37085355343;/37338715300;/37289197400;/37089734134;/37089893129;/37085355343;/37338715300;/37289197400",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Nanjing Artificial Intelligence Research of IA, Jiangning District, Nanjing, Jiangsu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160742/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14371902619784726020&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Nanjing Artificial Intelligence Research of IA",
        "aff_unique_dep": "School of Artificial Intelligence;",
        "aff_unique_url": "http://www.ucas.ac.cn;",
        "aff_unique_abbr": "UCAS;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160277",
        "title": "Unsupervised Learning of Depth and Pose Based on Monocular Camera and Inertial Measurement Unit (IMU)",
        "track": "main",
        "status": "Poster",
        "abstract": "The main content of the research in this paper is the estimation of depth and pose based on monocular vision and Inertial Measurement Unit (IMU). The usual depth estimation network and pose estimation network require depth ground truth or pose ground truth as a supervised signal for training, while the depth ground truth and pose ground truth are hard to obtain, and monocular vision based depth estimation cannot predict absolute depth. In this paper, with the help of IMU, which is inexpensive and widely used, we can obtain angular velocity and acceleration information. Two new supervision signals are proposed and the calculation expressions are given. Among them, the model trained with acceleration constraint shows a good ability to estimate the absolute depth during the test. It can be considered that the model can estimate the absolute depth. We also derive the method of estimating the scale factor during the test from the acceleration constraint, and also achieve good results as the acceleration constraint does. In addition, this paper also studies the method of using IMU information as pose network input and as selecting conditions. Moreover, it analyzes and discusses the experimental results. At the same time, we also evaluate the effect of the pose estimation of the relevant models. This article starts by reviewing the achievements and deficiencies of the work in this field, combines the use of IMU, puts forward three new methods such as a new loss function, and conducts a test analysis and discussion of relevant indicators on the KITTI data set.",
        "primary_area": "",
        "author": "Yanbo Wang;Hanwen Yang;Jianwei Cai;Guangming Wang;Jingchuan Wang;Yi Huang;Yanbo Wang;Hanwen Yang;Jianwei Cai;Guangming Wang;Jingchuan Wang;Yi Huang",
        "authorids": "/37089895133;/37089892327;/37089893048;/37086937116;/37539010600;/37089922032;/37089895133;/37089892327;/37089893048;/37086937116;/37539010600;/37089922032",
        "aff": "University of Michigan-Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China; Key Laboratory of System Control and Information Processing, Ministry of Education of China; Key Laboratory of System Control and Information Processing, Ministry of Education of China; Shanghai Weitong Vision Technology Co., Ltd.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160277/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14095215732006162490&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;2",
        "aff_unique_norm": "Shanghai Jiao Tong University;Ministry of Education of China;Shanghai Weitong Vision Technology Co., Ltd.",
        "aff_unique_dep": "University of Michigan-Shanghai Jiao Tong University Joint Institute;Key Laboratory of System Control and Information Processing;",
        "aff_unique_url": "https://www.sjtu.edu.cn;http://www.moe.gov.cn/;",
        "aff_unique_abbr": "SJTU;;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160679",
        "title": "Unsupervised Quality Prediction for Improved Single-Frame and Weighted Sequential Visual Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "While substantial progress has been made in the absolute performance of localization and Visual Place Recognition (VPR) techniques, it is becoming increasingly clear from translating these systems into applications that other capabilities like integrity and predictability are just as important, especially for safety- or operationally-critical autonomous systems. In this research we present a new, training-free approach to predicting the likely quality of localization estimates, and a novel method for using these predictions to bias a sequence-matching process to produce additional performance gains beyond that of a naive sequence matching approach. Our combined system is lightweight, runs in real-time and is agnostic to the underlying VPR technique. On extensive experiments across four datasets and three VPR techniques, we demonstrate our system improves precision performance, especially at the high-precision/low-recall operating point. We also present ablation and analysis identifying the performance contributions of the prediction and weighted sequence matching components in isolation, and the relationship between the quality of the prediction system and the benefits of the weighted sequential matcher.",
        "primary_area": "",
        "author": "Helen Carson;Jason J. Ford;Michael Milford;Helen Carson;Jason J. Ford;Michael Milford",
        "authorids": "/37089464802;/37363881000;/37283633100;/37089464802;/37363881000;/37283633100",
        "aff": "QUT Centre for Robotics, School of Electrical Engineering and Robotics at the Queensland University of Technology, Brisbane, Australia; QUT Centre for Robotics, School of Electrical Engineering and Robotics at the Queensland University of Technology, Brisbane, Australia; QUT Centre for Robotics, School of Electrical Engineering and Robotics at the Queensland University of Technology, Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160679/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12771625913126882150&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "School of Electrical Engineering and Robotics",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160872",
        "title": "Unsupervised RGB-to-Thermal Domain Adaptation via Multi-Domain Attention Network",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a new method for unsupervised thermal image classification and semantic segmentation by transferring knowledge from the RGB domain using a multi-domain attention network. Our method does not require any thermal annotations or co-registered RGB-thermal pairs, enabling robots to perform visual tasks at night and in adverse weather conditions without incurring additional costs of data labeling and registration. Current unsupervised domain adaptation methods look to align global images or features across domains. However, when the domain shift is significantly larger for cross-modal data, not all features can be transferred. We solve this problem by using a shared backbone network that promotes generalization, and domain-specific attention that reduces negative transfer by attending to domain-invariant and easily-transferable features. Our approach outperforms the state-of-the-art RGB-to-thermal adaptation method in classification benchmarks, and is successfully applied to thermal river scene segmentation using only synthetic RGB images. Our code is made publicly available at https://github.com/ganlumomo/thermal-uda-attention.",
        "primary_area": "",
        "author": "Lu Gan;Connor Lee;Soon-Jo Chung;Lu Gan;Connor Lee;Soon-Jo Chung",
        "authorids": "/37089894264;/37089893531;/37309487700;/37089894264;/37089893531;/37309487700",
        "aff": "Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, USA; Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, USA; Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160872/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12877457068768949205&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Division of Engineering and Applied Science",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160470",
        "title": "Unsupervised Road Anomaly Detection with Language Anchors",
        "track": "main",
        "status": "Poster",
        "abstract": "Road anomaly detection is critical to safe autonomous driving, because current road scene understanding models are usually trained in a closed-set manner and fail to identify unknown objects. What's worse, it is difficult, if not impossible, to collect a large-scale dataset with anomaly annotations. So this paper studies unsupervised anomaly detection which finds out anomaly regions using scene parsing logits solely. While former methods depend on the weights learned from the closed training set as anchors for logit generation, we resort to language anchors that are learned from enormous paired vision and language data. Thanks to rich open-set semantic information contained in these language anchors, our method performs better than former unsupervised counterparts while maintaining the advantage of training without accessing any out-of-distribution data. We delve into this new paradigm and identify the superiority of using pair-wise binary logits, which we credit to a better understanding of the negation language anchor. Last but not least, we find that the former top-1 selection of semantic labels for uncertainty measurement is problematic in many cases and a new blended standardization strategy brings clear improvements to our solution. We report state-of-the-art performance on FS LostAndFound, LostAndFound and RoadAnomaly datasets among comparable methods. The codes are publicly available at https://github.com/TB5z035/URAD-LA.git",
        "primary_area": "",
        "author": "Beiwen Tian;Mingdao Liu;Huan-ang Gao;Pengfei Li;Hao Zhao;Guyue Zhou;Beiwen Tian;Mingdao Liu;Huan-ang Gao;Pengfei Li;Hao Zhao;Guyue Zhou",
        "authorids": "/37089895365;/37089895012;/37089892178;/37089893178;/37086217629;/37085489402;/37089895365;/37089895012;/37089892178;/37089893178;/37086217629;/37085489402",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160470/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18229858592072625632&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Institute for AI Industry Research (AIR)",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161188",
        "title": "Upper-limb Geometric MyoPassivity Map for Physical Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "The intrinsic biomechanical characteristic of the human upper limb plays a central role in absorbing the interactive energy during physical human-robot interaction (pHRI). We have recently shown that based on the concept of \u201cExcess of Passivity (EoP),\u201d from nonlinear control theory, it is possible to decode such energetic behavior for both upper and lower limbs [1], [2]. The extracted knowledge can be used in the design of controllers (such as [2]-[5]) for optimizing the transparency and fidelity of force fields in human-robot interaction and in haptic systems. In this paper, for the first time, we investigate the frequency behavior of the passivity map for the upper limb when the muscle co-activation was controlled in real- time through visual electromyographic feedback. Five healthy subjects (age: 27\u00b15) were included in this study. The energetic behavior was evaluated at two stimulation frequencies at eight interaction directions over two controlled muscle co-activation levels. Electromyography (EMG) was captured using the Delsys Wireless Trigno system. Results showed a correlation between EMG and EoP, which was further amplified by decreasing the frequency. The proposed energetic behavior is named the Geometric MyoPassivity (GMP) map. The findings indicate that the GMP map has the potential to be used in real-time to quantify the absorbable energy, thus passivity margin of stability for upper limb interaction during pHRI.",
        "primary_area": "",
        "author": "Xingyuan Zhou;Peter Paik;S. Farokh Atashzar;Xingyuan Zhou;Peter Paik;S. Farokh Atashzar",
        "authorids": "/37089895794;/37089710488;/37592440100;/37089895794;/37089710488;/37592440100",
        "aff": "Department of Electrical and Computer Engineering, New York University (NYU), New York, NY, USA; Department of Electrical and Computer Engineering, New York University (NYU), New York, NY, USA; NYU WIRELESS Center and NYU CUSP",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161188/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4668887338557616746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160851",
        "title": "User-Conditioned Neural Control Policies for Mobile Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, learning-based controllers have been shown to push mobile robotic systems to their limits and provide the robustness needed for many real-world applications. However, only classical optimization-based control frameworks offer the inherent flexibility to be dynamically adjusted during execution by, for example, setting target speeds or actuator limits. We present a framework to overcome this shortcoming of neural controllers by conditioning them on an auxiliary input. This advance is enabled by including a feature-wise linear modulation layer (FiLM). We use model-free reinforcement-learning to train quadrotor control policies for the task of navigating through a sequence of waypoints in minimum time. By conditioning the policy on the maximum available thrust or the viewing direction relative to the next waypoint, a user can regulate the aggressiveness of the quadrotor's flight during deployment. We demonstrate in simulation and in real-world experiments that a single control policy can achieve close to time-optimal flight performance across the entire performance envelope of the robot, reaching up to 60 km/h and 4.5 g in acceleration. The ability to guide a learned controller during task execution has implications beyond agile quadrotor flight, as conditioning the control policy on human intent helps safely bringing learning based systems out of the well-defined laboratory environment into the wild. Video: https://youtu.be/rwT2QQZEH6U",
        "primary_area": "",
        "author": "Leonard Bauersfeld;Elia Kaufmann;Davide Scaramuzza;Leonard Bauersfeld;Elia Kaufmann;Davide Scaramuzza",
        "authorids": "/37086827655;/37086293209;/37397688400;/37086827655;/37086293209;/37397688400",
        "aff": "Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160851/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17986948062100481814&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Department of Neuroinformatics",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161105",
        "title": "Using Learning Curve Predictions to Learn from Incorrect Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots can incorporate data from human teachers when learning new tasks. However, this data can often be noisy, which can cause robots to learn slowly or not at all. One method for learning from human teachers is Human-in-the-loop Reinforcement Learning (HRL), which can combine information from both an environmental reward and external feedback from human teachers. However, many HRL methods assume near-perfect information from teachers or must know the skill level of each teacher before starting the learning process. Our algorithm, Classification for Learning Erroneous Assessments using Rewards (CLEAR), is a feedback filter for Reinforcement Learning (RL) algorithms, enabling learning agents to learn from imperfect teachers without prior modeling. CLEAR is able to determine whether human feedback is correct based on observations of the RL learning curve. Our results suggest that CLEAR improves the quality of human feedback - from 57.5% to 65% correct in a human study - and performs more reliably than baselines by matching or outperforming RL without human teachers in all tested cases.",
        "primary_area": "",
        "author": "Taylor A. Kessler Faulkner;Andrea L. Thomaz;Taylor A. Kessler Faulkner;Andrea L. Thomaz",
        "authorids": "/37086577615;/37296354000;/37086577615;/37296354000",
        "aff": "Department of Computer Science and Engineering, University of Washington; Department of Electrical and Computer Engineering, The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161105/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6693145035551600795&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Washington;The University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.washington.edu;https://www.utexas.edu",
        "aff_unique_abbr": "UW;UT Austin",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Seattle;Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161154",
        "title": "Using Memory-Based Learning to Solve Tasks with State-Action Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Tasks where the set of possible actions depend discontinuously on the state pose a significant challenge for current reinforcement learning algorithms. For example, a locked door must be first unlocked, and then the handle turned before the door can be opened. The sequential nature of these tasks makes obtaining final rewards difficult, and transferring information between task variants using continuous learned values such as weights rather than discrete symbols can be inefficient. Our key insight is that agents that act and think symbolically are often more effective in dealing with these tasks. We propose a memory-based learning approach that leverages the symbolic nature of constraints and temporal ordering of actions in these tasks to quickly acquire and transfer high-level information. We evaluate the performance of memory-based learning on both real and simulated tasks with approximately discontinuous constraints between states and actions, and show our method learns to solve these tasks an order of magnitude faster than both model-based and model-free deep reinforcement learning methods.",
        "primary_area": "",
        "author": "Mrinal Verghese;Christopher Atkeson;Mrinal Verghese;Christopher Atkeson",
        "authorids": "/37089298784;/37277593800;/37089298784;/37277593800",
        "aff": "Robotics Institute at Carnegie Mellon University; Robotics Institute at Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161154/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3666206832341751963&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160519",
        "title": "Using Registration with Fourier-SOFT in 2D (FS2D) for Robust Scan Matching of Sonar Range Data",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce Fourier-SOFT 2D (FS2D) as a new robust registration method. FS2D operates in the frequency domain where it exploits the well-known decoupling of rotation and translation. The challenging part of determining the rotation parameter is solved here based on a projection of the Fourier magnitude on a sphere and the SO(3) Fourier Transform (SOFT). The underlying use case is underwater mapping with sonar, i.e., with very noisy and partially overlapping environment data under non-trivial localization and navigation challenges. Fourier-SOFT 2D is compared with openly available registration methods on two real-world datasets and a simulated dataset. Results show the robustness of FS2D, i.e., its capabilities to handle large amounts of noise and occlusions of consecutive scans. The implementation in C++ is openly available.",
        "primary_area": "",
        "author": "Tim Hansen;Andreas Birk;Tim Hansen;Andreas Birk",
        "authorids": "/37088568293;/37283236400;/37088568293;/37283236400",
        "aff": "School of Computer Science and Engineering at Constructor University, Bremen, Germany; School of Computer Science and Engineering at Constructor University, Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160519/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15485052934461623370&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Constructor University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "https://www.constructor-university.org",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161348",
        "title": "Using a Collaborative Robotic Arm as Human-Machine Interface: System Setup and Application to Pose Control Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "While robotic arms have been used in a vast range of application areas, so far no extensive reports on the utilization as human-machine interface exist. Compared to HMI devices from literature, the robotic arm used in this work (KUKA LBR iiwa 14 R820) features a relatively large workspace and is able to generate force and torque feedback that surpasses the capabilities of literature devices. We describe the setup allowing to use the robotic arm as HMI and analytically determine the optimal initial pose of it based on the manipulability measure of Yoshikawa. To demonstrate that the robotic arm is able to serve as HMI, we report on a comparative study with a state of the art haptic HMI featuring 20 participants. Additionally, two applications from the context of planetary exploration are presented: The first considers the teleoperation of the pan-tilt unit of a lightweight rover unit and illustrates how the large workspace of the HMI benefits the precision of the teleoperation compared to a setup with a smaller workspace. The second experiment showcases the use of the force feedback of the HMI to enable a cooperation between the operator and a supporting path-following automation in a shared control of a simulated ground robot. Both the study and the applications highlight the performance, precision and reliability of our proposed system.",
        "primary_area": "",
        "author": "Christian A. Braun;Ludwig Haide;Lars Fischer;Sean Kille;Balint Varga;Simon Rothfuss;S\u00f6ren Hohmann;Christian A. Braun;Ludwig Haide;Lars Fischer;Sean Kille;Balint Varga;Simon Rothfuss;S\u00f6ren Hohmann",
        "authorids": "/37086072510;/37089895445;/37089893181;/37088922628;/37086841883;/37087240499;/37085386660;/37086072510;/37089895445;/37089893181;/37088922628;/37086841883;/37087240499;/37085386660",
        "aff": "Institute of Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161348/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1532594380040195234&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Control Systems",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10161384",
        "title": "V2XP-ASG: Generating Adversarial Scenes for Vehicle-to-Everything Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advancements in Vehicle-to-Everything communication technology have enabled autonomous vehicles to share sensory information to obtain better perception performance. With the rapid growth of autonomous vehicles and intelligent infrastructure, the V2X perception systems will soon be deployed at scale, which raises a safety-critical question: how can we evaluate and improve its performance under challenging traffic scenarios before the real-world deployment? Collecting diverse large-scale real-world test scenes seems to be the most straightforward solution, but it is expensive and time-consuming, and the collections can only cover limited scenarios. To this end, we propose the first open adversarial scene generator V2XP-ASG that can produce realistic, challenging scenes for modern LiDAR-based multi-agent perception systems. V2XP-ASG learns to construct an adversarial collaboration graph and simultaneously perturb multiple agents' poses in an adversarial and plausible manner. The experiments demonstrate that V2XP-ASG can effectively identify challenging scenes for a large range of V2X perception systems. Meanwhile, by training on the limited number of generated challenging scenes, the accuracy of V2X perception systems can be further improved by 12.3% on challenging and 4% on normal scenes. Our code will be released at https://github.com/XHwind/V2XP-ASG.",
        "primary_area": "",
        "author": "Hao Xiang;Runsheng Xu;Xin Xia;Zhaoliang Zheng;Bolei Zhou;Jiaqi Ma;Hao Xiang;Runsheng Xu;Xin Xia;Zhaoliang Zheng;Bolei Zhou;Jiaqi Ma",
        "authorids": "/37089006777;/37089002744;/37086487632;/37089449533;/37085668760;/37085693088;/37089006777;/37089002744;/37086487632;/37089449533;/37085668760;/37085693088",
        "aff": "University of California, Los Angeles, CA, USA; University of California, Los Angeles, CA, USA; University of California, Los Angeles, CA, USA; University of California, Los Angeles, CA, USA; University of California, Los Angeles, CA, USA; University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161384/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2633154020743423473&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161251",
        "title": "VINet: Visual and Inertial-based Terrain Classification and Adaptive Navigation over Unknown Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a visual and inertial-based terrain classification network (VINet) for robotic navigation over different traversable surfaces. We use a novel navigation-based labeling scheme for terrain classification and generalization on unknown surfaces. Our proposed perception method and adaptive scheduling control framework can make predictions according to terrain navigation properties and lead to better performance on both terrain classification and navigation control on known and unknown surfaces. Our VINet can achieve 98.37% in terms of accuracy under supervised setting on known terrains and improve the accuracy by 8.51% on unknown terrains compared to previous methods. We deploy VINet on a mobile tracked robot for trajectory following and navigation on different terrains, and we demonstrate an improvement of 10.3% compared to a baseline controller in terms of RMSE.",
        "primary_area": "",
        "author": "Tianrui Guan;Ruitao Song;Zhixian Ye;Liangjun Zhang;Tianrui Guan;Ruitao Song;Zhixian Ye;Liangjun Zhang",
        "authorids": "/37088414623;/37089919146;/37089515644;/37088642847;/37088414623;/37089919146;/37089515644;/37088642847",
        "aff": "Baidu RAL, USA; Robotics and Autonomous Driving Laboratory, Baidu USA, Sunnyvale, CA, USA; Robotics and Autonomous Driving Laboratory, Baidu USA, Sunnyvale, CA, USA; Robotics and Autonomous Driving Laboratory, Baidu USA, Sunnyvale, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161251/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4271810844008321383&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Baidu;Baidu USA",
        "aff_unique_dep": "Baidu RAL;Robotics and Autonomous Driving Laboratory",
        "aff_unique_url": "https://www.baidu.com;https://www.baidu.com",
        "aff_unique_abbr": "Baidu;Baidu",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Sunnyvale",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160214",
        "title": "VP-STO: Via-point-based Stochastic Trajectory Optimization for Reactive Robot Behavior",
        "track": "main",
        "status": "Poster",
        "abstract": "Achieving reactive robot behavior in complex dynamic environments is still challenging as it relies on being able to solve trajectory optimization problems quickly enough, such that we can replan the future motion at frequencies which are sufficiently high for the task at hand. We argue that current limitations in Model Predictive Control (MPC) for robot manipulators arise from inefficient, high-dimensional trajectory representations and the negligence of time-optimality in the trajectory optimization process. Therefore, we propose a motion optimization framework that optimizes jointly over space and time, generating smooth and timing-optimal robot trajectories in joint-space. While being task-agnostic, our formulation can incorporate additional task-specific requirements, such as collision avoidance, and yet maintain real-time control rates, demonstrated in simulation and real-world robot experiments on closed-loop manipulation. For additional material, please visit https://sites.google.com/oxfordrobotics.institute/vp-sto.",
        "primary_area": "",
        "author": "Julius Jankowski;Lara Bruderm\u00fcller;Nick Hawes;Sylvain Calinon;Julius Jankowski;Lara Bruderm\u00fcller;Nick Hawes;Sylvain Calinon",
        "authorids": "/37088532147;/37089228721;/37590842900;/37295947200;/37088532147;/37089228721;/37590842900;/37295947200",
        "aff": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), CH; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), CH",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160214/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10055065774732711515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne;University of Oxford",
        "aff_unique_dep": ";Oxford Robotics Institute",
        "aff_unique_url": "https://www.epfl.ch;https://www.ox.ac.uk",
        "aff_unique_abbr": "EPFL;Oxford",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Oxford",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Switzerland;United Kingdom"
    },
    {
        "id": "10160390",
        "title": "VQA-based Robotic State Recognition Optimized with Genetic Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "State recognition of objects and environment in robots has been conducted in various ways. In most cases, this is executed by processing point clouds, learning images with annotations, and using specialized sensors. In contrast, in this study, we propose a state recognition method that applies Visual Question Answering (VQA) in a Pre-Trained Vision-Language Model (PTVLM) trained from a large-scale dataset. By using VQA, it is possible to intuitively describe robotic state recognition in the spoken language. On the other hand, there are various possible ways to ask about the same event, and the performance of state recognition differs depending on the question. Therefore, in order to improve the performance of state recognition using VQA, we search for an appropriate combination of questions using a genetic algorithm. We show that our system can recognize not only the open/closed of a refrigerator door and the on/off of a display, but also the open/closed of a transparent door and the state of water, which have been difficult to recognize.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Yoshiki Obinata;Naoaki Kanazawa;Kei Okada;Masayuki Inaba;Kento Kawaharazuka;Yoshiki Obinata;Naoaki Kanazawa;Kei Okada;Masayuki Inaba",
        "authorids": "/37086101930;/37089892357;/37089442080;/37280639000;/37286658200;/37086101930;/37089892357;/37089442080;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160390/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10379655904670478381&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160558",
        "title": "Variable Admittance Interaction Control of UAVs via Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "A compliant control model based on reinforcement learning (RL) is proposed to allow robots to interact with the environment more effectively and autonomously execute force control tasks. The admittance model learns an optimal adjustment policy for interactions with the external environment using RL algorithms. The model combines energy consumption and trajectory tracking of the agent state using a cost function. Therein, an Unmanned Aerial Vehicle (UAV) can operate stably in unknown environments where interaction forces exist. Furthermore, the model ensures that the interaction process is safe, comfortable, and flexible while protecting the external structures of the UAV from damage. To evaluate the model performance, we verified the approach in a simulation environment using a UAV in three external force scenes. We also tested the model across different UAV platforms and various low-level control parameters, and the proposed approach provided the best results.",
        "primary_area": "",
        "author": "Yuting Feng;Chuanbeibei Shi;Jianrui Du;Yushu Yu;Fuchun Sun;Yixu Song;Yuting Feng;Chuanbeibei Shi;Jianrui Du;Yushu Yu;Fuchun Sun;Yixu Song",
        "authorids": "/37086311840;/37089892474;/37089893352;/37963812000;/37279269000;/37539746400;/37086311840;/37089892474;/37089893352;/37963812000;/37279269000;/37539746400",
        "aff": "School of Mechatronical Engineering, Beijing Institute of Technology, China; School of Mechatronical Engineering, Beijing Institute of Technology, China; School of Mechatronical Engineering, Beijing Institute of Technology, China; School of Mechatronical Engineering, Beijing Institute of Technology, China; Department of Computer Science and Technology, Tsinghua University, China; Department of Computer Science and Technology, Tsinghua University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160558/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17907087133616867362&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;1",
        "aff_unique_norm": "Beijing Institute of Technology;Tsinghua University",
        "aff_unique_dep": "School of Mechatronical Engineering;Department of Computer Science and Technology",
        "aff_unique_url": "http://www.bit.edu.cn/;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "BIT;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160976",
        "title": "Vector Field Aided Trajectory Tracking by a 10-gram Flapping-Wing Micro Aerial Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Here we describe how a 10-gram Flapping-Wing Micro Aerial Vehicle (FWMAV) was able to perform an automatic trajectory tracking task based on a vector field method. In this study, the desired heading was provided by a vector field which was computed depending on the desired trajectory. The FWMAV's heading was changed by a rear steering mechanism. This rear mechanism simultaneously (i) tenses one wing and relaxes the opposite wing, and (ii) moves the rudder in the same direction as the wing is relaxed. Due to the complex dynamics, system identification methods were used to identify simple linear models using a set of dedicated free flight tests. This yaw and roll simple models help to adjust the yaw controller and the inner loop roll controller. The experimental results obtained here show that a time-independent vector field-based strategy is robust to various initial position and/or speed conditions. The task of tracking circular and 8-shaped trajectories was accomplished successfully over tens of meters.",
        "primary_area": "",
        "author": "A. Ndoye;J. J. Castillo-Zamora;S. Samorah-Laki;R. Miot;E. Van Ruymbeke;F. Ruffier;A. Ndoye;J. J. Castillo-Zamora;S. Samorah-Laki;R. Miot;E. Van Ruymbeke;F. Ruffier",
        "authorids": "/37089896050;/37086418659;/37089894280;/37089892497;/37089893881;/37282466500;/37089896050;/37086418659;/37089894280;/37089892497;/37089893881;/37282466500",
        "aff": "Aix Marseille Universit\u00e9, CNRS. ISM., Marseille, France; Aix Marseille Universit\u00e9, CNRS. ISM., Marseille, France; Aix Marseille Universit\u00e9, CNRS. ISM., Marseille, France; XTIM - Bionic Bird, Marseille, France; XTIM - Bionic Bird, Marseille, France; Aix Marseille Universit\u00e9, CNRS. ISM., Marseille, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160976/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8459651264610326611&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Aix Marseille Universit\u00e9;XTIM - Bionic Bird",
        "aff_unique_dep": "CNRS. ISM.;",
        "aff_unique_url": "https://www.univ-amu.fr;",
        "aff_unique_abbr": "AMU;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Marseille;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "10160221",
        "title": "Versatile Real-Time Motion Synthesis via Kino-Dynamic MPC With Hybrid-Systems DDP",
        "track": "main",
        "status": "Poster",
        "abstract": "Specialized motions such as jumping are often achieved on quadruped robots by solving a trajectory optimization problem once and executing the trajectory using a tracking controller. This approach is in parallel with Model Predictive Control (MPC) strategies that commonly control regular gaits via online re-planning. In this work, we present a nonlinear MPC (NMPC) technique that unlocks on-the-fly replanning of specialized motion skills and regular locomotion within a unified framework. The NMPC reasons about a hybrid kinodynamic model, and is solved using a variant of a constrained Differential Dynamic Programming (DDP) solver. The proposed NMPC enables the robot to perform a variety of agile skills like jumping, bounding, and trotting, and the rapid transition between them. We evaluated the proposed algorithm with three challenging motion sequences that combine multiple agile skills, on two quadruped platforms, Unitree A1, and MIT Mini Cheetah, showing its effectiveness and generality.",
        "primary_area": "",
        "author": "He Li;Tingnan Zhang;Wenhao Yu;Patrick M. Wensing;He Li;Tingnan Zhang;Wenhao Yu;Patrick M. Wensing",
        "authorids": "/37088448396;/37088504200;/37085891022;/37946046300;/37088448396;/37088504200;/37085891022;/37946046300",
        "aff": "University of Notre Dame, Notre Dame, IN, USA; Robotics at Google, Mountain View, CA, USA; Robotics at Google, Mountain View, CA, USA; University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160221/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12666864941668274387&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Notre Dame;Google",
        "aff_unique_dep": ";Robotics",
        "aff_unique_url": "https://www.nd.edu;https://www.google.com",
        "aff_unique_abbr": "Notre Dame;Google",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Notre Dame;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160421",
        "title": "Versatile Skill Control via Self-supervised Adversarial Imitation of Unlabeled Mixed Motions",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning diverse skills is one of the main challenges in robotics. To this end, imitation learning approaches have achieved impressive results. These methods require explicitly labeled datasets or assume consistent skill execution to enable learning and active control of individual behaviors, which limits their applicability. In this work, we propose a cooperative adversarial method for obtaining single versatile policies with controllable skill sets from unlabeled datasets containing diverse state transition patterns by maximizing their discriminability. Moreover, we show that by utilizing unsupervised skill discovery in the generative adversarial imitation learning framework, novel and useful skills emerge with successful task fulfillment. Finally, the obtained versatile policies are tested on an agile quadruped robot called Solo 8 and present faithful replications of diverse skills encoded in the demonstrations.",
        "primary_area": "",
        "author": "Chenhao Li;Sebastian Blaes;Pavel Kolev;Marin Vlastelica;Jonas Frey;Georg Martius;Chenhao Li;Sebastian Blaes;Pavel Kolev;Marin Vlastelica;Jonas Frey;Georg Martius",
        "authorids": "/37089893348;/37089892944;/37089893924;/37088456946;/37089524961;/37870313400;/37089893348;/37089892944;/37089893924;/37088456946;/37089524961;/37870313400",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160421/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9121256225364889350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;ETH Zurich",
        "aff_unique_dep": ";Robotic Systems Lab",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.ethz.ch",
        "aff_unique_abbr": "MPI-IS;ETHZ",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "T\u00fcbingen;Zurich",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "10160612",
        "title": "ViNL: Visual Navigation and Locomotion Over Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Visual Navigation and Locomotion over obstacles (ViNL), which enables a quadrupedal robot to navigate unseen apartments while stepping over small obstacles that lie in its path (e.g., shoes, toys, cables), similar to how humans and pets lift their feet over objects as they walk. ViNL consists of: (1) a visual navigation policy that outputs linear and angular velocity commands that guides the robot to a goal coordinate in unfamiliar indoor environments; and (2) a visual locomotion policy that controls the robot's joints to avoid step-ping on obstacles while following provided velocity commands. Both the policies are entirely \u2018model-free\u2019, i.e. sensors-to-actions neural networks trained end-to-end. The two are trained independently in two entirely different simulators and then seamlessly co-deployed by feeding the velocity commands from the navigator to the locomotor, entirely \u2018zero-shot\u2019 (without any co-training). While prior works have developed learning methods for visual navigation or visual locomotion, to the best of our knowledge, this is the first fully learned approach that leverages vision to accomplish both (1) intelligent navigation in new environments, and (2) intelligent visual locomotion that aims to traverse cluttered environments without disrupting obstacles. On the task of navigation to distant goals in unknown environments, ViNL using just egocentric vision significantly outperforms prior work on robust locomotion using privileged terrain maps (+32.8% success and -4.42 collisions per meter). Additionally, we ablate our locomotion policy to show that each aspect of our approach helps reduce obstacle collisions. Videos and code at http://www.joannetruong.com/projects/vinl.html.",
        "primary_area": "",
        "author": "Simar Kareer;Naoki Yokoyama;Dhruv Batra;Sehoon Ha;Joanne Truong;Simar Kareer;Naoki Yokoyama;Dhruv Batra;Sehoon Ha;Joanne Truong",
        "authorids": "/37089894069;/37089657541;/37294512800;/37086314268;/37088473406;/37089894069;/37089657541;/37294512800;/37086314268;/37088473406",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160612/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1098334953618383895&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160658",
        "title": "ViPFormer: Efficient Vision-and-Pointcloud Transformer for Unsupervised Pointcloud Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, a growing number of work design unsupervised paradigms for point cloud processing to alleviate the limitation of expensive manual annotation and poor transferability of supervised methods. Among them, CrossPoint follows the contrastive learning framework and exploits image and point cloud data for unsupervised point cloud understanding. Although the promising performance is presented, the unbalanced architecture makes it unnecessarily complex and inefficient. For example, the image branch in CrossPoint is ~8.3x heavier than the point cloud branch leading to higher complexity and latency. To address this problem, in this paper, we propose a lightweight Vision-and-Pointcloud Transformer (ViPFormer) to unify image and point cloud processing in a single architecture. ViPFormer learns in an unsupervised manner by optimizing intra-modal and cross-modal contrastive objectives. Then the pretrained model is transferred to various downstream tasks, including 3D shape classification and semantic segmentation. Experiments on different datasets show ViPFormer surpasses previous state-of-the-art unsupervised methods with higher accuracy, lower model complexity and runtime latency. Finally, the effectiveness of each component in ViPFormer is validated by extensive ablation studies. The implementation of the proposed method is available at https://github.com/auniquesun/ViPFormer.",
        "primary_area": "",
        "author": "Hongyu Sun;Yongcai Wang;Xudong Cai;Xuewei Bai;Deying Li;Hongyu Sun;Yongcai Wang;Xudong Cai;Xuewei Bai;Deying Li",
        "authorids": "/37089895218;/37086331551;/37089893125;/37089762220;/37277108600;/37089895218;/37086331551;/37089893125;/37089762220;/37277108600",
        "aff": "Department of Computer Science, School of Information, Renmin University of China, Beijing, China; Department of Computer Science, School of Information, Renmin University of China, Beijing, China; Department of Computer Science, School of Information, Renmin University of China, Beijing, China; Department of Computer Science, School of Information, Renmin University of China, Beijing, China; Department of Computer Science, School of Information, Renmin University of China, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160658/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6281513949226559838&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Renmin University of China",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "http://www.ruc.edu.cn",
        "aff_unique_abbr": "RUC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161240",
        "title": "Video Waterdrop Removal via Spatio-Temporal Fusion in Driving Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "The waterdrops on windshields during driving can cause severe visual obstructions, which may lead to car accidents. Meanwhile, the waterdrops can also degrade the performance of a computer vision system in autonomous driving. To address these issues, we propose an attention-based framework that fuses the spatio-temporal representations from multiple frames to restore visual information occluded by waterdrops. Due to the lack of training data for video waterdrop removal, we propose a large-scale synthetic dataset with simulated waterdrops in complex driving scenes on rainy days. To improve the generality of our proposed method, we adopt a cross-modality training strategy that combines synthetic videos and real-world images. Extensive experiments show that our proposed method can generalize well and achieve the best waterdrop removal performance in complex real-world driving scenes.",
        "primary_area": "",
        "author": "Qiang Wen;Yue Wu;Qifeng Chen;Qiang Wen;Yue Wu;Qifeng Chen",
        "authorids": "/37089537414;/37088457572;/37087230927;/37089537414;/37088457572;/37087230927",
        "aff": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161240/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=177524587393202664&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160707",
        "title": "Viewer-Centred Surface Completion for Unsupervised Domain Adaptation in 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Every autonomous driving dataset has a different configuration of sensors, originating from distinct geographic regions and covering various scenarios. As a result, 3D detectors tend to overfit the datasets they are trained on. This causes a drastic decrease in accuracy when the detectors are trained on one dataset and tested on another. We observe that lidar scan pattern differences form a large component of this reduction in performance. We address this in our approach, SEE-VCN, by designing a novel viewer-centred surface completion network (VCN) to complete the surfaces of objects of interest within an unsupervised domain adaptation framework, SEE [1]. With SEE-VCN, we obtain a unified representation of objects across datasets, allowing the network to focus on learning geometry, rather than overfitting on scan patterns. By adopting a domain-invariant representation, SEE-VCN can be classed as a multi-target domain adaptation approach where no annotations or re-training is required to obtain 3D detections for new scan patterns. Through extensive experiments, we show that our approach outperforms previous domain adaptation methods in multiple domain adaptation settings. Our code and data are available at https://github.com/darrenjkt/SEE-VCN.",
        "primary_area": "",
        "author": "Darren Tsai;Julie Stephany Berrio;Mao Shan;Eduardo Nebot;Stewart Worrall;Darren Tsai;Julie Stephany Berrio;Mao Shan;Eduardo Nebot;Stewart Worrall",
        "authorids": "/37089003467;/38246299000;/38242373300;/37273559500;/37606436900;/37089003467;/38246299000;/38242373300;/37273559500;/37606436900",
        "aff": "Australian Centre for Field Robotics (ACFR) at the University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR) at the University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR) at the University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR) at the University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR) at the University of Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160707/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17398021885288641930&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Sydney",
        "aff_unique_dep": "Australian Centre for Field Robotics (ACFR)",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160373",
        "title": "Vis2Hap: Vision-based Haptic Rendering by Cross-modal Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "To assist robots in teleoperation tasks, haptic rendering which allows human operators access a virtual touch feeling has been developed in recent years. Most previous haptic rendering methods strongly rely on data collected by tactile sensors. However, tactile data is not widely available for robots due to their limited reachable space and the restrictions of tactile sensors. To eliminate the need for tactile data, in this paper we propose a novel method named as Vis2Hap to generate haptic rendering from visual inputs that can be obtained from a distance without physical interaction. We take the surface texture of objects as key cues to be conveyed to the human operator. To this end, a generative model is designed to simulate the roughness and slipperiness of the object's surface. To embed haptic cues in Vis2Hap, we use height maps from tactile sensors and spectrograms from friction coefficients as the intermediate outputs of the generative model. Once Vis2Hap is trained, it can be used to generate height maps and spectrograms of new surface textures, from which a friction image can be obtained and displayed on a haptic display. The user study demonstrates that our proposed Vis2Hap method enables users to access a realistic haptic feeling similar to that of physical objects. The proposed vision-based haptic rendering has the potential to enhance human operators' perception of the remote environment and facilitate robotic manipulation.",
        "primary_area": "",
        "author": "Guanqun Cao;Jiaqi Jiang;Ningtao Mao;Danushka Bollegala;Min Li;Shan Luo;Guanqun Cao;Jiaqi Jiang;Ningtao Mao;Danushka Bollegala;Min Li;Shan Luo",
        "authorids": "/37088686447;/37088912886;/37089896060;/37540532800;/38252239300;/37085478830;/37088686447;/37088912886;/37089896060;/37540532800;/38252239300;/37085478830",
        "aff": "Department of Computer Science, University of Liverpool, Liverpool, United Kingdom; Department of Engineering, King's College London, London, United Kingdom; School of Design, University of Leeds, United Kingdom; Department of Computer Science, University of Liverpool, Liverpool, United Kingdom; School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, China; Department of Engineering, King's College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160373/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4583629768034085287&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;1",
        "aff_unique_norm": "University of Liverpool;King's College London;University of Leeds;Xi'an Jiaotong University",
        "aff_unique_dep": "Department of Computer Science;Department of Engineering;School of Design;School of Mechanical Engineering",
        "aff_unique_url": "https://www.liverpool.ac.uk;https://www.kcl.ac.uk;https://www.leeds.ac.uk;http://www.xjtu.edu.cn",
        "aff_unique_abbr": "Liv Uni;KCL;Leeds;XJTU",
        "aff_campus_unique_index": "0;1;0;3;1",
        "aff_campus_unique": "Liverpool;London;;Xi'an",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "10160865",
        "title": "Visibility-Aware Navigation Among Movable Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we examine the problem of visibility-aware robot navigation among movable obstacles (VANAMO). A variant of the well-known NAMO robotic planning problem, VANAMO puts additional visibility constraints on robot motion and object movability. This new problem formulation lifts the restrictive assumption that the map is fully visible and the object positions are fully known. We provide a formal definition of the VANAMO problem and propose the Look and Manipulate Backchaining (LAMB) algorithm for solving such problems. Lamb has a simple vision-based interface that makes it more easily transferable to real-world robot applications and scales to the large 3D environments. To evaluate Lamb, we construct a set of tasks that illustrate the complex interplay between visibility and object movability that can arise in mobile base manipulation problems in unknown environments. We show that Lamb outperforms NAMO and visibility-aware motion planning approaches as well as simple combinations of them on complex manipulation problems with partial observability.",
        "primary_area": "",
        "author": "Jose Muguira-Iturralde;Aidan Curtis;Yilun Du;Leslie Pack Kaelbling;Tom\u00e1s Lozano-P\u00e9rez;Jose Muguira-Iturralde;Aidan Curtis;Yilun Du;Leslie Pack Kaelbling;Tom\u00e1s Lozano-P\u00e9rez",
        "authorids": "/37089892420;/37089450030;/37089315638;/37269373600;/38273814000;/37089892420;/37089450030;/37089315638;/37269373600;/38273814000",
        "aff": "CSAIL, MIT, USA; CSAIL, MIT, USA; CSAIL, MIT, USA; CSAIL, MIT, USA; CSAIL, MIT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160865/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15035487052198838877&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160638",
        "title": "Vision-aided UAV Navigation and Dynamic Obstacle Avoidance using Gradient-based B-spline Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigating dynamic environments requires the robot to generate collision-free trajectories and actively avoid moving obstacles. Most previous works designed path planning algorithms based on one single map representation, such as the geometric, occupancy, or ESDF map. Although they have shown success in static environments, due to the limitation of map representation, those methods cannot reliably handle static and dynamic obstacles simultaneously. To address the problem, this paper proposes a gradient-based B-spline trajectory optimization algorithm utilizing the robot's onboard vision. The depth vision enables the robot to track and represent dynamic objects geometrically based on the voxel map. The proposed optimization first adopts the circle-based guide-point algorithm to approximate the costs and gradients for avoiding static obstacles. Then, with the vision-detected moving objects, our receding-horizon distance field is simultaneously used to prevent dynamic collisions. Finally, the iterative re-guide strategy is applied to generate the collision-free trajectory. The simulation and physical experiments prove that our method can run in real-time to navigate dynamic environments safely.",
        "primary_area": "",
        "author": "Zhefan Xu;Yumeng Xiu;Xiaoyang Zhan;Baihan Chen;Kenji Shimada;Zhefan Xu;Yumeng Xiu;Xiaoyang Zhan;Baihan Chen;Kenji Shimada",
        "authorids": "/37088810563;/37089895489;/37089893921;/37089893828;/37324632500;/37088810563;/37089895489;/37089893921;/37089893828;/37324632500",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160638/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14982378966213029014&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161116",
        "title": "Vision-based Six-Dimensional Peg-in-Hole for Practical Connector Insertion",
        "track": "main",
        "status": "Poster",
        "abstract": "We study six-dimensional (6D) perceptive peg-in-hole problem for practical connector insertion task in this paper. To enable the manipulator system to handle different types of pegs in complex environment, we develop a perceptive robotic assembly system that utilizes an in-hand RGB-D camera for peg-in-hole with multiple types of pegs. The proposed framework addresses the critical hole detection and pose estimation problem through combining the learning-based detection with model-based pose estimation strategies. By exploiting the structure of the peg-in-hole task, we consider a rectangle-shape based characterization for modeling the candidate socket. Such a characterization allows us to design simple learning-based methods to detect and estimate the 6D pose of the target socket that balances between processing speed and accuracy. To validate our method, we test the performance of the proposed perceptive peg-in-hole solution using a KUKA iiwa7 robotic arm to accomplish the socket insertion task with two types of practical sockets (RJ45/HDMI). Without the need of additional search, our method achieves an acceptable success rate in the connector insertion tasks. The results confirm the reliability of our method and show that our method is suitable for real world application.",
        "primary_area": "",
        "author": "Kun Zhang;Chen Wang;Hua Chen;Jia Pan;Michael Yu Wang;Wei Zhang;Kun Zhang;Chen Wang;Hua Chen;Jia Pan;Michael Yu Wang;Wei Zhang",
        "authorids": "/37089895131;/37089197329;/37086195529;/37535628800;/37280913900;/37089656248;/37089895131;/37089197329;/37086195529;/37535628800;/37280913900;/37089656248",
        "aff": "Robotics Institute, Hong Kong University of Science and Technology, Hong Kong; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Monash University, Clayton, VIC, Australia; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161116/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17253844035625570861&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;2;1",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Southern University of Science and Technology;Monash University",
        "aff_unique_dep": "Robotics Institute;Department of Mechanical and Energy Engineering;",
        "aff_unique_url": "https://www.ust.hk;https://www.sustech.edu.cn;https://www.monash.edu",
        "aff_unique_abbr": "HKUST;SUSTech;Monash",
        "aff_campus_unique_index": "0;1;1;1;2;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen;Clayton",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "10161288",
        "title": "Visual Affordance Prediction for Guiding Robot Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the intuitive understanding humans have about the space of possible interactions, and the ease with which they can generalize this understanding to previously unseen scenes, we develop an approach for learning \u2018visual affordances\u2019. Given an input image of a scene, we infer a distribution over plausible future states that can be achieved via interactions with it. To allow predicting diverse plausible futures, we discretize the space of continuous images with a VQ-VAE and use a Transformer-based model to learn a conditional distribution in the latent embedding space. We show that these models can be trained using large-scale and diverse passive data, and that the learned models exhibit compositional generalization to diverse objects beyond the training distribution. We evaluate the quality and diversity of the generations, and demonstrate how the trained affordance model can be used for guiding exploration during visual goal-conditioned policy learning in robotic manipulation.",
        "primary_area": "",
        "author": "Homanga Bharadhwaj;Abhinav Gupta;Shubham Tulsiani;Homanga Bharadhwaj;Abhinav Gupta;Shubham Tulsiani",
        "authorids": "/37086638775;/37291130800;/37085649010;/37086638775;/37291130800;/37085649010",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161288/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15979805052095820058&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161096",
        "title": "Visual Backtracking Teleoperation: A Data Collection Protocol for Offline Image-Based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider how to most efficiently leverage teleoperator time to collect data for learning robust image-based value functions and policies for sparse reward robotic tasks. To accomplish this goal, we modify the process of data collection to include more than just successful demonstrations of the desired task. Instead we develop a novel protocol that we call Visual Backtracking Teleoperation (VBT), which deliberately collects a dataset of visually similar failures, recoveries, and successes. VBT data collection is particularly useful for efficiently learning accurate value functions from small datasets of image-based observations. We demonstrate VBT on a real robot to perform continuous control from image observations for the deformable manipulation task of T-shirt grasping. We find that by adjusting the data collection process we improve the quality of both the learned value functions and policies over a variety of baseline methods for data collection. Specifically, we find that offline reinforcement learning on VBT data outperforms standard behavior cloning on successful demonstration data by 13 % when both methods are given equal-sized datasets of 60 minutes of data from the real robot.",
        "primary_area": "",
        "author": "David Brandfonbrener;Stephen Tu;Avi Singh;Stefan Welker;Chad Boodoo;Nikolai Matni;Jake Varley;David Brandfonbrener;Stephen Tu;Avi Singh;Stefan Welker;Chad Boodoo;Nikolai Matni;Jake Varley",
        "authorids": "/37089895717;/37086432659;/37086235595;/37086577356;/37089894066;/37398611500;/37085632898;/37089895717;/37086432659;/37086235595;/37086577356;/37089894066;/37398611500;/37085632898",
        "aff": "New York University; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; University of Pennsylvania; Robotics at Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161096/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=266484565161519150&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;2;1",
        "aff_unique_norm": "New York University;Google;University of Pennsylvania",
        "aff_unique_dep": ";Robotics;",
        "aff_unique_url": "https://www.nyu.edu;https://www.google.com;https://www.upenn.edu",
        "aff_unique_abbr": "NYU;Google Robotics;UPenn",
        "aff_campus_unique_index": "1;1;1;1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160969",
        "title": "Visual Language Maps for Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Grounding language to the visual observations of a navigating agent can be performed using off-the-shelf visual-language models pretrained on Internet-scale data (e.g., image captions). While this is useful for matching images to natural language descriptions of object goals, it remains disjoint from the process of mapping the environment, so that it lacks the spatial precision of classic geometric maps. To address this problem, we propose VLMaps, a spatial map representation that directly fuses pretrained visual-language features with a 3D reconstruction of the physical world. VLMaps can be autonomously built from video feed on robots using standard exploration approaches and enables natural language indexing of the map without additional labeled data. Specifically, when combined with large language models (LLMs), VLMaps can be used to (i) translate natural language commands into a sequence of open-vocabulary navigation goals (which, beyond prior work, can be spatial by construction, e.g., \u201cin between the sofa and the TV\u201d or \u201cthree meters to the right of the chair\u201d) directly localized in the map, and (ii) can be shared among multiple robots with different embodiments to generate new obstacle maps on-the-fly (by using a list of obstacle categories). Extensive experiments carried out in simulated and real-world environments show that VLMaps enable navigation according to more complex language instructions than existing methods. Videos are available at https://vlmaps.github.io.",
        "primary_area": "",
        "author": "Chenguang Huang;Oier Mees;Andy Zeng;Wolfram Burgard;Chenguang Huang;Oier Mees;Andy Zeng;Wolfram Burgard",
        "authorids": "/37089893611;/37086205346;/37086217185;/37270485300;/37089893611;/37086205346;/37086217185;/37270485300",
        "aff": "University of Freiburg, Germany; University of Freiburg, Germany; Google Research, USA; University of Technology Nuremberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160969/",
        "gs_citation": 417,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16609027133720545857&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "University of Freiburg;Google;University of Technology Nuremberg",
        "aff_unique_dep": ";Google Research;",
        "aff_unique_url": "https://www.uni-freiburg.de;https://research.google;",
        "aff_unique_abbr": "UoF;Google;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "10160460",
        "title": "Visual Pitch and Roll Estimation For Inland Water Vessels",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion estimation is an essential element for autonomous vessels. It is used e.g. for lidar motion compensation as well as mapping and detection tasks in a maritime environment. Because the use of gyroscopes is not reliable and a high performance inertial measurement unit is quite expensive, we present an approach for visual pitch and roll estimation that utilizes a convolutional neural network for water segmentation, a stereo system for reconstruction and simple geometry to estimate pitch and roll. The algorithm is validated on a novel, publicly available dataset22https://git.ios.htwg-konstanz.de/dgriesse/constance_orientation_dataset/archive/main/constance_orientation_dataset-main.zip recorded at Lake Constance. Our experiments show that the pitch and roll estimator provides accurate results in comparison to an Xsens IMU sensor. We can further improve the pitch and roll estimation by sensor fusion with a gyroscope. The algorithm is available in its implementation as a ROS node33https://github.com/dionysos4/water_surface_detector.",
        "primary_area": "",
        "author": "Dennis Griesser;Georg Umlauf;Matthias O. Franz;Dennis Griesser;Georg Umlauf;Matthias O. Franz",
        "authorids": "/37088835976;/37074757700;/37430054200;/37088835976;/37074757700;/37430054200",
        "aff": "Institute for Optical Systems, University of Applied Sciences, Konstanz, Germany; Institute for Optical Systems, University of Applied Sciences, Konstanz, Germany; Institute for Optical Systems, University of Applied Sciences, Konstanz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160460/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5761427899796094476&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Applied Sciences Konstanz",
        "aff_unique_dep": "Institute for Optical Systems",
        "aff_unique_url": "https://www.hs-konstanz.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Konstanz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "10160822",
        "title": "Visual Tracking of Needle Tip in 2D Ultrasound based on Global Features in a Siamese Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultrasound (US) is widely used in image-guided needle procedures. Correctly tracking the needle tip position in US images during the procedure plays an important role in improving the needle targeting accuracy and patient safety. This paper presents a leaning-based visual tracking network with a Siamese architecture, which makes full use of the attention mechanism to explore the potential of global features and takes advantage of an online target model prediction module to robustly track the needle tip in US images. Several self- and cross-attention modules are applied to learn global features from the whole US image. A discriminative target model is also learned as a complementary part to improve the discriminability of the proposed tracker. The template used during the tracking is updated frequently according to the tracking results to ensure that the tracker can always capture the latest characteristics of the appearance of the needle tip. Experimental results in both phantom and tissue showed that the proposed tracking network was more robust than other state-of-the-art visual trackers. The mean success rates of the proposed tracker are 7.1% and 9.2% higher than the second best performing visual tacker when the needle was inserted by motors and human hands in the tissue experiments.",
        "primary_area": "",
        "author": "Wanquan Yan;Qingpeng Ding;Jianghua Chen;Kim Yan;Raymond Shing-Yan Tang;Shing Shin Cheng;Wanquan Yan;Qingpeng Ding;Jianghua Chen;Kim Yan;Raymond Shing-Yan Tang;Shing Shin Cheng",
        "authorids": "/37087466558;/37087466874;/37088810508;/37087472046;/37089894051;/37085474625;/37087466558;/37087466874;/37088810508;/37087472046;/37089894051;/37085474625",
        "aff": "Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Department of Medicine and Therapeutics and Institute of Digestive Disease, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, Shun Hing Institute of Advanced Engineering, Multi-Scale Medical Robotics Center, and Institute of Medical Intelligence and XR, The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160822/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4398366044077362356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160898",
        "title": "Visual-Inertial and Leg Odometry Fusion for Dynamic Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Implementing dynamic locomotion behaviors on legged robots requires a high-quality state estimation module. Especially when the motion includes flight phases, state-of-the-art approaches fail to produce reliable estimation of the robot posture, in particular base height. In this paper, we propose a novel approach for combining visual-inertial odometry (VIO) with leg odometry in an extended Kalman filter (EKF) based state estimator. The VIO module uses a stereo camera and IMU to yield low-drift 3D position and yaw orientation and drift-free pitch and roll orientation of the robot base link in the inertial frame. However, these values have a considerable amount of latency due to image processing and optimization, while the rate of update is quite low which is not suitable for low-level control. To reduce the latency, we predict the VIO state estimate at the rate of the IMU measurements of the VIO sensor. The EKF module uses the base pose and linear velocity predicted by VIO, fuses them further with a second high-rate IMU and leg odometry measurements, and produces robot state estimates with a high frequency and small latency suitable for control. We integrate this lightweight estimation framework with a nonlinear model predictive controller and show successful implementation of a set of agile locomotion behaviors, including trotting and jumping at varying horizontal speeds, on a torque-controlled quadruped robot.",
        "primary_area": "",
        "author": "Victor Dh\u00e9din;Haolong Li;Shahram Khorshidi;Lukas Mack;Adithya Kumar Chinnakkonda Ravi;Avadesh Meduri;Paarth Shah;Felix Grimminger;Ludovic Righetti;Majid Khadiv;Joerg Stueckler;Victor Dh\u00e9din;Haolong Li;Shahram Khorshidi;Lukas Mack;Adithya Kumar Chinnakkonda Ravi;Avadesh Meduri;Paarth Shah;Felix Grimminger;Ludovic Righetti;Majid Khadiv;Joerg Stueckler",
        "authorids": "/37089895791;/37088996982;/37089895764;/37089893729;/37089895275;/37088355351;/37089197319;/37627163100;/37295828600;/38667118200;/37088215404;/37089895791;/37088996982;/37089895764;/37089893729;/37089895275;/37088355351;/37089197319;/37627163100;/37295828600;/38667118200;/37088215404",
        "aff": "Embodied Vision Group, Max Planck Institute for Intelligent Systems, Tuebingen, Germany; Embodied Vision Group, Max Planck Institute for Intelligent Systems, Tuebingen, Germany; Movement Generation and Control Group, Max Planck Institute for Intelligent Systems, Tuebingen, Germany; Embodied Vision Group, Max Planck Institute for Intelligent Systems, Tuebingen, Germany; Movement Generation and Control Group, Max Planck Institute for Intelligent Systems, Tuebingen, Germany; Tandon School of Engineering, New York University, New York, USA; Oxford Robotics Institute, University of Oxford, England; Autonomous Motion Department, Max Planck Institute for Intelligent Systems, Tuebingen, Germany; Tandon School of Engineering, New York University, New York, USA; Movement Generation and Control Group, Max Planck Institute for Intelligent Systems, Tuebingen, Germany; Embodied Vision Group, Max Planck Institute for Intelligent Systems, Tuebingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160898/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12872645600822440707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;1;2;0;1;0;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;New York University;University of Oxford",
        "aff_unique_dep": "Embodied Vision Group;Tandon School of Engineering;Oxford Robotics Institute",
        "aff_unique_url": "https://www.mpituebingen.mpg.de;https://www.nyu.edu;https://www.ox.ac.uk",
        "aff_unique_abbr": "MPI-IS;NYU;Oxford",
        "aff_campus_unique_index": "0;0;0;0;0;1;2;0;1;0;0",
        "aff_campus_unique": "Tuebingen;New York;Oxford",
        "aff_country_unique_index": "0;0;0;0;0;1;2;0;1;0;0",
        "aff_country_unique": "Germany;United States;United Kingdom"
    },
    {
        "id": "10160888",
        "title": "Visuomotor Control in Multi-Object Scenes Using Object-Aware Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Perceptual understanding of the scene and the relationship between its different components is important for successful completion of robotic tasks. Representation learning has been shown to be a powerful technique for this, but most of the current methodologies learn task specific representations that do not necessarily transfer well to other tasks. Furthermore, representations learned by supervised methods require large, labeled datasets for each task that are expensive to collect in the real-world. Using self-supervised learning to obtain representations from unlabeled data can mitigate this problem. However, current self-supervised representation learning methods are mostly object agnostic, and we demonstrate that the resulting representations are insufficient for general purpose robotics tasks as they fail to capture the complexity of scenes with many components. In this paper, we show the effectiveness of using object-aware representation learning techniques for robotic tasks. Our self-supervised representations are learned by observing the agent freely interacting with different parts of the environment and are queried in two different settings: (i) policy learning and (ii) object location prediction. We show that our model learns control policies in a sample-efficient manner and outperforms state-of-the-art object agnostic techniques as well as methods trained on raw RGB images. Our results show a 20% increase in performance in low data regimes (1000 trajectories) in policy training using implicit behavioral cloning (IBC). Furthermore, our method outperforms the baselines for the task of object localization in multi-object scenes. Further qualitative results are available at https://sites.google.com/view/slots4robots.",
        "primary_area": "",
        "author": "Negin Heravi;Ayzaan Wahid;Corey Lynch;Pete Florence;Travis Armstrong;Jonathan Tompson;Pierre Sermanet;Jeannette Bohg;Debidatta Dwibedi;Negin Heravi;Ayzaan Wahid;Corey Lynch;Pete Florence;Travis Armstrong;Jonathan Tompson;Pierre Sermanet;Jeannette Bohg;Debidatta Dwibedi",
        "authorids": "/37088506105;/37086937669;/37086099911;/37085786926;/37089891992;/38093908100;/37680831200;/37591153900;/37086270049;/37088506105;/37086937669;/37086099911;/37085786926;/37089891992;/38093908100;/37680831200;/37591153900;/37086270049",
        "aff": "Stanford University; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Stanford University; Robotics at Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160888/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12956732377352608452&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;1;1;0;1",
        "aff_unique_norm": "Stanford University;Google",
        "aff_unique_dep": ";Robotics",
        "aff_unique_url": "https://www.stanford.edu;https://www.google.com",
        "aff_unique_abbr": "Stanford;Google Robotics",
        "aff_campus_unique_index": "0;1;1;1;1;1;1;0;1",
        "aff_campus_unique": "Stanford;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160795",
        "title": "Vitreoretinal Surgical Robotic System with Autonomous Orbital Manipulation using Vector-Field Inequalities",
        "track": "main",
        "status": "Poster",
        "abstract": "Vitreoretinal surgery pertains to the treatment of delicate tissues on the fundus of the eye using thin instruments. Surgeons frequently rotate the eye during surgery, which is called orbital manipulation, to observe regions around the fundus without moving the patient. In this paper, we propose the autonomous orbital manipulation of the eye in robot-assisted vitreoretinal surgery with our tele-operated surgical system. In a simulation study, we preliminarily investigated the increase in the manipulability of our system using orbital manipulation. Furthermore, we demonstrated the feasibility of our method in experiments with a physical robot and a realistic eye model, showing an increase in the view-able area of the fundus when compared to a conventional technique. Source code and minimal example available at https://github.com/mmmarinho/icra2023_orbitalmanipulation.",
        "primary_area": "",
        "author": "Yuki Koyama;Murilo M. Marinho;Kanako Harada;Yuki Koyama;Murilo M. Marinho;Kanako Harada",
        "authorids": "/37089467103;/38519488300;/37556612000;/37089467103;/38519488300;/37556612000",
        "aff": "Department of Mechanical Engineering, University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160795/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2137596760964161701&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "10160511",
        "title": "WAVN: Wide Area Visual Navigation for Large-scale, GPS-denied Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a novel approach to GPS-denied visual navigation of a robot team over a wide (i.e., out of line of sight) area which we call WAVN (Wide Area Visual Navigation). Application domains include small-scale precision agriculture as well as exploration and surveillance. The proposed approach requires no exploration or map generation, merging, and updating, some of the most computationally intensive aspects of multi-robot navigation, especially in dynamic environments and for long-term deployments. In contrast, we extend the visual homing paradigm to leverage visual information from the entire team to allow a robot to home to a distant location. Since it only employs the latest imagery, the approach can be resilient to the current state of the environment. WAVN requires three components: identification of common landmarks between robots, a communication infrastructure, and an algorithm to find a sequence of common landmarks to navigate to a goal. The principal contribution of this paper is the navigation algorithm in addition to simulation and physical robot results characterizing performance. The approach is also compared to more traditional map-based approaches.",
        "primary_area": "",
        "author": "Damian M. Lyons;Mohamed Rahouti;Damian M. Lyons;Mohamed Rahouti",
        "authorids": "/37277542500;/37086495680;/37277542500;/37086495680",
        "aff": "Computer & Information Science, Fordham University, New York, USA; Computer & Information Science, Fordham University, New York, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160511/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9767173215764355138&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Fordham University",
        "aff_unique_dep": "Computer & Information Science",
        "aff_unique_url": "https://www.fordham.edu",
        "aff_unique_abbr": "Fordham",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161228",
        "title": "WE-Filter: Adaptive Acceptance Criteria for Filter-based Shared Autonomy",
        "track": "main",
        "status": "Poster",
        "abstract": "Filter-based shared control aims to accept and augment an operator's ability to control a robot. Current solutions accept actions based on their direction aligning with the robot's optimal policy. These strategies reject a human's small corrective actions if they conflict with the robot's direction and accept too aggressive actions as long as they are consistent with the robot's direction. Such strategies may cause task failures and the operator's feeling of loss of control. To close the gap, we propose WE-Filter, which has flexible, adaptive criteria allowing the operator's small corrective actions and tempering too aggressive ones. Inspired by classical work-energy impact problems between two dynamic, interactive bodies, both inputs' properties (direction and magnitude) are inherently considered, creating intuitive, adaptive bounds to accept sensible actions. The model identifies behaviors before and after impact. The rationale is that each timestep of shared control acts as an impact between the operator's and the robot's policies, where post-impact behaviors depend on their previous behaviors. As time continues, a series of impacts occur. The aim is to minimize impacts that occur to reach an agreement faster and reduce strong reactionary behaviors. Our model determines flexible acceptance criteria to bound a mismatch of magnitude and finds a replacement action for conflicting policies. The WE-Filter achieves better task performance, the ratio of accepted actions, and action similarity than the existing methods.",
        "primary_area": "",
        "author": "Michael Bowman;Xiaoli Zhang;Michael Bowman;Xiaoli Zhang",
        "authorids": "/37086937096;/37085581881;/37086937096;/37085581881",
        "aff": "Colorado School of Mines, Intelligent Robotics and Systems Lab, Golden, CO, USA; Colorado School of Mines, Intelligent Robotics and Systems Lab, Golden, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161228/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5525236508378050474&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Intelligent Robotics and Systems Lab",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "CSM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Golden",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160999",
        "title": "WEDGE: Web-Image Assisted Domain Generalization for Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Domain generalization for semantic segmentation is highly demanded in real applications, where a trained model is expected to work well in previously unseen domains. One challenge lies in the lack of data which could cover the diverse distributions of the possible unseen domains for training. In this paper, we propose a WEb-image assisted Domain GEneralization (WEDGE) scheme, which is the first to exploit the diversity of web-crawled images for generalizable semantic segmentation. To explore and exploit the real-world data distributions, we collect web-crawled images which present large diversity in terms of weather conditions, sites, lighting, camera styles, etc. We also present a method which injects styles of the web-crawled images into training images on-the-fly during training, which enables the network to experience images of diverse styles with reliable labels for effective training. Moreover, we use the web-crawled images with their predicted pseudo labels for training to further enhance the capability of the network. Extensive experiments demonstrate that our method clearly outperforms existing domain generalization techniques.",
        "primary_area": "",
        "author": "Namyup Kim;Taeyoung Son;Jaehyun Pahk;Cuiling Lan;Wenjun Zeng;Suha Kwak;Namyup Kim;Taeyoung Son;Jaehyun Pahk;Cuiling Lan;Wenjun Zeng;Suha Kwak",
        "authorids": "/37089541579;/37089539892;/37089894624;/37572547200;/37286472700;/37086204638;/37089541579;/37089539892;/37089894624;/37572547200;/37286472700;/37086204638",
        "aff": "POSTECH, Pohang, Republic of Korea; NALBI, Seoul, Republic of Korea; POSTECH, Pohang, Republic of Korea; Microsoft Research Asia, Beijing, China; EIT Institute for Advanced Study, Beijing, China; POSTECH, Pohang, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160999/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1956474762650838997&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;3;0",
        "aff_unique_norm": "Pohang University of Science and Technology;NALBI;Microsoft Research Asia;EIT Institute for Advanced Study",
        "aff_unique_dep": ";;Research;",
        "aff_unique_url": "https://www.postech.ac.kr;;https://www.microsoft.com/en-us/research/group/asia;",
        "aff_unique_abbr": "POSTECH;;MSRA;",
        "aff_campus_unique_index": "0;1;0;2;2;0",
        "aff_campus_unique": "Pohang;Seoul;Beijing",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "South Korea;China"
    },
    {
        "id": "10161184",
        "title": "WS-3D-Lane: Weakly Supervised 3D Lane Detection With 2D Lane Labels",
        "track": "main",
        "status": "Poster",
        "abstract": "Compared to 2D lanes, real 3D lane data is difficult to collect accurately. In this paper, we propose a novel method for training 3D lanes with only 2D lane labels, called weakly supervised 3D lane detection WS-3D-Lane. By assumptions of constant lane width and equal height on adjacent lanes, we indirectly supervise 3D lane heights in the training. To overcome the problem of the dynamic change of the camera pitch during data collection, a camera pitch self-calibration method is proposed. In anchor representation, we propose a double-layer anchor with non-maximum suppression (NMS) method, which enables the anchor-based method to predict two lane lines that are close. Experiments are conducted on the base of 3D-LaneNet under two supervision methods. Under weakly supervised setting, our WS-3D-Lane outperforms previous 3D-LaneN et: F-score rises to 92.3% on Apollo 3D synthetic dataset, and F1 rises to 74.5% on ONCE-3DLanes. Meanwhile, WS-3D-Lane in purely supervised setting makes more increments and outperforms state-of-the-art. To the best of our knowledge, WS-3D- Lane is the first try of 3D lane detection under weakly supervised setting. Our code is available on https://github.com/SAIC-Vision/WS-3D-Lane.",
        "primary_area": "",
        "author": "Jianyong Ai;Wenbo Ding;Jiuhua Zhao;Jiachen Zhong;Jianyong Ai;Wenbo Ding;Jiuhua Zhao;Jiachen Zhong",
        "authorids": "/37089892800;/37089893683;/37089895184;/37089893588;/37089892800;/37089893683;/37089895184;/37089893588",
        "aff": "SAIC AI Lab, Shanghai, China; SAIC AI Lab, Shanghai, China; SAIC AI Lab, Shanghai, China; SAIC AI Lab, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161184/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4757922297803943604&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "SAIC",
        "aff_unique_dep": "AI Lab",
        "aff_unique_url": "",
        "aff_unique_abbr": "SAIC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160609",
        "title": "Wayformer: Motion Forecasting via Simple & Efficient Attention Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion forecasting for autonomous driving is a challenging task because complex driving scenarios involve a heterogeneous mix of static and dynamic inputs. It is an open problem how best to represent and fuse information about road geometry, lane connectivity, time-varying traffic light state, and history of a dynamic set of agents and their interactions into an effective encoding. To model this diverse set of input features, many approaches proposed to design an equally complex system with a diverse set of modality specific modules. This results in systems that are difficult to scale, extend, or tune in rigorous ways to trade off quality and efficiency. In this paper, we present Wayformer, a family of simple and homogeneous attention based architectures for motion forecasting. Wayformer offers a compact model description consisting of an attention based scene encoder and a decoder. In the scene encoder we study the choice of early, late and hierarchical fusion of input modalities. For each fusion type we explore strategies to trade off efficiency and quality via factorized attention or latent query attention. We show that early fusion, despite its simplicity, is not only modality agnostic but also achieves state-of-the-art results on both Waymo Open Motion Dataset (WOMD) and Argoverse leaderboards, demonstrating the effectiveness of our design philosophy.",
        "primary_area": "",
        "author": "Nigamaa Nayakanti;Rami Al-Rfou;Aurick Zhou;Kratarth Goel;Khaled S. Refaat;Benjamin Sapp;Nigamaa Nayakanti;Rami Al-Rfou;Aurick Zhou;Kratarth Goel;Khaled S. Refaat;Benjamin Sapp",
        "authorids": "/37089450300;/37089448595;/37089893067;/37085377654;/37540952100;/37089406608;/37089450300;/37089448595;/37089893067;/37085377654;/37540952100;/37089406608",
        "aff": "Waymo, 1600 Amphitheatre Pkwy, Mountain View, California, USA; Waymo, 1600 Amphitheatre Pkwy, Mountain View, California, USA; Waymo, 1600 Amphitheatre Pkwy, Mountain View, California, USA; Waymo, 1600 Amphitheatre Pkwy, Mountain View, California, USA; Waymo, 1600 Amphitheatre Pkwy, Mountain View, California, USA; Waymo, 1600 Amphitheatre Pkwy, Mountain View, California, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160609/",
        "gs_citation": 315,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=197816311966264254&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Waymo",
        "aff_unique_dep": "",
        "aff_unique_url": "https://waymo.com",
        "aff_unique_abbr": "Waymo",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161294",
        "title": "Weakly Supervised Referring Expression Grounding via Target-Guided Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "Weakly supervised referring expression grounding aims to train a model without the manual labels between image regions and referring expressions during the training phase. Current predominant models often adopt deep structures to reconstruct the region-expression correspondence. A crucial deficiency of the existing approaches lies in that these models neglect to exploit potential valuable information to further improve their grounding performance. To address this issue, we leverage knowledge distillation as a unique scheme to excavate and transfer helpful information for acquiring a better model. Specifically, we propose a target-guided knowledge distillation framework that accounts for region-expression pairs reconstruction and matching. We reactivate the target-related prediction information learned by a pre-trained teacher model and transfer the target-related prediction knowledge from the teacher to guide the training process and boost the performance of the student model. We conduct extensive experiments on three benchmark datasets, i.e., RefCOCO, RefCOCO+, and RefCOCOg. Without bells and whistles, our approach achieves state-of-the-art results on several splits of benchmark datasets. The implementation codes and trained models are available at: https://github.com/dami23/WREG_KD.",
        "primary_area": "",
        "author": "Jinpeng Mi;Song Tang;Zhiyuan Ma;Dan Liu;Qingdu Li;Jianwei Zhang;Jinpeng Mi;Song Tang;Zhiyuan Ma;Dan Liu;Qingdu Li;Jianwei Zhang",
        "authorids": "/37086033673;/37087324926;/37089195654;/37089717865;/37089197601;/37281460600;/37086033673;/37087324926;/37089195654;/37089717865;/37089197601;/37281460600",
        "aff": "Institute of Machine Intelligence (IMI), University of Shanghai for Science and Technology, China; Institute of Machine Intelligence (IMI), University of Shanghai for Science and Technology, China; Institute of Machine Intelligence (IMI), University of Shanghai for Science and Technology, China; Institute of Machine Intelligence (IMI), University of Shanghai for Science and Technology, China; Institute of Machine Intelligence (IMI), University of Shanghai for Science and Technology, China; Department of Informatics, Technical Aspects of Multimodal Systems (TAMS), University of Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161294/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8573766394184112073&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "University of Shanghai for Science and Technology;University of Hamburg",
        "aff_unique_dep": "Institute of Machine Intelligence (IMI);Department of Informatics",
        "aff_unique_url": "https://www.usst.edu.cn;https://www.uni-hamburg.de",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "10161417",
        "title": "Weighted Maximum Likelihood for Controller Tuning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, Model Predictive Contouring Control (MPCC) has arisen as the state-of-the-art approach for model-based agile flight. MPCC benefits from great flexibility in trading-off between progress maximization and path following at runtime without relying on globally optimized trajectories. However, finding the optimal set of tuning parameters for MPCC is challenging because (i) the full quadrotor dynamics are non-linear, (ii) the cost function is highly non-convex, and (iii) of the high dimensionality of the hyperparameter space. This paper leverages a probabilistic Policy Search method\u2014Weighted Maximum Likelihood (WML)\u2014to automatically learn the optimal objective for MPCC. WML is sample-efficient due to its closed-form solution for updating the learning parameters. Additionally, the data efficiency provided by the use of a model-based approach allows us to directly train in a high-fidelity simulator, which in turn makes our approach able to transfer zero-shot to the real world. We validate our approach in the real world, where we show that our method outperforms both the previous manually tuned controller and the state-of-the-art auto-tuning baseline reaching speeds of 75 km/h.",
        "primary_area": "",
        "author": "Angel Romero;Shreedhar Govil;Gonca Yilmaz;Yunlong Song;Davide Scaramuzza;Angel Romero;Shreedhar Govil;Gonca Yilmaz;Yunlong Song;Davide Scaramuzza",
        "authorids": "/37089284996;/37089893112;/37089892431;/37088688858;/37397688400;/37089284996;/37089893112;/37089892431;/37088688858;/37397688400",
        "aff": "Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161417/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12209988255160912648&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Department of Neuroinformatics",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "10161285",
        "title": "Wi-Closure: Reliable and Efficient Search of Inter-robot Loop Closures Using Wireless Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a novel algorithm, Wi-Closure, to improve the computational efficiency and robustness of loop closure detection in multi-robot SLAM. Our approach decreases the computational overhead of classical approaches by pruning the search space of potential loop closures, prior to evaluation by a typical multi-robot SLAM pipeline. Wi-Closure achieves this by identifying candidates that are spatially close to each other measured via sensing over the wireless communication signal between robots, even when they are operating in non-line-of-sight or in remote areas of the environment from one another. We demonstrate the validity of our approach in simulation and in hardware experiments. Our results show that using Wi-closure greatly reduces computation time, by 54.1% in simulation and 76.8% in hardware experiments, compared with a multi-robot SLAM baseline. Importantly, this is achieved without sacrificing accuracy. Using Wi-closure reduces absolute trajectory estimation error by 98.0% in simulation and 89.2% in hardware experiments. This improvement is partly due to Wi-Closure's ability to avoid catastrophic optimization failure that typically occurs with classical approaches in challenging repetitive environments.",
        "primary_area": "",
        "author": "Weiying Wang;Anne Kemmeren;Daniel Son;Javier Alonso-Mora;Stephanie Gil;Weiying Wang;Anne Kemmeren;Daniel Son;Javier Alonso-Mora;Stephanie Gil",
        "authorids": "/37089895649;/37089894910;/37089893979;/38271697300;/37396689900;/37089895649;/37089894910;/37089893979;/38271697300;/37396689900",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Allston, MA, USA; Faculty of Mechanical, Maritime and Materials Engineering, Technical University of Delft, Delft, The Netherlands; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Allston, MA, USA; Faculty of Mechanical, Maritime and Materials Engineering, Technical University of Delft, Delft, The Netherlands; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Allston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161285/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5918126885557520424&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Harvard University;Technical University of Delft",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences;Faculty of Mechanical, Maritime and Materials Engineering",
        "aff_unique_url": "https://www.harvard.edu;https://www.tudelft.nl",
        "aff_unique_abbr": "Harvard;TUDelft",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Allston;Delft",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "United States;Netherlands"
    },
    {
        "id": "10160607",
        "title": "Wide-Area Geolocalization with a Limited Field of View Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Cross-view geolocalization, a supplement or replacement for GPS, localizes an agent within a search area by matching images taken from a ground-view camera to overhead images taken from satellites or aircraft. Although the viewpoint disparity between ground and overhead images makes crossview geolocalization challenging, significant progress has been made assuming that the ground agent has access to a panoramic camera. For example, our prior work (WAG) introduced changes in search area discretization, training loss, and particle filter weighting that enabled city-scale panoramic cross-view geolocalization. However, panoramic cameras are not widely used in existing robotic platforms due to their complexity and cost. Non-panoramic cross-view geolocalization is more applicable for robotics, but is also more challenging. This paper presents Restricted FOV Wide-Area Geolocalization (ReWAG), a cross-view geolocalization approach that generalizes WAG for use with standard, non-panoramic ground cameras by creating pose-aware embeddings and providing a strategy to incorporate particle pose into the Siamese network. ReWAG is a neural network and particle filter system that is able to globally localize a mobile agent in a GPS-denied environment with only odometry and a 90\u00b0 FOV camera, achieving similar localization accuracy as what WAG achieved with a panoramic camera and improving localization accuracy by a factor of 100 compared to a baseline vision transformer (ViT) approach.",
        "primary_area": "",
        "author": "Lena M. Downes;Ted J. Steiner;Rebecca L. Russell;Jonathan P. How;Lena M. Downes;Ted J. Steiner;Rebecca L. Russell;Jonathan P. How",
        "authorids": "/37088482864;/38242279400;/37087682958;/37276347700;/37088482864;/38242279400;/37087682958;/37276347700",
        "aff": "Perception and Embedded ML Group, Draper, Cambridge, MA, USA; Perception and Embedded ML Group, Draper, Cambridge, MA, USA; Perception and Embedded ML Group, Draper, Cambridge, MA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160607/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12986468171955406676&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Draper;Massachusetts Institute of Technology",
        "aff_unique_dep": "Perception and Embedded ML Group;Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.draper.com;https://web.mit.edu",
        "aff_unique_abbr": ";MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160432",
        "title": "Wild-Places: A Large-Scale Dataset for Lidar Place Recognition in Unstructured Natural Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Many existing datasets for lidar place recognition are solely representative of structured urban environments, and have recently been saturated in performance by deep learning based approaches. Natural and unstructured environments present many additional challenges for the tasks of long-term localisation but these environments are not represented in currently available datasets. To address this we introduce Wild-Places, a challenging large-scale dataset for lidar place recognition in unstructured, natural environments. Wild-Places contains eight lidar sequences collected with a handheld sensor payload over the course of fourteen months, containing a total of 63K undistorted lidar submaps along with accurate 6DoF ground truth. This dataset contains multi-ple revisits both within and between sequences, allowing for both intra-sequence (i.e., loop closure detection) and inter-sequence (i.e., re-localisation) tasks. We also benchmark several state-of-the-art approaches to demonstrate the challenges that this dataset introduces, particularly the case of long-term place recognition due to natural environments changing over time. Our dataset and code is available at https://csiro-robotics.github.io/Wild-Places",
        "primary_area": "",
        "author": "Joshua Knights;Kavisha Vidanapathirana;Milad Ramezani;Sridha Sridharan;Clinton Fookes;Peyman Moghadam;Joshua Knights;Kavisha Vidanapathirana;Milad Ramezani;Sridha Sridharan;Clinton Fookes;Peyman Moghadam",
        "authorids": "/37088854855;/37087049355;/37088504403;/37266096100;/37281919100;/37666497200;/37088854855;/37087049355;/37088504403;/37266096100;/37281919100;/37666497200",
        "aff": "School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Australia; School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Australia; Robotics and Autonomous Systems Group, DATA61, CSIRO, Australia; School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Australia; School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Australia; School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160432/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11708015546266675627&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Queensland University of Technology;CSIRO",
        "aff_unique_dep": "School of Electrical Engineering and Robotics;Robotics and Autonomous Systems Group, DATA61",
        "aff_unique_url": "https://www.qut.edu.au;https://www.csiro.au",
        "aff_unique_abbr": "QUT;CSIRO",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "10160886",
        "title": "Wirelessly-Controlled Untethered Piezoelectric Planar Soft Robot Capable of Bidirectional Crawling and Rotation",
        "track": "main",
        "status": "Poster",
        "abstract": "Electrostatic actuators provide a promising approach to creating soft robotic sheets, due to their flexible form factor, modular integration, and fast response speed. However, their control requires kilo-Volt signals and understanding of complex dynamics resulting from force interactions by on-board and environmental effects. In this work, we demonstrate an untethered planar five-actuator piezoelectric robot powered by batteries and on-board high-voltage circuitry, and controlled through a wireless link. The scalable fabrication approach is based on bonding different functional layers on top of each other (steel foil substrate, actuators, flexible electronics). The robot exhibits a range of controllable motions, including bidirectional crawling (up to ~0.6 cm/s), turning, and in-place rotation (at ~1 degree/s). High-speed videos and control experiments show that the richness of the motion results from the interaction of an asymmetric mass distribution in the robot and the associated dependence of the dynamics on the driving frequency of the piezoelectrics. The robot's speed can reach 6 cm/s with specific payload distribution.",
        "primary_area": "",
        "author": "Zhiwu Zheng;Hsin Cheng;Prakhar Kumar;Sigurd Wagner;Minjie Chen;Naveen Verma;James C. Sturm;Zhiwu Zheng;Hsin Cheng;Prakhar Kumar;Sigurd Wagner;Minjie Chen;Naveen Verma;James C. Sturm",
        "authorids": "/37086703543;/37088918703;/37086380734;/37275442700;/37086129263;/37399412400;/37270459200;/37086703543;/37088918703;/37086380734;/37275442700;/37086129263;/37399412400;/37270459200",
        "aff": "Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A.; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A.; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A.; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A.; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A.; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A.; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160886/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12601503479358469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Princeton",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10160861",
        "title": "WorldGen: A Large Scale Generative Simulator",
        "track": "main",
        "status": "Poster",
        "abstract": "In the era of deep learning, data is the critical determining factor in the performance of neural network models. Generating large datasets suffers from various challenges such as scalability, cost efficiency and photorealism. To avoid expensive and strenuous dataset collection and annotations, researchers have inclined towards computer-generated datasets. However, a lack of photorealism and a limited amount of computer-aided data has bounded the accuracy of network predictions. To this end, we present WorldGen - an open source framework to automatically generate countless structured and unstructured 3D photorealistic scenes such as city view, object collection, and object fragmentation along with its rich ground truth annotation data. WorldGen being a generative model gives the user full access and control to features such as texture, object structure, motion, camera and lens properties for better generalizability by diminishing the data bias in the network. We demonstrate the effectiveness of WorldGen by evaluating deep optical flow. We hope such a tool can open doors for future research in a myriad of domains related to robotics and computer vision by reducing manual labor and cost for acquiring rich and high-quality data.",
        "primary_area": "",
        "author": "Chahat Deep Singh;Riya Kumari;Cornelia Ferm\u00fcller;Nitin J. Sanket;Yiannis Aloimonos;Chahat Deep Singh;Riya Kumari;Cornelia Ferm\u00fcller;Nitin J. Sanket;Yiannis Aloimonos",
        "authorids": "/37086392092;/37089766053;/37269887600;/37086390746;/37282631400;/37086392092;/37089766053;/37269887600;/37086390746;/37282631400",
        "aff": "Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA; Robotics Engineering, Worcester Polytechnic Institute, MA, USA; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160861/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9762269510304658172&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Maryland;Worcester Polytechnic Institute",
        "aff_unique_dep": "Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies;Robotics Engineering",
        "aff_unique_url": "https://www.umd.edu;https://www.wpi.edu",
        "aff_unique_abbr": "UMD;WPI",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "College Park;Worcester",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161289",
        "title": "Zero-Shot Object Goal Visual Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Object goal visual navigation is a challenging task that aims to guide a robot to find the target object based on its visual observation, and the target is limited to the classes pre-defined in the training stage. However, in real households, there may exist numerous target classes that the robot needs to deal with, and it is hard for all of these classes to be contained in the training stage. To address this challenge, we study the zero-shot object goal visual navigation task, which aims at guiding robots to find targets belonging to novel classes without any training samples. To this end, we also propose a novel zero-shot object navigation framework called semantic similarity network (SSNet). Our framework use the detection results and the cosine similarity between semantic word embeddings as input. Such type of input data has a weak correlation with classes and thus our framework has the ability to generalize the policy to novel classes. Extensive experiments on the AI2-THOR platform show that our model outperforms the baseline models in the zero-shot object navigation task, which proves the generalization ability of our model. Our code is available at: https://github.com/pioneer-innovation/Zero-Shot-Object-Navigation.",
        "primary_area": "",
        "author": "Qianfan Zhao;Lu Zhang;Bin He;Hong Qiao;Zhiyong Liu;Qianfan Zhao;Lu Zhang;Bin He;Hong Qiao;Zhiyong Liu",
        "authorids": "/37089408956;/37089734134;/38182723000;/37338715300;/37289197400;/37089408956;/37089734134;/38182723000;/37338715300;/37289197400",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; College of Electronic and Information Engineering, Tongji University, China; State Key Laboratory of Multimodal Artificial Intelligence System, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Nanjing Artificial Intelligence Research of IA, Nanjing, Jiangsu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161289/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17061116848415594540&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Tongji University;Chinese Academy of Sciences;Nanjing Artificial Intelligence Research of IA",
        "aff_unique_dep": "School of Artificial Intelligence;College of Electronic and Information Engineering;Institute of Automation;",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.tongji.edu.cn;http://www.ia.cas.cn;",
        "aff_unique_abbr": "UCAS;Tongji;CAS;",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Beijing;;Nanjing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10160764",
        "title": "Zero-Shot Policy Transfer with Disentangled Task Representation of Meta-Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans are capable of abstracting various tasks as different combinations of multiple attributes. This perspective of compositionality is vital for human rapid learning and adaption since previous experiences from related tasks can be combined to generalize across novel compositional settings. In this work, we aim to achieve zero-shot policy generalization of Reinforcement Learning (RL) agents by leveraging the task compositionality. Our proposed method is a meta-RL algorithm with disentangled task representation, explicitly encoding different aspects of the tasks. Policy generalization is then performed by inferring unseen compositional task representations via the obtained disentanglement without extra exploration. The evaluation is conducted on three simulated tasks and a challenging real-world robotic insertion task. Experimental results demonstrate that our proposed method achieves policy generalization to unseen compositional tasks in a zero-shot manner.",
        "primary_area": "",
        "author": "Zheng Wu;Yichen Xie;Wenzhao Lian;Changhao Wang;Yanjiang Guo;Jianyu Chen;Stefan Schaal;Masayoshi Tomizuka;Zheng Wu;Yichen Xie;Wenzhao Lian;Changhao Wang;Yanjiang Guo;Jianyu Chen;Stefan Schaal;Masayoshi Tomizuka",
        "authorids": "/37088444305;/37089315187;/37088998889;/37086426211;/37089895485;/37086004703;/37282144700;/37281933000;/37088444305;/37089315187;/37088998889;/37086426211;/37089895485;/37086004703;/37282144700;/37281933000",
        "aff": "University of California, Berkeley, Berkeley, CA, USA; University of California, Berkeley, Berkeley, CA, USA; Intrinsic Innovation LLC, Mountain View, CA, USA; University of California, Berkeley, Berkeley, CA, USA; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Intrinsic Innovation LLC, Mountain View, CA, USA; University of California, Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160764/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8835932151264418539&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;2;2;1;0",
        "aff_unique_norm": "University of California, Berkeley;Intrinsic Innovation LLC;Tsinghua University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.berkeley.edu;;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UC Berkeley;;THU",
        "aff_campus_unique_index": "0;0;1;0;2;2;1;0",
        "aff_campus_unique": "Berkeley;Mountain View;Beijing",
        "aff_country_unique_index": "0;0;0;0;1;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "10160346",
        "title": "Zero-Shot Transfer of Haptics-Based Object Insertion Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans naturally exploit haptic feedback during contact-rich tasks like loading a dishwasher or stocking a bookshelf. Current robotic systems focus on avoiding unexpected contact, often relying on strategically placed environment sensors. Recently, contact-exploiting manipulation policies have been trained in simulation and deployed on real robots. However, they require some form of real-world adaptation to bridge the sim-to-real gap, which might not be feasible in all scenarios. In this paper we train a contact-exploiting manipulation policy in simulation for the contact-rich household task of loading plates into a slotted holder, which transfers without any fine-tuning to the real robot. We investigate various factors necessary for this zero-shot transfer, like time delay modeling, memory representation, and domain randomization. Our policy transfers with minimal sim-to-real gap and significantly outperforms heuristic and learnt baselines. It also generalizes well to a cup and plates of different sizes and weights. The project website is https://sites.google.com/view/compliant-object-insertion.",
        "primary_area": "",
        "author": "Samarth Brahmbhatt;Ankur Deka;Andrew Spielberg;Matthias M\u00fcller;Samarth Brahmbhatt;Ankur Deka;Andrew Spielberg;Matthias M\u00fcller",
        "authorids": "/37085458304;/37089193949;/37085376500;/37088216388;/37085458304;/37089193949;/37085376500;/37088216388",
        "aff": "Intel Labs; Intel Labs; Intel Labs; Intel Labs",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160346/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1046763504231871076&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Intel Corporation",
        "aff_unique_dep": "Intel Labs",
        "aff_unique_url": "https://www.intel.com",
        "aff_unique_abbr": "Intel",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10161345",
        "title": "Zero-shot Active Visual Search (ZAVIS): Intelligent Object Search for Robotic Assistants",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on the problem of efficiently locating a target object described with free-form text using a mobile robot equipped with vision sensors (e.g., an RGBD camera). Conventional active visual search predefines a set of objects to search for, rendering these techniques restrictive in practice. To provide added flexibility in active visual searching, we propose a system where a user can enter target commands using free-form text; we call this system Zero-shot Active Visual Search (ZAVIS). ZAVIS detects and plans to search for a target object inputted by a user through a semantic grid map represented by static landmarks (e.g., desk or bed). For efficient planning of object search patterns, ZAVIS considers commonsense knowledge-based co-occurrence and predictive uncertainty while deciding which landmarks to visit first. We validate the proposed method with respect to SR (success rate) and SPL (success weighted by path length) in both simulated and real-world environments. The proposed method outperforms previous methods in terms of SPL in simulated scenarios, and we further demonstrate ZAVIS with a Pioneer-3AT robot in real-world studies.",
        "primary_area": "",
        "author": "Jeongeun Park;Taerim Yoon;Jejoon Hong;Youngjae Yu;Matthew Pan;Sungjoon Choi;Jeongeun Park;Taerim Yoon;Jejoon Hong;Youngjae Yu;Matthew Pan;Sungjoon Choi",
        "authorids": "/37089447938;/37089895115;/37089891861;/37086214094;/37085376434;/37085405040;/37089447938;/37089895115;/37089891861;/37086214094;/37085376434;/37085405040",
        "aff": "Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Mechanical Engineering, Korea University, Seoul, Korea; Department of Artificial Intelligence, Yonsei University, Seoul, Korea; Department of Electrical and Computer Engineering, Queens University, Kingston, Canada; Department of Artificial Intelligence, Korea University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161345/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10288672821305183670&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "Korea University;Yonsei University;Queens University",
        "aff_unique_dep": "Department of Artificial Intelligence;Department of Artificial Intelligence;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.korea.ac.kr;https://www.yonsei.ac.kr;https://www.queensu.ca",
        "aff_unique_abbr": "KU;Yonsei;Queen's U",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Seoul;Kingston",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "South Korea;Canada"
    },
    {
        "id": "10160870",
        "title": "Zero-shot Object Detection Based on Dynamic Semantic Vectors",
        "track": "main",
        "status": "Poster",
        "abstract": "Zero-shot object detection has shown its ability to overcome the problems of data scarcity and novel classes. Existing methods generally utilize static semantic vectors to classify objects and guide the network to map visual features to semantic vectors. However, the distribution of semantic vectors cannot adequately represent visual features, which makes migration from seen to unseen classes difficult. This work explores the dynamic semantic vector method to align the distributions of semantic vectors and visual features. The main challenge is to get a more reasonable distribution of semantic vectors. To address this issue, we proposed a two-way classification branch network and introduce N-pair loss into the dynamic semantic vector optimization process. Experiments on the MS-COCO dataset and SiTi (a real-world autonomous driving dataset collected by us) demonstrate the effectiveness and generalization of our method. Our code is available at https://github.com/HaoyuLizju/ZSD_tcb",
        "primary_area": "",
        "author": "Haoyu Li;Jilin Mei;Jiancong Zhou;Yu Hu;Haoyu Li;Jilin Mei;Jiancong Zhou;Yu Hu",
        "authorids": "/37089894783;/37086269220;/37089893996;/37277445400;/37089894783;/37086269220;/37089893996;/37277445400",
        "aff": "UCAS, Hangzhou Institute for Advanced Study, Hangzhou, China; Research Center for Intelligent Computing Systems, Chinese Academy of Sciences, Institute of Computing Technology, Beijing, China; UCAS, Hangzhou Institute for Advanced Study, Hangzhou, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160870/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10853218638999723456&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": "Hangzhou Institute for Advanced Study;Institute of Computing Technology",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.ac.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10161538",
        "title": "iMODE:Real-Time Incremental Monocular Dense Mapping Using Neural Field",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel real-time dense and semantic neural field mapping system that uses only monocular images as input. Our scene representation is a dense continuous radiance field represented by a Multi-Layer Perceptron (MLP), trained from scratch in real-time. We build on high-performance sparse visual SLAM and use camera poses and sparse keypoint depths as supervision alongside RGB keyframes. Since no prior training is required, our system flexibly fits to arbitrary scale and structure at runtime, and works even with strong specular reflections. We demonstrate reconstruction over a range of scenes from small indoor to large outdoor spaces. We also show that the method can straightforwardly benefit from additional inputs such as learned depth priors or semantic labels for more precise and advanced mapping.",
        "primary_area": "",
        "author": "Hidenobu Matsuki;Edgar Sucar;Tristan Laidow;Kentaro Wada;Raluca Scona;Andrew J. Davison;Hidenobu Matsuki;Edgar Sucar;Tristan Laidow;Kentaro Wada;Raluca Scona;Andrew J. Davison",
        "authorids": "/37086428834;/37086453728;/37089895525;/37086073523;/37086019206;/37293837200;/37086428834;/37086453728;/37089895525;/37086073523;/37086019206;/37293837200",
        "aff": "Dyson Robotics Laboratory, Imperial College London, United Kingdom; Dyson Robotics Laboratory, Imperial College London, United Kingdom; Dyson Robotics Laboratory, Imperial College London, United Kingdom; Dyson Robotics Laboratory, Imperial College London, United Kingdom; Advanced Technology Division of Ocado Technology; Dyson Robotics Laboratory, Imperial College London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10161538/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11216683171549547192&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Imperial College London;Ocado Technology",
        "aff_unique_dep": "Dyson Robotics Laboratory;Advanced Technology Division",
        "aff_unique_url": "https://www.imperial.ac.uk;https://technology.ocado.com",
        "aff_unique_abbr": "ICL;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "10160514",
        "title": "kollagen: A Collaborative SLAM Pose Graph Generator",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the lack of datasets for \u2013 and the issue of reproducibility in \u2013 collaborative SLAM pose graph optimizers by providing a novel pose graph generator. Our pose graph generator, kollagen, is based on a random walk in a planar grid world, similar to the popular M3500 dataset for single agent SLAM. It is simple to use and the user can set several parameters, e.g., the number of agents, the number of nodes, loop closure generation probabilities, and standard deviations of the measurement noise. Furthermore, a qualitative execution time analysis of our pose graph generator showcases the speed of the generator in the tunable parameters. In addition to the pose graph generator, our paper provides two example datasets that researchers can use out-of-the-box to evaluate their algorithms. One of the datasets has 8 agents, each with 3500 nodes, and 67645 constraints in the pose graphs, while the other has 5 agents, each with 10000 nodes, and 76134 constraints. In addition, we show that current state-of-the-art pose graph optimizers are able to process our generated datasets and perform pose graph optimization. The data generator can be found at https://github.com/EricssonResearch/kollagen.",
        "primary_area": "",
        "author": "Roberto C. Sundin;David Umsonst;Roberto C. Sundin;David Umsonst",
        "authorids": "/37089447840;/37086117126;/37089447840;/37086117126",
        "aff": "Ericsson Research, Stockholm, Sweden; Ericsson Research, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160514/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:8bd0Nl57wtcJ:scholar.google.com/&scioq=kollagen:+A+Collaborative+SLAM+Pose+Graph+Generator&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ericsson Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ericsson.com/research",
        "aff_unique_abbr": "Ericsson",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "10160794",
        "title": "nerf2nerf: Pairwise Registration of Neural Radiance Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a technique for pairwise registration of neural fields that extends classical optimization-based local registration (i.e. ICP) to operate on Neural Radiance Fields (NeRF)-neural 3D scene representations trained from collections of calibrated images. NeRF does not decompose illumination and color, so to make registration invariant to illumination, we introduce the concept of a \u201csurface field\u201d - a field distilled from a pre-trained NeRF model that measures the likelihood of a point being on the surface of an object. We then cast nerf2nerf registration as a robust optimization that iteratively seeks a rigid transformation that aligns the surface fields of the two scenes. We evaluate the effectiveness of our technique by introducing a dataset of pre-trained NeRF scenes - our synthetic scenes enable quantitative evaluations and comparisons to classical registration techniques, while our real scenes demonstrate the validity of our technique in real-world scenarios. Additional results available at: https://nerf2nerf.github.io",
        "primary_area": "",
        "author": "Lily Goli;Daniel Rebain;Sara Sabour;Animesh Garg;Andrea Tagliasacchi;Lily Goli;Daniel Rebain;Sara Sabour;Animesh Garg;Andrea Tagliasacchi",
        "authorids": "/37089894071;/37089015711;/37089539170;/37086330576;/37546684700;/37089894071;/37089015711;/37089539170;/37086330576;/37546684700",
        "aff": "Vector Institute; UBC; Google Research; NVIDIA; Google Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/10160794/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4492891789901258767&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;2",
        "aff_unique_norm": "Vector Institute;University of British Columbia;Google;NVIDIA Corporation",
        "aff_unique_dep": ";;Google Research;",
        "aff_unique_url": "https://vectorinstitute.ai/;https://www.ubc.ca;https://research.google;https://www.nvidia.com",
        "aff_unique_abbr": "Vector Institute;UBC;Google Research;NVIDIA",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;1;1;1",
        "aff_country_unique": "Canada;United States"
    }
]